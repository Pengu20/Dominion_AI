 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.8266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -50    0    0   20  -30    0    0    0   -6    0    0
    0    0] 
sum of rewards: -571 

action type: buy - action 0.0
Learning step: -30.0119686126709
desired expected reward: -0.7726020812988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[346.64258]
 [347.1109 ]
 [347.12656]
 [346.64484]
 [350.57956]
 [348.817  ]
 [349.05988]
 [365.29083]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.612548828125
desired expected reward: 358.2850036621094



buy possibilites: [-1] 
expected returns: [[335.75607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -25.427732467651367
desired expected reward: 321.2171325683594






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[338.244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.293517112731934
desired expected reward: 325.4625549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[325.62595]
 [326.10538]
 [326.11957]
 [325.6283 ]
 [327.9293 ]
 [329.6819 ]
 [327.86945]
 [334.58316]
 [329.311  ]
 [328.1206 ]
 [330.87234]
 [344.23627]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.667922019958496
desired expected reward: 329.0782165527344



buy possibilites: [-1] 
expected returns: [[333.30954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -9.730807304382324
desired expected reward: 316.3746032714844






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.53482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.635285377502441
desired expected reward: 322.67425537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[299.99243]
 [300.46878]
 [300.48465]
 [299.99472]
 [303.99655]
 [302.2038 ]
 [302.4508 ]
 [317.44144]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.230001449584961
desired expected reward: 308.8896484375



buy possibilites: [-1] 
expected returns: [[321.18414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -24.47309112548828
desired expected reward: 275.5216064453125






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[319.72482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [6. 3. 3. 0. 1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.548826217651367
desired expected reward: 310.63531494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[309.0641 ]
 [309.48828]
 [309.50156]
 [309.06613]
 [311.0899 ]
 [312.6348 ]
 [311.0379 ]
 [317.03748]
 [312.30374]
 [311.25757]
 [313.681  ]
 [325.7382 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [6. 3. 3. 0. 1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -10.64179515838623
desired expected reward: 309.8196105957031



buy possibilites: [-1] 
expected returns: [[354.5991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [6. 3. 3. 0. 1. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 3.0
Learning step: -8.546599388122559
desired expected reward: 300.9549560546875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.63712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -12.062019348144531
desired expected reward: 342.5370788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.95407]
 [311.3388 ]
 [311.35077]
 [310.95593]
 [314.18176]
 [312.73782]
 [312.93597]
 [325.01135]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -10.813965797424316
desired expected reward: 314.4276123046875



buy possibilites: [-1] 
expected returns: [[330.91617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -11.25208854675293
desired expected reward: 299.70196533203125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [0. 0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [0. 0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [0. 0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.6536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [0. 0. 6. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -10.265524864196777
desired expected reward: 320.650634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[335.5602 ]
 [336.01285]
 [336.02643]
 [335.56238]
 [337.73444]
 [339.39288]
 [337.6806 ]
 [343.81482]
 [339.04282]
 [337.9182 ]
 [340.5175 ]
 [352.27264]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [0. 0. 6. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -11.59262752532959
desired expected reward: 340.864501953125



buy possibilites: [-1] 
expected returns: [[330.98502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [0. 0. 6. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -11.17165470123291
desired expected reward: 298.2046813964844






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.7521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -11.028630256652832
desired expected reward: 319.9563903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[304.207  ]
 [304.60672]
 [304.61533]
 [304.207  ]
 [307.60336]
 [306.08514]
 [306.2903 ]
 [319.00952]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -10.633076667785645
desired expected reward: 308.06121826171875



buy possibilites: [-1] 
expected returns: [[297.72043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -20.0 

action type: buy - action 3.0
Learning step: -9.532057762145996
desired expected reward: 295.0832824707031






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  0.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.48138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  0.  0. 29.  0.  0.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.254251480102539
desired expected reward: 289.4661865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[330.8071 ]
 [331.22092]
 [330.8071 ]
 [332.73642]
 [346.04684]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 11.  0.  0. 29.  0.  0.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.717787742614746
desired expected reward: 332.9164733886719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 11.  0.  0. 29.  0.  0.  3. 10.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3. 0. 6. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 11.  0.  0. 29.  0.  0.  3. 10.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3. 0. 6. 6. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.06906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0. 6. 6. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -11.909926414489746
desired expected reward: 334.1369323730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[271.19736]
 [271.62756]
 [271.6368 ]
 [271.25467]
 [271.19736]
 [273.2814 ]
 [274.8677 ]
 [273.22763]
 [278.04556]
 [279.11942]
 [274.52417]
 [275.9953 ]
 [273.4503 ]
 [274.57788]
 [275.94156]
 [287.24423]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0. 6. 6. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.299928665161133
desired expected reward: 279.2519226074219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [29.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.69614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 3. 29.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.002493858337402
desired expected reward: 278.2417297363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[297.38803]
 [297.71762]
 [297.72296]
 [297.38803]
 [300.20453]
 [298.9486 ]
 [299.11917]
 [310.738  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 3. 29.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.279727935791016
desired expected reward: 299.04107666015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.56055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 3. 29.  0. 11.  0.  3.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.066447257995605
desired expected reward: 301.67156982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[341.75674]
 [342.1865 ]
 [341.75674]
 [343.76105]
 [357.77917]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 3. 29.  0. 11.  0.  3.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.7179594039917
desired expected reward: 346.9688720703125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.  0.  0.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.  0.  0.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 3. 29.  0. 11.  0.  3.  0.  0.  0. 10.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [6. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.7361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -12.305476188659668
desired expected reward: 345.4736633300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[309.59543]
 [310.04593]
 [310.05563]
 [309.59543]
 [311.77646]
 [313.4349 ]
 [311.71912]
 [317.87677]
 [313.07465]
 [311.95157]
 [314.55798]
 [326.4517 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.46648120880127
desired expected reward: 308.79937744140625



buy possibilites: [-1] 
expected returns: [[294.1135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3. 6. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -30.0 

action type: buy - action 8.0
Learning step: -10.468403816223145
desired expected reward: 301.250732421875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [10. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[281.98953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.968295097351074
desired expected reward: 284.14520263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[255.04994]
 [255.4106 ]
 [255.413  ]
 [255.04994]
 [256.81268]
 [258.152  ]
 [256.76636]
 [261.76727]
 [257.85645]
 [256.9496 ]
 [259.05887]
 [268.66504]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -8.969449996948242
desired expected reward: 255.30728149414062



buy possibilites: [-1] 
expected returns: [[250.8105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -10.209260940551758
desired expected reward: 244.84066772460938






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  3.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  3.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  3.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[330.0461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -6.709115028381348
desired expected reward: 244.10137939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[309.3998 ]
 [309.90012]
 [309.9051 ]
 [309.3998 ]
 [313.77664]
 [311.82413]
 [312.08792]
 [328.6403 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 1 6 3 0 0 3 8 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  9.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.013978958129883
desired expected reward: 319.2709655761719



buy possibilites: [-1] 
expected returns: [[281.24756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 11.0
Learning step: -10.060763359069824
desired expected reward: 303.7159118652344






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[357.25018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -7.651769161224365
desired expected reward: 273.5957946777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[333.37524]
 [333.8536 ]
 [333.85922]
 [333.37524]
 [335.7637 ]
 [337.5829 ]
 [335.70587]
 [342.4877 ]
 [337.19437]
 [335.96252]
 [338.81473]
 [351.8699 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.756804466247559
desired expected reward: 344.270263671875



buy possibilites: [-1] 
expected returns: [[315.03134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.  0.  0.  6.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 0 

action type: buy - action 14.0
Learning step: -9.771513938903809
desired expected reward: 327.4228515625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11 14] -> size -> 21 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11 14] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8. 29. 10.  0.  0.  0.  3.  0. 11.  0.  3.  3.  3.  0.  0.  0.  3.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11 14] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[240.93628]
 [228.86296]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  1  6  3  0  0  3  8  0 11 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -12.084029197692871
desired expected reward: 302.94732666015625



action possibilites: [-1] 
expected returns: [[269.96396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 1
Learning step: -5.169266700744629
desired expected reward: 218.69984436035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.32898]
 [261.69324]
 [261.32898]
 [263.0605 ]
 [275.07138]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -7.559460639953613
desired expected reward: 262.4045104980469



buy possibilites: [-1] 
expected returns: [[307.74493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 18 

action type: buy - action 3.0
Learning step: -5.260401248931885
desired expected reward: 256.4328308105469






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.85385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -9.459002494812012
desired expected reward: 298.2859191894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[274.88663]
 [275.30054]
 [275.30328]
 [274.88663]
 [278.45142]
 [276.85953]
 [277.06998]
 [290.5357 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -8.487133026123047
desired expected reward: 277.212646484375



buy possibilites: [-1] 
expected returns: [[253.21957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 8 

action type: buy - action 11.0
Learning step: -7.585132122039795
desired expected reward: 270.8662414550781






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  0.  3.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  0.  3.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[264.573  ]
 [253.74469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14] -> size -> 23 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -7.32101583480835
desired expected reward: 245.8985595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[252.46701]
 [252.82533]
 [252.46701]
 [254.22495]
 [266.4654 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14] -> size -> 23 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -7.914364814758301
desired expected reward: 256.19891357421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 1.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[227.1307 ]
 [215.94318]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  8.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -9.318819046020508
desired expected reward: 257.1465759277344



action possibilites: [-1] 
expected returns: [[231.50581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 14.0
Learning step: -5.5882792472839355
desired expected reward: 210.35491943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[219.61314]
 [220.00705]
 [219.61314]
 [220.00574]
 [219.65623]
 [219.61314]
 [221.56   ]
 [223.02147]
 [221.50519]
 [226.16873]
 [227.32611]
 [222.69984]
 [224.072  ]
 [221.70412]
 [222.75467]
 [224.0172 ]
 [236.15501]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3. 11.  0.  0.  0.  3.  6.  0. 11.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -6.512742042541504
desired expected reward: 224.99307250976562






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  7.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [10.  0.  3.  3.  3.  0. 14.  0.  0. 29.  0.  0.  3.  3.  3.  0.  8.  0.
  0.  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[241.8134 ]
 [230.30513]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -7.505384922027588
desired expected reward: 228.64962768554688



action possibilites: [-1] 
expected returns: [[294.5158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 14.0
Learning step: -4.8393683433532715
desired expected reward: 224.4801025390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[284.2481 ]
 [284.6229 ]
 [284.62073]
 [284.28918]
 [284.2481 ]
 [286.10718]
 [287.50885]
 [286.0535 ]
 [290.3789 ]
 [291.33466]
 [287.19873]
 [288.5184 ]
 [286.24246]
 [287.25235]
 [288.46478]
 [298.62408]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  6.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -8.217865943908691
desired expected reward: 286.2979431152344



buy possibilites: [-1] 
expected returns: [[264.4946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    5.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 4.5 

action type: buy - action 11.0
Learning step: -8.19931697845459
desired expected reward: 279.3096008300781






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 23. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[182.57246]
 [172.73819]
 [171.4503 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  8.] 
cards in discard: [11. 14.  3.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -10.771018028259277
desired expected reward: 253.7235870361328



action possibilites: [-1] 
expected returns: [[187.17433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: -4.418519496917725
desired expected reward: 167.18031311035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[173.6652 ]
 [174.06302]
 [173.6652 ]
 [175.61227]
 [188.69444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: -5.8320231437683105
desired expected reward: 181.34231567382812






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  6. 11.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[199.20702]
 [188.62895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 11.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -6.5527801513671875
desired expected reward: 182.14166259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[183.85817]
 [183.85817]
 [197.54652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  6. 11.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -7.188464641571045
desired expected reward: 192.0185546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[157.47948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 14.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -7.834037780761719
desired expected reward: 189.71246337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[148.3165 ]
 [148.62546]
 [148.6176 ]
 [148.34741]
 [148.3165 ]
 [149.88992]
 [151.10754]
 [149.84096]
 [153.63832]
 [154.48006]
 [150.8417 ]
 [151.99544]
 [150.00276]
 [150.89067]
 [151.94647]
 [160.93515]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 14.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -5.680560111999512
desired expected reward: 146.62892150878906



buy possibilites: [-1] 
expected returns: [[156.69565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14.  3.  0.  0.  0. 10. 11.  0.  0.  3.  8.  3.  0.  3.  6. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 14.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -22.0 

action type: buy - action 29.0
Learning step: -5.298350811004639
desired expected reward: 149.18170166015625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 14.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3
 11  0 10  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[263.38785]
 [251.287  ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -3.547382116317749
desired expected reward: 153.1482696533203



action possibilites: [-1] 
expected returns: [[307.79355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action 14.0
Learning step: -6.085233211517334
desired expected reward: 244.12652587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[287.23993]
 [287.79184]
 [287.786  ]
 [287.23993]
 [290.03854]
 [292.14362]
 [289.95428]
 [297.93103]
 [291.68002]
 [290.24026]
 [293.5833 ]
 [308.96616]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: -9.258471488952637
desired expected reward: 298.5350646972656



buy possibilites: [-1] 
expected returns: [[231.98256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 22 

action type: buy - action 14.0
Learning step: -8.26439380645752
desired expected reward: 283.4156188964844






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14] -> size -> 26 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14] -> size -> 26 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10. 11. 10.  3. 11.  0.  0. 29.  0.  3.  0.  0.  3.  0.  3.  0.  0.  0.
  8.  8.  3. 14.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  0.  0. 11.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14] -> size -> 26 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [11.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[169.66113]
 [161.6333 ]
 [161.6333 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0. 11.] 
cards in discard: [14. 14.  3.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -9.383159637451172
desired expected reward: 222.59939575195312



action possibilites: [-1] 
expected returns: [[181.51852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: gain_card_n - action 0
Learning step: -5.880462169647217
desired expected reward: 153.412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[169.89455]
 [170.2206 ]
 [169.89455]
 [171.51572]
 [182.87148]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: -5.650646686553955
desired expected reward: 175.8678741455078



buy possibilites: [-1] 
expected returns: [[198.7449]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -40.0 

action type: buy - action 0.0
Learning step: -6.022967338562012
desired expected reward: 163.87158203125






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[143.80066]
 [138.83147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [14.  3.  0. 10.  8.] 
adversary cards in discard: [8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -8.248808860778809
desired expected reward: 190.49609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[136.76543]
 [137.0152 ]
 [137.0108 ]
 [136.76543]
 [138.97374]
 [137.98941]
 [138.11623]
 [146.55286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [14.  3.  0. 10.  8.] 
adversary cards in discard: [8. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -5.542362213134766
desired expected reward: 138.25831604003906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [14.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0. 10.  8.] 
cards in discard: [8. 0. 0. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 1. 3.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 10.  8.] 
cards in discard: [8. 0. 0. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 1. 3.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[159.52782]
 [148.4693 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 1. 3.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -5.343034267425537
desired expected reward: 141.20982360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[146.69376]
 [146.9526 ]
 [146.94843]
 [146.69376]
 [148.98715]
 [147.95425]
 [148.08463]
 [158.48952]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 1. 3.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -6.093014717102051
desired expected reward: 153.43478393554688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.
  0.  8.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  7. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.
  0.  8.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.
  0.  8.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [11.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[132.52301]
 [121.93601]
 [120.73597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.
  0.  8.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -6.584021091461182
desired expected reward: 151.90550231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[114.704575]
 [115.042404]
 [114.704575]
 [116.39498 ]
 [128.26395 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [14. 14.  3.  0.  3.  0.  0.  0. 11.  6.  0.  0. 11.  0.  0.  0.  3. 29.
  0.  8.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -5.20684289932251
desired expected reward: 122.69178009033203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[212.40808]
 [202.00357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.  0.  3.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -3.257911443710327
desired expected reward: 125.00601959228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[200.16643]
 [200.45474]
 [200.45082]
 [200.16643]
 [201.63019]
 [202.72917]
 [201.58368]
 [205.7588 ]
 [202.48076]
 [201.73114]
 [203.47882]
 [211.6185 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.  0.  3.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -7.47198486328125
desired expected reward: 203.81155395507812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.  0.  3.
  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.  0.  3.
  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 22. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  0.  3. 14.  3.  0. 10.  8.  8.  3. 29.  0.  0.  0.  0.  3.
  0.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 9 





Player: 0 
cards in hand: [ 3.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[225.55975]
 [212.89172]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: buy - action -1.0
Learning step: -7.625845432281494
desired expected reward: 203.9926300048828



action possibilites: [-1] 
expected returns: [[249.61884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: -5.568967342376709
desired expected reward: 207.13885498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[234.43092]
 [234.43092]
 [247.65765]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 21. 30.  8.  8. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1
Learning step: -8.075723648071289
desired expected reward: 241.54310607910156



buy possibilites: [-1] 
expected returns: [[246.24994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -331.0 

action type: buy - action 6.0
Learning step: -22.730924606323242
desired expected reward: 211.70001220703125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3. 10.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 3.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[147.66142]
 [140.98138]
 [140.21332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3. 10.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [29.  8.  0.  3.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3  3] -> size -> 31 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -12.129347801208496
desired expected reward: 234.12059020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.60855]
 [139.60855]
 [148.35164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3. 10.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [29.  8.  0.  3.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3  3] -> size -> 31 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -7.205601692199707
desired expected reward: 140.45582580566406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [29.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  3.  0.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0
 10  3  0  0  8  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 1.  6. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[122.69591]
 [116.45007]
 [116.61903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 14.  0. 11.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: -7.784753322601318
desired expected reward: 140.56687927246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[114.90621]
 [115.1033 ]
 [115.09822]
 [114.90621]
 [116.61911]
 [115.85478]
 [115.94899]
 [123.26531]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.  0. 11.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 30.  8.  7. 10.  5.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -6.540219306945801
desired expected reward: 116.15568542480469



buy possibilites: [-1] 
expected returns: [[110.43394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.  0. 11.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  8. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -43 

action type: buy - action 11.0
Learning step: -5.496191501617432
desired expected reward: 111.12290954589844






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[78.26821]
 [74.33827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0  0] -> size -> 33 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -6.847894191741943
desired expected reward: 103.58604431152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[72.99963 ]
 [73.19762 ]
 [73.192764]
 [72.99963 ]
 [74.74291 ]
 [73.96511 ]
 [74.06349 ]
 [80.73673 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 0.  0.  8.  0.  0. 10.  6. 11.  3.  0.  3.  3.  3.  0. 11.  3. 10. 11.
  1.  6. 14.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0  0] -> size -> 33 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -5.265248775482178
desired expected reward: 73.00296783447266



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10
  3  0  0  8  3  3  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[201.96094]
 [191.15712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1.0
Learning step: -2.1450703144073486
desired expected reward: 78.59165954589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[179.22415]
 [179.49532]
 [179.22415]
 [180.629  ]
 [191.76302]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  6. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -7.995253086090088
desired expected reward: 183.52883911132812



buy possibilites: [-1] 
expected returns: [[202.1688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -43 

action type: buy - action 8.0
Learning step: -6.6326518058776855
desired expected reward: 173.996337890625






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[151.46841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10] -> size -> 32 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: -9.25040054321289
desired expected reward: 192.91839599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[142.29076]
 [142.52116]
 [142.51357]
 [142.29076]
 [143.46086]
 [144.3351 ]
 [143.42331]
 [146.7678 ]
 [144.13803]
 [143.53712]
 [144.93599]
 [151.7173 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10] -> size -> 32 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -6.849800109863281
desired expected reward: 144.61862182617188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.  0.  0.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 14.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.  0.  0.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 20. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 14.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  8. 29.  3.  0.  0.  0. 11.  3. 10.  8. 10.
  0.  8.  0. 10.  0.  0.  0. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 14.  0.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [10. 10. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
expected returns: [[136.8948 ]
 [127.87325]
 [127.87325]
 [128.53847]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 14.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: -7.680784702301025
desired expected reward: 144.03651428222656



action possibilites: [-1. 10. 14.] 
expected returns: [[182.11394]
 [172.67963]
 [173.40273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -40 

action type: take_action - action 10.0
Learning step: -4.410705089569092
desired expected reward: 123.4625473022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[162.7131 ]
 [162.98999]
 [162.97903]
 [162.7131 ]
 [165.1686 ]
 [164.07646]
 [164.21167]
 [174.27667]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 29. 30. 19. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -7.412308692932129
desired expected reward: 174.70162963867188



buy possibilites: [-1] 
expected returns: [[132.78389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  0.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -28.0 

action type: buy - action 3.0
Learning step: -6.561314582824707
desired expected reward: 156.417724609375






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  6.  3.  8.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  6.  3.  8.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  6.  3.  8.  3.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [29.  6.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[102.74404 ]
 [ 97.60374 ]
 [ 93.885216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  8.  3.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 14.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -6.915871620178223
desired expected reward: 125.8680191040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.19367 ]
 [ 93.19367 ]
 [103.310356]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  8.  3.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 14.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -5.440512180328369
desired expected reward: 97.30353546142578



buy possibilites: [-1] 
expected returns: [[153.0028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  8.  3.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 14.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: buy - action 0.0
Learning step: -5.21712064743042
desired expected reward: 87.97655487060547






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 14.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  1. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 14.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  5. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  1. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 14.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  1. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 10 





Player: 0 
cards in hand: [ 3. 11.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[111.20815]
 [102.4655 ]
 [102.4655 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  1. 11.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8. 11. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -7.758393287658691
desired expected reward: 145.24441528320312



action possibilites: [-1] 
expected returns: [[70.96772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 11. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -14 

action type: gain_card_n - action 10
Learning step: -4.178658962249756
desired expected reward: 97.32999420166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.397167]
 [60.612675]
 [60.604244]
 [60.397167]
 [62.327774]
 [61.456635]
 [61.561848]
 [69.60454 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 11.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 11. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -3.6240947246551514
desired expected reward: 67.3436279296875






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 10.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0
  8  3  3  0  0  0  0 10  3  0  8 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 18. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 11. 11.] 
adversary cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [ 0.  0.  6. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[85.145775]
 [76.7042  ]
 [76.7042  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11. 11.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10  3] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1.0
Learning step: -4.671079635620117
desired expected reward: 64.9334487915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[65.46832]
 [65.6285 ]
 [65.46832]
 [66.31846]
 [73.52331]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11. 11.] 
cards in discard: [ 8.  3.  3.  0.  0. 14.  0.  0.  3.  0.  0.  3. 10. 10. 14.  0.  0.  0.
  0. 29.  6.  3.  8.  3. 15. 11.  3.  0.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10  3] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: take_action - action -1.0
Learning step: -5.176311016082764
desired expected reward: 69.06998443603516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8
  3  3  0  0  0  0 10  3  0  8 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  4. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
adversary victory points: 5
player victory points: 11 





Player: 0 
cards in hand: [ 3.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[99.94073]
 [91.8249 ]
 [91.8249 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -60 

action type: buy - action -1.0
Learning step: -4.530017375946045
desired expected reward: 68.9932861328125



action possibilites: [-1] 
expected returns: [[203.23506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0  -1   0   0   9   0] 
sum of rewards: -32 

action type: gain_card_n - action 9
Learning step: -1.6114434003829956
desired expected reward: 90.07318878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.51884]
 [192.80553]
 [192.51884]
 [194.02963]
 [205.41022]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 17. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action -1
Learning step: -7.7286224365234375
desired expected reward: 195.50643920898438



buy possibilites: [-1] 
expected returns: [[139.6514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  20   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -23 

action type: buy - action 3.0
Learning step: -7.648120403289795
desired expected reward: 185.15740966796875






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3] -> size -> 37 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3] -> size -> 37 
adversary victory points: 6
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[156.75931]
 [147.28568]
 [151.25526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.  3.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -6.0000834465026855
desired expected reward: 133.6513214111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.37224]
 [147.64038]
 [147.62866]
 [147.37224]
 [149.79749]
 [148.71689]
 [148.8519 ]
 [158.20322]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.  3.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -6.894287109375
desired expected reward: 149.86500549316406



buy possibilites: [-1] 
expected returns: [[85.656166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.  3.  0.  3.  3.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6. -50.   0.   0.   0.   0.   0.   0.   0.  -3.   0.   0.
   2.   0.] 
sum of rewards: -50.0 

action type: buy - action 8.0
Learning step: -8.008581161499023
desired expected reward: 140.70831298828125






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 11.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.  3.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3  8] -> size -> 38 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 11.  0.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.  8.  3.  0. 29. 14.  0. 10.  3. 10. 11.  8.  0.
  0.  8.  8.  3.  0.  0.  3.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3  8] -> size -> 38 
adversary victory points: 6
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[77.63019 ]
 [73.758766]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10
 29 14  0  0 10  6 11  8  3  0 15 10  3  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -5.022806644439697
desired expected reward: 80.63336181640625



action possibilites: [-1] 
expected returns: [[73.311844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.424983263015747
desired expected reward: 69.06501770019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.7568 ]
 [63.7568 ]
 [71.15855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1
Learning step: -3.608023166656494
desired expected reward: 69.70381927490234






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [10.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
adversary victory points: 6
player victory points: 11 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 16. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
adversary victory points: 6
player victory points: 12 





Player: 0 
cards in hand: [3. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[62.252224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8  3] -> size -> 37 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -5.107252597808838
desired expected reward: 66.0512924194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.22987 ]
 [53.47405 ]
 [53.46189 ]
 [53.22987 ]
 [55.39243 ]
 [54.429016]
 [54.54435 ]
 [62.888035]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8  3] -> size -> 37 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -4.795553207397461
desired expected reward: 57.45667266845703



buy possibilites: [-1] 
expected returns: [[22.57407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8  3] -> size -> 37 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -41 

action type: buy - action 1.0
Learning step: -4.10886812210083
desired expected reward: 49.36518096923828






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10 11  3  0  3  0  8  8  0  0 14  3 11  0 10  3  0  0  8  3
  3  0  0  0  0 10  3  0  8 10  3  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 





Player: 0 
cards in hand: [ 3.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[30.17837 ]
 [23.744875]
 [24.396263]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 11.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -3.4768433570861816
desired expected reward: 19.097227096557617



action possibilites: [-1. 11.] 
expected returns: [[46.210423]
 [42.24894 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -38 

action type: take_action - action 10.0
Learning step: -2.0850398540496826
desired expected reward: 21.659833908081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.03423 ]
 [39.158596]
 [39.15159 ]
 [39.03423 ]
 [40.152897]
 [39.654873]
 [39.714733]
 [44.05225 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 10.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -3.3462376594543457
desired expected reward: 42.86418914794922






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29. 10.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6. 11. 14. 15.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6. 11. 14. 15.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6. 11. 14. 15.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6. 11. 14. 15.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [14.  6. 11. 14. 15.] 
adversary cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
adversary victory points: 6
player victory points: 12 





Player: 0 
cards in hand: [14.  6. 11. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14. 15.] 
expected returns: [[35.644398]
 [30.797802]
 [30.90632 ]
 [30.797802]
 [31.236658]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 11. 14. 15.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  8. 10.  3.  0.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -4.422005653381348
desired expected reward: 39.6302490234375



action possibilites: [-1] 
expected returns: [[42.379684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 14. 15.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action 14.0
Learning step: -2.5363471508026123
desired expected reward: 28.261455535888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.312786]
 [34.514866]
 [34.312786]
 [35.37372 ]
 [42.880314]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 14. 15.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  2. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -3.229259490966797
desired expected reward: 39.15042495727539



buy possibilites: [-1] 
expected returns: [[59.484165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 14. 15.] 
cards in discard: [10.  3. 11.  3.  0.  0. 11.  8.  0.  8.  0. 29.  0.  8.  1.  3.  1.  0.
  3.  3. 10.  3.  0.  0. 11.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
adversary owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
adversary victory points: 12
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -60   0   0  20   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -32 

action type: buy - action 8.0
Learning step: -2.030292510986328
desired expected reward: 33.34343338012695






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 10  3  3  8  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0
  0  0 10  3  0  8 10  3  8  3  0 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 11 





Player: 0 
cards in hand: [ 0.  3. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[148.21558]
 [140.31035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.] 
adversary owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15  0] -> size -> 35 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -2.1642515659332275
desired expected reward: 57.31991195678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.57704]
 [139.57704]
 [148.72606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.] 
adversary owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15  0] -> size -> 35 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -6.630011081695557
desired expected reward: 141.58555603027344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 10  3  3  8  0  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0
 10  3  0  8 10  3  8  3  0 15  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
adversary victory points: 6
player victory points: 10 





Player: 0 
cards in hand: [14.  3.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[69.797714]
 [64.24959 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
adversary owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0  0] -> size -> 34 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1.0
Learning step: -7.868415832519531
desired expected reward: 140.85760498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.920242]
 [63.920242]
 [70.1412  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 15. 30.  8.  7. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
adversary owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0  0] -> size -> 34 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -3.940291166305542
desired expected reward: 65.857421875



buy possibilites: [-1] 
expected returns: [[61.114494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.  6.] 
cards in discard: [ 0.  3. 10.  3.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
adversary owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0  0] -> size -> 34 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.  -50.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -352.0 

action type: buy - action 6.0
Learning step: -19.420934677124023
desired expected reward: 44.499305725097656






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14.  3.] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 10  3  3  8  0 14  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3
  0  8 10  3  8  3  0 15  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  1.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  1.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  1.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 10.  0.  3. 10.  0.  3.  0.  8.  3. 15. 29. 10.  3.  0.  3.  0.  0.
 10.  0.  0.  8.  0.  8. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  1.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [11.  3.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[71.81475]
 [62.00966]
 [60.98665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -3.0702109336853027
desired expected reward: 58.04428482055664



action possibilites: [-1] 
expected returns: [[60.79906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0  -3   0   0   9   0] 
sum of rewards: -4 

action type: gain_card_n - action 9
Learning step: -1.9253689050674438
desired expected reward: 59.941585540771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[49.57524 ]
 [49.81751 ]
 [49.803932]
 [49.57524 ]
 [51.75941 ]
 [50.786648]
 [50.903934]
 [59.448177]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: -2.3537511825561523
desired expected reward: 58.445308685302734



buy possibilites: [-1] 
expected returns: [[61.463566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0  -4   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 1.0
Learning step: -0.5864061713218689
desired expected reward: 42.80031967163086






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [14. 11. 11.  0. 29.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [14. 11. 11.  0. 29.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  1. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [14. 11. 11.  0. 29.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [14. 11. 11.  0. 29.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [14. 11. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11. 29.] 
expected returns: [[20.410519]
 [17.680227]
 [17.751648]
 [17.751648]
 [18.670004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 11.  0. 29.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0  8] -> size -> 32 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -4.151036262512207
desired expected reward: 57.312530517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.357685]
 [17.357685]
 [20.775023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 11.  0. 29.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.] 
adversary owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0  8] -> size -> 32 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -2.0962555408477783
desired expected reward: 18.31426429748535



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8  3 11  0 10  3  0  0  8  3  3  0  0  0  0 10  3  0  8 10  3
  8  3  0 15  0  0  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [8. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[45.901676]
 [41.224514]
 [41.224514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [10. 10.  8.  0.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.] 
adversary owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -1.06504487991333
desired expected reward: 19.709980010986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[39.12547 ]
 [39.247723]
 [39.12547 ]
 [44.460945]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [10. 10.  8.  0.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.] 
adversary owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -2.369954824447632
desired expected reward: 43.531715393066406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [10. 10.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  0.  8.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  8  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15
  0  0  0  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 15. 10.  8.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[27.31373 ]
 [24.2648  ]
 [23.66899 ]
 [23.626408]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.  8.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -2.6576621532440186
desired expected reward: 41.80327606201172



action possibilites: [-1. 15.  8.] 
expected returns: [[21.705164]
 [19.536175]
 [19.10716 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0
 10  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 10.0
Learning step: -0.7251912951469421
desired expected reward: 22.943798065185547



action possibilites: [-1.  8.] 
expected returns: [[62.001568]
 [53.16068 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10
  6 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 20 

action type: take_action - action 15.0
Learning step: 1.3344687223434448
desired expected reward: 20.870641708374023



action possibilites: [-1] 
expected returns: [[30.754677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 40 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.09619636833667755
desired expected reward: 52.011871337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[24.300499]
 [24.448996]
 [24.43852 ]
 [24.300499]
 [25.650812]
 [25.120628]
 [30.447834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: 1.0541542768478394
desired expected reward: 31.80883026123047






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  3.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  8.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  1. 11.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  1. 11.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  1. 11.] 
adversary cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 8.  0.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[19.08742 ]
 [13.742196]
 [14.328284]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  1. 11.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -2.156743288040161
desired expected reward: 28.291088104248047



action possibilites: [-1] 
expected returns: [[21.160303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0  -3   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 9
Learning step: 0.41307583451271057
desired expected reward: 14.67369556427002





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[14.969257 ]
 [15.095019 ]
 [15.086093 ]
 [14.969257 ]
 [16.121717 ]
 [15.6637745]
 [21.1603   ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -0.6768009066581726
desired expected reward: 20.483501434326172



buy possibilites: [-1] 
expected returns: [[35.616425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [ 0.  3. 10.  3.  6.  6. 14.  3.  3.  0.  6. 10.  1. 11.  3.  0. 10.  1.
 14. 11. 11.  0. 29.  8.  0.  0.  8.  3. 10. 15.  8.  3. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0  -4   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 10.0
Learning step: 0.7433663010597229
desired expected reward: 16.407142639160156






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  3. 29.  0.  8.  8. 10.  0. 29. 11.  3.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 10. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 8. 10. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 15.] 
expected returns: [[12.061635]
 [ 8.493985]
 [ 8.538404]
 [ 8.538404]
 [ 9.128536]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 15.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -2.560772657394409
desired expected reward: 33.0556526184082



action possibilites: [-1] 
expected returns: [[28.838577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 15.0
Learning step: 0.1924411803483963
desired expected reward: 9.320977210998535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.009956]
 [24.009956]
 [28.329082]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -0.8590831756591797
desired expected reward: 27.979494094848633



buy possibilites: [-1] 
expected returns: [[39.03852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  3.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20 -30   0   0   0  -5   0   0   0   0] 
sum of rewards: -35 

action type: buy - action 0.0
Learning step: -2.072131395339966
desired expected reward: 21.93782615661621






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  6. 14. 10.  3.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  6. 14. 10.  3.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
adversary victory points: 5
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  6. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[39.220673]
 [35.295776]
 [34.978542]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14. 10.  3.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -2.1210434436798096
desired expected reward: 36.917476654052734



action possibilites: [-1. 14.] 
expected returns: [[25.417484]
 [22.168623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 10.0
Learning step: -1.2078131437301636
desired expected reward: 33.770729064941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.158144]
 [21.158144]
 [25.215254]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0] -> size -> 40 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -0.7547798156738281
desired expected reward: 24.662702560424805



buy possibilites: [-1] 
expected returns: [[27.837955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: -36 

action type: buy - action 0.0
Learning step: -2.231553316116333
desired expected reward: 18.926589965820312






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [29.  0.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  6. 14.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [29.  0.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  6. 14.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [29.  0.  0.  0. 15.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  3.  8.  6. 14.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 8.  3.  8.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[8.199081 ]
 [7.7540116]
 [7.7540116]
 [7.792942 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  6. 14.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 11. 29.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -2.2135589122772217
desired expected reward: 25.62439727783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.2540407]
 [7.2540407]
 [7.7624097]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  6. 14.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  8.  8. 11. 29.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.] 
adversary owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29  0] -> size -> 29 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -1.241721510887146
desired expected reward: 6.957359790802002



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 11. 29.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11 10  3  8  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0
  0  8  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 8.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[12.381556]
 [ 9.413259]
 [ 9.705021]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  0. 11.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  7. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -0.6451879739761353
desired expected reward: 7.117222309112549



action possibilites: [-1] 
expected returns: [[3.9230072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0  -7   0   0  16   0] 
sum of rewards: 19 

action type: gain_card_n - action 7
Learning step: 0.5745081901550293
desired expected reward: 9.849699020385742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[0.9474994]
 [0.9861481]
 [0.9828204]
 [0.9474994]
 [1.1541669]
 [1.3217188]
 [1.8550097]
 [1.2817794]
 [1.1672459]
 [1.4431103]
 [3.0919373]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  6. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: 0.3409789204597473
desired expected reward: 4.263986110687256



buy possibilites: [-1] 
expected returns: [[20.95102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0  -8   0   0  32   0] 
sum of rewards: 34 

action type: buy - action 14.0
Learning step: 2.107309103012085
desired expected reward: 3.3890891075134277






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 15.  1.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14] -> size -> 43 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 15.  1.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14] -> size -> 43 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6. 11. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[14.274004]
 [11.50399 ]
 [11.737199]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 15.  1.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29. 10.  0.  3.  0.  3.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -1.2599034309387207
desired expected reward: 19.691116333007812



action possibilites: [-1] 
expected returns: [[6.9868093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  1.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29. 10.  0.  3.  0.  3.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0  -9   0   0   9   0] 
sum of rewards: 10 

action type: gain_card_n - action 1
Learning step: 0.15824022889137268
desired expected reward: 10.137499809265137





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[4.653245 ]
 [4.698118 ]
 [4.693903 ]
 [4.653245 ]
 [5.065394 ]
 [4.9032626]
 [6.986812 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  1.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29. 10.  0.  3.  0.  3.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: 0.27198728919029236
desired expected reward: 7.258796691894531






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29. 10.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 29.  3. 10.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0. 15.  0.  0. 10.  8.  0.  3.  8. 29. 10.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  3. 29.  3. 10.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  3. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-0.2817121 ]
 [-0.44259495]
 [-0.44259495]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  3. 10.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -0.8577112555503845
desired expected reward: 6.129097938537598



action possibilites: [-1. 10. 11.] 
expected returns: [[-0.34770703]
 [-0.44259495]
 [-0.44259495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: discard_n_cards - action 1
Learning step: 0.5131077170372009
desired expected reward: 0.07051274180412292



action possibilites: [-1] 
expected returns: [[-0.44259498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  40   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 36 

action type: gain_card_n - action 9
Learning step: 1.8121713399887085
desired expected reward: 1.369576334953308





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.44259495]
 [-0.44259495]
 [-0.44259495]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 15. 30.  8.  6. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: 1.5121713876724243
desired expected reward: 1.069576382637024



buy possibilites: [-1] 
expected returns: [[-0.44259498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -20.    0.    0.   40.    0.    0.    0.    0.  -11.
    0. -300.    0.    0.] 
sum of rewards: -292.0 

action type: buy - action 6.0
Learning step: -14.587828636169434
desired expected reward: -15.030423164367676






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.134167]
 [34.11055 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -0.1688927412033081
desired expected reward: -0.6114877462387085



action possibilites: [-1. 11.] 
expected returns: [[45.909363]
 [38.899467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -0.7889772653579712
desired expected reward: 33.321556091308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[36.91237 ]
 [37.13127 ]
 [37.110096]
 [36.91237 ]
 [38.899467]
 [38.1152  ]
 [45.909363]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0. 15.  8. 10. 10.  3.  0. 10.  3.  6. 14.  3.  3.  8.  3.  8.  6. 14.
 14. 14. 11.  8.  1.  0.  0.  1. 11.  0.  6. 15.  1.  1. 15.  6. 29. 11.
  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.4488648176193237
desired expected reward: 44.46049118041992






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  7.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [10.  8.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[24.081715]
 [19.523293]
 [19.465591]
 [20.325924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 10. 15.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -2.864879608154297
desired expected reward: 43.04447555541992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[16.784695]
 [16.899883]
 [16.784695]
 [22.029846]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 10. 15.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -1.8324066400527954
desired expected reward: 22.249303817749023



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 15.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 10.  8.  1.] 
adversary cards in discard: [10.  8.  0. 15.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 15.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 10.  8.  1.] 
adversary cards in discard: [10.  8.  0. 15.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 15.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [15.  3. 10.  8.  1.] 
adversary cards in discard: [10.  8.  0. 15.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [15.  3. 10.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[27.852829]
 [24.9519  ]
 [24.363838]
 [24.320858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  8.  1.] 
cards in discard: [10.  8.  0. 15.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29  0] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -1.571803092956543
desired expected reward: 20.45804214477539





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[24.145046]
 [24.065887]
 [27.934906]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  8.  1.] 
cards in discard: [10.  8.  0. 15.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.] 
adversary owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29  0] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -1.83184015750885
desired expected reward: 25.4082088470459



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  8. 10.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0
 29  0  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 15. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 14. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[52.035206]
 [47.80898 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 14. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.  3.  8.  0.  0. 10.] 
adversary owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -1.315991997718811
desired expected reward: 26.618911743164062





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[47.658466]
 [47.56957 ]
 [52.423405]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 14. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.  3.  8.  0.  0. 10.] 
adversary owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -2.5329861640930176
desired expected reward: 49.502235412597656



buy possibilites: [-1] 
expected returns: [[9.028054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.  3.  8.  0.  0. 10.] 
adversary owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0 -12   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 3.0
Learning step: -2.879791736602783
desired expected reward: 44.77866744995117






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 29.] 
cards in discard: [ 0.  0.  0.  8.  3. 10.  3. 29. 29.  0.  0.  0.  3.  0.  0.  0.  3. 10.
 15.  3.  8.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [14.  3. 10. 11. 11.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 10  3  3  0  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29
  0  0 29  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [14.  3. 10. 11. 11.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [14.  3. 10. 11. 11.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [14.  3. 10. 11. 11.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [14.  3. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11. 11.] 
expected returns: [[6.360945 ]
 [4.5854216]
 [4.490587 ]
 [4.6194296]
 [4.6194296]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10. 11. 11.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  8.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -0.3352969288825989
desired expected reward: 8.692757606506348



action possibilites: [-1] 
expected returns: [[15.164355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10. 11.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  8.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   5   0   0   0  20   0   0   0   0 -13   0   0   9   0] 
sum of rewards: 16 

action type: gain_card_n - action 0
Learning step: 0.9264032244682312
desired expected reward: 5.222297191619873





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 9.991567 ]
 [14.3412485]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10. 11.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 13. 30.  8.  5. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  8.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: 0.5232517719268799
desired expected reward: 15.687606811523438



buy possibilites: [-1] 
expected returns: [[0.47834527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10. 11.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 13. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  8.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    4  -10    0    0   20    0    0    0    0  -14    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -15.73881721496582
desired expected reward: -5.747247695922852






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  0. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 13. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 14.  0. 11.  0.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6] -> size -> 49 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  0. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 30. 13. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 14.  0. 11.  0.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6] -> size -> 49 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 14.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[8.123271 ]
 [6.964774 ]
 [6.9660263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 11.  0.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 13. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -0.4057697355747223
desired expected reward: 0.07257553935050964





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[6.9073687]
 [6.904402 ]
 [8.123271 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 11.  0.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 13. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -0.7887676358222961
desired expected reward: 7.334498405456543



buy possibilites: [-1] 
expected returns: [[19.230444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 11.  0.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [10.  0.  8.  0. 10.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   5   0   0   0   0   0   0   0   0 -15   0   0   8   0] 
sum of rewards: -7 

action type: buy - action 3.0
Learning step: -0.262683629989624
desired expected reward: 6.644687652587891






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [10.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0. 10.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  0  0  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0
 29  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  6. 11.  1. 10.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  6. 11.  1. 10.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  6. 11.  1. 10.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-0.44219753]
 [-0.44219753]
 [-0.4309283 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  1. 10.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
adversary owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -0.9713603854179382
desired expected reward: 18.259082794189453





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[-0.33360684]
 [-0.3093658 ]
 [-0.44219753]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  1. 10.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 12. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
adversary owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: 0.014157086610794067
desired expected reward: -0.428040474653244



buy possibilites: [-1] 
expected returns: [[3.0884962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  1. 10.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
adversary owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  10   0   0   0   0   0   0   0 -16   0   0   8   0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: 0.2361716479063034
desired expected reward: -0.09743846952915192






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  3. 29.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  0 10  3  0  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  6. 15.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3  3] -> size -> 51 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  6. 15.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3  3] -> size -> 51 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  6. 15.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
adversary owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3  3] -> size -> 51 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 1. 14.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[-0.13741028]
 [-0.44219753]
 [-0.44219753]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  6. 15.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6
 11  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1
  6  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: 0.8886333703994751
desired expected reward: 3.9771294593811035



action possibilites: [-1] 
expected returns: [[24.528997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  6.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action 15.0
Learning step: 2.6240041255950928
desired expected reward: 2.1819682121276855





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.14944 ]
 [22.141836]
 [22.096199]
 [22.09445 ]
 [22.4031  ]
 [22.629704]
 [23.130337]
 [23.289764]
 [22.582064]
 [22.795872]
 [22.422634]
 [22.58879 ]
 [22.789143]
 [24.529   ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  6.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 11. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1
Learning step: 1.3405836820602417
desired expected reward: 25.86958122253418



buy possibilites: [-1] 
expected returns: [[37.01687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  6.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  30.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   2.   0.] 
sum of rewards: 38.0 

action type: buy - action 3.0
Learning step: 1.6257883310317993
desired expected reward: 23.767614364624023






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  0.  0.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3.  6. 29.  0.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  0.  0.] 
cards in discard: [ 3.  0. 29.  8.  3.  0.  3.  0.  0.  8. 10.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3.  6. 29.  0.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  3.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[48.771946]
 [44.50568 ]
 [46.2747  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 29.  0.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: 0.8038074374198914
desired expected reward: 37.820674896240234





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[43.945908]
 [48.771946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 29.  0.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: 0.21304951608181
desired expected reward: 48.985008239746094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8 10  3  8  3  0 15  0  0  0  8  0 29  0  0 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[54.28766 ]
 [50.032867]
 [50.35337 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3. 14.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: 0.3311527371406555
desired expected reward: 49.103111267089844



action possibilites: [-1] 
expected returns: [[1.585488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 8. 29. 29.  3.] 
adversary owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action 14.0
Learning step: 0.1180051788687706
desired expected reward: 50.471370697021484





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.02980246]
 [-0.0346489 ]
 [-0.06690499]
 [-0.0680261 ]
 [ 0.13388564]
 [ 0.2882809 ]
 [ 0.62042737]
 [ 0.7259518 ]
 [ 0.25236583]
 [ 0.39728993]
 [ 0.14684136]
 [ 0.25585043]
 [ 0.39380568]
 [ 1.5854887 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.  8.  0. 15.  0. 15.  3. 10.  8.  1.  3.  0.  8.  3.  0.  3.  1.  6.
 11. 14.  3. 10. 11.  3.  3. 14.  0. 11.  0.  3.  3.  6. 11.  1. 10.  3.
 15.  1. 14.  6.  8.  3.  6. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 8. 29. 29.  3.] 
adversary owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1
Learning step: 2.5325844287872314
desired expected reward: 4.118072509765625






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 29. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  1. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 29. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  1. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
adversary victory points: 7
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-0.44203597]
 [-0.44203597]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  6.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 8. 29. 29.  3.  0.  3.  0.] 
adversary owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: 1.510779857635498
desired expected reward: 3.0962677001953125



Player 0 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 3 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 0 
Workshop: 4 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 3 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 3. 1. 6.] 
cards in discard: [10.] 
cards in deck: 46 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3  1  6  3  0  0  3  8  0 11 14  3 11 11 10 29 14  0  0 10  6 11
  8  3  0 15 10  3  8  1  8  6 10  1 15 10  0  0 14 14  1 15  6  3  1  6
  3  3  3 10] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 10. 30.  8.  4. 10.  4.  0. 10.  6.  5. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  3. 15.  0.  8.] 
adversary cards in discard: [ 8. 29. 29.  3.  0.  3.  0.] 
adversary owned cards: [29 10  3  8 10  3  8  3 15  0  8  0 29  0  0 29  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5 500   7  30   0   0  20   0   0   0   0 -17   0   0   9   0] 
sum of rewards: 544 

action type: gain_card_n - action 7
Learning step: 27.22210121154785
desired expected reward: 26.780065536499023



