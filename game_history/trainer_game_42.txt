 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.22015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5  500    6   20    0    1    0    0    0    0    0  -21    0 -300
    0    0] 
sum of rewards: 201 

action type: buy - action 6.0
Learning step: 8.200851440429688
desired expected reward: 45.18382263183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.21866]
 [301.44708]
 [299.83536]
 [279.6237 ]
 [310.98718]
 [302.37665]
 [300.9349 ]
 [318.4838 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.10415267944336
desired expected reward: 310.849853515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.59256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.727108955383301
desired expected reward: 310.7566833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[337.91928]
 [345.7238 ]
 [343.8559 ]
 [327.40372]
 [341.07913]
 [353.4429 ]
 [346.66412]
 [351.268  ]
 [336.99075]
 [344.90845]
 [345.5252 ]
 [358.8365 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.60367488861084
desired expected reward: 358.15545654296875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.09607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.940561294555664
desired expected reward: 348.8959045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[333.7438 ]
 [342.81308]
 [341.10168]
 [323.1406 ]
 [337.4965 ]
 [352.34155]
 [343.76965]
 [349.63498]
 [332.82562]
 [342.22025]
 [343.1403 ]
 [359.43558]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.186720848083496
desired expected reward: 349.8693542480469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 0 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[406.0309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  8 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.88930606842041
desired expected reward: 350.5462951660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[378.66873]
 [386.1109 ]
 [384.4331 ]
 [368.68863]
 [393.87015]
 [387.00546]
 [385.45248]
 [401.93616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  8 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -11.618927001953125
desired expected reward: 396.49102783203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  8 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  8 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[351.31064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -12.228190422058105
desired expected reward: 389.7080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[327.8203 ]
 [336.58243]
 [335.0556 ]
 [315.82224]
 [345.95435]
 [337.4782 ]
 [336.11667]
 [353.318  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.026395797729492
desired expected reward: 344.13446044921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[374.81375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.259657859802246
desired expected reward: 344.0583801269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[346.27234]
 [353.81555]
 [352.144  ]
 [336.17065]
 [349.34616]
 [361.45724]
 [354.69656]
 [359.29813]
 [345.4839 ]
 [353.1434 ]
 [353.79773]
 [366.97418]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.884308815002441
desired expected reward: 367.17095947265625



buy possibilites: [-1] 
expected returns: [[373.04074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -9.172362327575684
desired expected reward: 344.6432189941406






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.00668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [8. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.992733001708984
desired expected reward: 362.0480041503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[322.8196 ]
 [331.13773]
 [329.63336]
 [311.82986]
 [340.04288]
 [332.0218 ]
 [330.67834]
 [347.033  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [8. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.693766593933105
desired expected reward: 335.1642150878906



buy possibilites: [-1] 
expected returns: [[329.84607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  0.] 
adversary cards in discard: [8. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -9.17955493927002
desired expected reward: 322.8422546386719






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.  0.] 
cards in discard: [8. 3. 0. 3. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0  8 10  8  8] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0 10  8  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0 10  8  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0 10  8  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.70538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 10  8  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.479994773864746
desired expected reward: 321.3660888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[296.37936]
 [305.73648]
 [304.1261 ]
 [287.6695 ]
 [284.10602]
 [300.27856]
 [315.88586]
 [306.6804 ]
 [322.63968]
 [312.94794]
 [295.73392]
 [299.83228]
 [305.2466 ]
 [289.32486]
 [306.24133]
 [324.00305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 10  8  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.724591255187988
desired expected reward: 315.5963439941406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 10  8  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 10  8  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 10  8  8  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[310.61737]
 [294.36966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 10  8  8  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.88753890991211
desired expected reward: 315.1155090332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[280.92413]
 [289.43604]
 [287.83008]
 [269.8019 ]
 [284.4507 ]
 [298.3598 ]
 [290.32626]
 [295.79373]
 [280.2215 ]
 [288.87375]
 [289.70758]
 [305.186  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 10  8  8  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.438661575317383
desired expected reward: 302.40966796875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 10  8  8  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.20114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [0. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -7.654256343841553
desired expected reward: 297.53173828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[297.88345]
 [305.02435]
 [303.38626]
 [288.54388]
 [300.61703]
 [314.1582 ]
 [305.94943]
 [311.56317]
 [296.95407]
 [304.46765]
 [305.34543]
 [321.17   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [0. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.545914649963379
desired expected reward: 311.67822265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [8. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [8. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 10  8  0  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [8. 3. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 10  8  0  8  1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.94913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  8  0  8  1] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.695305824279785
desired expected reward: 312.47467041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[283.32324]
 [292.1049 ]
 [290.3924 ]
 [275.26788]
 [271.90125]
 [286.94214]
 [301.32803]
 [293.048  ]
 [307.80838]
 [298.67987]
 [282.55942]
 [286.23914]
 [291.4891 ]
 [276.55148]
 [292.3513 ]
 [308.26492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  8  0  8  1] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.316246032714844
desired expected reward: 301.15899658203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 10  8  0  8  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 10  0  8  1] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 10  0  8  1] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[308.3703 ]
 [293.59515]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0. 0. 1. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.119020462036133
desired expected reward: 300.1458740234375



action possibilites: [-1] 
expected returns: [[317.5424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 1. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 1 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.254737377166748
desired expected reward: 289.7341003417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[288.7839 ]
 [295.7479 ]
 [278.36533]
 [298.22092]
 [313.30032]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 1. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 1 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -7.606719493865967
desired expected reward: 309.9356689453125



buy possibilites: [-1] 
expected returns: [[278.27676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 1. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -21.807039260864258
desired expected reward: 256.55828857421875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 10  0  8  1  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 0 0 8 8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 0 0 8 8] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 0 0 8 8 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[262.62473]
 [248.14447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 0 0 8 8 0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -7.7214035987854
desired expected reward: 270.55535888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[240.59601]
 [246.65834]
 [232.34758]
 [248.91951]
 [263.39975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 0 0 8 8 0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -7.028192043304443
desired expected reward: 255.76055908203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 0 0 8 8 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.09537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -6.456771373748779
desired expected reward: 256.9429931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[258.21426]
 [266.28888]
 [264.64545]
 [247.59477]
 [261.5294 ]
 [274.65863]
 [267.1846 ]
 [272.2047 ]
 [257.47812]
 [265.6436 ]
 [266.3633 ]
 [280.9107 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 1 8 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -7.622311592102051
desired expected reward: 275.18731689453125



buy possibilites: [-1] 
expected returns: [[189.68552]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 39 

action type: buy - action 29.0
Learning step: -6.893954753875732
desired expected reward: 255.3436279296875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[221.79391]
 [204.82124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -3.6726620197296143
desired expected reward: 186.01284790039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[194.07646]
 [201.98262]
 [200.24176]
 [183.57135]
 [211.00063]
 [202.86684]
 [201.24463]
 [219.45865]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  9. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.596248149871826
desired expected reward: 218.65625



buy possibilites: [-1] 
expected returns: [[238.6572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -294.0 

action type: buy - action 6.0
Learning step: -18.508779525756836
desired expected reward: 165.0625762939453






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[197.0871 ]
 [191.45032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [6. 0. 8. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -7.16695499420166
desired expected reward: 231.490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[181.73764]
 [173.2926 ]
 [197.91956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [6. 0. 8. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.363974571228027
desired expected reward: 194.33717346191406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[215.33496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -4.689294815063477
desired expected reward: 193.2302703857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[186.71092]
 [193.77756]
 [192.24986]
 [177.30313]
 [189.61624]
 [201.8702 ]
 [194.57693]
 [199.50801]
 [185.94171]
 [193.18965]
 [193.90865]
 [207.98837]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -6.069047451019287
desired expected reward: 212.00579833984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [0. 3. 6. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [0. 3. 6. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  6.  0. 29.] 
adversary cards in discard: [0. 3. 6. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[213.73553]
 [208.12723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 29.] 
cards in discard: [0. 3. 6. 1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.288233280181885
desired expected reward: 202.7001190185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[200.4333 ]
 [205.18515]
 [191.99664]
 [207.43372]
 [216.74927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  0. 29.] 
cards in discard: [0. 3. 6. 1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.6955060958862305
desired expected reward: 209.3452911376953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[214.71689]
 [201.57658]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8  6 29  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.706214427947998
desired expected reward: 211.04306030273438



action possibilites: [-1] 
expected returns: [[219.1189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.875880479812622
desired expected reward: 190.24522399902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[200.96991]
 [206.42784]
 [192.0452 ]
 [208.41937]
 [220.7349 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -4.2852349281311035
desired expected reward: 214.8336639404297






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  1.  3.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  1.  3.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  1.  3.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[279.3811 ]
 [273.86072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  1.  3.] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.954693555831909
desired expected reward: 216.78016662597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[256.8425 ]
 [263.94763]
 [261.83752]
 [247.23416]
 [270.57883]
 [264.88235]
 [262.84317]
 [274.8588 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  1.  3.] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 30. 30.  8.  8. 10. 10.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -6.995540142059326
desired expected reward: 271.274658203125



buy possibilites: [-1] 
expected returns: [[215.89183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  1.  3.] 
cards in discard: [ 8.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: -6.504481792449951
desired expected reward: 255.73648071289062






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[212.68878]
 [200.63937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -5.140132427215576
desired expected reward: 210.75169372558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[187.75414]
 [195.55647]
 [193.94672]
 [177.58305]
 [203.76703]
 [196.38028]
 [194.894  ]
 [209.60635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.380434989929199
desired expected reward: 210.70166015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  3.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  3.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 11.  3.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[211.09898]
 [201.8198 ]
 [204.31308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  3.  0.] 
cards in discard: [0. 8. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -4.800631523132324
desired expected reward: 204.80569458007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[186.37485]
 [175.67009]
 [211.32828]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  3.  0.] 
cards in discard: [0. 8. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.446901321411133
desired expected reward: 211.66458129882812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[209.38664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -4.942388534545898
desired expected reward: 206.38589477539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[184.99487]
 [191.66293]
 [190.21426]
 [178.10939]
 [175.1448 ]
 [187.7715 ]
 [199.55042]
 [192.43936]
 [205.22693]
 [197.33716]
 [184.2983 ]
 [187.07886]
 [191.08185]
 [179.22572]
 [191.81155]
 [205.81738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.2805962562561035
desired expected reward: 206.8983154296875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[235.82927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [0. 0. 1. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -4.044673442840576
desired expected reward: 201.772705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[216.43614]
 [222.51244]
 [206.66716]
 [225.08553]
 [237.99512]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [0. 0. 1. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.944528102874756
desired expected reward: 233.8863983154297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[223.87408]
 [218.73352]
 [216.83685]
 [212.60457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -5.985838890075684
desired expected reward: 232.00924682617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[204.14279]
 [195.1008 ]
 [222.89424]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.668929576873779
desired expected reward: 221.99855041503906



buy possibilites: [-1] 
expected returns: [[203.85883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -6.270317077636719
desired expected reward: 197.87249755859375






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 3.] 
adversary cards in discard: [ 0.  0.  3. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 3.] 
adversary cards in discard: [ 0.  0.  3. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 3.] 
adversary cards in discard: [ 0.  0.  3. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 3.] 
adversary cards in discard: [ 0.  0.  3. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 1. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[171.9638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 3.] 
cards in discard: [ 0.  0.  3. 11. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -5.437410831451416
desired expected reward: 198.42141723632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[164.38123]
 [170.04353]
 [168.30128]
 [156.63461]
 [175.45067]
 [170.75795]
 [169.05319]
 [178.88702]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 3.] 
cards in discard: [ 0.  0.  3. 11. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  9.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.8981857299804688
desired expected reward: 169.68096923828125



buy possibilites: [-1] 
expected returns: [[137.68488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 3.] 
cards in discard: [ 0.  0.  3. 11. 29.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: -3.9246232509613037
desired expected reward: 171.52603149414062






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11] -> size -> 15 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[195.22104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.6394833326339722
desired expected reward: 136.04539489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[160.58975]
 [166.31561]
 [164.60872]
 [155.2724 ]
 [152.90387]
 [162.86378]
 [171.64851]
 [167.06078]
 [176.13763]
 [170.11101]
 [159.59496]
 [161.49344]
 [165.41078]
 [155.44022]
 [165.69247]
 [175.18787]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 30. 30.  8.  8. 10.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.68400239944458
desired expected reward: 182.97731018066406



buy possibilites: [-1] 
expected returns: [[181.20612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 25.0 

action type: buy - action 16.0
Learning step: -2.8160526752471924
desired expected reward: 160.04774475097656






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[241.73187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [16.  3.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -2.70918345451355
desired expected reward: 178.49693298339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.80644]
 [229.93457]
 [215.60068]
 [232.52628]
 [243.41653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [16.  3.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -6.03535795211792
desired expected reward: 238.45896911621094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11.  0.  8. 11.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11.  0.  8. 11.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11.  0.  8. 11.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11.  0.  8. 11.] 
adversary cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29. 11.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8. 11.] 
expected returns: [[264.5493 ]
 [258.94467]
 [260.60052]
 [255.66644]
 [260.60052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  8. 11.] 
cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -5.419700622558594
desired expected reward: 237.99685668945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[245.78696]
 [236.9894 ]
 [261.68936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  8. 11.] 
cards in discard: [16.  3.  1.  0.  0.  0.  6.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -6.611142158508301
desired expected reward: 257.7431335449219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  0. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[196.48239]
 [191.70993]
 [193.17325]
 [188.48773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 11.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -7.8089447021484375
desired expected reward: 253.8804168701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[183.7285 ]
 [189.85335]
 [188.42   ]
 [175.42793]
 [195.22218]
 [190.53563]
 [189.2354 ]
 [199.1286 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 11.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.687850475311279
desired expected reward: 193.69883728027344



buy possibilites: [-1] 
expected returns: [[174.9458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 11.  8.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -5.900145530700684
desired expected reward: 177.828369140625






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 16.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 16.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 16.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[130.82582 ]
 [127.393974]
 [119.55712 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3. 16.] 
cards in discard: [ 0.  1.  0. 29. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6 11  0 11 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.968746185302734
desired expected reward: 169.97705078125



action possibilites: [-1] 
expected returns: [[137.33853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  1.  0. 29. 11.  8. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 62 

action type: gain_card_n - action 8
Learning step: -0.5160309076309204
desired expected reward: 133.60691833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.465965]
 [104.93215 ]
 [133.62585 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  1.  0. 29. 11.  8. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -2.168494462966919
desired expected reward: 135.1700439453125



buy possibilites: [-1] 
expected returns: [[161.6004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 7.0 

action type: buy - action 0.0
Learning step: -1.687289834022522
desired expected reward: 111.7786865234375






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[107.66105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.7937846183776855
desired expected reward: 156.80662536621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 93.955635]
 [ 99.52358 ]
 [ 98.1784  ]
 [ 86.44234 ]
 [105.06566 ]
 [100.19444 ]
 [ 98.92508 ]
 [108.971085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 0.  1.  0. 29. 11.  8. 25.  0. 16.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.2496979236602783
desired expected reward: 106.82647705078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[209.40842]
 [202.17587]
 [199.7436 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.1374889463186264
desired expected reward: 109.10858154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[187.46936]
 [176.77823]
 [211.40506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.221434116363525
desired expected reward: 207.5479278564453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[115.96784 ]
 [115.644226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [ 3. 11.  6. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -7.071842193603516
desired expected reward: 204.333251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.02727]
 [105.47838]
 [104.05102]
 [ 90.48007]
 [111.98077]
 [106.20134]
 [104.87414]
 [117.2554 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [ 3. 11.  6. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.520416021347046
desired expected reward: 115.2566146850586



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[125.066795]
 [113.512924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 16.  0.] 
cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.2313621044158936
desired expected reward: 115.0240249633789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[106.236374]
 [111.64895 ]
 [110.05483 ]
 [101.10318 ]
 [ 98.831276]
 [108.40208 ]
 [116.50872 ]
 [112.336845]
 [120.823975]
 [115.0635  ]
 [105.2842  ]
 [107.06687 ]
 [110.78957 ]
 [101.34774 ]
 [111.00335 ]
 [119.77029 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 16.  0.] 
cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 28. 30. 30. 30.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.8453876972198486
desired expected reward: 123.28551483154297



buy possibilites: [-1] 
expected returns: [[110.588585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 16.  0.] 
cards in discard: [ 3. 11.  6. 29.  0.  0.  0.  3.  0. 25.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 100 

action type: buy - action 4.0
Learning step: 2.433084487915039
desired expected reward: 103.5362548828125






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[173.36356]
 [158.9074 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 0.8249344229698181
desired expected reward: 111.41352081298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[148.28723]
 [155.64415]
 [154.11482]
 [138.0482 ]
 [151.31526]
 [163.22813]
 [156.44666]
 [161.058  ]
 [147.56055]
 [155.03947]
 [155.71716]
 [169.33904]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -2.5539605617523193
desired expected reward: 171.87469482421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.  0.  3.] 
adversary cards in discard: [0. 1. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.  0.  3.] 
adversary cards in discard: [0. 1. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.  0.  3.] 
adversary cards in discard: [0. 1. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 6. 11. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[215.50899]
 [210.04803]
 [215.17868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 25.  0.  3.] 
cards in discard: [0. 1. 0. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -1.1170936822891235
desired expected reward: 168.22193908691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[195.62366]
 [186.65454]
 [215.49974]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 25.  0.  3.] 
cards in discard: [0. 1. 0. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -3.626340627670288
desired expected reward: 212.72091674804688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[227.0546 ]
 [220.72238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -3.1767914295196533
desired expected reward: 212.32296752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[205.27614]
 [212.39035]
 [210.84451]
 [195.80624]
 [208.20694]
 [219.51566]
 [213.16129]
 [217.41684]
 [204.47618]
 [211.71964]
 [212.27225]
 [223.93234]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -3.985605001449585
desired expected reward: 224.0330047607422



buy possibilites: [-1] 
expected returns: [[206.1557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 0.  1.  0.  8.  3.  6. 11. 25.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.  50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 54.5 

action type: buy - action 10.0
Learning step: -3.2224786281585693
desired expected reward: 208.49716186523438






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  4.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 30. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  4.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 29. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  4.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  4.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[225.32101]
 [203.07614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 29. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -3.3276658058166504
desired expected reward: 202.82803344726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[198.05635]
 [205.42471]
 [186.8425 ]
 [208.00945]
 [223.99693]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 29. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -4.409482002258301
desired expected reward: 220.78521728515625



buy possibilites: [-1] 
expected returns: [[172.66704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 16.  3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 59 

action type: buy - action 3.0
Learning step: -3.4362282752990723
desired expected reward: 201.98849487304688






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  8.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3] -> size -> 21 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 28. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  8.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3] -> size -> 21 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[197.8857 ]
 [188.2577 ]
 [193.0624 ]
 [189.94173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  8.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -1.6674851179122925
desired expected reward: 170.9995574951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.43753]
 [192.24248]
 [178.91391]
 [194.53856]
 [204.73227]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 29.  8.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 28. 29.  8.  8.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -2.918651580810547
desired expected reward: 196.02792358398438



buy possibilites: [-1] 
expected returns: [[169.2434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 29.  8.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -260.0 

action type: buy - action 6.0
Learning step: -18.137720108032227
desired expected reward: 160.7761993408203






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3 1] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[138.40634]
 [134.70613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3 1] -> size -> 6 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -3.3458404541015625
desired expected reward: 165.89755249023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[125.50082]
 [130.61302]
 [129.2115 ]
 [118.6806 ]
 [136.68678]
 [131.28783]
 [129.95953]
 [140.58704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 3 1] -> size -> 6 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -1.9062122106552124
desired expected reward: 137.48719787597656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 3 1] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0 1] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0 1] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 28. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0 1 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  1. 25.] 
adversary cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 6.  0.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[179.88861]
 [178.10466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  1. 25.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 1 3] -> size -> 6 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -1.0023616552352905
desired expected reward: 139.58468627929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.31732]
 [166.95522]
 [165.75781]
 [149.4861 ]
 [176.18498]
 [167.72926]
 [166.6812 ]
 [183.79373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  1. 25.] 
cards in discard: [ 3.  0.  4.  0. 16.  3.  6.  0. 10.  0. 29.  8.  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 1 3] -> size -> 6 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -2.9924488067626953
desired expected reward: 176.2995147705078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 1 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 1] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 1] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  8.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  1 11] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3.  4.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[154.24138]
 [137.31967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  1 11] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -3.2814178466796875
desired expected reward: 180.5122833251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[133.75107 ]
 [142.76796 ]
 [141.03017 ]
 [122.221344]
 [152.1889  ]
 [143.65675 ]
 [142.10385 ]
 [159.43451 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  1 11] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -1.8326736688613892
desired expected reward: 153.20799255371094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  1 11] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  1 11] -> size -> 5 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 11.  0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  1 11  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 4 
card supply: [10. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 0. 16.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[233.77946]
 [216.54025]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [ 3.  4.  1.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  6  0 11 16  0 25  0  4 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 27. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  1 11  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -0.2968330383300781
desired expected reward: 159.13771057128906



action possibilites: [-1] 
expected returns: [[200.97014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  4.  1.  0. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 26. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  1 11  0] -> size -> 6 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 96 

action type: gain_card_n - action 1
Learning step: 0.7891006469726562
desired expected reward: 171.44363403320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[186.13063]
 [190.10985]
 [178.44476]
 [192.48128]
 [200.21835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  4.  1.  0. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 26. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  1 11  0] -> size -> 6 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1
Learning step: -1.0479110479354858
desired expected reward: 199.92222595214844






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  1 11  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 26. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 11  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 26. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 11  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 26. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 11  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[197.08772]
 [193.52429]
 [191.6375 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  0.] 
cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 11  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -2.5845513343811035
desired expected reward: 198.47283935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[185.50114]
 [192.07864]
 [190.113  ]
 [176.75084]
 [198.06319]
 [192.88933]
 [190.972  ]
 [201.57658]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  0.] 
cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 11  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -2.238806962966919
desired expected reward: 193.19114685058594



buy possibilites: [-1] 
expected returns: [[246.38309]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  0.] 
cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 11  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 80 

action type: buy - action 10.0
Learning step: -0.0049804686568677425
desired expected reward: 190.96701049804688






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [11.  3.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 11  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  3.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 11  0  3] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  7.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  3.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  8.  0.] 
cards in discard: [11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 11  0  3 11] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  3.] 
adversary cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[166.22144]
 [165.39798]
 [152.86516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  8.  3.] 
cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10. 11.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 11  0  3 11] -> size -> 6 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1
Learning step: -5.550869941711426
desired expected reward: 240.83221435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.02953]
 [150.11926]
 [134.31514]
 [152.30324]
 [165.84955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  8.  3.] 
cards in discard: [ 3.  4.  1.  0. 10.  3. 16.  0.  0.  3. 10. 11.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 11  0  3 11] -> size -> 6 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -1.5849822759628296
desired expected reward: 163.5370330810547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 11  0  3 11] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[175.96951]
 [167.55151]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -1.262926459312439
desired expected reward: 164.58663940429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[158.39633]
 [149.67065]
 [179.18025]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -1.8544296026229858
desired expected reward: 174.60903930664062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [29.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [29.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [29.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3 11  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [29.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[138.80716 ]
 [128.1171  ]
 [125.222496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [29.  3.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -2.787553548812866
desired expected reward: 176.3927001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[118.54308 ]
 [124.526924]
 [123.18147 ]
 [110.70643 ]
 [130.41293 ]
 [125.17236 ]
 [123.90676 ]
 [134.90106 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [29.  3.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -0.9755577445030212
desired expected reward: 139.10797119140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 25. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3 11  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3 11  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3 11  0  3  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[139.3309]
 [128.6108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0] -> size -> 7 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: -1.0667771100997925
desired expected reward: 133.8343048095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.4335 ]
 [129.86066]
 [118.38438]
 [131.32608]
 [141.16576]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0] -> size -> 7 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1.0
Learning step: -1.2966049909591675
desired expected reward: 137.84255981445312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 25.  1.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 24. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 25.  1.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 25.  1.  0.] 
adversary cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[125.821625]
 [121.4436  ]
 [124.90221 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  1.  0.] 
cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.  3.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -2.1836941242218018
desired expected reward: 138.9820556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[112.51516 ]
 [117.43596 ]
 [116.68029 ]
 [106.1049  ]
 [114.58939 ]
 [122.80559 ]
 [117.900024]
 [121.25139 ]
 [112.229744]
 [117.242546]
 [117.79278 ]
 [127.18361 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 25.  1.  0.] 
cards in discard: [29.  3.  0.  3.  6.  0. 10.  0.  0. 16.  3.  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -1.3413585424423218
desired expected reward: 122.736083984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 4. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 3. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[182.11041]
 [167.93793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 4. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -0.254721462726593
desired expected reward: 126.92887115478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[160.31033]
 [151.0852 ]
 [182.60742]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 4. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -3.019382953643799
desired expected reward: 178.05711364746094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3 11  0  3  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6. 29.  0.  0.] 
adversary cards in discard: [3. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6. 29.  0.  0.] 
adversary cards in discard: [3. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11  0  3] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6. 29.  0.  0.] 
adversary cards in discard: [3. 3. 3. 4. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [10.  6. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[141.5246 ]
 [131.75528]
 [136.2396 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 29.  0.  0.] 
cards in discard: [3. 3. 3. 4. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -2.87516450881958
desired expected reward: 179.7322540283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.69332]
 [130.01219]
 [117.9999 ]
 [132.087  ]
 [140.44089]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 29.  0.  0.] 
cards in discard: [3. 3. 3. 4. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -0.9618064761161804
desired expected reward: 141.29843139648438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  9.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 11  0  3 16] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 11  0  3 16] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[155.2447 ]
 [141.13475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3 16] -> size -> 6 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -0.4712463319301605
desired expected reward: 139.96963500976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[144.8184 ]
 [151.3978 ]
 [149.99759]
 [135.75298]
 [147.59726]
 [157.50085]
 [152.11093]
 [155.77875]
 [144.13365]
 [150.80498]
 [151.31366]
 [161.89044]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3 16] -> size -> 6 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -1.1861984729766846
desired expected reward: 155.1290740966797



buy possibilites: [-1] 
expected returns: [[188.38333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.] 
cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3 16] -> size -> 6 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5.   0.   7.  60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 66.5 

action type: buy - action 10.0
Learning step: 0.02337646484375
desired expected reward: 150.82833862304688






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [11.  0. 16. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16. 11.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11  0  3 16] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0. 25.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  3.] 
cards in discard: [1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 11  0  3 16  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0. 25.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 11.  3.] 
cards in discard: [1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11 11  0  3 16  1] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  1.  0. 25.] 
adversary cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.  0.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [10.  3.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[159.41052]
 [148.16994]
 [158.73013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0. 25.] 
cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.  0.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3 16  1] -> size -> 7 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1
Learning step: -2.8311867713928223
desired expected reward: 185.55213928222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.8298 ]
 [147.62627]
 [146.60779]
 [134.24472]
 [153.72879]
 [148.18303]
 [147.26642]
 [158.507  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0. 25.] 
cards in discard: [ 3.  3.  3.  4.  8. 10.  6. 29.  0.  0. 10.  0.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11  0  3 16  1] -> size -> 7 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -1.279748558998108
desired expected reward: 155.45672607421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [11.  3. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11  0  3 16  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  4.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 16  1] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  4.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 11 16  1] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  4.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 1.  4.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[178.17386]
 [173.9378 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  4.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11 16  1] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: -0.357308954000473
desired expected reward: 158.1497039794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[163.5478 ]
 [169.26878]
 [168.0847 ]
 [155.98099]
 [175.0363 ]
 [169.85753]
 [168.7586 ]
 [179.27237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  4.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 11 16  1] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: -1.3323783874511719
desired expected reward: 175.93927001953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 8. 11. 11.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  1. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 11 16  1] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8. 16.  0. 29.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 16  1] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8. 16.  0. 29.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 16  1] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 23. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8. 16.  0. 29.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 16.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 16  1  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8. 16.  0. 29.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [10.  8. 16.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16. 29.] 
expected returns: [[146.02275]
 [137.0693 ]
 [138.24915]
 [134.64568]
 [141.13387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 16.  0. 29.] 
cards in discard: [ 1.  4.  3.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 16  1  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: -2.647502899169922
desired expected reward: 176.62486267089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[132.97801]
 [126.40818]
 [146.37628]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.  0. 29.] 
cards in discard: [ 1.  4.  3.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 22. 29.  8.  7.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 16  1  3] -> size -> 5 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1.0
Learning step: -1.0032013654708862
desired expected reward: 144.76986694335938



buy possibilites: [-1] 
expected returns: [[200.76016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.  0. 29.] 
cards in discard: [ 1.  4.  3.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  1. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11 16  1  3] -> size -> 5 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    6.   50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -249.0 

action type: buy - action 6.0
Learning step: -14.253305435180664
desired expected reward: 112.15487670898438






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [16.  3.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1. 11.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 16  1  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  6.  3.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  6.  3.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  6.  3.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.] 
cards in discard: [0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  3  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  6.  3.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[116.66285 ]
 [101.843094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  6.  3.] 
cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -5.009726047515869
desired expected reward: 195.7504425048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 98.17295]
 [ 90.89133]
 [116.44578]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  6.  3.] 
cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -0.6249569058418274
desired expected reward: 112.43721771240234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 26. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 11.] 
cards in discard: [1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[149.3573 ]
 [148.29633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1] -> size -> 7 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 0.0469539649784565
desired expected reward: 116.49272918701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.70779 ]
 [134.85812 ]
 [133.6823  ]
 [119.257965]
 [142.69609 ]
 [135.52208 ]
 [134.48195 ]
 [149.06152 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1] -> size -> 7 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.6235374212265015
desired expected reward: 146.12734985351562



buy possibilites: [-1] 
expected returns: [[156.81775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [ 1.  4.  3.  0. 11.  6. 10.  8. 16.  0. 29.  3. 10.  0.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1] -> size -> 7 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 21.0 

action type: buy - action 0.0
Learning step: -1.8108112812042236
desired expected reward: 125.89695739746094






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1. 16.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 16.] 
cards in discard: [14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  1  3  0  0  1 14] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 16.] 
cards in discard: [14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  1  3  0  0  1 14] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 16.] 
cards in discard: [14. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[159.21278]
 [148.00264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -1.8104145526885986
desired expected reward: 155.00733947753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.35016]
 [145.06795]
 [133.15453]
 [146.6164 ]
 [156.92712]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.8959239721298218
desired expected reward: 155.21109008789062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [11.  1. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  3  0  0  1 14 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  0.] 
cards in discard: [23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  3  0  0  1 14 10 23] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[126.06787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1 14 10 23] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[  -5    0    6   50    0    0    0 -210    0    0    0    0    0 -600
  104    0] 
sum of rewards: -655 

action type: discard_down_to_3_cards - action 0
Learning step: -33.94672393798828
desired expected reward: 46.996795654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.561874]
 [104.9722  ]
 [126.82268 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  3  0  0  1 14 10 23] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.050971269607544
desired expected reward: 125.63590240478516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [11. 10.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  3  0  0  1 14 10 23] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  0  1 14 10 23 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  0  1 14 10 23 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[128.02753 ]
 [130.26921 ]
 [119.407196]
 [125.6371  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  6.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  1. 23.  1.  0.] 
adversary cards in discard: [29.  0. 16. 11. 10.  0.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0] -> size -> 11 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -0.3828926086425781
desired expected reward: 126.43978881835938



action possibilites: [-1] 
expected returns: [[133.4011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 16.  4.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  1. 23.  1.  0.] 
adversary cards in discard: [29.  0. 16. 11. 10.  0.  6.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action 25.0
Learning step: 0.49307557940483093
desired expected reward: 131.66204833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.130066]
 [129.08015 ]
 [109.81557 ]
 [130.81694 ]
 [148.96236 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0. 16.  4.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  4.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  1. 23.  1.  0.] 
adversary cards in discard: [29.  0. 16. 11. 10.  0.  6.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 0.5276398062705994
desired expected reward: 133.92872619628906



buy possibilites: [-1] 
expected returns: [[109.896866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0. 16.  4.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  1. 23.  1.  0.] 
adversary cards in discard: [29.  0. 16. 11. 10.  0.  6.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 89 

action type: buy - action 8.0
Learning step: 0.3818321228027344
desired expected reward: 131.1987762451172






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [14.  1. 23.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1. 23.  1.  0.] 
cards in discard: [29.  0. 16. 11. 10.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  6.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8. 25.  0. 10. 11.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 23.  1.  0.] 
cards in discard: [29.  0. 16. 11. 10.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  6.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8. 25.  0. 10. 11.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 23.  1.  0.] 
cards in discard: [29.  0. 16. 11. 10.  0.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  6.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8. 25.  0. 10. 11.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 3.  8. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[58.751625]
 [49.849106]
 [48.506233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  6.  0.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8. 25.  0. 10. 11.  0. 16.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 10.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1
Learning step: -0.7121437191963196
desired expected reward: 109.18472290039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.4733  ]
 [36.31209 ]
 [58.078278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  6.  0.] 
cards in discard: [ 6.  0. 10.  3.  0. 29.  1.  3.  3.  0.  8. 25.  0. 10. 11.  0. 16.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 10.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: 1.866040825843811
desired expected reward: 59.325618743896484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 10.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  6. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  6.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  1. 16.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6.  1. 16.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  9.  5. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6.  1. 16.] 
cards in discard: [23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [4. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[129.25946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 23. 11. 15.] 
adversary cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: 3.5093953609466553
desired expected reward: 61.58768081665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[116.66528 ]
 [120.931046]
 [120.12407 ]
 [112.24786 ]
 [126.615005]
 [121.481636]
 [120.7923  ]
 [131.3554  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 23. 11. 15.] 
adversary cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: 0.04470367357134819
desired expected reward: 127.30290985107422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 23. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 11. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 23. 11. 15.] 
cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [16.  3. 25.  0.  0.] 
adversary cards in discard: [4. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 11. 15.] 
cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 11. 15.] 
cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 22. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 11. 15.] 
cards in discard: [23. 29. 10.  0.  1.  6.  1. 16.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 21. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[144.608  ]
 [133.99348]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10
  6  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 21. 29.  8.  5.  8.  6.  3.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 14.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    6   60    0    0    0 -180    0    0    0    0    0 -300
   96    0] 
sum of rewards: -323 

action type: discard_down_to_3_cards - action 0
Learning step: -12.780384063720703
desired expected reward: -16.966651916503906



action possibilites: [-1] 
expected returns: [[70.445786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 21. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 14.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 85 

action type: gain_card_n - action 3
Learning step: -1.2965065240859985
desired expected reward: 141.334228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.142147]
 [53.528385]
 [71.93736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 21. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [23. 14.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 2.0452866554260254
desired expected reward: 72.49107360839844






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [23. 14.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  0  1 14 10 23 29  0  6 15 23  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 21. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 14.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 14.  3.] 
cards in discard: [3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[103.18364 ]
 [ 96.129456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 23.  0.] 
adversary cards in discard: [ 3.  0. 16. 23. 14.  3.] 
adversary owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 1.248407006263733
desired expected reward: 73.18575286865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.91775 ]
 [100.72395 ]
 [ 98.89385 ]
 [ 89.694   ]
 [104.777794]
 [101.452576]
 [ 99.599945]
 [106.5344  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 23.  0.] 
adversary cards in discard: [ 3.  0. 16. 23. 14.  3.] 
adversary owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -0.2930763363838196
desired expected reward: 103.18132019042969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  6. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 23.  0.] 
cards in discard: [ 3.  0. 16. 23. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  0. 10.] 
cards in discard: [ 3.  0. 16. 23. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  0. 11.] 
cards in discard: [ 3.  0. 16. 23. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0] -> size -> 16 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  8.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0.] 
cards in discard: [ 3.  0. 16. 23. 14.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10. 11.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0.] 
cards in discard: [ 3.  0. 16. 23. 14.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10. 11.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29] -> size -> 17 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 2. 25. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0.] 
cards in discard: [ 3.  0. 16. 23. 14.  3. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10. 11.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0.] 
cards in discard: [ 3.  0. 16. 23. 14.  3. 29.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 10. 11.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 29.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 8.  8.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[214.91344]
 [198.89192]
 [198.89192]
 [204.56328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  3. 29.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 1.9559059143066406
desired expected reward: 108.49029541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[191.24062]
 [182.73936]
 [215.18652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3.  3. 29.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -3.5365302562713623
desired expected reward: 211.3768768310547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 10.  6.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 15. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 16  1  0  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 10.  6.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 10.  6.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 1. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 10.  6.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 7 
card supply: [ 0. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 10.  6.] 
adversary cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 1.  0.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[202.22789]
 [186.9081 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 10.  6.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 3. 14.  6. 16. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -3.733588457107544
desired expected reward: 211.4529266357422





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[174.19203]
 [173.25038]
 [157.45999]
 [182.31827]
 [174.80348]
 [174.00906]
 [189.08463]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 10.  6.] 
cards in discard: [ 4.  0.  3.  0.  0. 25.  0.  8. 16.  3.  0. 10.  3.  0.  0.  8.  8.  3.
  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 3. 14.  6. 16. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -3.4436111450195312
desired expected reward: 198.78427124023438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6. 16. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6. 16. 23.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6. 16.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  3  0 29  1  0  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 20. 29.  8.  5.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 16.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[160.53334]
 [149.83014]
 [155.80194]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: -2.4411728382110596
desired expected reward: 186.64344787597656



action possibilites: [-1. 11.] 
expected returns: [[122.976814]
 [117.62152 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 92 

action type: take_action - action 10.0
Learning step: 0.04232940822839737
desired expected reward: 146.0152130126953



action possibilites: [-1.] 
expected returns: [[144.94798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [11.  0. 29.  0. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 127 

action type: gain_card_n - action 9
Learning step: 3.6945979595184326
desired expected reward: 122.02922821044922





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[145.84485]
 [145.14104]
 [140.5088 ]
 [148.31598]
 [146.17967]
 [145.50348]
 [150.06699]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [11.  0. 29.  0. 23.] 
adversary cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action -1.0
Learning step: 1.639001488685608
desired expected reward: 146.5869903564453






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [11.  0. 29.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 23.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 8. 25.  3.  8.  3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 8. 25.  3.  8.  3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6] -> size -> 19 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  9.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 8. 25.  3.  8.  3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
adversary victory points: 6
player victory points: -1 


buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  1.] 
cards in discard: [ 0. 29. 15.  0.  1. 10.  6. 23. 16. 14.  6.  1. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 8. 25.  3.  8.  3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 8. 25.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
expected returns: [[125.74748 ]
 [113.987236]
 [124.140015]
 [113.987236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  3.  8.  3.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [25. 11. 29. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: -1.23589289188385
desired expected reward: 148.83111572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[102.20633]
 [125.7007 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  3.  8.  3.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [25. 11. 29. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: 0.0910438522696495
desired expected reward: 123.55377960205078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [25. 11. 29. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 23.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29. 23.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  4.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [29.  6. 10.  3.  0.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15] -> size -> 28 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 23.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 20. 29.  8.  3.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [29.  6. 10.  3.  0.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6] -> size -> 29 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 23.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30. 20. 29.  8.  3.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [29.  6. 10.  3.  0.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6] -> size -> 29 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 23.  3.  1.  6.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  3.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [29.  6. 10.  3.  0.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6] -> size -> 29 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [29.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[104.86241 ]
 [101.27942 ]
 [ 98.734924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10.  3.  0.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  3.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  1.  1.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25  3] -> size -> 21 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5    0    5   50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -250 

action type: buy - action -1.0
Learning step: -16.470552444458008
desired expected reward: 109.4998779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 92.255005]
 [105.1001  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  3.  0.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 19. 29.  8.  3.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  1.  1.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25  3] -> size -> 21 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -0.44074249267578125
desired expected reward: 104.42168426513672



buy possibilites: [-1] 
expected returns: [[65.91755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  3.  0.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  1.  1.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6.] 
adversary owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25  3] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -261.0 

action type: buy - action 6.0
Learning step: -16.17960548400879
desired expected reward: 76.0754165649414






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 16.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.  1.  1.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23 29  0  6 15 23  3  0 29  1  0  0  6 25  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  8.  6.  2.  8.  7.  9.  8.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  8.  6.  2.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  8.  6.  2.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  2.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.51624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  2.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [23.  0.  6.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.7267619967460632
desired expected reward: 65.19078826904297





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.53857 ]
 [21.751442]
 [16.604488]
 [15.350175]
 [20.715073]
 [25.472935]
 [22.903137]
 [27.749561]
 [24.661533]
 [19.067806]
 [20.195435]
 [22.155602]
 [16.878105]
 [22.385143]
 [27.515106]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  2.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [23.  0.  6.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.1400892734527588
desired expected reward: 28.656328201293945



buy possibilites: [-1] 
expected returns: [[113.2084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [23.  0.  6.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 41.0 

action type: buy - action 8.0
Learning step: 3.4520325660705566
desired expected reward: 26.355161666870117






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [23.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  0. 10.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  4.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1. 23. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  0. 14.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  4.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  0. 14.] 
cards in discard: [ 3. 25. 11. 29. 23.  3.  1.  6. 14. 16. 16.  0.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  8.  4.] 
adversary cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  3.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[67.84444 ]
 [57.026123]
 [57.9896  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  4.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [25. 16. 14.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -2.2508435249328613
desired expected reward: 110.95755004882812



action possibilites: [-1.  8. 16.] 
expected returns: [[60.43565 ]
 [53.716763]
 [51.51207 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  4. 16.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [25. 16. 14.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action 10.0
Learning step: 1.4078587293624878
desired expected reward: 58.43396759033203





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[46.216354]
 [60.811306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  4. 16.] 
cards in discard: [15. 10. 11.  0.  0.  6.  0.  8. 25.  3.  8.  3.  6.  6. 29.  6. 10.  3.
  0.  8.  1.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [25. 16. 14.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 1.2256017923355103
desired expected reward: 61.6612434387207






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [25. 16. 14.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16. 14.  0. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [15.  4.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 16.  0. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [15.  3.  8.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 16.  0. 15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 24. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [15.  3.  8.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 16.  0. 15.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [15.  3.  8.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[32.753086]
 [30.220924]
 [31.296326]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  8.] 
cards in discard: [4. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8 15  6  6  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [29. 23.  6.  0.  6.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   40    0    0    0 -120    0    0    0    0    0 -600
   71    0] 
sum of rewards: -610 

action type: discard_down_to_3_cards - action 1
Learning step: -29.321094512939453
desired expected reward: -38.44403076171875



action possibilites: [-1] 
expected returns: [[112.09192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [4. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [29. 23.  6.  0.  6.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: trash_cards_n_from_hand - action 1
Learning step: 4.082011699676514
desired expected reward: 31.883136749267578





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 89.8807 ]
 [115.33477]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [4. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [29. 23.  6.  0.  6.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -0.18316422402858734
desired expected reward: 111.90875244140625






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [29. 23.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 23.  6.  0.  6.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  6.  0.] 
adversary cards in discard: [4. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1. 23. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  6. 10.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  6.  0.] 
adversary cards in discard: [4. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 16.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  6.  0.] 
adversary cards in discard: [4. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 16.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1] -> size -> 23 
action values: 1 
buys: 2 
player value: 2 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  1.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  6.  0.] 
adversary cards in discard: [4. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10. 16.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  6.  0.] 
adversary cards in discard: [4. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[72.1617  ]
 [70.009735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  6.  0.] 
cards in discard: [4. 0. 8. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0. 23.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -2.220344305038452
desired expected reward: 113.11444091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[68.938705]
 [74.31593 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  6.  0.] 
cards in discard: [4. 0. 8. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0. 23.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.025786591693758965
desired expected reward: 71.43000793457031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [11.  0.  1.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0. 23.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [25. 10.  8.  0. 10.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0. 23.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  5. 10.  8.] 
adversary cards in hand: [25. 10.  8.  0. 10.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0. 23.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [25. 10.  8.  0. 10.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [25. 10.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8. 10.] 
expected returns: [[10.316704]
 [10.069544]
 [ 6.007648]
 [ 6.327824]
 [ 6.007648]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  8.  0. 10.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 14.  1.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -1.586600661277771
desired expected reward: 73.28858947753906



action possibilites: [-1. 25.  8. 10. 11.] 
expected returns: [[40.271782]
 [39.27071 ]
 [33.81463 ]
 [33.588493]
 [37.17187 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0. 10. 11.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 14.  1.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action 10.0
Learning step: 3.5222442150115967
desired expected reward: 9.529888153076172





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[26.383677]
 [39.686375]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0. 10. 11.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 14.  1.] 
adversary cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 1.7647589445114136
desired expected reward: 42.036537170410156






         -------------------- Turn: 76 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 14.  1.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  7.  8.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [ 1. 14. 25. 16.  0. 15.  0.  8. 29. 23.  6.  6. 10. 16. 10. 11.  0.  1.
  0. 23. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 8.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[34.58611 ]
 [26.660492]
 [26.660492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  3. 11.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   40    0    0    0 -120    0    0    0    0    0 -600
   58    0] 
sum of rewards: -623 

action type: discard_down_to_3_cards - action 1
Learning step: -31.046524047851562
desired expected reward: -18.57854652404785





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[18.457615]
 [35.193172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  3. 11.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.9312757849693298
desired expected reward: 35.51738739013672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 77 -------------------- 
Player: 1 
cards in hand: [16.  3. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11.  6.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  6.  3. 16.  3.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 11.  6.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  6.  3. 16.  3.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  6.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[100.07929]
 [ 85.89439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 16.  3.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23. 29. 14.  0.  1.] 
adversary cards in discard: [16.  3. 11.  6.  6.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 2.37324595451355
desired expected reward: 37.56642150878906





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 78.3426 ]
 [101.61033]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 16.  3.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23. 29. 14.  0.  1.] 
adversary cards in discard: [16.  3. 11.  6.  6.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.880715548992157
desired expected reward: 99.19856262207031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 1 
cards in hand: [23. 29. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 29. 14.  0.  1.] 
cards in discard: [16.  3. 11.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 29.  0.  1.] 
cards in discard: [16.  3. 11.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 29.  0.  1.] 
cards in discard: [16.  3. 11.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  6.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 29.  0.  1.] 
cards in discard: [16.  3. 11.  6.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.323626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29 29] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   40    0    0    0 -120    0    0    0    0    0 -600
   58    0] 
sum of rewards: -623 

action type: discard_down_to_3_cards - action 4
Learning step: -30.304519653320312
desired expected reward: -34.018516540527344





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[26.370478]
 [26.089033]
 [23.270523]
 [25.585445]
 [27.726887]
 [27.332293]
 [24.90838 ]
 [26.261961]
 [26.373306]
 [28.713917]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 4.  0.  8.  3.  3.  3. 10.  6.  0. 10. 25.  8.  0. 10. 11.  0.  0.  6.
  8.  8.  6.  6.  3. 16.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.] 
adversary owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29 29] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.106081485748291
desired expected reward: 30.429706573486328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 79 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1  1 14 10 23  0  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8
 10 29 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  1.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  1.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  1.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[110.27331]
 [ 97.05689]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 25. 29. 10. 16.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 2.9009995460510254
desired expected reward: 31.61492156982422



action possibilites: [-1.] 
expected returns: [[51.12554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 25. 29. 10. 16.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 60 

action type: take_action - action 10.0
Learning step: -0.6352367401123047
desired expected reward: 95.07598876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.23636 ]
 [45.392982]
 [39.34386 ]
 [37.970978]
 [44.09202 ]
 [49.85767 ]
 [52.624504]
 [48.828682]
 [42.245655]
 [43.608433]
 [45.871   ]
 [39.756126]
 [46.160152]
 [52.659393]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 19. 29.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 25. 29. 10. 16.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 1.5073978900909424
desired expected reward: 52.632938385009766



buy possibilites: [-1] 
expected returns: [[137.22134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 25. 29. 10. 16.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 142 

action type: buy - action 4.0
Learning step: 8.22028636932373
desired expected reward: 47.564151763916016






         -------------------- Turn: 80 -------------------- 
Player: 1 
cards in hand: [14. 25. 29. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25. 29. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25. 29. 10. 16.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25. 29. 10. 16.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[172.70322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 1. 15.  0. 23.  1.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3. 14. 25. 29. 10.
 16.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1
Learning step: 0.6247550845146179
desired expected reward: 137.84609985351562





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[157.4897 ]
 [148.39699]
 [169.00078]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 1. 15.  0. 23.  1.] 
adversary cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3. 14. 25. 29. 10.
 16.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: -1.2134026288986206
desired expected reward: 169.02574157714844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 81 -------------------- 
Player: 1 
cards in hand: [ 1. 15.  0. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 23.  1.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3. 14. 25. 29. 10.
 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  0. 25.  3.  3.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 23.  1.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3. 14. 25. 29. 10.
 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  8.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  0. 25.  3.  3.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 23.  1.] 
cards in discard: [16.  3. 11.  6.  6. 29. 14. 23. 29.  0.  1.  8.  0.  3. 14. 25. 29. 10.
 16. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  0. 25.  3.  3.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [29.  0. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[45.89361 ]
 [42.401516]
 [44.97017 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3.  3.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25] -> size -> 26 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: -3.8317267894744873
desired expected reward: 165.16905212402344





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[34.32229 ]
 [44.845604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  3.  3.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  0.  1.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25] -> size -> 26 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 2.2632460594177246
desired expected reward: 48.156856536865234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 1 
cards in hand: [29.  0.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  6. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 11.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  6. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 19. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 11.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  6. 10.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 11.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [ 8.  8.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
expected returns: [[35.970036]
 [26.856138]
 [26.856138]
 [31.095913]
 [26.856138]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 11.  8.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6
  0  8  8  6  6  8  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23.  1. 10.  6. 25.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  7 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: buy - action -1.0
Learning step: 1.6044710874557495
desired expected reward: 46.4500846862793



action possibilites: [-1] 
expected returns: [[66.4844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23.  1. 10.  6. 25.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: trash_cards_n_from_hand - action 4
Learning step: 4.040416240692139
desired expected reward: 24.15008544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[60.706745]
 [69.91176 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23.  1. 10.  6. 25.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 1.7540966272354126
desired expected reward: 68.23849487304688






         -------------------- Turn: 83 -------------------- 
Player: 1 
cards in hand: [23.  1. 10.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 25.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1. 10.  6. 25.] 
cards in discard: [ 3. 29.  0.  1.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 23. 25. 16.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  6. 25. 16.] 
cards in discard: [ 3. 29.  0.  1.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 25. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 25. 16. 29.] 
cards in discard: [ 3. 29.  0.  1.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6 25  3 14 16  1  8 10 29
 29 25  3] -> size -> 27 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  7.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 29.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 23. 16.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 23. 16. 29.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16] -> size -> 27 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 23. 16. 29.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16] -> size -> 27 
action values: 1 
buys: 2 
player value: 2 
card supply: [ 0. 23. 30. 18. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 1 


buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 23. 16. 29.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [16.  6. 10.  6.  8.] 
adversary cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [16.  6. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
expected returns: [[76.774666]
 [65.42054 ]
 [67.791336]
 [68.2701  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 10.  6.  8.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4 10  3  6  3 10 10  6  0  8
  8  6  6  8  4] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [25.  3. 14.  0.  8.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1.0
Learning step: 0.21181602776050568
desired expected reward: 70.12358093261719



action possibilites: [-1] 
expected returns: [[125.95922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [25.  3. 14.  0.  8.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 83 

action type: trash_cards_n_from_hand - action 9
Learning step: 3.682065963745117
desired expected reward: 69.72240447998047





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[105.63842]
 [119.25027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 4. 10.  0.  1.  6.  0.  0.  3.  0.  6.  3.  0. 29.  0. 25.  3.  3.  8.
 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [25.  3. 14.  0.  8.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[-5  0  8 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 83 

action type: take_action - action -1
Learning step: 0.4690731167793274
desired expected reward: 126.42829132080078






         -------------------- Turn: 84 -------------------- 
Player: 1 
cards in hand: [25.  3. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 14.  0.  8.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  2.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  4.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4] -> size -> 26 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  8. 23. 16.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  4.  0. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  8. 23. 16.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 8.  4.  0. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 8.  4.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-3.694129 ]
 [-4.101119 ]
 [-4.0941257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  4.  0. 10.  0.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 14.  1.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11. 25.  3. 14.
  0.  8. 23. 16.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[  -5    0    7   50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -248 

action type: buy - action -1.0
Learning step: -18.44661521911621
desired expected reward: 100.80363464355469





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[-3.8139262]
 [-3.7365384]
 [-3.1513193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  4.  0. 10.  0.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 14.  1.] 
adversary cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11. 25.  3. 14.
  0.  8. 23. 16.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1.0
Learning step: 2.705461263656616
desired expected reward: -0.9026472568511963



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 85 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 14.  1.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11. 25.  3. 14.
  0.  8. 23. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 10. 25.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 14.  1.] 
cards in discard: [ 3. 29.  0.  1.  6. 10. 16.  1.  6.  3. 10. 23. 16. 29. 11. 25.  3. 14.
  0.  8. 23. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 29. 10. 25.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 29. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[9.714579 ]
 [8.8390255]
 [8.162531 ]
 [9.479448 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10. 25.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  3.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: buy - action -1.0
Learning step: 2.969679355621338
desired expected reward: -0.18164324760437012





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 6.73014 ]
 [11.416927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 10. 25.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [29.  3.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1.0
Learning step: 2.348393201828003
desired expected reward: 12.062983512878418



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 86 -------------------- 
Player: 1 
cards in hand: [29.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 17. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  0. 29.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[15.058001]
 [ 6.22737 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 16.  6.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3. 29. 16.  3.  0.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: 1.8250782489776611
desired expected reward: 13.242011070251465





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 1.832027]
 [16.615938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 16.  6.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 3. 29. 16.  3.  0.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: 1.5995936393737793
desired expected reward: 17.64912986755371



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 87 -------------------- 
Player: 1 
cards in hand: [ 3. 29. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 16.  3.  0.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 4.  0. 11.  0.  1.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 16.  3.  0.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 4.  0. 11.  0.  1.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 4.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.192318]
 [37.90495 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0. 11.  0.  1.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 23.  1. 25.  0.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: 2.162423849105835
desired expected reward: 18.77835464477539





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[35.27923 ]
 [35.133606]
 [31.27353 ]
 [34.017174]
 [37.729664]
 [37.12301 ]
 [33.37512 ]
 [35.388767]
 [35.76121 ]
 [40.04225 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0. 11.  0.  1.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [14. 23.  1. 25.  0.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: 0.9473413825035095
desired expected reward: 41.13967514038086



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 88 -------------------- 
Player: 1 
cards in hand: [14. 23.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 23.  1. 25.  0.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.  4.  0.
 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 23.  1. 25.  0.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30. 16. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.  4.  0.
 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 23.  1. 25.  0.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.  4.  0.
 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[15.834038]
 [13.493711]
 [13.493711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.  4.  0.
 11.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 6. 16. 15.  6.  3.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: -0.060999300330877304
desired expected reward: 39.98125457763672





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[14.588829]
 [ 9.703812]
 [18.09711 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [ 6.  8.  4.  0. 10.  0.  0.  3. 29. 10. 25.  3.  0.  3. 16.  6.  4.  0.
 11.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 6. 16. 15.  6.  3.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: 1.176954984664917
desired expected reward: 17.01099395751953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 89 -------------------- 
Player: 1 
cards in hand: [ 6. 16. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 15.  6.  3.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  3  0 29  1  0  0  6  3 14 16  1  8 10 29 29
 25  3 16  3  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  5.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1 14 10 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25
  3 16  3  3  3 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1 14 10 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25
  3 16  3  3  3 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  8.  8.  4. 10.  8.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[46.46058]
 [42.27058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23. 10.  8. 16.  1.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25
  3 16  3  3  3 29] -> size -> 30 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: 2.1989030838012695
desired expected reward: 20.296024322509766





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[41.359364]
 [37.141537]
 [46.514515]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  8.  8.  4. 10.  8.] 
adversary cards in hand: [23. 10.  8. 16.  1.] 
adversary cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6.] 
adversary owned cards: [11 16  1 14 10 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25
  3 16  3  3  3 29] -> size -> 30 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: 0.8248880505561829
desired expected reward: 46.31804275512695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 90 -------------------- 
Player: 1 
cards in hand: [23. 10.  8. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  8. 16.  1.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  1 14 10 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25
  3 16  3  3  3 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  8.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  3. 10. 25.  0.] 
adversary cards in discard: [3. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  1.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  3. 10. 25.  0.] 
adversary cards in discard: [3. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  1.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 15. 28.  8.  1.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  3. 10. 25.  0.] 
adversary cards in discard: [3. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  1.] 
cards in discard: [ 3. 29.  3.  1.  0. 29.  3. 29. 16.  3.  0.  3. 14. 23.  1. 25.  0. 29.
 16.  6. 15.  6. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 28.  8.  1.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [ 6.  3. 10. 25.  0.] 
adversary cards in discard: [3. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 6.  3. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[73.56743]
 [67.18726]
 [73.44835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10. 25.  0.] 
cards in discard: [3. 0. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 28.  8.  1.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [16. 29. 14. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14  3] -> size -> 31 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: 0.9085018038749695
desired expected reward: 47.42301940917969





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[60.619965]
 [74.57095 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10. 25.  0.] 
cards in discard: [3. 0. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 14. 28.  8.  1.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [16. 29. 14. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14  3] -> size -> 31 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: -0.46826860308647156
desired expected reward: 73.09915924072266



Player 0 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 1 
Gold: 0 
Estate: 1 
Duchy: 2 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 2 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  3. 10. 25.  0.] 
cards in discard: [3. 0. 8. 0. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  0 11 16  0 25  0  4  3  3 10 10  0  8  8  6  6
  8  4  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 14. 28.  8.  0.  6.  6.  0.  7.  4.  7.  8.  4. 10.  8.] 
adversary cards in hand: [16. 29. 14. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 16  1 14 23  6 15 23  0 29  1  0  0  6  3 14 16  1  8 10 29 29 25  3
 16  3  3  3 29 14  3] -> size -> 31 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[  -5  500    6   20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: 221 

action type: buy - action 6.0
Learning step: 8.019001960754395
desired expected reward: 68.63897705078125



