 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.24802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -5 -200    0    0   60    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -646 

action type: buy - action 8.0
Learning step: -30.993061065673828
desired expected reward: -57.131866455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[288.56818]
 [298.47998]
 [296.30508]
 [271.14844]
 [306.98053]
 [297.27856]
 [295.40887]
 [312.9427 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.543867111206055
desired expected reward: 303.0093688964844



buy possibilites: [-1] 
expected returns: [[285.23425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -8.94615650177002
desired expected reward: 288.3323669433594






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[295.58408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.66605281829834
desired expected reward: 276.5682067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.02026]
 [281.22   ]
 [278.71057]
 [253.59863]
 [275.17688]
 [290.27896]
 [280.0563 ]
 [283.3062 ]
 [263.8676 ]
 [277.7557 ]
 [275.58426]
 [296.62592]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.710899353027344
desired expected reward: 287.8740234375



buy possibilites: [-1] 
expected returns: [[280.00842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 10 

action type: buy - action 14.0
Learning step: -6.393192291259766
desired expected reward: 257.4744567871094






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[273.01123]
 [257.37344]
 [241.28279]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.773080825805664
desired expected reward: 270.2353515625



action possibilites: [-1] 
expected returns: [[263.2682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 14.0
Learning step: -6.763182163238525
desired expected reward: 234.97113037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[235.49475]
 [246.82983]
 [244.22305]
 [215.20787]
 [240.32121]
 [256.03833]
 [245.49518]
 [249.33224]
 [227.45897]
 [243.21336]
 [240.82059]
 [262.1868 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -8.282710075378418
desired expected reward: 254.9854736328125



buy possibilites: [-1] 
expected returns: [[263.03625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 11.0
Learning step: -7.258599758148193
desired expected reward: 248.77969360351562






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[268.95514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 14.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -9.196089744567871
desired expected reward: 253.8401641845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[249.48792]
 [259.66306]
 [257.37405]
 [231.90434]
 [253.74426]
 [268.0183 ]
 [258.37988]
 [261.70547]
 [242.5077 ]
 [256.35925]
 [254.16672]
 [273.64658]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 14.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -9.778765678405762
desired expected reward: 259.3644714355469



buy possibilites: [-1] 
expected returns: [[174.8286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 14.  3.  8.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -10 

action type: buy - action 29.0
Learning step: -9.651630401611328
desired expected reward: 252.05384826660156






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [29.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[234.16452]
 [225.41231]
 [207.99585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -5.832021236419678
desired expected reward: 168.99658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[212.89575]
 [219.77486]
 [196.28554]
 [221.19916]
 [232.75998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -8.879190444946289
desired expected reward: 224.665771484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[248.78107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  0. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -8.157881736755371
desired expected reward: 224.60214233398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[230.13853]
 [239.23735]
 [237.06975]
 [215.82393]
 [233.79485]
 [246.9695 ]
 [238.11507]
 [241.2443 ]
 [224.25507]
 [236.21312]
 [234.2193 ]
 [251.98836]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  0. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8. 10. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -9.170737266540527
desired expected reward: 238.83457946777344



buy possibilites: [-1] 
expected returns: [[226.14343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  0. 14.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -353.0 

action type: buy - action 6.0
Learning step: -22.554624557495117
desired expected reward: 177.30239868164062






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29  6] -> size -> 15 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 0. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[204.4058 ]
 [199.19385]
 [189.91878]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14 11 29  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -10.023076057434082
desired expected reward: 216.120361328125



action possibilites: [-1] 
expected returns: [[164.00497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: trash_cards_n_from_hand - action 9
Learning step: -9.622637748718262
desired expected reward: 202.6323699951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[136.36824 ]
 [122.336555]
 [155.40936 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -7.767612457275391
desired expected reward: 156.23736572265625



buy possibilites: [-1] 
expected returns: [[220.00026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  0.  3.  0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -6.068405628204346
desired expected reward: 130.29981994628906






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  3.  6.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  3.  6.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  3.  6.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  3. 14.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[226.51294]
 [194.73291]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  6.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -9.945197105407715
desired expected reward: 210.05506896972656



action possibilites: [-1] 
expected returns: [[253.78632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action 14.0
Learning step: -6.713681221008301
desired expected reward: 187.76377868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.10846]
 [239.50458]
 [237.42163]
 [213.62067]
 [247.37212]
 [238.26224]
 [236.46652]
 [252.71121]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  9.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -10.033990859985352
desired expected reward: 243.7523193359375



buy possibilites: [-1] 
expected returns: [[201.517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -36 

action type: buy - action 11.0
Learning step: -9.634474754333496
desired expected reward: 237.7376708984375






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 15.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 11. 14.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[286.7837 ]
 [275.80563]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [ 0.  8.  0. 11. 14.  0.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -7.492777347564697
desired expected reward: 194.0242156982422



action possibilites: [-1.  8.] 
expected returns: [[224.21335]
 [214.18387]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action 29.0
Learning step: -11.399417877197266
desired expected reward: 261.3829345703125



action possibilites: [-1] 
expected returns: [[175.54709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 0
Learning step: -8.044028282165527
desired expected reward: 197.8327178955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[150.8605 ]
 [160.11403]
 [156.9093 ]
 [134.13545]
 [154.54237]
 [166.4966 ]
 [159.17293]
 [161.46138]
 [143.59148]
 [156.16441]
 [153.87633]
 [170.71478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -6.951587200164795
desired expected reward: 168.5955047607422






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 25. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 24. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [ 3.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[189.8424]
 [153.6243]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 14.  0.] 
cards in discard: [29.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 24. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  3.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -8.866604804992676
desired expected reward: 161.84817504882812



action possibilites: [-1] 
expected returns: [[169.64413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 24. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action 14.0
Learning step: -6.538491249084473
desired expected reward: 136.57118225097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[155.71687]
 [163.58716]
 [161.97595]
 [142.43196]
 [158.90207]
 [170.85127]
 [162.42227]
 [165.44641]
 [150.42682]
 [161.09373]
 [159.3574 ]
 [175.70776]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 24. 30.  8.  9. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -8.044159889221191
desired expected reward: 161.5999755859375



buy possibilites: [-1] 
expected returns: [[187.9157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  8.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: -21.64349365234375
desired expected reward: 120.78846740722656






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.] 
cards in discard: [3. 3. 0. 3. 3. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6] -> size -> 14 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [3. 3. 0. 3. 3. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6] -> size -> 14 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [3. 3. 0. 3. 3. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6] -> size -> 14 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[200.62473]
 [191.9034 ]
 [196.57872]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -9.710708618164062
desired expected reward: 178.20498657226562



action possibilites: [-1] 
expected returns: [[145.076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: gain_card_n - action 8
Learning step: -9.173235893249512
desired expected reward: 180.57568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.80855]
 [113.47626]
 [144.24794]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -8.095030784606934
desired expected reward: 136.98097229003906



buy possibilites: [-1] 
expected returns: [[175.62766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.] 
cards in discard: [14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: -7.638806343078613
desired expected reward: 119.16975402832031






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 14.] 
adversary cards in discard: [14.  0. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  8.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 14.] 
adversary cards in discard: [14.  0. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  3.  3.  0.  3.  3.  0.  0. 15.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 14.] 
adversary cards in discard: [14.  0. 11. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 6.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[181.50412]
 [164.25879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 14.] 
cards in discard: [14.  0. 11. 29.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -9.677565574645996
desired expected reward: 165.95008850097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[165.9567 ]
 [170.10085]
 [155.19955]
 [171.94579]
 [179.69453]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 14.] 
cards in discard: [14.  0. 11. 29.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -9.908797264099121
desired expected reward: 169.47061157226562



buy possibilites: [-1] 
expected returns: [[117.7453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 14.] 
cards in discard: [14.  0. 11. 29.  3.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -406.0 

action type: buy - action 6.0
Learning step: -25.410709381103516
desired expected reward: 129.78883361816406






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[164.43718]
 [153.11562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  3.  3.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -7.6062774658203125
desired expected reward: 110.13902282714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[149.97981]
 [156.4466 ]
 [155.05055]
 [138.48921]
 [152.6222 ]
 [162.18628]
 [155.67601]
 [158.06651]
 [145.5387 ]
 [154.51096]
 [153.21399]
 [166.07765]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  3.  3.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -10.038023948669434
desired expected reward: 154.38987731933594



buy possibilites: [-1] 
expected returns: [[172.41425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  3.  3.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.     0.    -1.  -100.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -101.5 

action type: buy - action 1.0
Learning step: -9.0180082321167
desired expected reward: 147.42857360839844






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3.  3.] 
cards in discard: [0. 3. 0. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [14.  6. 14.  6. 29.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [0. 3. 0. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [14.  6. 14.  6. 29.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [0. 3. 0. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [14.  6. 14.  6. 29.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [14.  6. 14.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 29.] 
expected returns: [[198.7404 ]
 [176.27385]
 [176.27385]
 [190.90721]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 14.  6. 29.] 
cards in discard: [1. 0. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -9.826683044433594
desired expected reward: 162.58755493164062



action possibilites: [-1] 
expected returns: [[178.26726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6. 29.] 
cards in discard: [1. 0. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action 14.0
Learning step: -8.590662002563477
desired expected reward: 163.18739318847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[164.80324]
 [169.24483]
 [152.72023]
 [171.65234]
 [179.41237]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6. 29.] 
cards in discard: [1. 0. 0. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  9. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -9.424853324890137
desired expected reward: 168.8424072265625



buy possibilites: [-1] 
expected returns: [[154.89233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6. 29.] 
cards in discard: [1. 0. 0. 0. 8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -78 

action type: buy - action 8.0
Learning step: -8.997540473937988
desired expected reward: 162.65481567382812






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8] -> size -> 19 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8] -> size -> 19 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  3. 15. 11.  3.  3.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8] -> size -> 19 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[140.63828]
 [136.22902]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -10.043680191040039
desired expected reward: 144.84864807128906



action possibilites: [-1] 
expected returns: [[104.78827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -77 

action type: gain_card_n - action 1
Learning step: -7.719356536865234
desired expected reward: 116.82249450683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 94.036224]
 [100.94681 ]
 [ 98.66037 ]
 [ 81.80678 ]
 [105.97542 ]
 [100.262436]
 [ 98.15059 ]
 [108.477234]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  7.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -7.306954860687256
desired expected reward: 97.48131561279297



buy possibilites: [-1] 
expected returns: [[71.85336]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  8.  0.  8. 14.  6. 14.  6. 29.  1. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -68 

action type: buy - action 11.0
Learning step: -7.082070350646973
desired expected reward: 98.89334869384766






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  8. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [1. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.78346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 11.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8] -> size -> 19 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -6.9943671226501465
desired expected reward: 64.85899353027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[61.278996]
 [67.61482 ]
 [66.48781 ]
 [50.4092  ]
 [63.78043 ]
 [74.21097 ]
 [66.70174 ]
 [69.36069 ]
 [57.343227]
 [65.83316 ]
 [64.468   ]
 [79.21277 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 11.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8] -> size -> 19 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -8.022331237792969
desired expected reward: 76.34659576416016



buy possibilites: [-1] 
expected returns: [[78.25665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 11.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8] -> size -> 19 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.     0.    -1.  -100.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -101.5 

action type: buy - action 10.0
Learning step: -6.6058831214904785
desired expected reward: 59.22727584838867






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 11.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  7. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 24. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3. 6. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 0.  0. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[116.431305]
 [113.260254]
 [ 94.102615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [10.  1.  0.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  3.  6.  3. 11.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -6.897049903869629
desired expected reward: 71.35960388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.559906]
 [107.180176]
 [105.08157 ]
 [ 86.08185 ]
 [112.936554]
 [106.210464]
 [104.30498 ]
 [116.27826 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [10.  1.  0.  0.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 23. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  3.  6.  3. 11.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -8.468060493469238
desired expected reward: 102.36689758300781



buy possibilites: [-1] 
expected returns: [[121.48497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  3.  6.  3. 11.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -93.0 

action type: buy - action 3.0
Learning step: -7.170666694641113
desired expected reward: 97.91090393066406






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 8.  3.  0.  0.  3.  3.  6.  3. 11.  0.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  8.  3. 11.  1.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 8.  3.  0.  0.  3.  3.  6.  3. 11.  0.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  8.  3. 11.  1.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3] -> size -> 23 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14.  8.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
expected returns: [[81.89583 ]
 [60.863644]
 [72.14674 ]
 [78.607864]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3. 11.  1.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -9.200118064880371
desired expected reward: 112.28485107421875



action possibilites: [-1] 
expected returns: [[112.36857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  1.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -105 

action type: gain_card_n - action 0
Learning step: -5.678708076477051
desired expected reward: 58.8521614074707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 99.30888]
 [104.27021]
 [ 88.03647]
 [105.18934]
 [116.17179]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  1.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -7.039103984832764
desired expected reward: 105.3294677734375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0.  8.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0.  8.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  6.  0.  8.] 
adversary cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [29.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[87.91816 ]
 [79.374725]
 [78.031685]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  0.  8.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -9.209184646606445
desired expected reward: 106.96260833740234



action possibilites: [-1.  8.] 
expected returns: [[94.21969]
 [82.3884 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: -6.222775459289551
desired expected reward: 73.15193939208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.26215 ]
 [84.149704]
 [82.78505 ]
 [68.216194]
 [89.71763 ]
 [83.35384 ]
 [82.16658 ]
 [93.81802 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -7.080817699432373
desired expected reward: 87.13887023925781



buy possibilites: [-1] 
expected returns: [[169.58434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [10.  1.  0.  0.  6.  3.  3.  0.  0. 11. 14.  0.  0. 11. 14.  8.  3.  1.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -67 

action type: buy - action 1.0
Learning step: -3.741838216781616
desired expected reward: 80.40787506103516






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 14.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8. 29.] 
expected returns: [[72.65306 ]
 [57.703796]
 [64.86486 ]
 [64.86486 ]
 [66.4747  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 29  6  0 11  6 14  0  6  1  8  1 11 10  3  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -12.292104721069336
desired expected reward: 157.292236328125



action possibilites: [-1] 
expected returns: [[108.82163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.2689409255981445
desired expected reward: 64.07960510253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 97.952324]
 [ 86.076775]
 [111.78752 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  6. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -7.4521355628967285
desired expected reward: 101.36949920654297



buy possibilites: [-1] 
expected returns: [[41.267956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -396 

action type: buy - action 6.0
Learning step: -23.175310134887695
desired expected reward: 62.90147399902344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.  3.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [6. 8. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.  3.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [6. 8. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.  3.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [6. 8. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
adversary victory points: -1
player victory points: 10 





Player: 0 
cards in hand: [11.  6.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[69.73303 ]
 [67.091576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  1.  0.] 
cards in discard: [6. 8. 3. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -6.358311653137207
desired expected reward: 34.909645080566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.89647 ]
 [58.77273 ]
 [57.15947 ]
 [42.945152]
 [55.299572]
 [63.273342]
 [58.045395]
 [59.664303]
 [48.454384]
 [56.58587 ]
 [55.104717]
 [65.81802 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  1.  0.] 
cards in discard: [6. 8. 3. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 21. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -7.924021244049072
desired expected reward: 60.1296501159668



buy possibilites: [-1] 
expected returns: [[60.260548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  1.  0.] 
cards in discard: [6. 8. 3. 8. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  3.  3.  0.] 
adversary cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -103.0 

action type: buy - action 3.0
Learning step: -6.652111053466797
desired expected reward: 50.50735855102539






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [11.  3.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  6. 14.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  6. 14.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3.  0.] 
cards in discard: [ 3.  0.  3.  3. 10.  0.  3.  0.  0.  3.  6.  0. 15.  3.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3.  6. 14.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 0.  1.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[56.511005]
 [41.010464]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  6. 14.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -7.1539626121521
desired expected reward: 53.10658645629883



action possibilites: [-1] 
expected returns: [[87.727516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 14.0
Learning step: -4.326653957366943
desired expected reward: 36.68381118774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[70.15874 ]
 [76.21662 ]
 [75.01969 ]
 [62.6831  ]
 [59.534325]
 [72.686455]
 [81.79821 ]
 [75.42074 ]
 [87.024   ]
 [77.53789 ]
 [65.93013 ]
 [69.994194]
 [74.43313 ]
 [62.841236]
 [73.08309 ]
 [86.03208 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 20. 30.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -6.969120979309082
desired expected reward: 80.75839233398438



buy possibilites: [-1] 
expected returns: [[94.630714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: -2 

action type: buy - action 4.0
Learning step: -0.6464805603027344
desired expected reward: 52.86695098876953






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 8. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [11.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[70.463875]
 [68.74155 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -6.7641472816467285
desired expected reward: 87.86656951904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.44974 ]
 [68.05469 ]
 [67.06053 ]
 [58.55298 ]
 [71.044205]
 [67.58314 ]
 [66.697365]
 [72.79352 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: take_action - action -1.0
Learning step: -5.606143951416016
desired expected reward: 64.85772705078125



buy possibilites: [-1] 
expected returns: [[56.38521]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -54 

action type: buy - action 1.0
Learning step: -4.8340678215026855
desired expected reward: 63.22062683105469






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [3. 8. 0. 6. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [3. 8. 0. 6. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [3. 8. 0. 6. 0. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [ 1. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[107.99476]
 [ 97.84691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -4.095719814300537
desired expected reward: 52.28948974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[101.25086 ]
 [108.1749  ]
 [105.9329  ]
 [ 88.53087 ]
 [103.97885 ]
 [113.2657  ]
 [107.433014]
 [109.25919 ]
 [ 95.70352 ]
 [105.37609 ]
 [103.65209 ]
 [115.86649 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: take_action - action -1.0
Learning step: -6.623238563537598
desired expected reward: 101.37153625488281



buy possibilites: [-1] 
expected returns: [[75.73549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  8.  3. 11.  6.  0.  1.  0.  4. 14.  0.  1.  3.  6.  1. 11.
  0.  6.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -40 

action type: buy - action 14.0
Learning step: -5.0811285972595215
desired expected reward: 90.6224136352539






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1 14] -> size -> 28 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1 14] -> size -> 28 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1 14] -> size -> 28 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [3. 3. 0. 8. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[12.981429]
 [ 6.208931]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 4.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6
  3  4  1 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -7.189068794250488
desired expected reward: 68.54641723632812



action possibilites: [-1] 
expected returns: [[58.624653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.3881306648254395
desired expected reward: -2.2444238662719727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.67231 ]
 [37.4865  ]
 [60.720882]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  5. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1
Learning step: -5.518490791320801
desired expected reward: 53.106163024902344



buy possibilites: [-1] 
expected returns: [[-2.861859]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  0.  3.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -385 

action type: buy - action 6.0
Learning step: -21.188716888427734
desired expected reward: 16.297775268554688






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  3.] 
cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [6. 8. 4.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6] -> size -> 26 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.  3.] 
cards in discard: [ 3.  8.  0.  6.  0.  3.  0.  3. 10.  3.  0.  0.  1.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10.  3.  6.] 
adversary cards in discard: [6. 8. 4.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6] -> size -> 26 
adversary victory points: 0
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[32.038998]
 [29.99321 ]
 [25.698437]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  6.] 
cards in discard: [6. 8. 4.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -4.458985805511475
desired expected reward: -7.320844650268555



action possibilites: [-1] 
expected returns: [[34.606873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  6.] 
cards in discard: [6. 8. 4. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: gain_card_n - action 0
Learning step: -6.128847599029541
desired expected reward: 17.021196365356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.709938]
 [21.028278]
 [34.7561  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  6.] 
cards in discard: [6. 8. 4. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -5.350447654724121
desired expected reward: 29.256423950195312



buy possibilites: [-1] 
expected returns: [[13.008436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  6.] 
cards in discard: [6. 8. 4. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -6.5319037437438965
desired expected reward: 14.95997428894043






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 11. 14.  0.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 11. 14.  0.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 11. 14.  0.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 11. 14.  0.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 6. 14. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14.] 
expected returns: [[21.885662]
 [ 8.771942]
 [19.834797]
 [ 8.771942]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 11. 14.  0.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [8. 1. 3. 0. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -5.556161403656006
desired expected reward: 7.452274799346924



action possibilites: [-1] 
expected returns: [[18.624847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 14.  0.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 14.0
Learning step: -4.269538402557373
desired expected reward: 4.502400875091553





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.42178 ]
 [13.662433]
 [12.579732]
 [ 5.963026]
 [16.244497]
 [13.211173]
 [12.215261]
 [17.64317 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 14.  0.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  8. 10.  9.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -4.886978626251221
desired expected reward: 13.737869262695312



buy possibilites: [-1] 
expected returns: [[4.201232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 14.  0.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -67 

action type: buy - action 10.0
Learning step: -3.8662354946136475
desired expected reward: 8.349026679992676






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 1.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [6. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.041252]
 [23.0854  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -4.893087863922119
desired expected reward: -0.6918559074401855





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.198814]
 [20.000458]
 [18.517319]
 [11.782336]
 [17.210253]
 [23.094807]
 [19.478146]
 [20.414515]
 [14.0643  ]
 [18.083914]
 [16.700123]
 [24.360525]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -6.180436134338379
desired expected reward: 20.86081314086914



buy possibilites: [-1] 
expected returns: [[12.586717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 1.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.     0.     0.  -100.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -100.5 

action type: buy - action 10.0
Learning step: -5.645994186401367
desired expected reward: 12.43791389465332






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 1. 6.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 1. 6.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [1. 3. 0. 1. 6.] 
adversary cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [1. 3. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.633648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1. 6.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -5.415078639984131
desired expected reward: 7.171638011932373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[11.994722 ]
 [15.974629 ]
 [15.196546 ]
 [ 7.4898987]
 [ 5.686844 ]
 [13.687266 ]
 [19.111048 ]
 [15.437444 ]
 [21.903448 ]
 [16.569597 ]
 [ 9.269796 ]
 [11.747161 ]
 [14.75879  ]
 [ 7.512271 ]
 [13.723779 ]
 [21.189537 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 6.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 24. 30. 20. 29.  8.  4. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -5.958096981048584
desired expected reward: 14.67555046081543



buy possibilites: [-1] 
expected returns: [[25.714916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 6.] 
cards in discard: [ 6.  8.  4.  0.  0. 11.  0. 10.  3.  6. 10. 14.  6. 11. 14.  0. 10.  6.
  0.  0.  8.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -416.0 

action type: buy - action 6.0
Learning step: -20.505756378173828
desired expected reward: -14.818913459777832






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  6.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
adversary victory points: -1
player victory points: 10 





Player: 0 
cards in hand: [11. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[24.45224 ]
 [23.422636]
 [19.990017]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -6.57393741607666
desired expected reward: 19.140979766845703



action possibilites: [-1. 11. 11.] 
expected returns: [[15.840346]
 [15.147286]
 [15.147286]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: take_action - action 10.0
Learning step: -5.452776908874512
desired expected reward: 14.53724193572998



action possibilites: [-1. 11.] 
expected returns: [[25.01123 ]
 [22.891905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   40    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -67 

action type: gain_card_n - action 9
Learning step: -3.585448980331421
desired expected reward: 11.934399604797363





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.880467]
 [16.96209 ]
 [16.627478]
 [11.247999]
 [15.752568]
 [19.253368]
 [16.667616]
 [17.450972]
 [13.440101]
 [16.417278]
 [15.95844 ]
 [21.929554]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -4.673407554626465
desired expected reward: 20.337825775146484






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6. 14.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 0. 15.  3.  3.  3.  3.  3.  0.  1.  8.  1.  0. 10.  6.  0.  0.  3.  0.
 11.  0.  0. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  6. 14.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
adversary victory points: -1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 14.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[18.15929 ]
 [ 9.937099]
 [ 9.937099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  6. 14.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1.0
Learning step: -6.29511022567749
desired expected reward: 9.481130599975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.181171 ]
 [12.794443 ]
 [12.235954 ]
 [ 5.6777987]
 [15.009352 ]
 [12.415516 ]
 [11.943985 ]
 [16.413174 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  6. 14.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -6.4294023513793945
desired expected reward: 11.729889869689941



buy possibilites: [-1] 
expected returns: [[-6.4065895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  6. 14.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -146.0 

action type: buy - action 0.0
Learning step: -7.953206539154053
desired expected reward: 2.2279629707336426






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 4. 6. 8.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 10 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 4. 6. 8.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 20. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 4. 6. 8.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 4. 6. 8.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [0. 8. 4. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[ 0.9713502]
 [-1.53731  ]
 [-1.53731  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 4. 6. 8.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  4  1
 14  6  0  0 10 10  6 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -126 

action type: buy - action -1
Learning step: -5.992866516113281
desired expected reward: -12.399456024169922



action possibilites: [-1] 
expected returns: [[32.10718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.146998882293701
desired expected reward: -7.758783340454102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.129875]
 [20.4033  ]
 [31.723452]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: take_action - action -1
Learning step: -7.959743022918701
desired expected reward: 24.147438049316406



buy possibilites: [-1] 
expected returns: [[35.720505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -150.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -169.0 

action type: buy - action 0.0
Learning step: -8.95278263092041
desired expected reward: 17.17708969116211






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  9.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 11 





Player: 0 
cards in hand: [6. 0. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-5.228607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  0.  8.  3. 10.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action -1
Learning step: -9.853669166564941
desired expected reward: 25.866836547851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-6.638013 ]
 [-7.7324796]
 [-6.7730026]
 [-4.5326447]
 [-7.575707 ]
 [-7.624095 ]
 [-6.636292 ]
 [-7.123225 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  0.  8.  3. 10.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: take_action - action -1.0
Learning step: -7.838691234588623
desired expected reward: -13.067298889160156



buy possibilites: [-1] 
expected returns: [[12.728697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  0.  8.  3. 10.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -150.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -189.0 

action type: buy - action 0.0
Learning step: -8.831703186035156
desired expected reward: -15.469718933105469






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8.  3. 10.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 11 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 3. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 3. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 3. 0.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 11 





Player: 0 
cards in hand: [6. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.318932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [15.  3.  3.  3.  1.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action -1
Learning step: -8.331759452819824
desired expected reward: 4.396937370300293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 5.8441043]
 [ 8.364841 ]
 [ 7.7502465]
 [ 0.5917878]
 [ 6.8336625]
 [10.657925 ]
 [ 8.010193 ]
 [ 8.732288 ]
 [ 4.193763 ]
 [ 7.4714313]
 [ 6.783195 ]
 [12.113995 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [15.  3.  3.  3.  1.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: take_action - action -1.0
Learning step: -8.34471607208252
desired expected reward: 2.974215507507324



buy possibilites: [-1] 
expected returns: [[15.365976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [15.  3.  3.  3.  1.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5.     0.    -4.  -150.     0.     0.     0.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -154.5 

action type: buy - action 1.0
Learning step: -7.7975077629089355
desired expected reward: 0.5673336982727051






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  3.  1.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  6.  0.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  6.  0.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  7. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  6.  0.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  6. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0. 10.  6.  0.] 
adversary cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
adversary victory points: -4
player victory points: 11 





Player: 0 
cards in hand: [10.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[13.097816 ]
 [10.3762455]
 [10.3762455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  6.  0.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  6. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action -1
Learning step: -8.461625099182129
desired expected reward: 6.904351234436035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 8.663805 ]
 [ 9.390409 ]
 [ 7.0917716]
 [ 9.600134 ]
 [11.811638 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  6.  0.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  6. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: take_action - action -1.0
Learning step: -8.39152717590332
desired expected reward: 4.706295013427734



buy possibilites: [-1] 
expected returns: [[14.350655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  6.  0.] 
cards in discard: [10. 10. 11.  0.  0.  1. 11.  0.  1. 14.  0.  6. 14.  0.  8.  0.  6.  8.
  0.  6.  0.  3.  6.  1.  1.  6.  0.  3.  0.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0   -1    0    0
    8    0] 
sum of rewards: -152 

action type: buy - action 8.0
Learning step: -7.511664867401123
desired expected reward: -2.8205738067626953






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
adversary victory points: -4
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
adversary victory points: -4
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 3. 10.  0. 11. 11.  0.  3. 29.  3.  0.  0.  0.  0. 10. 10.  1.  0.  8.
  3.  0.  8. 15.  3.  3.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
adversary victory points: -4
player victory points: 11 





Player: 0 
cards in hand: [ 0. 10.  3.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-2.481697 ]
 [-4.1142044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action -1
Learning step: -8.740478515625
desired expected reward: 5.610176086425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-4.3116097]
 [-4.0961113]
 [-3.828986 ]
 [-3.67901  ]
 [-3.1534715]
 [-4.1249123]
 [-3.8141284]
 [-2.3771877]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 30. 19. 29.  8.  3. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
adversary victory points: 11
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: take_action - action -1.0
Learning step: -7.906564235687256
desired expected reward: -10.388260841369629



buy possibilites: [-1] 
expected returns: [[-11.653082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  6.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 19. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
adversary victory points: 11
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -160.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -472.0 

action type: buy - action 6.0
Learning step: -23.67824363708496
desired expected reward: -27.357254028320312






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8  6] -> size -> 37 
adversary victory points: -5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 19. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8  6] -> size -> 37 
adversary victory points: -5
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8  6] -> size -> 37 
adversary victory points: -5
player victory points: 12 





Player: 0 
cards in hand: [6. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.111656]
 [16.99622 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 6.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  6  0 11  6 14  0  6  1  8  1 11 10  3  0  1  6  3  1 14
  6  0  0 10 10  6 10  0  0  0  1  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
adversary victory points: 12
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -180 

action type: buy - action -1
Learning step: -8.021522521972656
desired expected reward: -19.674604415893555



action possibilites: [-1] 
expected returns: [[-3.563084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  0. 10.  3.  1.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: trash_cards_n_from_hand - action 8
Learning step: -7.283027648925781
desired expected reward: 9.774131774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.7979937]
 [-3.1208205]
 [-3.0038335]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  0. 10.  3.  1.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  2. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1
Learning step: -6.238493919372559
desired expected reward: -9.8015775680542



buy possibilites: [-1] 
expected returns: [[-7.2983885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -150    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -438 

action type: buy - action 6.0
Learning step: -21.908172607421875
desired expected reward: -25.028995513916016






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  3.  0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0
  0  0  1  0  1 10 11  3 29 10  8  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
adversary victory points: -3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [3. 0. 0. 3. 3. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [1. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-8.206871]
 [-8.519801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -6.723014831542969
desired expected reward: -14.021403312683105





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-6.8221884]
 [-7.200888 ]
 [-6.685014 ]
 [-5.9781013]
 [-6.954941 ]
 [-6.842292 ]
 [-7.1479154]
 [-6.983141 ]
 [-6.16979  ]
 [-6.604775 ]
 [-6.424141 ]
 [-6.315811 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  5. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1.0
Learning step: -6.638820171356201
desired expected reward: -14.845693588256836



buy possibilites: [-1] 
expected returns: [[-9.928536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  4. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -130.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -136.0 

action type: buy - action 8.0
Learning step: -6.665996074676514
desired expected reward: -13.813908576965332






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  4. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  6.  6.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8] -> size -> 35 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  4. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  6.  6.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8] -> size -> 35 
adversary victory points: -3
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-6.4789186]
 [-6.514878 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  4. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -6.549725532531738
desired expected reward: -16.478261947631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-6.5725007]
 [-6.645313 ]
 [-4.589711 ]
 [-7.2225895]
 [-6.478918 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  4. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1.0
Learning step: -6.715205669403076
desired expected reward: -13.194123268127441



buy possibilites: [-1] 
expected returns: [[4.170206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  6.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 10. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0   -1    0    0
    8    0] 
sum of rewards: -131 

action type: buy - action 8.0
Learning step: -6.095041275024414
desired expected reward: -13.317630767822266






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 10.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 15.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0
  1  0  1 10 11  3 29 10  8  0  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 14.  1. 11.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [ 0. 14.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[-11.914526]
 [-11.107632]
 [-12.278835]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -7.372251987457275
desired expected reward: -3.2020459175109863



action possibilites: [-1] 
expected returns: [[7.401519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action 14.0
Learning step: -5.175495624542236
desired expected reward: -16.33490562438965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.92789936]
 [ 2.7378526 ]
 [ 0.23705363]
 [ 2.147183  ]
 [-0.9676018 ]
 [-1.5885203 ]
 [ 1.6318936 ]
 [ 4.948366  ]
 [ 2.5210643 ]
 [ 7.656599  ]
 [ 2.8876643 ]
 [-0.34115314]
 [ 0.5378847 ]
 [ 1.9781122 ]
 [-1.0794024 ]
 [ 1.42696   ]
 [ 6.2838106 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 23. 30. 18. 29.  8.  1. 10.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1
Learning step: -6.218888759613037
desired expected reward: 1.1826300621032715



buy possibilites: [-1] 
expected returns: [[-6.096217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 18. 29.  8.  1.  9.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -130.    0.    0.   20.    0.    0.    0.    0.   -2.
    0.    0.    8.    0.] 
sum of rewards: -112.0 

action type: buy - action 16.0
Learning step: -5.818759441375732
desired expected reward: -4.1868672370910645






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1.  9.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
adversary victory points: -3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [ 0. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[4.1225405]
 [2.5851831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -6.5185418128967285
desired expected reward: -12.61475944519043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.76643896]
 [ 1.7596998 ]
 [ 1.5090978 ]
 [-0.69568527]
 [-0.8854619 ]
 [ 1.1746805 ]
 [ 2.599978  ]
 [ 1.7134542 ]
 [ 3.5442085 ]
 [ 1.9037051 ]
 [-0.4471991 ]
 [ 0.4502859 ]
 [ 1.4959514 ]
 [-0.80029714]
 [ 1.1361063 ]
 [ 2.8503604 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1.0
Learning step: -7.076985836029053
desired expected reward: -2.9544544219970703



buy possibilites: [-1] 
expected returns: [[0.3238752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1.  0.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5.     0.    -3.  -130.     0.     0.     0.     0.     0.     0.
    0.    -3.     0.     0.     4.5    0. ] 
sum of rewards: -136.5 

action type: buy - action 10.0
Learning step: -6.892510890960693
desired expected reward: -5.396561622619629






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 1. 14. 11.  0.  8.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 1. 14. 11.  0.  8.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  3. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 1. 14. 11.  0.  8.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
adversary victory points: -3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  3.  3.  8. 11.  0.  3.  0.  1.  3.  0. 10. 10. 15. 10.
  0.  6.  1.  3.  0. 16.  0. 11.  3. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 1. 14. 11.  0.  8.] 
adversary cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [ 1. 14. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
expected returns: [[-6.5909376]
 [-5.558064 ]
 [-7.0865517]
 [-7.133719 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 11.  0.  8.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -7.062926769256592
desired expected reward: -6.739051818847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-6.542992 ]
 [-7.2476645]
 [-6.6301026]
 [-4.6887016]
 [-7.086551 ]
 [-7.1337194]
 [-6.495724 ]
 [-6.5909376]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 11.  0.  8.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 30. 18. 29.  8.  1.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1.0
Learning step: -6.715001583099365
desired expected reward: -13.305938720703125



buy possibilites: [-1] 
expected returns: [[-6.610236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14. 11.  0.  8.] 
cards in discard: [ 6.  0. 10.  3.  1.  6.  6.  8.  8.  1.  8.  0.  0.  3.  8. 10.  0.  6.
  6.  0. 16. 14.  0.  1. 11.  0. 10.  0. 10.  0.  1.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -140.    0.    0.    0.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -453.0 

action type: buy - action 6.0
Learning step: -22.56429672241211
desired expected reward: -27.25299835205078






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
adversary victory points: -4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
adversary victory points: -4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  3.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
adversary victory points: -4
player victory points: 10 





Player: 0 
cards in hand: [ 0. 11.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 0.48991632]
 [-0.3503194 ]
 [-1.9027023 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 16. 15.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: buy - action -1
Learning step: -7.131051063537598
desired expected reward: -13.741287231445312



action possibilites: [-1. 11. 10.] 
expected returns: [[-6.7039638]
 [-7.1467967]
 [-6.645482 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 16. 15.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action 10.0
Learning step: -6.508299350738525
desired expected reward: -8.410998344421387



action possibilites: [-1. 11.] 
expected returns: [[-6.7039638]
 [-7.1467967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
action values: 3 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 16. 15.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action 10.0
Learning step: -5.273205757141113
desired expected reward: -11.91868782043457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.6608286]
 [-6.7855577]
 [-7.3600264]
 [-6.7039638]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 18. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 16. 15.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
adversary victory points: 10
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -140    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.269213676452637
desired expected reward: -11.973176956176758



buy possibilites: [-1] 
expected returns: [[-7.6660194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  6.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0. 16. 15.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   40    0    0    0    0   -5    0    0
    8    0] 
sum of rewards: -95 

action type: buy - action 3.0
Learning step: -4.583207607269287
desired expected reward: -11.368765830993652






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [10.  0. 16. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16. 15.  0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  6. 14.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 40 
adversary victory points: -3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16. 15.  0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  2. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  6. 14.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 40 
adversary victory points: -3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16. 15.  0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  6. 14.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 40 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [10.  6. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
expected returns: [[-3.1592388]
 [-3.6063056]
 [-3.6073418]
 [-4.117015 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 14.  8.  0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11 10  3  0  1  6  3  1 14  6  0  0 10
 10  6 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -6.5974907875061035
desired expected reward: -14.263509750366211



action possibilites: [-1] 
expected returns: [[-8.645235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: trash_cards_n_from_hand - action 8
Learning step: -5.276655197143555
desired expected reward: -10.6339111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.9295373]
 [-8.991199 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1
Learning step: -5.107278347015381
desired expected reward: -13.752513885498047






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10.  0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  1.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8] -> size -> 40 
action values: 2 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  8.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  1. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [10.  1.  0.  1.  8.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [10.  1.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-4.934944 ]
 [-5.6115646]
 [-6.1732903]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  1.  8.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0 11 14  0  1  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6
 10  0  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 3.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1.0
Learning step: -6.0248541831970215
desired expected reward: -15.016054153442383



action possibilites: [-1] 
expected returns: [[-8.591114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 3.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: trash_cards_n_from_hand - action 7
Learning step: -5.263486385345459
desired expected reward: -10.85975170135498





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.504692 ]
 [-7.7829814]
 [-8.3026705]
 [-8.458597 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 3.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1
Learning step: -5.099937438964844
desired expected reward: -13.691051483154297



buy possibilites: [-1] 
expected returns: [[-11.423927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [8. 0. 1. 3. 3.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -120.    0.    0.   20.  -30.    0.    0.    0.   -2.
    0.    0.    0.    0.] 
sum of rewards: -139.0 

action type: buy - action 0.0
Learning step: -6.831803798675537
desired expected reward: -14.336495399475098






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 3. 3.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3. 3.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 23. 30. 17. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3. 3.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 30. 16. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14.  0.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 6.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-7.853104 ]
 [-6.0829563]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14.  0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 16. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -6.4342193603515625
desired expected reward: -17.85814666748047



action possibilites: [-1] 
expected returns: [[6.044828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 16. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action 14.0
Learning step: -5.409843921661377
desired expected reward: -11.492799758911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[5.5823064]
 [6.3473735]
 [6.1932416]
 [5.875612 ]
 [7.2229123]
 [6.2295117]
 [6.539681 ]
 [5.046727 ]
 [5.9620643]
 [7.701244 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 30. 16. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1
Learning step: -6.00895881652832
desired expected reward: 0.03586912155151367



buy possibilites: [-1] 
expected returns: [[0.40546322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -120.    0.    0.   20.    0.    0.    0.    0.   -3.
    0.    0.    2.    0.] 
sum of rewards: -107.0 

action type: buy - action 3.0
Learning step: -5.650539398193359
desired expected reward: 0.5427050590515137






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 16.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0  3] -> size -> 38 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 16.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0  3] -> size -> 38 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 23. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 16.] 
adversary cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.] 
adversary owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0  3] -> size -> 38 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [ 0.  0.  3.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-6.514457 ]
 [-6.5518966]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 16.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11 14  0  8  1 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0
  0  0  1  8  6  6  8  8 16 10  6  3  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3  0] -> size -> 44 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -126 

action type: buy - action -1
Learning step: -6.467240333557129
desired expected reward: -6.061777114868164



action possibilites: [-1] 
expected returns: [[-7.7873597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  0 11 14  0  8 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0  0
  0  1  8  6  6  8  8 16 10  6  3  0  3  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3  0] -> size -> 44 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0   -3    0    0
    9    0] 
sum of rewards: -100 

action type: gain_card_n - action 1
Learning step: -4.762667179107666
desired expected reward: -13.013631820678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.8539352]
 [-7.1120396]
 [-7.6258473]
 [-7.2808824]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  0 11 14  0  8 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0  0
  0  1  8  6  6  8  8 16 10  6  3  0  3  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 15. 29.  8.  0.  8.  5.  1. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3  0] -> size -> 44 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1
Learning step: -5.072479248046875
desired expected reward: -12.859838485717773



Player 1 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 4 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 3 
Chapel: 6 
Witch: 0 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 10. 10.  0. 11.  6.  0.  6.  8. 14.  0.  0.  8. 10.  1.  3. 14.  6.
  0.  6.  0.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  0 11 14  0  8 11  3  0  1  3  1 14  6  0  0 10 10  6 10  0  0
  0  1  8  6  6  8  8 16 10  6  3  0  3  1  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 29.  8.  0.  8.  5.  0. 10.  7.  7. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  8.  0.  3.  8. 10.  0. 16. 15.  0.  0. 29. 10. 29. 10. 11.
  3.  0.  1.  3.  8.  0.  1.  3.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3 15  3  3  0 11 10  8  6  3  3  0  0  0  0  1
  0  1 10 11  3 29 10  8  0  3 10 16  0  8  0  8 29 10  3  0] -> size -> 44 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1 -120    0    0   20    0    0    0    0   -4    0    0
    4    0] 
sum of rewards: -606 

action type: buy - action 8.0
Learning step: -29.896759033203125
desired expected reward: -37.9615592956543



