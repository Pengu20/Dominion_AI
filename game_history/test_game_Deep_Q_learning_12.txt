 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[112.878204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -270        0        0       20        0
        0        0        0     -160        0     -300        0        0] 
sum of rewards: -3000715 

action type: buy - action 6.0
Learning step: -120029.296875
desired expected reward: -120011.703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.89873 ]
 [111.218056]
 [110.71072 ]
 [106.90069 ]
 [113.68254 ]
 [111.87054 ]
 [111.36322 ]
 [111.36243 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.22473907470703



buy possibilites: [-1] 
expected returns: [[109.551895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 113.68253326416016






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.25544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.55189514160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[112.13016]
 [114.44948]
 [113.94215]
 [110.1321 ]
 [114.67495]
 [116.91397]
 [115.10197]
 [118.41609]
 [113.04465]
 [114.59463]
 [115.36398]
 [114.59386]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.6042251586914



buy possibilites: [-1] 
expected returns: [[107.38451]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 118.41610717773438






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.5048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.38450622558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[92.52238]
 [94.74483]
 [94.26008]
 [90.6126 ]
 [97.10617]
 [95.36846]
 [94.88371]
 [94.89942]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.6918716430664



buy possibilites: [-1] 
expected returns: [[109.75976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.10617065429688






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 29.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 29.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 29.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[110.99333 ]
 [113.07789 ]
 [114.438705]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.75975799560547



action possibilites: [-1. 11.] 
expected returns: [[130.37283]
 [132.52138]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.59591674804688



action possibilites: [-1] 
expected returns: [[136.46523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 136.4983673095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[134.57648]
 [136.74788]
 [136.27357]
 [132.71199]
 [136.955  ]
 [139.0537 ]
 [137.35657]
 [140.46095]
 [135.43674]
 [136.8823 ]
 [137.60814]
 [136.90515]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.46522521972656



buy possibilites: [-1] 
expected returns: [[125.23603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 140.46096801757812






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[110.704796]
 [112.85334 ]
 [110.68194 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.23603057861328



action possibilites: [-1] 
expected returns: [[109.167046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.68450164794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.098305]
 [108.294754]
 [107.81476 ]
 [104.212265]
 [110.62677 ]
 [108.910324]
 [108.43032 ]
 [108.453926]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.16704559326172



buy possibilites: [-1] 
expected returns: [[125.58248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.62677764892578






Player: 1 
cards in hand: [10.  3.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  3 10 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[123.61794]
 [127.26351]
 [125.8247 ]
 [127.26351]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0. 29.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.58248138427734



action possibilites: [-1. 11. 29.] 
expected returns: [[137.6577 ]
 [139.80624]
 [141.2135 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.31906127929688



action possibilites: [-1. 11.] 
expected returns: [[139.50493]
 [141.65347]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.2135009765625



action possibilites: [-1] 
expected returns: [[135.32277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.13644409179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[132.5074 ]
 [134.5517 ]
 [134.10495]
 [131.14404]
 [130.7495 ]
 [134.74844]
 [136.72313]
 [135.1256 ]
 [139.41092]
 [138.04756]
 [133.31549]
 [134.98265]
 [134.67883]
 [132.93835]
 [135.35977]
 [134.68988]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.32276916503906



buy possibilites: [-1] 
expected returns: [[150.91306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0. 10. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 139.41091918945312






Player: 1 
cards in hand: [ 3. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[119.176216]
 [121.32475 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.91305541992188



action possibilites: [-1] 
expected returns: [[119.891014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 123.11788177490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.99387 ]
 [115.12939 ]
 [119.322556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.8910140991211






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [10. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[159.54109]
 [163.09691]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [10. 11.  3.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.32254791259766



action possibilites: [-1. 10.] 
expected returns: [[152.15062]
 [152.12776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 162.94680786132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[151.02011]
 [153.19153]
 [152.71724]
 [149.57455]
 [149.15562]
 [153.39865]
 [155.49734]
 [153.80022]
 [158.35016]
 [156.9046 ]
 [151.88037]
 [153.6502 ]
 [153.32593]
 [151.47879]
 [154.05177]
 [153.3488 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 152.15061950683594



buy possibilites: [-1] 
expected returns: [[143.4997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 158.35015869140625






Player: 1 
cards in hand: [ 8.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0. 10.] 
adversary cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0.  0.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0. 10.] 
adversary cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[142.12907]
 [144.2757 ]
 [147.0951 ]
 [142.13452]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.49969482421875



action possibilites: [-1] 
expected returns: [[147.26418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 29. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.82467651367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.4999 ]
 [149.30666]
 [145.50804]
 [150.46385]
 [149.96428]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10. 29. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  9.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.26417541503906



buy possibilites: [-1] 
expected returns: [[143.07425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10. 29. 10.] 
cards in discard: [10. 11.  3.  3.  3.  0. 25. 29.  0.  0.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 150.4638671875






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
expected returns: [[129.74097]
 [130.19238]
 [134.74234]
 [131.88951]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 15.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.07424926757812



action possibilites: [-1] 
expected returns: [[147.41455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  8.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 15.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.8859100341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.03326]
 [148.73038]
 [145.16878]
 [149.81335]
 [149.36194]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  8.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 15.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.41455078125



buy possibilites: [-1] 
expected returns: [[153.1286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 11. 10.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 15.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 149.8133544921875






Player: 1 
cards in hand: [ 0.  8.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 15.  0.] 
cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 15.  0.] 
cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  6.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 15.  0.] 
cards in discard: [ 6. 10.  0.  0.  3.  0. 11.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[152.52979]
 [152.5237 ]
 [152.5237 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.12860107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.67943]
 [152.54672]
 [148.62201]
 [153.74142]
 [153.22467]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  7.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 153.0419158935547



buy possibilites: [-1] 
expected returns: [[147.25049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  6.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 153.74142456054688






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  6.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0. 29. 29. 25.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  6.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0. 29. 29. 25.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0. 29. 29. 25.] 
adversary cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 25.] 
expected returns: [[153.90573]
 [153.90509]
 [157.6021 ]
 [157.6021 ]
 [159.10039]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29. 25.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8] -> size -> 18 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.25048828125



action possibilites: [-1] 
expected returns: [[164.98283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29.  3.  3.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.30792236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.42569]
 [164.54913]
 [168.72357]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29. 29.  3.  3.] 
cards in discard: [ 8. 25.  8.  0.  0. 11. 11. 10.  8.  3. 10. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.9828338623047






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  5.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  4.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[134.29858]
 [136.44713]
 [136.44713]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  4.  8.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.72357177734375



action possibilites: [-1] 
expected returns: [[121.802505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  4.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.4877166748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.834915]
 [123.53202 ]
 [119.97043 ]
 [124.61501 ]
 [124.16358 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  4.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.80250549316406



buy possibilites: [-1] 
expected returns: [[136.87358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  3. 11.] 
adversary cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 124.6150131225586






Player: 1 
cards in hand: [ 0.  6.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 11.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  8  3 15  0 11  0  6 10  6 11  8  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8. 25.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8. 25.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8. 25.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 11.  0.  0.  0.  0.  6.  8.  0.  0.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8. 25.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[136.75067]
 [140.42776]
 [137.24649]
 [141.91745]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8. 25.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0] -> size -> 18 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.8735809326172



action possibilites: [-1] 
expected returns: [[153.67368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  8. 10.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.1685791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[153.44812]
 [151.3516 ]
 [156.04236]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  8.  8. 10.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.67367553710938






Player: 1 
cards in hand: [11.  0.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 15.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10. 10.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10. 15.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10. 10.  0.  0.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[136.48978]
 [136.48264]
 [136.48264]
 [136.48264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.0423583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[135.13808]
 [137.04074]
 [133.04155]
 [138.2582 ]
 [137.73232]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  3.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 136.48977661132812



buy possibilites: [-1] 
expected returns: [[146.93259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 138.25820922851562






Player: 1 
cards in hand: [0. 8. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 8.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8 15  0  0  6 10  6 11  8  6  8  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29.] 
expected returns: [[158.91975]
 [159.39537]
 [164.13913]
 [162.63086]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25. 29.  0.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6] -> size -> 17 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.93258666992188



action possibilites: [-1] 
expected returns: [[157.29094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  0.  0. 11.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  5. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 164.1391143798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[155.77928]
 [157.60765]
 [153.77103]
 [158.77368]
 [158.28683]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  0.  0. 11.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  5. 10.  5.  2.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.2909393310547



buy possibilites: [-1] 
expected returns: [[161.46783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  0.  0. 11.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 25.  3.  0. 29.  8.  8. 10.  8. 10. 10. 10.
  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 158.773681640625






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  8.  6.  8.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 29.] 
expected returns: [[107.63309]
 [108.09363]
 [108.09363]
 [107.60916]
 [111.26319]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.46783447265625



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[125.42908]
 [125.88961]
 [125.88961]
 [125.40516]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8  8
 10  8  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.37760925292969



action possibilites: [-1] 
expected returns: [[125.60665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 127.87016296386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.040855]
 [122.209496]
 [126.339584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.60665130615234






Player: 1 
cards in hand: [11.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 10. 10.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 10. 10.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  1.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 10. 10.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [29.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 10. 10.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 10.] 
expected returns: [[145.39973]
 [145.91695]
 [145.91695]
 [145.39944]
 [145.39944]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 10. 10.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 29 10 11 10 25 10 25  8  8 10  8
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [15. 10.  6.  6.  0.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.33958435058594



action possibilites: [-1] 
expected returns: [[130.33832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [15. 10.  6.  6.  0.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 148.75831604003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.60886 ]
 [127.744385]
 [131.93755 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [15. 10.  6.  6.  0.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.33831787109375






Player: 1 
cards in hand: [15. 10.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  6.  6.  0.] 
cards in discard: [29.  8. 11.  0.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  0.] 
adversary cards in discard: [29.  8. 10.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  6.  6.  0.] 
cards in discard: [29.  8. 11.  0.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  0.] 
adversary cards in discard: [29.  8. 10.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
adversary victory points: 2
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[137.17397]
 [137.65578]
 [142.26422]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  0.  0.] 
cards in discard: [29.  8. 10.  3.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8] -> size -> 21 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.9375457763672



action possibilites: [-1] 
expected returns: [[112.428635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0. 0.] 
cards in discard: [29.  8. 10.  3.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 141.65150451660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.046036]
 [113.3799  ]
 [112.869064]
 [109.49273 ]
 [109.0553  ]
 [113.60646 ]
 [115.859314]
 [118.93056 ]
 [117.371506]
 [111.966385]
 [113.87045 ]
 [113.525444]
 [111.53658 ]
 [114.300255]
 [113.526535]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0. 0.] 
cards in discard: [29.  8. 10.  3.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.42863464355469



buy possibilites: [-1] 
expected returns: [[137.00546]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0. 0.] 
cards in discard: [29.  8. 10.  3.  8. 10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6] -> size -> 22 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 118.93055725097656






Player: 1 
cards in hand: [3. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 11.  3. 10. 11.] 
adversary cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 11.  3. 10. 11.] 
adversary cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [29.  8. 11.  0.  6.  0.  0. 15. 10.  6.  6.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 11.  3. 10. 11.] 
adversary cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 11.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11.] 
expected returns: [[155.34204]
 [159.15091]
 [157.6553 ]
 [155.34674]
 [157.6553 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 10. 11.] 
cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.00546264648438



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[178.92352]
 [181.23059]
 [178.92664]
 [181.23059]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 11.] 
cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 155.20260620117188



action possibilites: [-1] 
expected returns: [[146.47917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 181.7351531982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.35286]
 [142.25632]
 [146.94708]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.] 
cards in discard: [29.  8. 10.  3.  8. 10. 25. 25.  0.  8.  0.  0.  0.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.4791717529297






Player: 1 
cards in hand: [29.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 25. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 25. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 11.] 
expected returns: [[147.58136]
 [149.77438]
 [152.68715]
 [147.55745]
 [149.77438]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  4. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3] -> size -> 22 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.9470977783203



action possibilites: [-1] 
expected returns: [[126.530266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 151.8015594482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[128.18054]
 [126.31605]
 [130.50922]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6] -> size -> 23 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.53026580810547






Player: 1 
cards in hand: [ 6.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [15.  8. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 29. 29.] 
expected returns: [[125.22595 ]
 [125.981346]
 [125.72704 ]
 [125.23174 ]
 [128.96053 ]
 [128.96053 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 29. 29.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.5092315673828



action possibilites: [-1. 15. 10. 29.] 
expected returns: [[136.37149]
 [137.12021]
 [136.38144]
 [140.06116]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 125.17442321777344



action possibilites: [-1. 10. 11.] 
expected returns: [[130.79059]
 [130.80115]
 [133.00656]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 136.21640014648438



action possibilites: [-1] 
expected returns: [[151.66266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 299 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 133.49105834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[149.5989 ]
 [151.78387]
 [151.30537]
 [147.72794]
 [154.1057 ]
 [151.92076]
 [151.90988]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  5.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.66265869140625



buy possibilites: [-1] 
expected returns: [[159.58925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0.  3.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 289 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 154.105712890625






Player: 1 
cards in hand: [ 0. 15.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0.  3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25.  0.] 
adversary cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[145.96323]
 [146.46281]
 [151.31396]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 25.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  3. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.58924865722656



action possibilites: [-1] 
expected returns: [[136.17966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 151.31396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[134.5316 ]
 [136.60313]
 [136.14714]
 [132.79825]
 [136.80353]
 [138.81741]
 [140.1691 ]
 [135.34224]
 [136.73218]
 [137.42747]
 [136.74588]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  7. 10. 10.  3. 10.  7.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.17965698242188



buy possibilites: [-1] 
expected returns: [[140.72473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.  0.] 
cards in discard: [25. 11. 10. 11.  0. 25.  3.  8. 15. 15. 11. 29. 29. 11. 10.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  7.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6] -> size -> 25 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 140.1691131591797






Player: 1 
cards in hand: [6. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29] -> size -> 28 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29] -> size -> 28 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 6. 29.  8.  8.  0.  6.  0.  0. 11.  6.  0.  0.  3.  8. 15.  0.  3.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  7.] 
adversary cards in hand: [11.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29] -> size -> 28 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  8.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 10.] 
expected returns: [[137.3175 ]
 [139.46603]
 [137.76892]
 [137.76892]
 [137.29463]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8. 10.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  3.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 140.7247314453125



action possibilites: [-1] 
expected returns: [[129.69612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  3.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 139.2684783935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.44117]
 [125.53239]
 [129.8535 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  3.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.6961212158203






Player: 1 
cards in hand: [ 6.  3.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [11.  3. 11. 10.  8.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0
  6  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [11.  3. 11. 10.  8.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [11.  3. 11. 10.  8.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [11.  3. 11. 10.  8.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [11.  3. 11. 10.  8.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  3. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.  8.] 
expected returns: [[144.60773]
 [146.92099]
 [146.92099]
 [144.61244]
 [145.11792]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 10.  8.] 
cards in discard: [15. 11.  8.  8. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.85350036621094



action possibilites: [-1] 
expected returns: [[128.35268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  8.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 147.4264678955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[125.94624 ]
 [123.849724]
 [128.5405  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  8.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.35267639160156






Player: 1 
cards in hand: [ 6. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11. 10. 25. 10.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 10.] 
expected returns: [[169.24591]
 [171.67447]
 [169.2388 ]
 [174.87865]
 [169.2388 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 25. 10.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  2. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0  1] -> size -> 27 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.5404815673828



action possibilites: [-1] 
expected returns: [[153.83217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10. 29. 29.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0  1  6] -> size -> 28 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.87860107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[152.19534]
 [150.09882]
 [154.78958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 10. 29. 29.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0  1  6] -> size -> 28 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.83216857910156






Player: 1 
cards in hand: [ 8. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  3.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  0  0 10  6 11  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6
  0  0  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 25.  0. 15.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 25.  0. 15.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 25.  0. 15.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 25.  0. 15.] 
adversary cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[110.814156]
 [115.85644 ]
 [111.522675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 15.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  1. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  6. 15.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0] -> size -> 28 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.78958129882812



action possibilites: [-1] 
expected returns: [[163.6518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.  0.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  6. 15.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.85643768310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[161.74504]
 [164.08385]
 [163.5734 ]
 [160.18759]
 [164.30716]
 [166.56781]
 [169.64035]
 [168.08287]
 [162.67155]
 [164.57806]
 [164.22902]
 [162.23926]
 [165.01036]
 [164.25261]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.  0.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  7.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  6. 15.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.65179443359375



buy possibilites: [-1] 
expected returns: [[150.59155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.  0.] 
cards in discard: [15. 11.  8.  8. 10.  3. 15. 11.  3. 11. 10.  8. 25.  0. 11. 10. 10. 29.
 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  6. 15.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 505 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 169.6403350830078






Player: 1 
cards in hand: [ 6.  0.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  6. 15.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0
  0  1  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11. 25. 15. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11. 25. 15. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 27. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11. 25. 15. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11. 25. 15. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 25. 15. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 15. 29.  8.] 
expected returns: [[124.8186  ]
 [127.09565 ]
 [130.13118 ]
 [125.570015]
 [128.58723 ]
 [125.31053 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 15. 29.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.591552734375



action possibilites: [-1] 
expected returns: [[131.29947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29.  8.  8. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.1311798095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[129.04373]
 [131.42143]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 29.  8.  8. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.29946899414062






Player: 1 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 10. 11.  0. 11.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 10. 11.  0. 11.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 0. 10.  8.  6.  3.  6.  1.  6. 29.  0.  0.  0.  6.  0.  8.  8.  3.  0.
  6.  3. 15.  6.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 10. 11.  0. 11.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[96.11642]
 [96.11982]
 [98.40305]
 [98.40305]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0. 11.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.4214324951172



action possibilites: [-1] 
expected returns: [[118.913635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 96.61991119384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[117.26165]
 [119.70618]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.91363525390625






Player: 1 
cards in hand: [ 8.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [25. 29. 11. 10.  0.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [25. 29. 11. 10.  0.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  1. 15.] 
cards in discard: [14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [25. 29. 11. 10.  0.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 10.] 
expected returns: [[149.01375]
 [154.47807]
 [152.90152]
 [151.3721 ]
 [149.01183]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 11. 10.  0.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.70616912841797



action possibilites: [-1] 
expected returns: [[154.0427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0.  0. 10.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.47808837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[152.35478]
 [154.08725]
 [154.7325 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10.  0.  0. 10.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.04269409179688






Player: 1 
cards in hand: [6. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0.  0. 29.  8.] 
adversary cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[152.96103]
 [152.94266]
 [156.67212]
 [153.43665]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  8.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.73248291015625



action possibilites: [-1. 10.  8. 25.] 
expected returns: [[146.85672]
 [146.85483]
 [147.37141]
 [152.32108]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 25.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 152.80184936523438



action possibilites: [-1] 
expected returns: [[142.01231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  3.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.32106018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[139.83168]
 [142.3612 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.  3.] 
cards in discard: [25. 11. 15. 29.  8.  8. 15. 15. 11.  3. 10.  0. 11. 25. 29. 11. 10.  0.
  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.01231384277344






Player: 1 
cards in hand: [6. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 25. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25. 15.] 
expected returns: [[118.510925]
 [119.00091 ]
 [119.257996]
 [123.75117 ]
 [119.257996]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 25. 15.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  6.  0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.3612060546875



action possibilites: [-1] 
expected returns: [[125.13885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 15.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  6.  0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.75116729736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[123.514854]
 [125.24732 ]
 [125.89256 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 15.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  6.  0.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.13884735107422






Player: 1 
cards in hand: [ 6. 29.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  6.  0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 10.  8. 25. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 10.  8. 25. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 10.  8. 25. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 10.  8. 25. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15. 10.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8. 25. 11.] 
expected returns: [[128.05513]
 [128.83694]
 [128.05324]
 [128.56982]
 [133.51949]
 [130.4135 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8. 25. 11.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 1. 8. 3.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.89256286621094



action possibilites: [-1] 
expected returns: [[143.83142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8. 11.  3. 10.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 1. 8. 3.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.51947021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[141.78632]
 [144.23082]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  8. 11.  3. 10.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 6. 1. 8. 3.] 
adversary cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.8314208984375






Player: 1 
cards in hand: [6. 6. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 8. 3.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6  3 29  8  6  3  6  0  0  6  0  0
  1  6  0  6  3  1 14  3  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 25. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1.] 
cards in discard: [14.  8.  0.  0.  1. 15.  3.  6.  6.  0.  6.  0.  0.  6.  6.  3.  8.  0.
  0.  0.  0. 29.  6.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[161.0465 ]
 [165.05348]
 [161.5724 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  0.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 144.23081970214844



action possibilites: [-1.  8.] 
expected returns: [[157.83813]
 [158.36403]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25
 15 15 11 29 15 15 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 160.88795471191406



action possibilites: [-1] 
expected returns: [[127.48318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 156.91366577148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[125.938805]
 [128.53304 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.4831771850586






Player: 1 
cards in hand: [ 3.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  3. 10. 29. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  3. 10. 29. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  3. 10. 29. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  3. 10. 29. 11.] 
adversary cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  3. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29. 11.] 
expected returns: [[144.97241]
 [145.77522]
 [144.96526]
 [148.97937]
 [147.40096]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10. 29. 11.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6.  6.  3.  1. 29.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.53305053710938



action possibilites: [-1. 15. 10. 25.] 
expected returns: [[135.67368]
 [136.39775]
 [135.65784]
 [140.79486]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.
  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6.  6.  3.  1. 29.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 147.93397521972656



action possibilites: [-1] 
expected returns: [[178.41188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25.  8.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.
  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6.  6.  3.  1. 29.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.79486083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[176.33374]
 [178.84647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 25.  8.] 
cards in discard: [25.  8. 15. 15.  0. 11.  0. 25. 15. 10.  8. 11.  3. 10.  0. 11. 29.  8.
  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 6.  6.  3.  1. 29.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.41188049316406






Player: 1 
cards in hand: [ 6.  6.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  1. 29.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3.  1. 29.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8. 15. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
adversary victory points: 2
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29. 10.] 
expected returns: [[110.552475]
 [111.013016]
 [111.269806]
 [114.18257 ]
 [110.52855 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.84646606445312



action possibilites: [-1. 10. 29.] 
expected returns: [[107.72331]
 [107.70078]
 [111.21253]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [ 8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 113.22992706298828



action possibilites: [-1.] 
expected returns: [[109.82902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 15. 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 107.56915283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[107.34769 ]
 [109.47837 ]
 [109.012825]
 [111.74071 ]
 [109.61002 ]
 [109.63253 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 15. 10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  4.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 109.82901763916016



buy possibilites: [-1] 
expected returns: [[127.37765]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 15. 10. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
adversary owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.74071502685547






Player: 1 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  0  0 10  6  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1
  6  0  6  3  1 14  3  0  0  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 25.  0.  8. 29.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 25.  0.  8. 29.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 23. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 25.  0.  8. 29.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 25.  0.  8. 29.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 25.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 29.] 
expected returns: [[ 97.14916 ]
 [ 99.404205]
 [102.37565 ]
 [ 97.64172 ]
 [100.86826 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  8. 29.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.37764739990234



action possibilites: [-1] 
expected returns: [[115.066185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29.  0.  8.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.3756332397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[113.56236]
 [115.30685]
 [115.93095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8. 29.  0.  8.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.0661849975586






Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0. 11. 11. 25.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0. 11. 11. 25.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0. 11. 11. 25.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 25.] 
expected returns: [[134.72993]
 [134.7228 ]
 [137.15848]
 [137.15848]
 [140.36264]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11. 25.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3 10] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.93096160888672



action possibilites: [-1] 
expected returns: [[149.05984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11. 10. 15.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3 10] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.36264038085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[147.6626 ]
 [150.25685]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 11. 10. 15.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [6. 6. 8. 0. 6.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3 10] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.05984497070312






Player: 1 
cards in hand: [6. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 6.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  6  8  0  6  6 29  8  6  3  6  0  0  6  0  0  1  6  0
  6  3  1 14  3  0  0  3  3  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 15. 10.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 15. 10.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 15. 10.] 
adversary cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 10.] 
expected returns: [[135.20415]
 [135.91264]
 [135.91264]
 [135.91264]
 [135.18079]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 15. 10.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.2568359375



action possibilites: [-1] 
expected returns: [[128.99086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 10.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 135.9126434326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[126.76883]
 [129.18118]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15. 10.] 
cards in discard: [ 8. 15. 10. 11. 11. 29. 29.  0. 25. 11.  0.  8. 29.  0.  8. 25. 10.  0.
 11. 11. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [15.  0.  0.  0. 14.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.99085998535156






Player: 1 
cards in hand: [15.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 14.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [25. 25. 25.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [25. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  6.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [25. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.  3.  6.  6.  3.  1. 29.  3.  8.  0.  0. 10.  6.
  0.  8.  0.  0.  8.  0.  6. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [25. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [25.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[120.66567]
 [125.60998]
 [121.11209]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3.] 
cards in discard: [25. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 101.65187072753906



action possibilites: [-1] 
expected returns: [[146.64464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 10.] 
cards in discard: [25. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.60997772216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[144.3889]
 [146.7666]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 10.] 
cards in discard: [25. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.64463806152344






Player: 1 
cards in hand: [ 0. 25.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  6.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10. 15. 15. 15. 11.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  6.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  3.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10. 15. 15. 15. 11.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  6.  6.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10. 15. 15. 15. 11.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [10. 15. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15. 15. 11.] 
expected returns: [[117.81192]
 [117.82394]
 [118.4835 ]
 [118.4835 ]
 [118.4835 ]
 [119.82022]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15. 15. 11.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  4.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.7666015625



action possibilites: [-1] 
expected returns: [[135.90443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15. 15.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 118.26139068603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[133.92554]
 [136.2437 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 15. 15.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.90443420410156






Player: 1 
cards in hand: [14.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 29.  0.  3.] 
cards in discard: [11.  0. 25.  1.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [11.  0. 25.  1.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [11.  0. 25.  1.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 10.  0.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[170.40208]
 [170.92798]
 [170.39494]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 11 10 25 10 25  8 10  8  8  8 25 15 15
 11 29 15 15 25 15 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 173.07891845703125



action possibilites: [-1] 
expected returns: [[128.91138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 168.9903106689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[127.57996]
 [130.01312]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.911376953125






Player: 1 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [29. 11. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[151.59695]
 [155.60394]
 [154.0255 ]
 [151.58981]
 [155.60394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0. 29.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 10.  0. 15.  8.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.01312255859375



action possibilites: [-1. 10. 29. 29.] 
expected returns: [[173.19778]
 [173.19067]
 [177.20476]
 [177.20476]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 10.  0. 15.  8.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 151.4384002685547



action possibilites: [-1. 10.] 
expected returns: [[186.6503 ]
 [186.64377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 10.  0. 15.  8.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 173.03924560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[184.46042]
 [186.34146]
 [187.02472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 10.  0. 15.  8.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 186.65029907226562






Player: 1 
cards in hand: [ 0. 10.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.  8.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [11.  8. 15.  0. 25.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  8.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [11.  8. 15.  0. 25.] 
adversary cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [11.  8. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 25.] 
expected returns: [[142.68405]
 [145.0424 ]
 [143.19875]
 [143.46585]
 [148.14839]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  0. 25.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15. 29. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [3. 8. 8. 6. 6.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 187.0247039794922



action possibilites: [-1] 
expected returns: [[150.05269]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  0.  3. 11.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15. 29. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [3. 8. 8. 6. 6.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.1483917236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[148.2106 ]
 [150.71985]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15.  0.  3. 11.] 
cards in discard: [25. 25. 25.  8.  3.  8. 10. 15. 11. 10. 15. 15. 15. 11.  0.  8.  0. 11.
  0. 29. 15. 29. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [3. 8. 8. 6. 6.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.0526885986328






Player: 1 
cards in hand: [3. 8. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 6. 6.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 6. 6.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 99.798775]
 [101.94451 ]
 [104.79406 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.71986389160156



action possibilites: [-1] 
expected returns: [[157.72028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 10. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.79407501220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[155.85947]
 [157.55658]
 [158.18816]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3. 10. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.72027587890625






Player: 1 
cards in hand: [6. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 11.  0. 15. 15.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 11.  0. 15. 15.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [11.  0. 25.  1.  6.  6. 14.  3. 29.  0.  3.  0.  0.  6.  3.  3.  0. 10.
  0. 15.  8.  3.  8.  8.  6.  6. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  3.] 
adversary cards in hand: [ 8. 11.  0. 15. 15.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15. 15.] 
expected returns: [[138.98323]
 [139.46614]
 [141.19229]
 [139.71584]
 [139.71584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 15. 15.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  3.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.1881561279297



action possibilites: [-1] 
expected returns: [[151.35384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15. 15.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 139.46615600585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[149.7171 ]
 [152.08919]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15. 15.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.3538360595703






Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [15. 25. 11. 15. 29.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [15. 25. 11. 15. 29.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [15. 25. 11. 15. 29.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [15. 25. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11. 15. 29.] 
expected returns: [[161.2702 ]
 [162.073  ]
 [166.90288]
 [163.69875]
 [162.073  ]
 [165.27716]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 11. 15. 29.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25.  8.  0. 14.  1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 152.0891876220703



action possibilites: [-1] 
expected returns: [[181.0222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15. 29. 15.  8.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25.  8.  0. 14.  1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 166.90289306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[178.78308]
 [181.37732]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 15. 29. 15.  8.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25.  8.  0. 14.  1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 181.02220153808594






Player: 1 
cards in hand: [25.  8.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0. 14.  1.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25. 25. 10. 29.  3.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0. 14.  1.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 21. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25. 25. 10. 29.  3.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0. 14.  1.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [25. 25. 10. 29.  3.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [25. 25. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10. 29.] 
expected returns: [[179.35904]
 [184.46481]
 [184.46481]
 [179.33513]
 [182.98915]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 10. 29.  3.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 181.3773193359375



action possibilites: [-1] 
expected returns: [[158.4057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  3. 29.  8.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 184.46482849121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[156.1751 ]
 [158.71729]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10. 29.  3. 29.  8.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [11.  8.  3.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
adversary owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.40570068359375






Player: 1 
cards in hand: [11.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  0.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3
  1 14  3  0  0  3  3  3 10 25 11 23  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [ 8. 10.  0. 11. 11.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [ 8. 10.  0. 11. 11.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [ 8. 10.  0. 11. 11.] 
adversary cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 11.] 
expected returns: [[182.06044]
 [182.58632]
 [182.05328]
 [184.48897]
 [184.48897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 11. 11.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  2.] 
adversary cards in hand: [15.  3. 23.  3.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.71730041503906



action possibilites: [-1] 
expected returns: [[215.24043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 11.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15.  3. 23.  3.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 182.58631896972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[213.12694]
 [215.72118]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 11.] 
cards in discard: [25.  0.  0. 11.  3. 10. 15. 15. 11.  8.  0. 15. 15. 25. 15. 11. 15. 29.
 15.  8. 25. 25. 10. 29.  3. 29.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15.  3. 23.  3.  3.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 215.2404327392578






Player: 1 
cards in hand: [15.  3. 23.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 23.  3.  3.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15. 15.  0. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 23.  3.  3.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15. 15.  0. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15. 15.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 15.] 
expected returns: [[143.68007]
 [144.39738]
 [144.39738]
 [147.31015]
 [144.39738]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0. 29. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 0. 29.  0.  6.  8.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 215.72119140625



action possibilites: [-1. 15. 15. 15.] 
expected returns: [[151.40062]
 [152.13986]
 [152.13986]
 [152.13986]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.] 
cards in discard: [ 0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 0. 29.  0.  6.  8.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 143.519287109375



action possibilites: [-1] 
expected returns: [[144.66098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [ 0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 0. 29.  0.  6.  8.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 152.13987731933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[142.48071]
 [144.85843]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 0. 29.  0.  6.  8.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
adversary owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.66098022460938






Player: 1 
cards in hand: [ 0. 29.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  6.  8.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  6 29  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1
 14  3  0  0  3  3  3 10 25 23  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 8. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 8. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 8. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
expected returns: [[112.670135]
 [113.12156 ]
 [117.67149 ]
 [113.12156 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  8.  0.] 
cards in discard: [ 0. 15. 29. 15. 15. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [6. 6. 6. 0. 1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 144.85842895507812



action possibilites: [-1] 
expected returns: [[117.064575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 29. 11.] 
cards in discard: [ 0. 15. 29. 15. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [6. 6. 6. 0. 1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.67149353027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[115.449104]
 [117.03231 ]
 [117.61686 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8.  0. 29. 11.] 
cards in discard: [ 0. 15. 29. 15. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [6. 6. 6. 0. 1.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.0645751953125






Player: 1 
cards in hand: [6. 6. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 1.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [10.  3.  8.  3. 25.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 1.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [10.  3.  8.  3. 25.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10.  3.  8.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.] 
expected returns: [[122.53806]
 [122.53167]
 [123.05532]
 [128.0728 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3. 25.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.61685943603516



action possibilites: [-1] 
expected returns: [[145.91928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3. 11. 10.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 128.0727996826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[143.89542]
 [146.48965]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3. 11. 10.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6.  6.  0. 10.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.91928100585938






Player: 1 
cards in hand: [ 3.  6.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  0. 10.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11. 25. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6.  0. 10.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11. 25. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6.  0. 10.] 
cards in discard: [ 3.  0. 10.  3.  0.  0.  3. 25.  8.  0. 14.  1.  8.  3.  0. 15.  3. 23.
  3.  3.  8.  0.  0.  6.  6.  6.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11. 25. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11. 25. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11. 29. 11.] 
expected returns: [[139.45981]
 [141.64467]
 [144.51791]
 [141.64467]
 [143.05971]
 [141.64467]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 11. 29. 11.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.48968505859375



action possibilites: [-1] 
expected returns: [[160.96657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 11. 10. 15.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.51791381835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[158.7564 ]
 [161.25778]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 29. 11. 10. 15.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.96656799316406






Player: 1 
cards in hand: [1. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [15  0  0 10  8  8  0  8  6  3  6  0  0  6  0  0  1  6  0  6  3  1 14  3
  0  0  3  3  3 10 25 23  3  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15. 25. 15. 15.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10. 25. 11. 11. 29. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15. 25. 15. 15.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10. 25. 11. 11. 29. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [15. 25. 15. 15.  0.] 
adversary cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10. 25. 11. 11. 29. 11. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [15. 25. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 15. 15.] 
expected returns: [[155.34564]
 [156.13373]
 [160.8541 ]
 [156.13373]
 [156.13373]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 15. 15.  0.] 
cards in discard: [ 0. 15. 29. 15. 15. 15. 25.  8.  0.  8.  0. 29. 11. 25. 10.  3.  8.  3.
 11. 10. 25. 11. 11. 29. 11. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.2577667236328



action possibilites: [-1] 
expected returns: [[153.03024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 160.85409545898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[151.24509]
 [153.57376]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.03024291992188






Player: 1 
cards in hand: [ 3.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [8. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [25. 15. 15. 15.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [8. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [25. 15. 15. 15.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [8. 3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [11.  8.  0. 29.  3.] 
adversary cards in discard: [25. 15. 15. 15.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[140.56604]
 [142.80222]
 [141.05441]
 [144.25363]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 29.  3.] 
cards in discard: [25. 15. 15. 15.  0. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.5737762451172



action possibilites: [-1. 11.  8.] 
expected returns: [[138.73242]
 [141.03877]
 [139.23203]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [25. 15. 15. 15.  0. 15.  8.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  1.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 143.29281616210938



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 6 
Witch: 4 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 0.] 
cards in discard: [25. 15. 15. 15.  0. 15.  8.  3. 15. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 11 10 25 10 25  8 10  8  8  8 25 15 15 11
 29 15 15 25 15 11 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 20. 30.  8.  0. 10.  2.  0.  5.  6.  9.  9.  2. 10.  0.] 
adversary cards in hand: [ 3. 14.  0.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [15 10  8  8  0  8  6  3  6  0  0  6  0  0  6  0  6  3  1 14  3  0  0  3
  3  3 10 25 23  3  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       40        0
        0        0        0        0        0        0       64        0] 
sum of rewards: -2999931 

action type: gain_card_n - action 8
Learning step: -120002.8046875
desired expected reward: -119863.5703125



