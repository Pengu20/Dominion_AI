 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.49036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    4  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -511 

action type: buy - action -1.0
Learning step: -26.338031768798828
desired expected reward: -10.57742691040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.8283 ]
 [290.18832]
 [283.7319 ]
 [241.46968]
 [280.61697]
 [299.25   ]
 [284.78378]
 [286.84048]
 [258.6409 ]
 [281.53702]
 [275.52374]
 [304.65457]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.915080070495605
desired expected reward: 295.5809631347656



buy possibilites: [-1] 
expected returns: [[256.88483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -6.496278285980225
desired expected reward: 269.0274658203125






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.6833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.401749610900879
desired expected reward: 250.4830780029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[270.2841 ]
 [284.1598 ]
 [277.63202]
 [244.136  ]
 [290.9798 ]
 [280.0377 ]
 [275.9873 ]
 [293.90167]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.32972240447998
desired expected reward: 282.4477233886719



buy possibilites: [-1] 
expected returns: [[266.3303]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.009454727172852
desired expected reward: 272.02825927734375






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [15.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[250.78654]
 [228.03435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.9919586181640625
desired expected reward: 258.33831787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.5046 ]
 [244.03583]
 [236.7671 ]
 [203.19588]
 [249.47336]
 [240.43004]
 [234.95529]
 [251.31285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.2467851638793945
desired expected reward: 243.35302734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[246.2142 ]
 [235.32845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [15.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.7097673416137695
desired expected reward: 243.6031036376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[225.97858]
 [233.19612]
 [198.46288]
 [236.1704 ]
 [246.82812]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [15.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.731357097625732
desired expected reward: 239.19314575195312



buy possibilites: [-1] 
expected returns: [[247.70724]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [15.  3.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 8.0
Learning step: -6.435105800628662
desired expected reward: 229.7352752685547






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 0 8 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 0 8 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 0. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[296.2896 ]
 [278.77057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.5895586013793945
desired expected reward: 242.11769104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.43076]
 [268.85703]
 [231.27686]
 [271.9585 ]
 [285.73862]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.129961967468262
desired expected reward: 283.122314453125



buy possibilites: [-1] 
expected returns: [[280.29352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 27 

action type: buy - action 3.0
Learning step: -5.786248683929443
desired expected reward: 263.07080078125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 15.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 0 8 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 15.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 15.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[339.27057]
 [318.56448]
 [306.30917]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 15.] 
cards in discard: [3. 8. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -5.768380165100098
desired expected reward: 274.525146484375



action possibilites: [-1] 
expected returns: [[275.8928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 8. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action 15.0
Learning step: -7.166801452636719
desired expected reward: 299.32098388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[243.83736]
 [262.0649 ]
 [254.45723]
 [221.25755]
 [209.98082]
 [251.36818]
 [270.74533]
 [255.8545 ]
 [283.9877 ]
 [257.6886 ]
 [226.05437]
 [237.49483]
 [251.15372]
 [218.5883 ]
 [244.40932]
 [274.3097 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 8. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -6.112204074859619
desired expected reward: 269.78057861328125



buy possibilites: [-1] 
expected returns: [[312.43726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3. 8. 3. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -4.214614391326904
desired expected reward: 229.67442321777344






Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[258.26126]
 [245.54225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -8.493403434753418
desired expected reward: 303.94384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[231.7894 ]
 [239.02835]
 [202.8161 ]
 [241.92006]
 [254.70076]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -6.0754289627075195
desired expected reward: 251.56712341308594



buy possibilites: [-1] 
expected returns: [[283.92197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -5.251224994659424
desired expected reward: 226.5381622314453






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [0. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[294.4452 ]
 [271.19458]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [0. 3. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -6.409437656402588
desired expected reward: 277.5125427246094



action possibilites: [-1] 
expected returns: [[262.13684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action 15.0
Learning step: -5.038374423980713
desired expected reward: 262.6907043457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[237.44316]
 [252.19449]
 [230.3917 ]
 [246.2871 ]
 [219.47313]
 [210.58879]
 [243.54073]
 [259.86905]
 [247.06706]
 [270.11356]
 [248.6692 ]
 [224.05571]
 [232.85461]
 [243.89072]
 [217.8745 ]
 [238.42471]
 [263.98193]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: -5.117628574371338
desired expected reward: 257.01922607421875



buy possibilites: [-1] 
expected returns: [[150.83757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  8.  0.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 61.5 

action type: buy - action 25.0
Learning step: -7.036832332611084
desired expected reward: 263.07672119140625






Player: 1 
cards in hand: [ 8.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[227.54147]
 [216.87572]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  8  8  3  0  0 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -1.1182327270507812
desired expected reward: 149.71932983398438



action possibilites: [-1] 
expected returns: [[179.72159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 5
Learning step: -4.854065895080566
desired expected reward: 200.10195922851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.29604]
 [129.07927]
 [170.38637]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -4.167083263397217
desired expected reward: 175.55450439453125



buy possibilites: [-1] 
expected returns: [[190.05455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -3.4385743141174316
desired expected reward: 147.85745239257812






Player: 1 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[191.39485]
 [201.41695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -4.7298970222473145
desired expected reward: 185.32464599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[172.1222 ]
 [185.72029]
 [178.52913]
 [146.6462 ]
 [191.62962]
 [181.69696]
 [176.76488]
 [192.95197]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -5.096868991851807
desired expected reward: 185.34519958496094



buy possibilites: [-1] 
expected returns: [[217.88899]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 25 

action type: buy - action 10.0
Learning step: -2.6117660999298096
desired expected reward: 174.153076171875






Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1.  0.  0.  3. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 1.  0.  0.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  8  3  0 29 10  1] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3. 29.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[245.82068]
 [221.22256]
 [230.92688]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  8.  0.] 
cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8  8  3  0  0 25  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -5.298222064971924
desired expected reward: 212.5907745361328



action possibilites: [-1] 
expected returns: [[175.42068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 10
Learning step: -5.5880351066589355
desired expected reward: 212.1119842529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[147.90524]
 [118.49848]
 [176.1951 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  0. 10. 25.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -3.9758548736572266
desired expected reward: 171.44482421875






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8. 25.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8. 25.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  8. 25.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.  8.] 
expected returns: [[153.81549]
 [138.35089]
 [142.62738]
 [163.26714]
 [142.62738]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 25.  3.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  1.] 
adversary cards in discard: [ 0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -5.051660060882568
desired expected reward: 171.14340209960938



action possibilites: [-1] 
expected returns: [[154.48233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  1.] 
adversary cards in discard: [ 0. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 29 

action type: take_action - action 25.0
Learning step: -3.2771942615509033
desired expected reward: 160.7837371826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.09126]
 [137.5721 ]
 [103.59752]
 [140.09018]
 [151.98605]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  1.] 
adversary cards in discard: [ 0. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -3.304384708404541
desired expected reward: 151.17794799804688



buy possibilites: [-1] 
expected returns: [[155.06119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  8.  0.  0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  1.] 
adversary cards in discard: [ 0. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 46 

action type: buy - action 3.0
Learning step: -1.0897258520126343
desired expected reward: 136.48233032226562






Player: 1 
cards in hand: [29.  8.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  1.] 
cards in discard: [ 0. 11.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  0.  1.] 
cards in discard: [ 0. 11.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  0.  1.] 
cards in discard: [ 0. 11.  0.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[229.7543]
 [216.2047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -1.3306816816329956
desired expected reward: 153.73049926757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[211.33693]
 [223.69308]
 [216.94968]
 [186.59291]
 [228.0987 ]
 [220.24348]
 [215.04715]
 [228.39117]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -5.109759330749512
desired expected reward: 223.47872924804688



buy possibilites: [-1] 
expected returns: [[150.36897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 10.0
Learning step: -5.069056510925293
desired expected reward: 209.9781036376953






Player: 1 
cards in hand: [29.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  8.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  8.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  8.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
expected returns: [[229.75272]
 [240.89006]
 [213.92654]
 [213.92654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  3.  8.] 
cards in discard: [10. 10.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 8. 29.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -1.000740885734558
desired expected reward: 149.36822509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[201.8519 ]
 [167.3461 ]
 [229.02829]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8.  3.  8.] 
cards in discard: [10. 10.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 8. 29.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -5.469489097595215
desired expected reward: 224.251953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [ 8. 29.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [ 8. 29.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [ 8. 29.  0.  0. 10.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[178.50824]
 [170.26474]
 [164.06236]
 [164.06236]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -6.199761867523193
desired expected reward: 222.82852172851562



action possibilites: [-1.  8. 10.] 
expected returns: [[141.30942]
 [134.04753]
 [130.50224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 10.0
Learning step: -2.6902997493743896
desired expected reward: 161.52281188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.91298]
 [135.1685 ]
 [114.89237]
 [138.11565]
 [145.18596]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -1.6185356378555298
desired expected reward: 139.69088745117188






Player: 1 
cards in hand: [0. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  8.  0.] 
adversary cards in discard: [10.  8. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  8.  0.] 
adversary cards in discard: [10.  8. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 25.  8.  0.] 
adversary cards in discard: [10.  8. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[187.95749]
 [199.10242]
 [177.60283]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  8.  0.] 
cards in discard: [10.  8. 10.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  9. 10.  9.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  8.  0.  1.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -1.4058338403701782
desired expected reward: 140.38018798828125



action possibilites: [-1] 
expected returns: [[225.01164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3. 0.] 
cards in discard: [10.  8. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  8.  0.  1.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 25.0
Learning step: -2.4367196559906006
desired expected reward: 196.55288696289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[194.88332]
 [208.76189]
 [201.46173]
 [167.82422]
 [213.74654]
 [204.76634]
 [199.08846]
 [213.79993]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3. 0.] 
cards in discard: [10.  8. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  8.  0.  1.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -4.280257701873779
desired expected reward: 220.73138427734375



buy possibilites: [-1] 
expected returns: [[206.78564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3. 0.] 
cards in discard: [10.  8. 10.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0.  1.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 66 

action type: buy - action 10.0
Learning step: -2.00174880027771
desired expected reward: 197.0867462158203






Player: 1 
cards in hand: [10.  8.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  1.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10] -> size -> 14 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  1.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10] -> size -> 14 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[147.09836]
 [135.15564]
 [135.15564]
 [135.15564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  3.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: -5.3086371421813965
desired expected reward: 201.4770050048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.2434  ]
 [135.38354 ]
 [111.062965]
 [136.9713  ]
 [145.94052 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  3.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: -2.408094882965088
desired expected reward: 144.34756469726562



buy possibilites: [-1] 
expected returns: [[144.13518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10. 10.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29. 11.  3.  0.] 
adversary cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 57 

action type: buy - action 3.0
Learning step: -0.676135241985321
desired expected reward: 134.7073974609375






Player: 1 
cards in hand: [ 8. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  3.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [14.  0.  1.  0.  6.  0.  6. 10.  8.  0.  1.  0. 14.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [ 3.  0.  0. 10. 10. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[119.620735]
 [128.25685 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [ 3.  0.  0. 10. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  8. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0] -> size -> 20 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: -2.0129761695861816
desired expected reward: 142.12220764160156



action possibilites: [-1] 
expected returns: [[186.76865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8. 8.] 
cards in discard: [ 3.  0.  0. 10. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  7. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action 25.0
Learning step: 1.3824833631515503
desired expected reward: 126.77871704101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[164.15192]
 [177.6935 ]
 [172.29404]
 [132.92368]
 [184.5302 ]
 [172.86089]
 [169.8941 ]
 [187.88086]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8. 8.] 
cards in discard: [ 3.  0.  0. 10. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  7. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: -1.979974389076233
desired expected reward: 184.78866577148438



buy possibilites: [-1] 
expected returns: [[110.98209]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8. 8.] 
cards in discard: [ 3.  0.  0. 10. 10. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -242.0 

action type: buy - action 6.0
Learning step: -16.249088287353516
desired expected reward: 116.67459106445312






Player: 1 
cards in hand: [ 8. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  1.  0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  0. 11.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  9.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  0. 11.] 
cards in discard: [ 6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[125.95846]
 [133.25587]
 [119.09335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1
Learning step: -0.32811853289604187
desired expected reward: 110.65397644042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.39561 ]
 [ 90.21378 ]
 [122.901215]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -1.3032734394073486
desired expected reward: 122.48920440673828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 25.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 25.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 25.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.61447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 25.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1.0
Learning step: -1.6526355743408203
desired expected reward: 121.2485580444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[72.66234 ]
 [84.197334]
 [78.205154]
 [50.718098]
 [77.38172 ]
 [88.57296 ]
 [80.841774]
 [81.69742 ]
 [60.600124]
 [76.358894]
 [71.9607  ]
 [89.269966]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 25.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -0.48093682527542114
desired expected reward: 92.51570129394531



buy possibilites: [-1] 
expected returns: [[173.09529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 25.  8.  3.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  8.] 
adversary cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 80 

action type: buy - action 29.0
Learning step: 3.832448959350586
desired expected reward: 85.52987670898438






Player: 1 
cards in hand: [10.  0.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  8.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29 10  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6. 11. 29.  8.  0.  1.  0. 11.  0.  0.  0. 14.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 10.] 
expected returns: [[111.65374 ]
 [103.1496  ]
 [ 99.318214]
 [ 99.318214]
 [ 99.318214]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 10. 10.] 
cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  6. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1
Learning step: -3.9944894313812256
desired expected reward: 169.10079956054688



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[137.4552  ]
 [125.827896]
 [122.96655 ]
 [122.96655 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 10.  0.] 
cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  6. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 69 

action type: take_action - action 10.0
Learning step: 1.5866997241973877
desired expected reward: 97.02981567382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.64278]
 [ 93.52178]
 [134.54836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 10.  0.] 
cards in discard: [ 6. 25.  8.  3.  3. 29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  6. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 68 

action type: take_action - action -1.0
Learning step: -0.8073101043701172
desired expected reward: 136.6479034423828






Player: 1 
cards in hand: [11.  0.  6. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 14.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 14.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[56.457516]
 [44.6788  ]
 [62.00723 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1.0
Learning step: -3.1320557594299316
desired expected reward: 131.41632080078125



action possibilites: [-1. 25.] 
expected returns: [[72.66931]
 [78.6655 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  6. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10] -> size -> 23 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 69 

action type: take_action - action 29.0
Learning step: 3.0627267360687256
desired expected reward: 45.12146759033203



action possibilites: [-1] 
expected returns: [[84.195366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: take_action - action 25.0
Learning step: 2.361121416091919
desired expected reward: 81.02660369873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.538525]
 [74.30612 ]
 [68.055504]
 [32.135586]
 [64.95509 ]
 [80.35659 ]
 [68.202286]
 [69.88627 ]
 [44.464825]
 [65.450226]
 [59.716145]
 [82.922874]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 14.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: take_action - action -1
Learning step: 1.7147057056427002
desired expected reward: 85.91007232666016






Player: 1 
cards in hand: [ 0.  1. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 14.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  6.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  5.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  5.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[59.744   ]
 [50.46926 ]
 [49.179394]
 [50.46926 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  8.] 
cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 29.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: buy - action -1.0
Learning step: -0.14488601684570312
desired expected reward: 82.77801513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.7477  ]
 [30.07988 ]
 [57.668365]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  8.] 
cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  5. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 29.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[-5  0  3 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1.0
Learning step: 1.208053469657898
desired expected reward: 55.984867095947266



buy possibilites: [-1] 
expected returns: [[53.566914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  8.] 
cards in discard: [29. 25.  3.  0.  0.  0.  6. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 29.  0.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -253.0 

action type: buy - action 6.0
Learning step: -12.948740005493164
desired expected reward: 17.131139755249023






Player: 1 
cards in hand: [ 0.  6.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 29.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6] -> size -> 18 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 29.  0.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6] -> size -> 18 
adversary victory points: 2
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[55.596645]
 [47.220737]
 [46.30923 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 8.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1
Learning step: 0.7962228655815125
desired expected reward: 54.363136291503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.34911 ]
 [39.190533]
 [54.462017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 8.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 0.6716718673706055
desired expected reward: 55.559814453125



buy possibilites: [-1] 
expected returns: [[79.51736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  3.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 8.] 
adversary cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 17.0 

action type: buy - action 0.0
Learning step: 0.4716850221157074
desired expected reward: 43.82079315185547






Player: 1 
cards in hand: [8. 0. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 8.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  3. 29.  8.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 8.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 26. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  3. 29.  8.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 8.] 
cards in discard: [11.  0.  6. 14.  3.  6.  8. 14. 11.  0.  1. 14.  0.  0.  6.  6. 29.  0.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  3. 29.  8.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[56.20164 ]
 [61.835827]
 [50.24156 ]
 [49.546383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 29.  8.] 
cards in discard: [ 0.  8.  3. 10.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: -0.8902969360351562
desired expected reward: 78.62705993652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.423054]
 [27.621584]
 [54.639324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  3. 29.  8.] 
cards in discard: [ 0.  8.  3. 10.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 0.08166046440601349
desired expected reward: 55.29802703857422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  8.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  0. 10.] 
adversary cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[22.103416]
 [14.626426]
 [14.626426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  8. 14.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1.0
Learning step: -0.48843881487846375
desired expected reward: 54.15089416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.057401 ]
 [15.526135 ]
 [ 1.7416699]
 [14.969245 ]
 [21.305325 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  5.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  8. 14.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 1.0957063436508179
desired expected reward: 22.803442001342773



buy possibilites: [-1] 
expected returns: [[51.82079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0. 10.] 
cards in discard: [ 0.  8.  3. 10.  3.  0.  3. 25.  3. 29.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  4.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  8. 14.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 45 

action type: buy - action 8.0
Learning step: 2.6675050258636475
desired expected reward: 17.636756896972656






Player: 1 
cards in hand: [ 8. 14.  8.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  8.  8. 14.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  4.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 14.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  4.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 14.] 
cards in discard: [29.  0.  0. 10.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  4.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 14.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.068165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  1.  6.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: discard_down_to_3_cards - action 1
Learning step: -0.25965234637260437
desired expected reward: 53.75526428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.315198 ]
 [15.060016 ]
 [ 1.5707729]
 [15.273252 ]
 [22.117691 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  1.  6.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 0.8701621294021606
desired expected reward: 27.140981674194336



buy possibilites: [-1] 
expected returns: [[104.978096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  1.  6.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 7.0 

action type: buy - action 0.0
Learning step: 2.146247148513794
desired expected reward: 13.46144962310791






Player: 1 
cards in hand: [ 6.  0. 11.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  1.  6.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  1.  6.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  1.  6.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[66.039474]
 [60.86996 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [8. 0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  0 25  0 10  3 10 10  3  6 29  6  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  1. 11.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: -1.9869197607040405
desired expected reward: 102.99117279052734



action possibilites: [-1] 
expected returns: [[96.93053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  1. 11.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.6521682739257812
desired expected reward: 69.2275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.322914]
 [58.516823]
 [98.871   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  1. 11.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: -0.12759743630886078
desired expected reward: 96.80293273925781






Player: 1 
cards in hand: [ 3.  0. 14.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  1. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  1. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 25. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  1. 11.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  3.  8.  0.] 
adversary cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
expected returns: [[86.01761 ]
 [86.93178 ]
 [73.752716]
 [74.44228 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  8.  0.] 
cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  4. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 29.  0.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: -1.7935360670089722
desired expected reward: 97.07746887207031



action possibilites: [-1] 
expected returns: [[30.260925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  3. 29.] 
cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 29.  0.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 25.0
Learning step: -1.2293094396591187
desired expected reward: 83.97429656982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -0.8871472]
 [-11.061903 ]
 [ 19.553738 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  3. 29.] 
cards in discard: [8. 0. 0. 0. 6. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 29.  0.] 
adversary cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 0.968619167804718
desired expected reward: 31.229543685913086






Player: 1 
cards in hand: [ 0.  3.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 29.  0.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  7.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [29.  0.  0. 10.  0.  0.  8. 14.  8.  8.  8. 14. 10.  6.  0. 11.  1.  6.
  3.  3.  0. 14.  1. 11.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[ 3.515999 ]
 [-1.7434509]
 [-1.0472944]
 [-1.0472944]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  1. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1.0
Learning step: 0.850003719329834
desired expected reward: 20.403766632080078



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[33.298153]
 [27.830908]
 [25.959541]
 [25.959541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  1. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action 10.0
Learning step: 3.6415798664093018
desired expected reward: 0.9695837497711182





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.509214]
 [14.921515]
 [33.375473]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  1. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1.0
Learning step: 1.7650350332260132
desired expected reward: 35.06318664550781



buy possibilites: [-1] 
expected returns: [[71.62259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10. 10.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  1. 29.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 27.0 

action type: buy - action 0.0
Learning step: 1.6381607055664062
desired expected reward: 28.10511016845703






Player: 1 
cards in hand: [ 6.  1. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 29.  0.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 29.  0.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 29.  0.  6.] 
cards in discard: [10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
adversary owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-3.790435]
 [-4.38017 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8  3  0  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3. 11.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: -1.8217557668685913
desired expected reward: 69.80083465576172



action possibilites: [-1] 
expected returns: [[123.59634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3. 11.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: trash_cards_n_from_hand - action 3
Learning step: 5.825221538543701
desired expected reward: 1.9391427040100098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.67023 ]
 [103.670906]
 [119.352   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3. 11.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: -0.7794300317764282
desired expected reward: 122.81690979003906






Player: 1 
cards in hand: [29.  3. 11.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  6. 14.] 
cards in discard: [10.  6.  1. 29.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  3. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6. 14.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  2. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6. 14.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 24. 30.  8.  2. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6. 14.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  2. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 25.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-10.7881565]
 [-10.414175 ]
 [ -7.6246195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  6.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  2. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 1.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: buy - action -1.0
Learning step: -3.8251004219055176
desired expected reward: 115.52689361572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.716995]
 [-16.046928]
 [ -8.842995]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 25.  6.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  2. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 1.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[-5  0  2 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.6416640281677246
desired expected reward: -8.14649772644043



buy possibilites: [-1] 
expected returns: [[42.221516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 25.  6.  0.] 
cards in discard: [ 0. 10.  8.  0.  3. 10. 10.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 0. 8. 1.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6  0] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -264.0 

action type: buy - action 6.0
Learning step: -11.447669982910156
desired expected reward: -27.49459457397461






Player: 1 
cards in hand: [8. 8. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 1.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6
  8 14  3 29  8 10  3  6 29 10  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.319748 ]
 [12.2999525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: 0.014185524545609951
desired expected reward: 42.23570251464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 5.163432 ]
 [11.565504 ]
 [ 9.522114 ]
 [-4.321661 ]
 [14.870574 ]
 [ 9.3067   ]
 [ 8.2974825]
 [17.391645 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 1.2143809795379639
desired expected reward: 17.703487396240234



buy possibilites: [-1] 
expected returns: [[-15.704168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  0. 29.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  6. 14.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 6.0 

action type: buy - action 0.0
Learning step: -0.3115147054195404
desired expected reward: 4.851903915405273






Player: 1 
cards in hand: [ 6. 10.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  6. 14.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [10.  3. 10.  8.  6.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  3.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[34.456715]
 [31.520119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.] 
cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: discard_down_to_3_cards - action 1
Learning step: 0.8026599884033203
desired expected reward: 35.7230224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.372883]
 [24.174938]
 [34.158783]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.] 
cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 10.  0.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 0.7625905871391296
desired expected reward: 35.21931838989258



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 25.  0.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 25.  0.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 25.  0.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 25.  0.] 
adversary cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[41.798973]
 [29.123402]
 [50.33183 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 25.  0.] 
cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1.0
Learning step: 1.0449402332305908
desired expected reward: 35.203731536865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.23816 ]
 [ 9.110909]
 [41.38303 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 25.  0.] 
cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 24. 30.  8.  1. 10.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 0.34881362318992615
desired expected reward: 42.14779281616211



buy possibilites: [-1] 
expected returns: [[20.344536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 25.  0.] 
cards in discard: [ 0.  6.  0.  0.  0. 29. 10.  8.  3. 10.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 24. 30.  8.  0. 10.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 11.  0.  0.] 
adversary cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14] -> size -> 37 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 6.0
Learning step: -13.740588188171387
desired expected reward: -4.773802757263184






Player: 1 
cards in hand: [ 3. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  0. 10.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  2.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.] 
cards in discard: [10.  6.  1. 29.  0.  6.  6.  0. 11. 29.  3.  6. 14.  8.  8.  8.  1.  8.
 14.  6. 10.  3.  6. 14. 10.  0.  0. 14.  0.  0. 16.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-0.06991196]
 [-1.0790658 ]
 [-1.0790658 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 14. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0.21901312470436096
desired expected reward: 20.563549041748047



action possibilites: [-1] 
expected returns: [[27.077398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 14. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 2
Learning step: 2.957821846008301
desired expected reward: 0.9862140417098999





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.170616]
 [14.017656]
 [13.652464]
 [23.679806]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 24. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 14. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 1.2740496397018433
desired expected reward: 28.35144805908203



buy possibilites: [-1] 
expected returns: [[47.11574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 14. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 64 

action type: buy - action 3.0
Learning step: 3.5592217445373535
desired expected reward: 17.576873779296875






Player: 1 
cards in hand: [ 3. 14. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10.  8. 10.  3.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 23. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 23. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10. 10.] 
adversary cards in discard: [3. 8. 0. 0. 8. 3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[52.89215]
 [48.23986]
 [48.23986]
 [48.23986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3] -> size -> 40 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: discard_down_to_3_cards - action 3
Learning step: 1.827828288078308
desired expected reward: 13.808598518371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.71407]
 [52.98061]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [3. 8. 0. 0. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3] -> size -> 40 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -0.21835938096046448
desired expected reward: 52.67377853393555



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  6.  6.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  1.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  6.  6.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  3.  6.  6.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-22.947304]
 [-25.691072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  6.  6.] 
cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  6.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 41 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1.0
Learning step: -1.8901957273483276
desired expected reward: 51.09040451049805





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-22.412634]
 [-20.980623]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.  6.] 
cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  6.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 41 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 1.96233069896698
desired expected reward: -20.98497200012207



buy possibilites: [-1] 
expected returns: [[-4.0015454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  6.  6.] 
cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  6.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 41 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: 0.830596923828125
desired expected reward: -21.5820369720459






Player: 1 
cards in hand: [ 8.  8. 29.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  6.  6.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  3  0 29  1 11  6  0  8  1 14  6 14  0  6 11  0 10  6  8
 14  3 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0. 29.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0. 29.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0. 29.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0. 29.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[22.089115]
 [23.104164]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 25.] 
cards in discard: [ 3.  8.  0.  0.  8.  3. 10. 10. 10.  0. 29.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6. 11.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: 1.5107271671295166
desired expected reward: -2.4908182621002197



action possibilites: [-1] 
expected returns: [[6.2754493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6. 11.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 37 

action type: take_action - action 25.0
Learning step: 0.835988461971283
desired expected reward: 23.94017219543457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-0.7509248]
 [ 4.292058 ]
 [ 2.0850115]
 [ 6.1808486]
 [ 0.6968086]
 [ 5.746079 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  8.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6. 11.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: 1.5684304237365723
desired expected reward: 7.843879699707031



buy possibilites: [-1] 
expected returns: [[15.714761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6. 11.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 54 

action type: buy - action 11.0
Learning step: 2.7649686336517334
desired expected reward: 8.94581127166748






Player: 1 
cards in hand: [14.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6. 11.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10. 10.  6.  0.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6. 11.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10. 10.  6.  0.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6. 11.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10. 10.  6.  0.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-10.24586]
 [-12.67295]
 [-12.67295]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  6.  0.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [16.  3.  6.  0. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: -0.24558082222938538
desired expected reward: 15.4691801071167



action possibilites: [-1. 10.] 
expected returns: [[12.517255]
 [ 5.007003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.  0.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [16.  3.  6.  0. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: 2.6972620487213135
desired expected reward: -9.97568416595459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 7.105874]
 [11.307956]
 [16.774239]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  0.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 22. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [16.  3.  6.  0. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 1.460171103477478
desired expected reward: 13.977408409118652



buy possibilites: [-1] 
expected returns: [[-5.192461]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  0.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [16.  3.  6.  0. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 55 

action type: buy - action 3.0
Learning step: 2.067772388458252
desired expected reward: 13.375715255737305






Player: 1 
cards in hand: [16.  3.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  0. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3
 29  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 30.  8.  0.  9.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[15.769084]
 [12.088496]
 [11.782997]
 [11.782997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8.  8.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  8.  1. 29.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: 2.4116554260253906
desired expected reward: -2.7808055877685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.902078]
 [16.135254]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  8.  8.] 
cards in discard: [11. 25.  0.  0.  6.  3.  0.  3.  3. 10.  6. 10.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  8.  1. 29.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0] -> size -> 42 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 1.3771898746490479
desired expected reward: 17.146276473999023



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  6.  8.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  1. 29.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  1. 29.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 21. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  1. 29.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[46.61697 ]
 [40.549118]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  6. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 1.5371599197387695
desired expected reward: 17.67241668701172



action possibilites: [-1.] 
expected returns: [[-16.961372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  6. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 10.0
Learning step: -0.05908718332648277
desired expected reward: 40.49003982543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-16.13211 ]
 [-17.789656]
 [-16.103182]
 [-16.866253]
 [-17.377964]
 [-17.638428]
 [-13.218388]
 [-15.913091]
 [-15.188131]
 [-16.504547]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  6. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 2.845317840576172
desired expected reward: -14.11605453491211



buy possibilites: [-1] 
expected returns: [[54.213223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  6. 10.] 
adversary cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 79 

action type: buy - action 14.0
Learning step: 5.830716609954834
desired expected reward: -7.387668132781982






Player: 1 
cards in hand: [ 0. 14.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  6. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 6.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  6. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 6.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  6. 10.] 
cards in discard: [ 3. 14.  3. 11.  8.  0.  8.  0.  3.  0.  8. 10.  0.  8. 29.  6.  0. 14.
  0.  0.  6. 11. 16.  0. 16.  6.  0. 10.  3. 14.  6.  8.  1. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 6.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.049894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 6.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -1.5192837715148926
desired expected reward: 52.693939208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.512704]
 [ -5.682117]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 6.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 1.5037221908569336
desired expected reward: -5.54617166519165



buy possibilites: [-1] 
expected returns: [[51.986137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 6.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: 1.6953232288360596
desired expected reward: -11.817378044128418






Player: 1 
cards in hand: [29.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25.  0. 10.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25.  0. 10.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  5. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25.  0. 10.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 25.  0. 10.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[-53.013325]
 [-56.13882 ]
 [-54.419342]
 [-55.17188 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0. 10.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [16.  6.  0. 14.  0.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -2.4724040031433105
desired expected reward: 49.51373291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-56.17523]
 [-53.28813]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0. 10.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [16.  6.  0. 14.  0.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 2.7755343914031982
desired expected reward: -50.2378044128418



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0. 14.  0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 29. 10. 11.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-14.50456 ]
 [-14.172196]
 [-14.554534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [10. 11.  0.  0.  6.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: discard_down_to_3_cards - action 1
Learning step: 0.7355073690414429
desired expected reward: 6.5615620613098145





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.491572]
 [-14.401596]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [10. 11.  0.  0.  6.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 1.7768677473068237
desired expected reward: -12.727691650390625



buy possibilites: [-1] 
expected returns: [[45.803165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  3.  0.  6.  3.  6.  0.  6.  8. 25.  0. 10.  3.
 29. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [10. 11.  0.  0.  6.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  30   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: buy - action 0.0
Learning step: 1.5051498413085938
desired expected reward: -10.986422538757324






Player: 1 
cards in hand: [10. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  6.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.  6.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.  6.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.6421854]
 [-1.8640517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [11. 14.  3.  0. 14.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -0.9215239882469177
desired expected reward: 44.88164138793945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.08129311]
 [ 1.7417047 ]
 [ 4.376849  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [11. 14.  3.  0. 14.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 1.2735389471054077
desired expected reward: 3.915717601776123



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 14.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  0. 14.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 14.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 14.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 14.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.2896967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3. 29.  8.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: discard_down_to_3_cards - action 1
Learning step: 1.3083107471466064
desired expected reward: 4.972460746765137





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.186804]
 [6.294793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  8.  3. 29.  8.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 48 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 1.1489976644515991
desired expected reward: 7.438694477081299



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 29.  8.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  1 11  0  8  1 14  6 14  0  6 11  0 10  6  8 14  3 29
  8 10  3  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [14.  0. 10.  6.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [14.  0. 10.  6.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [14.  0. 10.  6.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [14.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[12.6285095]
 [ 2.3186095]
 [ 8.703948 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  6.  0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1.0
Learning step: 1.733449935913086
desired expected reward: 8.028246879577637





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[2.3728688]
 [4.872957 ]
 [7.1342373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  6.  0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 1.336689829826355
desired expected reward: 13.965206146240234



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 11.  0. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  4. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
adversary owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [25.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[ -9.4910345]
 [ -9.325213 ]
 [-11.269795 ]
 [-10.59642  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 10.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0 10  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 46 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: discard_down_to_3_cards - action 3
Learning step: 0.9925526976585388
desired expected reward: 13.638867378234863



action possibilites: [-1] 
expected returns: [[17.350258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 46 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: trash_cards_n_from_hand - action 1
Learning step: 3.7766666412353516
desired expected reward: -6.949048042297363





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.553953]
 [16.789125]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 46 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: 2.294710397720337
desired expected reward: 19.644968032836914






Player: 1 
cards in hand: [6. 8. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 8.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 11  0  1 14  6 14  0  6 11  0 10  6  8 14 29  8 10  3
  6 29 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  6. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  6. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  6. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  6. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[15.611632 ]
 [12.666871 ]
 [12.8051405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  6. 10.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.  8.  6.
  8.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.8270780444145203
desired expected reward: 17.61619758605957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.29336]
 [15.61315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  6. 10.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  3.  6.  0.  3. 14.  0. 10.  6.  0. 11.  0.  8.
 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.  8.  6.
  8.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.8823698163032532
desired expected reward: 16.47836685180664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 16.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.  8.  6.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.  8.  6.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  7.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [29.  1. 14. 29.  0.  0.  0. 15. 14. 16.  6.  0.  0.  0. 10. 11.  0.  0.
  6.  0. 14. 11.  3.  0. 14.  8.  6. 14. 14.  3.  3.  0.  0.  0.  8.  6.
  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-14.586464]
 [ -9.706997]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [11.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.3067392408847809
desired expected reward: 15.91989803314209



action possibilites: [-1] 
expected returns: [[14.066341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10.] 
adversary cards in discard: [11.  8.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 14.0
Learning step: 3.1518425941467285
desired expected reward: -6.555154323577881





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 2.754087 ]
 [ 7.5445876]
 [ 6.134002 ]
 [ 4.6767354]
 [ 9.897034 ]
 [ 5.829021 ]
 [-1.2202336]
 [ 4.719594 ]
 [ 2.9991832]
 [10.77178  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10.] 
adversary cards in discard: [11.  8.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 1.7919305562973022
desired expected reward: 15.858271598815918






Player: 1 
cards in hand: [ 0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11.  8.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [14.  3.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [11.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [14.  3.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14.] 
cards in discard: [11.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [14.  3.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14.] 
cards in discard: [11.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [14.  3.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 14.] 
cards in discard: [11.  8.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [14.  3.  0.  0.  3.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-18.850552]
 [-20.125353]
 [-20.125353]
 [-19.022789]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 11.] 
cards in discard: [14.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15. 29.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.37494707107543945
desired expected reward: 11.146728515625



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[30.012224]
 [23.003613]
 [27.949717]
 [23.456244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 29.] 
cards in discard: [14.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15. 29.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 10.0
Learning step: 3.9607720375061035
desired expected reward: -16.164581298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[25.623476]
 [29.266584]
 [35.0955  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11. 29.] 
cards in discard: [14.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15. 29.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 1.5466465950012207
desired expected reward: 31.55885887145996



buy possibilites: [-1] 
expected returns: [[31.93159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11. 29.] 
cards in discard: [14.  3.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 15. 29.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 66 

action type: buy - action 3.0
Learning step: 2.5551323890686035
desired expected reward: 31.821701049804688






Player: 1 
cards in hand: [ 0.  3.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15. 29.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29
 10  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  3. 10.  8.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
adversary owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [3. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.99123 ]
 [18.024956]
 [18.024956]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 6.] 
cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 25  0  3 10 10  3 29  6  0  8  0  0  6  0  6  3  0 11  3 14  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0.  6. 10.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 0.7607476115226746
desired expected reward: 32.69233703613281



action possibilites: [-1] 
expected returns: [[30.55556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0.  6. 10.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: trash_cards_n_from_hand - action 9
Learning step: 2.562973737716675
desired expected reward: 23.053497314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.26666 ]
 [29.197706]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0.  6. 10.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 1.9935654401779175
desired expected reward: 32.54912567138672






Player: 1 
cards in hand: [ 6.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  6. 10.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6. 25.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.  8.  8.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  6. 10.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6. 25.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.  8.  8.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  6. 10.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  6. 25.  3.  0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.  8.  8.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-3.5342581]
 [-4.5813656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 25.  3.  0.] 
cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  1.  0. 14.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -0.14889059960842133
desired expected reward: 29.0488224029541





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.1558604]
 [-4.033247 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 25.  3.  0.] 
cards in discard: [14.  3.  0.  0.  3.  3. 10.  0. 10.  0. 11. 29.  8.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  8.  1.  0. 14.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 1.4757968187332153
desired expected reward: -2.0584588050842285



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  0. 14.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  6.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.2888627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: discard_down_to_3_cards - action 3
Learning step: 1.6906778812408447
desired expected reward: -1.2928900718688965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-1.4187175]
 [ 0.8272219]
 [ 6.859865 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 1.0941599607467651
desired expected reward: 8.569597244262695



buy possibilites: [-1] 
expected returns: [[3.4443233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 0. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 47 

action type: buy - action 3.0
Learning step: 2.386136293411255
desired expected reward: 3.2133584022521973






Player: 1 
cards in hand: [ 0. 14.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  6. 29.  3.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  6. 29.  3.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  6. 29.  3.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 29.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-18.80316]
 [-19.36614]
 [-19.28491]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 29.  3.  6.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 29.  6.  0. 14.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: 0.8484044075012207
desired expected reward: 4.292727470397949



action possibilites: [-1.  8.] 
expected returns: [[20.262215]
 [16.138998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 29.  6.  0. 14.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: discard_n_cards - action 3
Learning step: 3.823103666305542
desired expected reward: -15.267889976501465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.928092]
 [17.1798  ]
 [20.478172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 29.  6.  0. 14.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 1.8442188501358032
desired expected reward: 22.10643196105957






Player: 1 
cards in hand: [ 8. 29.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  6.  0. 14.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0. 25.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  6.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 25.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  6.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 16. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 25.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  6.  0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 25.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-5.018048]
 [-4.825527]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: discard_down_to_3_cards - action 5
Learning step: 1.226177453994751
desired expected reward: -6.503732681274414



action possibilites: [-1] 
expected returns: [[17.330778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 40 

action type: take_action - action 25.0
Learning step: 2.6312191486358643
desired expected reward: -2.194312810897827





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.7578745]
 [13.531089 ]
 [19.042406 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: 1.4286121129989624
desired expected reward: 18.759389877319336



buy possibilites: [-1] 
expected returns: [[-4.0098004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -0.17811398208141327
desired expected reward: 10.579755783081055






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  8. 10. 11.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 15. 30.  8.  0.  8.  5.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  8. 10. 11.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  8. 10. 11.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[29.664522]
 [25.19068 ]
 [24.960272]
 [28.714212]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10. 11.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [16. 11. 16.  0.  8.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 1.7720731496810913
desired expected reward: -2.237727165222168



action possibilites: [-1] 
expected returns: [[15.526818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [16. 11. 16.  0.  8.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 48 

action type: gain_card_n - action 1
Learning step: 1.426125407218933
desired expected reward: 27.89068603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.232654]
 [16.46681 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [16. 11. 16.  0.  8.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: 1.4786396026611328
desired expected reward: 17.00545883178711



buy possibilites: [-1] 
expected returns: [[-1.1901727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  6. 29.  8.  6.  0. 10.  0.  0. 25.  3.  0.
  0. 14.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [16. 11. 16.  0.  8.] 
adversary cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -0.07224085181951523
desired expected reward: 9.160406112670898






Player: 1 
cards in hand: [16. 11. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 16.  0.  8.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 11  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10
  6  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3
 11  3  3 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  4.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.] 
cards in discard: [11.  8.  0. 10. 10.  0. 11. 14. 10. 15.  3.  0. 29.  3.  6.  0.  0.  6.
 10. 11. 14.  0.  8.  1.  0.  3.  0. 14.  8.  0.  0.  3. 14.  8. 29.  6.
  0. 11.  3.  0.  3.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[47.168514]
 [37.982365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [29. 14. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 1.9875974655151367
desired expected reward: 0.7974247932434082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[43.79878 ]
 [47.523888]
 [47.02001 ]
 [45.860832]
 [49.335686]
 [46.448463]
 [41.03873 ]
 [45.821625]
 [43.929737]
 [50.8237  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6.  3. 10.  2. 10.  8.] 
adversary cards in hand: [29. 14. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -0.34937191009521484
desired expected reward: 46.81913757324219



buy possibilites: [-1] 
expected returns: [[4.878645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [29. 14. 14.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 51 

action type: buy - action 29.0
Learning step: 0.3373466432094574
desired expected reward: 46.78580093383789






Player: 1 
cards in hand: [29. 14. 14.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 14.  6.  1.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0 29] -> size -> 28 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14. 14.  6.  1.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0 29] -> size -> 28 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[31.941256]
 [30.332396]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25  0  3 10 10  3 29  0  8  0  0  6  0  6  3  0 11  3 14  0  0  3  3
  0  1  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [11.  3.  8. 11. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 1.4101738929748535
desired expected reward: 6.288818836212158



action possibilites: [-1] 
expected returns: [[-2.6060643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  0.  0. 14.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [11.  3.  8. 11. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.4559011459350586
desired expected reward: 29.165149688720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.343382 ]
 [-3.2231805]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  0. 14.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [11.  3.  8. 11. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: 1.9976354837417603
desired expected reward: -0.6084288358688354



buy possibilites: [-1] 
expected returns: [[28.551758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [11.  3.  8. 11. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: 1.3095834255218506
desired expected reward: -3.033795118331909






Player: 1 
cards in hand: [11.  3.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 11. 11.] 
cards in discard: [29. 14. 14.  6.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  3. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 29. 10.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11.] 
cards in discard: [29. 14. 14.  6.  1. 14.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 29. 10.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 11.] 
cards in discard: [29. 14. 14.  6.  1. 14.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 29. 10.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 11.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 29. 10.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[22.068533]
 [19.192678]
 [18.863613]
 [19.192678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 10.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0] -> size -> 54 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -0.02160787582397461
desired expected reward: 28.530149459838867





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.376497]
 [23.335558]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 29. 10.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0] -> size -> 54 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: 0.33576497435569763
desired expected reward: 22.40428924560547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 27. 30. 15. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[37.549984]
 [35.004673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [29. 15.  3.  0.  0.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: 0.10504274815320969
desired expected reward: 23.440601348876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.226765]
 [40.542126]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [29. 15.  3.  0.  0.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -0.5453302264213562
desired expected reward: 37.00465774536133



buy possibilites: [-1] 
expected returns: [[1.9971697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [29. 15.  3.  0.  0.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -2.866401433944702
desired expected reward: 34.3603515625






Player: 1 
cards in hand: [29. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3.  0.  0.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.  6.  0.  8.
  3.  3.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  3.  0.  0.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.  6.  0.  8.
  3.  3.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  3.  0.  0.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.
  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 13. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.  6.  0.  8.
  3.  3.] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-9.211864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.  6.  0.  8.
  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 13. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 14. 16.  0. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.
  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3  3] -> size -> 56 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -0.3571254312992096
desired expected reward: 1.6400443315505981





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-11.463765]
 [-12.013614]
 [-11.144251]
 [-11.702991]
 [-11.390885]
 [-12.054411]
 [-10.164182]
 [-11.292179]
 [-11.055096]
 [-10.470546]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [29.  0.  0. 14.  0.  0.  0.  8.  0.  3.  0. 10. 29. 10.  0.  6.  0.  8.
  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 27. 30. 13. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 3. 14. 16.  0. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.
  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3  3] -> size -> 56 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: 0.16177339851856232
desired expected reward: -9.050090789794922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 14. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 16.  0. 11.] 
cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.
  3. 29. 15.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  3  6 29 10  6
  0  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11
  3  3 11 11 14  0  3  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 13. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 0 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 1 
Poacher: 2 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 10 10  3 29  0  8  0  0  0  6  3  0 11  3 14  0  0  3  3  0  1  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 13. 30.  8.  0.  8.  3.  0.  9.  5.  2. 10.  2. 10.  8.] 
adversary cards in hand: [14.  0. 11.] 
adversary cards in discard: [29. 14. 14.  6.  1. 14.  0. 11.  3.  8. 11. 11.  3.  0.  0.  0.  0.  1.
  3. 29. 15.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  1  0  1 14 14  0  6 11  0 10  6  8 14 29  8 10  6 29 10  6  0
  8 14 16  8  3  8  0  0 16  0  3  0 14 15  0  0 14  0 11  0 10  3 11  3
  3 11 11 14  0  3  3  0] -> size -> 56 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5 500   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 509 

action type: buy - action -1.0
Learning step: 25.973526000976562
desired expected reward: 15.502986907958984



