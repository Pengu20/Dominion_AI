 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.1088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -50    0    0    0    0    0    0    0  -12    0    0
    9    0] 
sum of rewards: -555 

action type: buy - action 10.0
Learning step: -31.569339752197266
desired expected reward: 44.81743240356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[278.26178]
 [290.92697]
 [286.4331 ]
 [251.51031]
 [283.59244]
 [299.38956]
 [286.91992]
 [288.22238]
 [265.29852]
 [285.0972 ]
 [279.7603 ]
 [304.26685]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.281176567077637
desired expected reward: 295.1726379394531



buy possibilites: [-1] 
expected returns: [[286.45816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -7.826344966888428
desired expected reward: 278.6067199707031






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.66293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.375308990478516
desired expected reward: 279.0828552246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.8225 ]
 [298.8213 ]
 [293.4137 ]
 [254.11888]
 [308.99075]
 [293.35403]
 [291.20013]
 [315.00336]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.843684196472168
desired expected reward: 302.1607360839844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.17746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 2
Learning step: -4.976166725158691
desired expected reward: 229.4738006591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[287.69687]
 [292.74515]
 [265.10422]
 [295.48468]
 [305.9035 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.510068893432617
desired expected reward: 293.54913330078125



buy possibilites: [-1] 
expected returns: [[290.0611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -7.8978590965271
desired expected reward: 287.5868225097656






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1. 14.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1. 14.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1. 14.  3.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[279.94553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.2726469039917
desired expected reward: 281.7884521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[261.0338 ]
 [272.56653]
 [266.88904]
 [238.1088 ]
 [265.7318 ]
 [278.39008]
 [269.1584 ]
 [269.85413]
 [248.66905]
 [265.52252]
 [260.6641 ]
 [281.33954]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.916197299957275
desired expected reward: 271.21307373046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[297.70242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.421199321746826
desired expected reward: 273.9183349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.46185]
 [278.04858]
 [273.4189 ]
 [238.68748]
 [285.0419 ]
 [274.3052 ]
 [271.95056]
 [288.84442]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.675646781921387
desired expected reward: 288.9145202636719



buy possibilites: [-1] 
expected returns: [[276.04663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -21.32332420349121
desired expected reward: 217.3641357421875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1.  0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1.  0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1.  0.] 
cards in discard: [1. 3. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.5283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.245262145996094
desired expected reward: 267.8013610839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[268.2082 ]
 [284.65955]
 [278.04175]
 [237.59627]
 [293.74182]
 [279.4843 ]
 [275.78336]
 [299.00107]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.484637260437012
desired expected reward: 286.3851013183594



buy possibilites: [-1] 
expected returns: [[269.6198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 3.0
Learning step: -7.856205940246582
desired expected reward: 270.1855773925781






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[239.94356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: discard_down_to_3_cards - action 0
Learning step: -5.0663323402404785
desired expected reward: 193.19847106933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[211.95512]
 [224.86113]
 [219.83607]
 [186.1166 ]
 [232.52628]
 [220.69057]
 [218.16132]
 [236.59833]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.477597713470459
desired expected reward: 232.38499450683594



buy possibilites: [-1] 
expected returns: [[243.1215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -7.1775221824646
desired expected reward: 204.777587890625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [3. 8. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[240.1464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [3. 8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.342621803283691
desired expected reward: 235.7788848876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[216.5688 ]
 [222.72673]
 [195.9342 ]
 [223.89632]
 [237.00426]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [3. 8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.394456386566162
desired expected reward: 230.98129272460938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 1.] 
cards in discard: [14.  0.  3.  3.  0.  0.  0.  0.  3.  3.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[241.25822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -7.001936435699463
desired expected reward: 230.0023193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[206.36797]
 [219.82849]
 [215.28993]
 [181.06898]
 [228.64322]
 [215.12451]
 [213.27368]
 [233.109  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.5775346755981445
desired expected reward: 232.3459014892578



buy possibilites: [-1] 
expected returns: [[226.9096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 2.0 

action type: buy - action 3.0
Learning step: -5.559030532836914
desired expected reward: 209.73089599609375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[220.7413]
 [203.6475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -6.5034379959106445
desired expected reward: 220.4061737060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.82254]
 [209.92497]
 [206.37215]
 [179.4023 ]
 [217.88516]
 [206.1247 ]
 [205.25072]
 [223.29367]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.265777111053467
desired expected reward: 214.47386169433594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[233.71008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -5.818297863006592
desired expected reward: 217.47537231445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[219.70607]
 [226.14001]
 [195.283  ]
 [228.09781]
 [240.19162]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.742506504058838
desired expected reward: 230.87464904785156



buy possibilites: [-1] 
expected returns: [[201.08719]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 0. 0. 3. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -30.0 

action type: buy - action 0.0
Learning step: -7.96084451675415
desired expected reward: 211.74526977539062






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3 0] -> size -> 17 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3 0] -> size -> 17 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 0. 10.  0.  1.  0.  0.  1.  0.  3.  0.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3 0] -> size -> 17 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[155.62788]
 [141.52571]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 8 6 3 0 3 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -6.695654392242432
desired expected reward: 194.39154052734375



action possibilites: [-1] 
expected returns: [[246.08066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.2087128162384033
desired expected reward: 164.70184326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[220.7854 ]
 [200.18442]
 [244.15247]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1
Learning step: -5.586662292480469
desired expected reward: 240.49398803710938



buy possibilites: [-1] 
expected returns: [[216.48837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 22.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[  -5    0    5    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -280 

action type: buy - action 6.0
Learning step: -19.138233184814453
desired expected reward: 181.0461883544922






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 22.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 27. 30. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0. 0. 1.] 
cards in discard: [2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[199.5875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [6. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -6.327415943145752
desired expected reward: 210.16094970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[185.15923]
 [196.23393]
 [191.1903 ]
 [163.39044]
 [189.68422]
 [202.6011 ]
 [192.95319]
 [193.59023]
 [173.70636]
 [190.00471]
 [185.20708]
 [205.22176]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [6. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -5.610363006591797
desired expected reward: 194.2564239501953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[166.13716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -6.479015350341797
desired expected reward: 198.74273681640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.74744]
 [155.2459 ]
 [137.08763]
 [158.27174]
 [163.3502 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -4.874636650085449
desired expected reward: 163.2174835205078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 2. 22. 14. 10.  0.  0.  1.  3.  0.  0.  1. 15.  3.  3.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[174.44255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0. 15. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -3.2586324214935303
desired expected reward: 160.091552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.8921  ]
 [157.3422  ]
 [125.098816]
 [158.1657  ]
 [173.12373 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 29. 25. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0. 15. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -4.08745002746582
desired expected reward: 169.6404266357422



buy possibilites: [-1] 
expected returns: [[206.75093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0. 15. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 39 

action type: buy - action 3.0
Learning step: -1.265215277671814
desired expected reward: 156.07699584960938






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 14.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 29. 24. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 29. 24. 30.  8.  8. 10. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.] 
cards in discard: [16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[273.8742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3. 0. 3. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  0.  8.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: discard_down_to_3_cards - action 3
Learning step: 2.0085647106170654
desired expected reward: 113.88042449951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[246.28629]
 [252.66313]
 [223.56396]
 [254.44849]
 [267.78076]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3. 0. 3. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  0.  8.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -6.147749423980713
desired expected reward: 262.8370666503906



buy possibilites: [-1] 
expected returns: [[230.62068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  0.  8.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 1.0 

action type: buy - action 0.0
Learning step: -7.075348854064941
desired expected reward: 239.21092224121094






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.  8.] 
cards in discard: [16. 14.  0.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [16. 14.  0.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [16. 14.  0.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [16. 14.  0.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[130.66013]
 [118.2313 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [1. 1. 0. 0. 3.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -7.104595184326172
desired expected reward: 223.51608276367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.25143]
 [127.14184]
 [123.17773]
 [ 98.37309]
 [133.18416]
 [123.96069]
 [121.78019]
 [136.35771]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [3. 3. 0. 3. 0. 3. 3. 3. 0. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [1. 1. 0. 0. 3.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -2.176065444946289
desired expected reward: 129.7245330810547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [1. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 27. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3.] 
cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[185.18326]
 [169.67183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  2. 22.  0.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.  1.  1.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1.0
Learning step: -0.9960784912109375
desired expected reward: 130.64463806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.49261]
 [171.87282]
 [167.88655]
 [135.88501]
 [179.16815]
 [167.76562]
 [166.50093]
 [183.59116]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  2. 22.  0.] 
adversary cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.  1.  1.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -3.7909610271453857
desired expected reward: 180.6845245361328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  2. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  2. 22.  0.] 
cards in discard: [16. 14.  0.  0. 15.  0. 10.  8.  3.  1.  1.  1.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 2. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 8 
card supply: [24. 26. 29. 24. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 1. 0. 3.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[173.0434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 6. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15. 16.  1. 10.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1.0
Learning step: -3.7402877807617188
desired expected reward: 179.85086059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.97247]
 [152.93188]
 [125.21256]
 [153.1116 ]
 [169.57797]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 6. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  8. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15. 16.  1. 10.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -3.571005344390869
desired expected reward: 169.28543090820312



buy possibilites: [-1] 
expected returns: [[194.22437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 6. 0. 8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15. 16.  1. 10.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1 11] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 39 

action type: buy - action 8.0
Learning step: -1.3355334997177124
desired expected reward: 151.77609252929688






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15. 16.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  1. 10.  0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  1  3  0 22  0  1  8  2 15  0 16  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  9. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[205.51524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -3.650456666946411
desired expected reward: 190.57391357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[174.3477 ]
 [184.45143]
 [148.6649 ]
 [182.75253]
 [203.4827 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 29. 24. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -4.254994869232178
desired expected reward: 196.22332763671875



buy possibilites: [-1] 
expected returns: [[141.38318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 6. 0. 8. 0. 8. 3. 0. 0. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  0.] 
adversary cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 50 

action type: buy - action 3.0
Learning step: -3.541450262069702
desired expected reward: 180.9099884033203






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14.  0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [8. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [8. 3. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11. 22.  0.  3.  2.  0.  1.  0.  3. 14.  0. 16. 15. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [8. 3. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[133.11903]
 [115.68417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 2. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: discard_down_to_3_cards - action 1
Learning step: 0.6789814233779907
desired expected reward: 85.66584777832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.08774]
 [ 91.84745]
 [134.9768 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 3. 2. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -1.7437118291854858
desired expected reward: 129.47640991210938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 3. 2. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 2. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 0. 1.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[140.40897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  9.] 
adversary cards in hand: [22.  1.  0. 14.  0.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -1.5062347650527954
desired expected reward: 133.4705352783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[127.7651  ]
 [137.61589 ]
 [132.35759 ]
 [107.69294 ]
 [131.7369  ]
 [141.935   ]
 [135.1695  ]
 [135.37529 ]
 [116.60716 ]
 [131.3163  ]
 [126.898705]
 [142.59566 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 3 8 3 0 3 0 6 3 0 8 3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  9.] 
adversary cards in hand: [22.  1.  0. 14.  0.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -1.849585771560669
desired expected reward: 137.82171630859375



buy possibilites: [-1] 
expected returns: [[92.81924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  8.  3.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [22.  1.  0. 14.  0.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 74 

action type: buy - action 15.0
Learning step: -0.556501030921936
desired expected reward: 126.34217071533203






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [22.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.  0. 14.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  1.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 26. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  1.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[175.48637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 24 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: discard_down_to_3_cards - action 3
Learning step: -0.6670807003974915
desired expected reward: 132.72116088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.03471]
 [131.14539]
 [171.70813]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8.  0.  8.  3.  3. 15.  0.  0.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 24 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -2.9523441791534424
desired expected reward: 169.4326629638672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  7. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[133.40915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11.  3.  3. 14.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8] -> size -> 24 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -3.4913742542266846
desired expected reward: 168.2167510986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.40048]
 [ 94.97199]
 [134.31512]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11.  3.  3. 14.] 
adversary cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8] -> size -> 24 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -1.8231033086776733
desired expected reward: 131.2449951171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 14.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.  8. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [3. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3. 14.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.  8. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [3. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3. 14.] 
cards in discard: [14.  0.  3.  2.  0.  1.  1. 14. 22.  1.  0.  0.  8.  8. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [3. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[140.33736]
 [128.14337]
 [128.14337]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [3. 3. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  3  0  3  0  6  3  0  8  3 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 2.  3. 14. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -1.6633564233779907
desired expected reward: 132.65176391601562



action possibilites: [-1] 
expected returns: [[173.96071]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [3. 3. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 2.  3. 14. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.25091513991355896
desired expected reward: 124.51493072509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[153.96176]
 [128.22481]
 [176.94406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [3. 3. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 2.  3. 14. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1
Learning step: -2.513997793197632
desired expected reward: 171.44671630859375






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 2.  3. 14. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 14. 16. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 14. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 14. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[155.98155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 3. 0. 3. 6. 8. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [15.  2.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1.0
Learning step: -3.884798049926758
desired expected reward: 173.05926513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[134.91064]
 [147.9183 ]
 [143.16151]
 [109.48733]
 [155.63461]
 [143.56258]
 [141.2098 ]
 [159.30174]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 3. 0. 3. 6. 8. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [15.  2.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -2.7016541957855225
desired expected reward: 148.96080017089844



buy possibilites: [-1] 
expected returns: [[148.7041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [15.  2.  3. 14. 16.] 
adversary owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 49 

action type: buy - action 10.0
Learning step: -1.264647364616394
desired expected reward: 139.9451446533203






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  8.] 
cards in discard: [15.  2.  3. 14. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 14 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [15.  2.  3. 14. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [15.  2.  3. 14. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[149.63768]
 [131.0527 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 22. 11.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -2.188434600830078
desired expected reward: 146.5156707763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.84145 ]
 [136.97105 ]
 [132.70534 ]
 [107.562515]
 [142.51369 ]
 [133.65216 ]
 [131.08263 ]
 [145.03497 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  6. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 22. 11.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -2.2728958129882812
desired expected reward: 145.67678833007812



buy possibilites: [-1] 
expected returns: [[121.9127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [ 3.  3.  0.  3.  6.  8.  0.  3. 10.  0.  0.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 22. 11.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 43.0 

action type: buy - action 8.0
Learning step: -1.7895710468292236
desired expected reward: 131.86256408691406






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 22. 11.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10  8] -> size -> 20 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22. 11.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10  8] -> size -> 20 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22. 11.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [3. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10  8] -> size -> 20 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [3. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[180.6041 ]
 [168.80478]
 [168.80478]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3  0  6  3  0  8  3 15 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  1.  0.  0.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -0.06163673475384712
desired expected reward: 121.85105895996094



action possibilites: [-1] 
expected returns: [[178.5347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  1.  0.  0.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.074402332305908
desired expected reward: 177.98085021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.25273]
 [131.37105]
 [176.51295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  1.  0.  0.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -3.326735734939575
desired expected reward: 175.2079620361328






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  0.  0.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 15. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[173.6448 ]
 [149.98872]
 [155.65178]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10. 14.  1.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: discard_down_to_3_cards - action 1
Learning step: 2.241553783416748
desired expected reward: 49.793148040771484



action possibilites: [-1] 
expected returns: [[201.42609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10. 14.  1.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action 15.0
Learning step: -0.9215370416641235
desired expected reward: 147.15093994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[178.265  ]
 [150.38574]
 [203.01672]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  8.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10. 14.  1.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -3.9281413555145264
desired expected reward: 197.49794006347656



buy possibilites: [-1] 
expected returns: [[208.15077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [8. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10. 14.  1.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    3   10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -272 

action type: buy - action 6.0
Learning step: -16.435895919799805
desired expected reward: 133.9498291015625






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  1.  0.] 
cards in discard: [15.  2.  3. 14. 16.  8.  0.  8.  0.  3.  0.  0. 22. 11. 10. 14.  1.  0.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  8.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 25. 29. 23. 30.  8.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 5.0 : ['Province' '5' '8']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 25. 29. 23. 30.  8.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [5.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[123.30835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 22.  2.  1.  8.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -10.55604076385498
desired expected reward: 197.5947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.97262 ]
 [118.11153 ]
 [113.623184]
 [ 86.28181 ]
 [124.140686]
 [114.01343 ]
 [111.45855 ]
 [126.475105]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 22.  2.  1.  8.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -6.2087016105651855
desired expected reward: 113.85789489746094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  2.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  2.  1.  8.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  1.  8. 10.  0. 14.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  1.  8. 10.  0. 14.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 25. 29. 23. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  1.  8. 10.  0. 14.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 25. 29. 22. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[124.42313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 22. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -6.921000003814697
desired expected reward: 119.5540771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.268616]
 [108.55109 ]
 [ 79.40802 ]
 [108.87846 ]
 [121.89576 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 22. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -6.9845428466796875
desired expected reward: 115.3600845336914



buy possibilites: [-1] 
expected returns: [[128.46045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  6. 15.  3. 10.  0.  3.  6.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 14.  0.  0.  3.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -48 

action type: buy - action 3.0
Learning step: -4.937193393707275
desired expected reward: 103.61387634277344






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 8. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  3.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [ 0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[120.856544]
 [103.86063 ]
 [108.417984]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14] -> size -> 27 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: discard_down_to_3_cards - action 9
Learning step: -4.216857433319092
desired expected reward: 74.45010375976562



action possibilites: [-1. 15.] 
expected returns: [[106.601776]
 [ 85.45483 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.] 
cards in discard: [6. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14] -> size -> 27 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -4.8411173820495605
desired expected reward: 100.8800048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 83.79846 ]
 [ 61.743538]
 [105.35818 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [6. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 11.  0.  0. 16.] 
adversary cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14] -> size -> 27 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.075126647949219
desired expected reward: 101.52665710449219






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 16.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  7.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 21. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 5. 10. 15.  1.  1.  0.  3. 22.  0.  2.  1.  8. 10.  0. 14. 14. 14.  8.
  0.  0.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 21. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.4957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 21. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.133021831512451
desired expected reward: 100.22514343261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.63036 ]
 [101.989395]
 [ 98.28286 ]
 [ 77.13666 ]
 [107.25664 ]
 [ 98.73361 ]
 [ 96.674866]
 [109.40303 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 24. 29. 21. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -5.3661417961120605
desired expected reward: 101.80628204345703



buy possibilites: [-1] 
expected returns: [[108.02805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -30.   0.  -5.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -33.0 

action type: buy - action 3.0
Learning step: -4.133512020111084
desired expected reward: 94.14933776855469






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[91.68832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [22.  3.  0.  2. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_down_to_3_cards - action 3
Learning step: 0.45131373405456543
desired expected reward: -2.3152222633361816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.40173 ]
 [83.701355]
 [60.436203]
 [83.968956]
 [93.59422 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  5. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [22.  3.  0.  2. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.425731658935547
desired expected reward: 87.26258850097656



buy possibilites: [-1] 
expected returns: [[98.5472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  3. 10.  0. 15.  3.  3.  3.  0.  0.  0.  3.  3.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [22.  3.  0.  2. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 8.0
Learning step: -3.3311359882354736
desired expected reward: 80.6378173828125






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [22.  3.  0.  2. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  2. 14.] 
cards in discard: [ 0. 14.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  2. 14.] 
cards in discard: [ 0. 14.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[86.93947]
 [78.2914 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  0. 10.  8.  8.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.8510966300964355
desired expected reward: 93.69610595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.95879 ]
 [79.14643 ]
 [75.39748 ]
 [54.71657 ]
 [83.897255]
 [76.76866 ]
 [74.64157 ]
 [86.16664 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  0. 10.  8.  8.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
adversary owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.16792106628418
desired expected reward: 79.78262329101562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  8.  8.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8.  8. 15.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10
  5  3 14  6  1  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 15.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[160.85391]
 [146.53555]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 5. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -2.6208488941192627
desired expected reward: 83.54579162597656



action possibilites: [-1.] 
expected returns: [[120.74514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 5. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -5.1916327476501465
desired expected reward: 137.97633361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.1258  ]
 [ 88.92843 ]
 [123.215904]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 5. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -4.273372173309326
desired expected reward: 116.47177124023438






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [6. 0. 5. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 5. 0. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 5. 0. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 5. 0. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 15.  8.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[63.28594 ]
 [46.750217]
 [52.563465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  8.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  1. 10. 11. 16.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -6.6188554763793945
desired expected reward: 116.5970458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.993473]
 [54.05533 ]
 [31.036278]
 [54.009243]
 [64.754616]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  8.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  4. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  1. 10. 11. 16.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.666287660598755
desired expected reward: 59.619667053222656



buy possibilites: [-1] 
expected returns: [[80.89681]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  8.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  3. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  1. 10. 11. 16.] 
adversary cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 8.0
Learning step: -2.230283498764038
desired expected reward: 51.77894592285156






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 1.  1. 10. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 10. 11. 16.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  3. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11. 16.  0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  9.  3. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 16.  0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3 10  3  0 22  0  1  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5
  3 14  6  1  0  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  3. 10. 10.  6. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0. 11. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  3. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0. 11. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  3. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 0. 14.  0.  3.  0.  3. 22.  3.  0.  2. 14. 10.  8. 15.  1.  8.  0.  6.
  0.  5.  0.  0. 11. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  2. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
adversary victory points: 5
player victory points: 8 





Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.79774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  2. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 22.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.044391632080078
desired expected reward: 76.8524169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.243626]
 [66.50417 ]
 [46.86129 ]
 [67.50727 ]
 [76.617294]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  2. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 22.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.100063323974609
desired expected reward: 73.69767761230469



buy possibilites: [-1] 
expected returns: [[83.40201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 3.  0.  8.  0.  0. 10.  3.  0.  3.  3.  6.  8.  0.  6.  0. 15.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 22.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0  -5   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 8.0
Learning step: -2.4549198150634766
desired expected reward: 57.17437744140625






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 23 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 20. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 23 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0. 14.  1.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 23 
adversary victory points: 5
player victory points: 9 





Player: 0 
cards in hand: [8. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[62.08593 ]
 [58.716698]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3  0  6  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.059807300567627
desired expected reward: 78.34220123291016



action possibilites: [-1] 
expected returns: [[56.62005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.7312216758728027
desired expected reward: 52.372230529785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.88529 ]
 [34.1147  ]
 [58.069397]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3] -> size -> 33 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -2.949437379837036
desired expected reward: 53.67061233520508






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 11.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  1. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 9 





Player: 0 
cards in hand: [6. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[41.062737]
 [33.35248 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -4.325585842132568
desired expected reward: 53.743812561035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.011772]
 [14.346823]
 [38.40193 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.522186040878296
desired expected reward: 35.672794342041016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[61.588814]
 [51.22409 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1. 16.  0.  0.  5.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -40   0  -5   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.859632730484009
desired expected reward: 35.54229736328125



action possibilites: [-1] 
expected returns: [[87.42275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1. 16.  0.  0.  5.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.0321624279022217
desired expected reward: 41.95132064819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[72.7985  ]
 [74.66572 ]
 [61.434395]
 [81.77156 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 29. 19. 30.  7.  6.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1. 16.  0.  0.  5.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0  -5  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -4.463531970977783
desired expected reward: 82.95922088623047



buy possibilites: [-1] 
expected returns: [[91.28176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 1. 16.  0.  0.  5.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -60.    0.   -5.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -347.0 

action type: buy - action 6.0
Learning step: -18.36787986755371
desired expected reward: 43.066505432128906






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 1. 16.  0.  0.  5.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  0.  5.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  5  3
 14  6  1  0  0 11 14  8  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  3. 15.  3.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  3. 15.  3.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  3. 15.  3.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 10.  3. 15.  3.] 
adversary cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 10.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[39.918804]
 [31.400745]
 [30.042236]
 [27.0731  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 15.  3.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 6. 15. 10. 14. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -3.8793723583221436
desired expected reward: 87.40238952636719



action possibilites: [-1] 
expected returns: [[65.44903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 6. 15. 10. 14. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 15.0
Learning step: 1.0189478397369385
desired expected reward: 28.092056274414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.45323 ]
 [30.883186]
 [65.90101 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 6. 15. 10. 14. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -1.1582621335983276
desired expected reward: 64.29076385498047



buy possibilites: [-1] 
expected returns: [[80.41815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.] 
cards in discard: [8. 0. 6. 8. 3. 3. 0. 6. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 6. 15. 10. 14. 11.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action 0.0
Learning step: -0.9648115038871765
desired expected reward: 44.488407135009766






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 6. 15. 10. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 10. 14. 11.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15. 14. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 14. 11. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 19. 30.  7.  5.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 14. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[39.373924]
 [34.33358 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  2.  8. 14.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0. 10. 11. 14.  6. 15. 14.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: discard_down_to_3_cards - action 1
Learning step: 1.502786636352539
desired expected reward: -4.363070011138916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[27.718529]
 [30.984568]
 [14.186899]
 [37.532547]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  2.  8. 14.] 
adversary cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0. 10. 11. 14.  6. 15. 14.] 
adversary owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -0.7729949355125427
desired expected reward: 36.692378997802734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  2.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  2.  8. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0. 10. 11. 14.  6. 15. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  0 22  0  8  2 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14
  6  1  0  0 11 14  8  3  8 23 15  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0. 10. 11. 14.  6. 15. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  0 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1
  0  0 11 14  8  3  8 23 15  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.] 
cards in discard: [ 3.  0. 22.  0. 14.  1.  8. 11.  0.  8.  0.  3.  0.  1.  3.  0.  3. 23.
 15. 16.  1.  0.  0.  6.  0. 10. 11. 14.  6. 15. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  0 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1
  0  0 11 14  8  3  8 23 15  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.23952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [0. 3. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  0 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1
  0  0 11 14  8  3  8 23 15  6  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -0.5712383389472961
desired expected reward: 36.96131134033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[29.068205]
 [33.417763]
 [19.79186 ]
 [40.55195 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [0. 3. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  0 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1
  0  0 11 14  8  3  8 23 15  6  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -0.8425685167312622
desired expected reward: 39.39695358276367



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  0 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1
  0  0 11 14  8  3  8 23 15  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15. 10.  0.  3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15. 10.  0.  3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15. 10.  0.  3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15. 10.  0.  3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 8. 15. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[67.89867 ]
 [59.75967 ]
 [57.160213]
 [59.649513]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.  0.  3.] 
cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [22.  8. 15.  1. 16.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -0.19839516282081604
desired expected reward: 40.35356521606445



action possibilites: [-1] 
expected returns: [[47.071087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.] 
cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [22.  8. 15.  1. 16.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 15.0
Learning step: -0.3989112973213196
desired expected reward: 56.76130294799805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[37.65741 ]
 [44.027527]
 [41.58675 ]
 [24.509228]
 [47.082077]
 [40.313824]
 [47.863747]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.] 
cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 29. 19. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [22.  8. 15.  1. 16.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0.015453147701919079
desired expected reward: 47.08654022216797



buy possibilites: [-1] 
expected returns: [[58.665047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.] 
cards in discard: [0. 3. 8. 0. 0. 0. 3. 3. 0. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 29. 18. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [22.  8. 15.  1. 16.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 20.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 41.0 

action type: buy - action 3.0
Learning step: 1.2906255722045898
desired expected reward: 42.877384185791016






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [22.  8. 15.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 15. 16.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8. 15.  1. 16.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 16.  0. 15.  0.  6.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22. 15. 11.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 16.  0. 15.  0.  6.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22. 15. 11.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 29. 18. 30.  7.  4.  9.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 16.  0. 15.  0.  6.] 
cards in discard: [ 0.  8.  3.  3. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22. 15. 11.] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[30.990908]
 [27.189299]
 [27.189299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 14. 11.  1.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16] -> size -> 35 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -1.3227742910385132
desired expected reward: 57.3422737121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.072626]
 [17.282562]
 [31.720385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 6. 8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  3.  3.  0.  6.  3. 15.  8. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 14. 11.  1.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16] -> size -> 35 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: 0.012060070410370827
desired expected reward: 31.002960205078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  1.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [3. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11.  1.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  5.  9.  7.  9.  7.] 
adversary cards in hand: [3. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 11.  1.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [3. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [3. 6. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.481205]
 [18.9875  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -0.14929437637329102
desired expected reward: 31.571090698242188



action possibilites: [-1] 
expected returns: [[36.8643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.1511362791061401
desired expected reward: 22.71734619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.814692]
 [19.015785]
 [34.061264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [10.  8.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0.22006015479564667
desired expected reward: 37.08435821533203






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [6. 3. 0. 8. 3.] 
adversary cards in discard: [8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [6. 3. 0. 8. 3.] 
adversary cards in discard: [8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  3.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [6. 3. 0. 8. 3.] 
adversary cards in discard: [8. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[60.486107]
 [55.743843]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 3.] 
cards in discard: [8. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 15 10  8  6  3  3  8  8  8  6  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [14.  1.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: 0.023429488763213158
desired expected reward: 34.084678649902344



action possibilites: [-1] 
expected returns: [[29.680672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [14.  1.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.8925878405570984
desired expected reward: 58.315467834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.559261]
 [ 8.257091]
 [33.32472 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 6. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [14.  1.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0.46804505586624146
desired expected reward: 30.14871597290039



buy possibilites: [-1] 
expected returns: [[36.90311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 6. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [14.  1.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: buy - action 0.0
Learning step: -0.1476435661315918
desired expected reward: 17.4116268157959






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [14.  1.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  6.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  3. 10.  0.] 
adversary cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  6.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  3. 10.  0.] 
adversary cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.  6.  0.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  3. 10.  0.] 
adversary cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 15.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[40.634323]
 [33.588757]
 [35.27052 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3. 10.  0.] 
cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [23. 14.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -0.5909736752510071
desired expected reward: 36.312137603759766



action possibilites: [-1. 15.] 
expected returns: [[51.230434]
 [42.038727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [23. 14.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: 0.7723949551582336
desired expected reward: 36.042911529541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[47.12086 ]
 [54.279785]
 [49.169464]
 [28.020775]
 [55.003174]
 [47.750404]
 [52.87831 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [8. 6. 3. 3. 0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  8.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [23. 14.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -0.02937336079776287
desired expected reward: 51.2010498046875



buy possibilites: [-1] 
expected returns: [[30.00811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [ 8.  6.  3.  3.  0.  8.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [23. 14.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 11.0
Learning step: 0.22502346336841583
desired expected reward: 55.22820281982422






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [23. 14.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  0.  8. 14.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 14.  0.  8. 14.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 14.  0.  8. 14.] 
cards in discard: [ 0.  8.  3.  3. 16. 22. 15. 11.  8.  1. 16.  0. 15.  0.  6. 14.  0. 14.
 11.  1.  0.  0. 10.  8.  3.  3.  0.  1. 14.  1.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[31.126156]
 [26.289015]
 [26.289015]
 [26.289015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 16.  1.  6. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -0.4418558180332184
desired expected reward: 29.566253662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[23.825233]
 [26.778261]
 [14.099293]
 [32.26152 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 16.  1.  6. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -0.5706450343132019
desired expected reward: 31.029678344726562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  1.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  1.  6. 23.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 16  1 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0
 11 14  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 6. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 6. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 6. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [8. 6. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-2.874553]
 [-4.346369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 3. 3.] 
cards in discard: [8. 0. 0. 8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0. 22.  3.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -1.2884441614151
desired expected reward: 30.973079681396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-15.697636]
 [-30.587627]
 [ -4.797538]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 3.] 
cards in discard: [8. 0. 0. 8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0. 22.  3.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: 0.25811630487442017
desired expected reward: -2.616427421569824



buy possibilites: [-1] 
expected returns: [[30.259209]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 3.] 
cards in discard: [8. 0. 0. 8. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0. 22.  3.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: 0.36571207642555237
desired expected reward: -15.33188533782959






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 22.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 22.  3.  0.] 
cards in discard: [ 0.  8.  6. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [8. 0. 0. 8. 8. 0. 8. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0.  8. 14.  3.] 
cards in discard: [ 0.  8.  6. 23.] 
cards in deck: 26 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [8. 0. 0. 8. 8. 0. 8. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  8. 14.  3.] 
cards in discard: [ 0.  8.  6. 23.] 
cards in deck: 26 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [8. 0. 0. 8. 8. 0. 8. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  8. 14.  3.] 
cards in discard: [ 0.  8.  6. 23.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [8. 0. 0. 8. 8. 0. 8. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-0.43617034]
 [-2.8689187 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [8. 0. 0. 8. 8. 0. 8. 6. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10. 10.  4.  9.  7.  9.  7.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -1.1404446363449097
desired expected reward: 29.118764877319336



action possibilites: [-1] 
expected returns: [[14.578914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  8.  8.  0.  8.  6.  0.  3.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  7.  9.  7.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 44 

action type: gain_card_n - action 6
Learning step: 2.8559603691101074
desired expected reward: -3.878082752227783





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[14.523265]
 [17.156874]
 [15.576983]
 [ 9.570022]
 [17.438534]
 [15.13535 ]
 [16.191385]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  8.  8.  0.  8.  6.  0.  3.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  7.  9.  7.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 1.0292261838912964
desired expected reward: 15.608139991760254



buy possibilites: [-1] 
expected returns: [[16.812527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  8.  8.  0.  8.  6.  0.  3.  3. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 10.0
Learning step: 1.9215147495269775
desired expected reward: 17.05685806274414






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [16.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  6  1  0  0 11 14
  8  3  8 23 15  6  0  0 16 14  0  1  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 18. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11. 10.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 17. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11. 10.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 23. 29. 17. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11. 10.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 16. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11. 10.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 6. 11. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[-2.386158 ]
 [-2.2512412]
 [-4.002509 ]
 [-4.7408943]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  3. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -2.007171392440796
desired expected reward: 14.805355072021484



action possibilites: [-1] 
expected returns: [[8.010259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3. 15.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  6.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 14 

action type: gain_card_n - action 9
Learning step: 0.9609984755516052
desired expected reward: -0.6543534398078918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.04058123]
 [-5.4210835 ]
 [ 7.7380953 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3. 15.] 
cards in discard: [15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  4.  8.  7.  0. 10.  9.  4.  9.  6.  9.  6.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -0.4277939796447754
desired expected reward: 7.582464694976807



buy possibilites: [-1] 
expected returns: [[17.918262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3. 15.] 
cards in discard: [15.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  6.  9.  6.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action 6.0
Learning step: -14.975784301757812
desired expected reward: -20.396875381469727






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 14.  1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  6.  9.  6.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [3. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-13.34956]
 [ -6.21286]
 [ -6.21286]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 8.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 10  8  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [ 0.  3.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -2.7202608585357666
desired expected reward: 15.198001861572266



action possibilites: [-1] 
expected returns: [[4.757806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [ 0.  3.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.5826115608215332
desired expected reward: -10.78936767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.071129]
 [-12.748172]
 [  4.067483]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [ 0.  3.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -1.486578345298767
desired expected reward: 3.2712273597717285






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 14.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3.] 
adversary owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  9.  5.  9.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-2.4436574]
 [-6.0337853]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [11.  8. 14. 15.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: discard_down_to_3_cards - action 3
Learning step: -2.1296966075897217
desired expected reward: -5.156948089599609



action possibilites: [-1] 
expected returns: [[18.589703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [11.  8. 14. 15.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.46281275153160095
desired expected reward: -6.84119176864624





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.149863]
 [ 9.50988 ]
 [16.246473]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  3.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [11.  8. 14. 15.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -1.8115551471710205
desired expected reward: 16.778146743774414



buy possibilites: [-1] 
expected returns: [[-10.97638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [11.  8. 14. 15.  0.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
adversary owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action 6.0
Learning step: -17.452421188354492
desired expected reward: -8.343361854553223






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [11.  8. 14. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 14. 15.  0.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  0  8 15  0 11 14  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8
  3  8 23 15  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-10.681321]
 [-15.655143]
 [-15.05317 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 29.  0.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 1. 10. 15.  0.  3.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
adversary owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.4867656230926514
desired expected reward: -13.463146209716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-15.959791]
 [-11.376796]
 [-22.796442]
 [-10.650785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 29.  0.] 
cards in discard: [15.  6. 11.  6. 10.  3. 15.  8.  3. 10.  0.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 1. 10. 15.  0.  3.] 
adversary cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
adversary owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.521604299545288
desired expected reward: -13.202924728393555



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 1. 10. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 15.  0.  3.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  3. 14.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  8  0  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15
  6  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  5.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.] 
cards in discard: [ 0.  8.  6. 23.  0. 22.  8.  0.  3.  0.  8. 14.  3.  3.  3. 16.  0.  0.
  0. 15. 10. 11.  0.  0. 14.  1. 23. 14.  0.  3.  0.  1.  0.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-10.813212]
 [-14.042758]
 [-13.655021]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15 10  3  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -2.4901578426361084
desired expected reward: -13.14094352722168



action possibilites: [-1] 
expected returns: [[26.45268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 7
Learning step: -1.2273520231246948
desired expected reward: -10.776607513427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.260471]
 [16.756166]
 [26.275358]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 29. 16. 30.  7.  2.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -3.1018173694610596
desired expected reward: 23.350862503051758



buy possibilites: [-1] 
expected returns: [[-15.171625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 16. 30.  7.  1.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -357.0 

action type: buy - action 6.0
Learning step: -19.029170989990234
desired expected reward: -2.2730026245117188






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  1.  8.  7.  0. 10.  9.  4.  8.  5.  9.  4.] 
adversary cards in hand: [15.  6.  3.  3. 10.] 
adversary cards in discard: [ 6.  8. 29.  0.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 16. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [15.  6.  3.  3. 10.] 
adversary cards in discard: [ 6.  8. 29.  0.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 23. 29. 16. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [15.  6.  3.  3. 10.] 
adversary cards in discard: [ 6.  8. 29.  0.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [14.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [15.  6.  3.  3. 10.] 
adversary cards in discard: [ 6.  8. 29.  0.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [15.  6.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-12.539208]
 [-11.816118]
 [-12.43493 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  3. 10.] 
cards in discard: [ 6.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -3.8637795448303223
desired expected reward: -19.035404205322266



action possibilites: [-1] 
expected returns: [[-11.627994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 10.] 
cards in discard: [ 6.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 15.0
Learning step: -3.0208241939544678
desired expected reward: -14.83693790435791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.843105]
 [-11.552851]
 [-12.239238]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 10.] 
cards in discard: [ 6.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.0381109714508057
desired expected reward: -14.666104316711426



buy possibilites: [-1] 
expected returns: [[-15.9816065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 10.] 
cards in discard: [ 6.  8. 29.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action 0.0
Learning step: -4.567431449890137
desired expected reward: -17.410526275634766






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8.  0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  0 14  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6
  0  0 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 23. 29. 15. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [0. 6. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[15.975177]
 [ 8.710834]
 [ 8.710834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [10. 23.  3. 15. 15.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -3.761831045150757
desired expected reward: -19.743436813354492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 5.728881 ]
 [ 8.686914 ]
 [-2.0684197]
 [16.742775 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [10. 23.  3. 15. 15.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -5.409620761871338
desired expected reward: 10.565555572509766



buy possibilites: [-1] 
expected returns: [[-11.012071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [ 6.  8. 29.  0.  0. 15.  6.  3.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [10. 23.  3. 15. 15.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -127.0 

action type: buy - action 0.0
Learning step: -6.884214878082275
desired expected reward: -1.1553435325622559






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [10. 23.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 15. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  3. 15. 15.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [29.  6. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 23. 15. 15. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 15. 15. 23.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [29.  6. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3. 15. 15. 23.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [29.  6. 15. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [29.  6. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 11.] 
expected returns: [[28.378412]
 [27.820879]
 [25.36298 ]
 [26.581839]
 [28.795906]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 15. 10. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -3.6719415187835693
desired expected reward: -14.684012413024902



action possibilites: [-1] 
expected returns: [[-17.727364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action 15.0
Learning step: -5.450933456420898
desired expected reward: 18.59042739868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-21.192263]
 [-28.227432]
 [-18.086466]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.434722661972046
desired expected reward: -21.162086486816406






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6.  0. 16.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15. 29.  6. 10. 11.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6.  0. 16.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15. 29.  6. 10. 11.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6.  0. 16.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [15. 29.  6. 10. 11.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.9684925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [15. 29.  6. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.25996732711792
desired expected reward: -22.34644889831543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-14.816523]
 [-15.272086]
 [-14.762641]
 [-13.596542]
 [-15.689496]
 [-14.632263]
 [-16.1956  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [15. 29.  6. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.477813243865967
desired expected reward: -18.446306228637695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 0. 8. 3. 8.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  5.  9.  4.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
adversary owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-14.833914]
 [-15.529005]
 [-15.529005]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [14.  3.  0. 10.  1.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: discard_down_to_3_cards - action 3
Learning step: -5.396548748016357
desired expected reward: -1.2754759788513184



action possibilites: [-1] 
expected returns: [[-16.214314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [14.  3.  0. 10.  1.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.491638660430908
desired expected reward: -17.95530891418457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-19.420603]
 [-19.03053 ]
 [-17.366386]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [14.  3.  0. 10.  1.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -3.4480340480804443
desired expected reward: -19.6623477935791






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [14.  3.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0. 10.  1.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15.  8.  6.  3. 10.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 10.  1.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15.  8.  6.  3. 10.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0. 10.  1.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15.  8.  6.  3. 10.] 
adversary cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [15.  8.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[-2.64418 ]
 [-5.549453]
 [-4.978965]
 [-4.650796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  6.  3. 10.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 8.  3.  8. 15.  3.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 44 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -4.067492961883545
desired expected reward: -21.433889389038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-5.7809076]
 [-6.3053207]
 [-2.5632029]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  6.  3. 10.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 8.  3.  8. 15.  3.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 44 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.809165000915527
desired expected reward: -7.45334529876709



buy possibilites: [-1] 
expected returns: [[-7.2549877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  6.  3. 10.] 
cards in discard: [15. 29.  6. 10. 11.  6.  0.  6.  0.  0.  0.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 8.  3.  8. 15.  3.] 
adversary cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
adversary owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 44 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -127 

action type: buy - action 0.0
Learning step: -6.224192142486572
desired expected reward: -12.005094528198242






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 15.  3.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0
 16 14  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [14.  3. 11.  0.  0.  8.  1.  3.  8.  0.  0. 10. 23.  3. 15. 15. 23.  0.
  3.  1.  6.  0. 16. 10. 14.  0.  0.  0.  0.  0. 14.  3.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [0. 0. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-5.1173325]
 [-6.119171 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11.  0.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -3.6096673011779785
desired expected reward: -10.864654541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-5.910823 ]
 [-5.3564157]
 [-7.2823353]
 [-5.281869 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 29. 14. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11.  0.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.7227954864501953
desired expected reward: -8.840127944946289



buy possibilites: [-1] 
expected returns: [[38.522366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 6.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11.  0.  3. 14. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -58 

action type: buy - action 3.0
Learning step: -1.7654260396957397
desired expected reward: -7.121842384338379






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 14. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 14. 22.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 11.  3.  3. 15.] 
adversary cards in discard: [3. 0. 0. 6. 8. 6.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 11.  3.  3. 15.] 
adversary cards in discard: [3. 0. 0. 6. 8. 6.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 23. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 11.  3.  3. 15.] 
adversary cards in discard: [3. 0. 0. 6. 8. 6.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 14.  0.  3.  0.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 11.  3.  3. 15.] 
adversary cards in discard: [3. 0. 0. 6. 8. 6.] 
adversary owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[-24.868074]
 [-24.618357]
 [-22.087923]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 15.] 
cards in discard: [3. 0. 0. 6. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  0  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [23.  3.  1.  8. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -5.748812198638916
desired expected reward: 32.77355194091797



action possibilites: [-1] 
expected returns: [[-14.594913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [3. 0. 0. 6. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [23.  3.  1.  8. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 15.0
Learning step: -1.3235126733779907
desired expected reward: -27.420970916748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-14.079836]
 [-15.692658]
 [-14.206306]
 [-10.75516 ]
 [-15.37268 ]
 [-13.827248]
 [-14.496942]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [3. 0. 0. 6. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [23.  3.  1.  8. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
adversary owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -1.8602774143218994
desired expected reward: -16.455190658569336






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [23.  3.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  1.  8. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 10. 29.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.  8. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 10. 23.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [23.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 10. 29.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 10.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 23.] 
owned cards: [22  8  1  8  0  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14
  0  1  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 43 
action values: 1 
buys: 2 
player value: 2 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 10. 29.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 23.  8.] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
action values: 0 
buys: 2 
player value: 2 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 10. 29.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 23.  8.] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
action values: 0 
buys: 3 
player value: 2 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 0. 10. 29.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[-13.3308735]
 [-11.921147 ]
 [-13.736102 ]
 [-13.749807 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0.  8.] 
cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 1.  0. 14.  3.  3.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -2.8617310523986816
desired expected reward: -17.358680725097656



action possibilites: [-1. 29.  8.] 
expected returns: [[-7.660515]
 [-9.651358]
 [-9.750787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  6.] 
cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 1.  0. 14.  3.  3.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 10.0
Learning step: -1.8960663080215454
desired expected reward: -13.817215919494629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-9.338263]
 [-8.355866]
 [-9.615186]
 [-6.568472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  6.] 
cards in discard: [ 3.  0.  0.  6.  8.  6. 15. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 1.  0. 14.  3.  3.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -2.0923800468444824
desired expected reward: -9.752901077270508






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.  3.  3.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11.  0.  6. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 22. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [11. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[-26.056389]
 [-26.57322 ]
 [-22.131132]
 [-23.487251]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.] 
cards in discard: [0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 6.  8.  0. 15.  1.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: discard_down_to_3_cards - action 4
Learning step: -2.820233106613159
desired expected reward: -23.08084487915039



action possibilites: [-1] 
expected returns: [[-18.61976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 6.  8.  0. 15.  1.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 15.0
Learning step: -1.6123876571655273
desired expected reward: -23.743526458740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-20.430904]
 [-20.140678]
 [-18.674793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [ 6.  8.  0. 15.  1.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
adversary owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -1.8047970533370972
desired expected reward: -20.424556732177734






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  0. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 15.  1.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8  0 10  3 14  1  0  0 11 14  8  3  8 23 15  6  0  0 16 14  0  1
  0  0  0  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.] 
adversary owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-4.602268 ]
 [-3.7071474]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [ 0.  6. 15. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  3  8  8  6  3  0 11  0 29 10 15  6  6  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15. 14.  8. 14.  0.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -2.4561727046966553
desired expected reward: -21.130966186523438



action possibilites: [-1] 
expected returns: [[-15.635608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  6. 15. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15. 14.  8. 14.  0.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.9188841581344604
desired expected reward: -5.577226161956787





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-20.04375 ]
 [-20.94768 ]
 [-14.328692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  6. 15. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [15. 14.  8. 14.  0.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -1.3503408432006836
desired expected reward: -16.98594856262207






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [15. 14.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8. 14.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [29. 10.  0.  3.  6.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.  8.] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 14.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [10.  0.  6.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 14.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  4.  9.  4.] 
adversary cards in hand: [10.  0.  6.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 14.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [10.  0.  6.] 
adversary cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-20.515203]
 [-19.475452]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.] 
cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 16.  3.  0. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 5
Learning step: -2.3738808631896973
desired expected reward: -18.811264038085938



action possibilites: [-1.] 
expected returns: [[5.3216133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 16.  3.  0. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -0.5427193641662598
desired expected reward: -20.01817512512207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[3.7874396]
 [4.133811 ]
 [1.6012361]
 [5.0787754]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 21. 29. 13. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 16.  3.  0. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -1.9225596189498901
desired expected reward: 3.3990535736083984



buy possibilites: [-1] 
expected returns: [[-9.947751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  6. 15. 11. 10.  8. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 16.  3.  0. 10.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.] 
adversary owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: -1.2305148839950562
desired expected reward: 2.903294086456299






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10  3 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0
  3  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3  3] -> size -> 17 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-16.400723]
 [-17.035343]
 [-18.409782]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8  3 11  0 29 10 15  6  6  0  0  0  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10.  0.  0. 15.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
adversary owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -1.616710901260376
desired expected reward: -11.564461708068848



action possibilites: [-1] 
expected returns: [[-6.4399786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10.  0.  0. 15.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
adversary owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 6
Learning step: -0.6031696200370789
desired expected reward: -16.437768936157227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-8.924655]
 [-7.484329]
 [-6.272238]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10.  0.  0. 15.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
adversary owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.0878397226333618
desired expected reward: -7.527818202972412



buy possibilites: [-1] 
expected returns: [[-14.966137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10.  0.  0. 15.] 
adversary cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
adversary owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action 0.0
Learning step: -2.64050555229187
desired expected reward: -11.565157890319824






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 15.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14  0  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3
  3 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10. 11. 10.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10. 11. 10.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 20. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10. 11. 10.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 1. 22. 11.  0.  3. 14.  0.  3.  0. 23. 23.  8.  3. 10.  1. 14.  1.  0.
  3.  3.  8.  6. 10. 14. 15.  8. 14.  0.  1. 16.  0.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 19. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 0. 10. 11. 10.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-62.1298 ]
 [-68.7609 ]
 [-65.66841]
 [-68.7609 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  3.] 
cards in discard: [ 0.  8.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.960629940032959
desired expected reward: -17.926767349243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-72.836174]
 [-72.567986]
 [-61.722256]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.  3.] 
cards in discard: [ 0.  8.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 19. 29. 12. 30.  7.  1.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -0.6385963559150696
desired expected reward: -62.768402099609375



buy possibilites: [-1] 
expected returns: [[7.482072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.  3.] 
cards in discard: [ 0.  8.  3. 15.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -14.003252983093262
desired expected reward: -86.57122802734375






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 6. 15.  6.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [ 6. 15.  6.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 15.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[-3.2946658]
 [-6.366873 ]
 [-5.185359 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  0. 29.] 
cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  0  3  3  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [15.  1.  8.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 8.] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.272265672683716
desired expected reward: 4.209806442260742



action possibilites: [-1] 
expected returns: [[-21.74692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.] 
cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [15.  1.  8.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 8.] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 15.0
Learning step: -1.970962405204773
desired expected reward: -8.337827682495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-21.842709]
 [-21.92003 ]
 [-22.019297]
 [-21.777136]
 [-21.62276 ]
 [-22.48838 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29.] 
cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 19. 29. 12. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [15.  1.  8.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 8.] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.2038480043411255
desired expected reward: -22.950767517089844



buy possibilites: [-1] 
expected returns: [[-14.910732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29.] 
cards in discard: [ 0.  8.  3. 15.  6.  0. 10. 11. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [15.  1.  8.  0.  8.] 
adversary cards in discard: [3. 3. 0. 0. 8.] 
adversary owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -23.0 

action type: buy - action 3.0
Learning step: -0.38452664017677307
desired expected reward: -22.403823852539062






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [15.  1.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  8.  0.  8.] 
cards in discard: [3. 3. 0. 0. 8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14  0 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3
 15 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8.] 
cards in discard: [3. 3. 0. 0. 8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 8.] 
cards in discard: [3. 3. 0. 0. 8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  9.  4.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 8.] 
cards in discard: [ 3.  3.  0.  0.  8. 22.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-15.130451]
 [-12.009072]
 [-13.370799]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -1.7902002334594727
desired expected reward: -16.700931549072266



action possibilites: [-1.  8.] 
expected returns: [[-8.837513]
 [-8.505066]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  0  0  3  3  0  6  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -0.8487133383750916
desired expected reward: -12.566954612731934



action possibilites: [-1.] 
expected returns: [[-11.481876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.54392409324646
desired expected reward: -13.832295417785645





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -8.817716]
 [-12.792799]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0 -60   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -3.4531776905059814
desired expected reward: -14.935053825378418



buy possibilites: [-1] 
expected returns: [[-13.626305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [ 3.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40 -30   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action 0.0
Learning step: -3.665705919265747
desired expected reward: -12.483426094055176






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [15.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 19. 29. 11. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [15.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  0.] 
cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [15.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [15.  6. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[-17.019901]
 [-13.086572]
 [-14.528009]
 [-16.276825]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 10.  3.  8.] 
cards in discard: [ 0. 10.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [14. 23. 10.  1.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.444238662719727
desired expected reward: -18.07054328918457



action possibilites: [-1] 
expected returns: [[-12.55028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  8.] 
cards in discard: [ 0. 10.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [14. 23. 10.  1.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 15.0
Learning step: -3.4280529022216797
desired expected reward: -16.51462173461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -7.328991]
 [-11.15134 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  8.] 
cards in discard: [ 0. 10.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [14. 23. 10.  1.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -3.36515212059021
desired expected reward: -15.91543197631836



buy possibilites: [-1] 
expected returns: [[-14.764894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  8.] 
cards in discard: [ 0. 10.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [14. 23. 10.  1.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action 0.0
Learning step: -3.765760898590088
desired expected reward: -11.094751358032227






         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [14. 23. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 23. 10.  1.  8.] 
cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [15. 29. 11.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 15.  6. 10.  3.  8.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 23. 10.  1.  8.] 
cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [15. 29. 11.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 15.  6. 10.  3.  8.] 
adversary owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 0 
Gold: 0 
Estate: 11 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 0 
Workshop: 1 
Chapel: 6 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 29. 11.  6.  0.] 
cards in discard: [ 0. 10.  8.  6.  0. 15.  6. 10.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8  8 11 29 10 15  6  6  3  0  6  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 29. 10. 30.  7.  0.  8.  7.  0. 10.  9.  3.  8.  3.  8.  4.] 
adversary cards in hand: [14. 23. 10.  1.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  8. 22. 15.  1.  8.  8.  3.  3.  0. 15.  0.  0.  0.] 
adversary owned cards: [22  8  8 10 14 11 14  8  3  8 23  6  0  0 16 14  0  1  0  0  0  3  3 15
 10 23  0 15 14  3  3  0 10  0  1  1 10  1  1 22  3  0] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -566 

action type: buy - action -1
Learning step: -27.561756134033203
desired expected reward: -42.3266487121582



