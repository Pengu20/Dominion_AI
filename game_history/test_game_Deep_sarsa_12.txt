 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.96927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -270        0        0       20        0
        0        0        0        0        0        0       64        0] 
sum of rewards: -3000191 

action type: buy - action 29.0
Learning step: -300018.21875
desired expected reward: -300027.1875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[81.109886]
 [82.64944 ]
 [81.943504]
 [81.0567  ]
 [82.267426]
 [83.72218 ]
 [82.88858 ]
 [86.06371 ]
 [82.65626 ]
 [82.18265 ]
 [84.19579 ]
 [81.28235 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.57987976074219



buy possibilites: [-1] 
expected returns: [[55.832626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.06370544433594






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.02174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.83262634277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[84.871864]
 [86.40885 ]
 [85.7041  ]
 [84.81877 ]
 [87.47988 ]
 [86.647644]
 [85.94289 ]
 [85.04412 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.20645141601562



buy possibilites: [-1] 
expected returns: [[82.63049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.4798812866211






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[57.07083]
 [61.11209]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.6304931640625



action possibilites: [-1. 11.] 
expected returns: [[43.88459]
 [45.79635]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.61402893066406



action possibilites: [-1] 
expected returns: [[46.380146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.0659065246582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.082306]
 [47.754963]
 [47.04036 ]
 [48.523705]
 [47.23731 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.38014602661133



buy possibilites: [-1] 
expected returns: [[43.519096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 48.52370834350586






Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  8. 29. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  8. 29. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.50962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 29. 11.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.51909637451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[74.06957 ]
 [75.50663 ]
 [74.847984]
 [74.51053 ]
 [74.02041 ]
 [75.15033 ]
 [76.515144]
 [75.73283 ]
 [78.27272 ]
 [78.718315]
 [75.51511 ]
 [76.372246]
 [75.074165]
 [74.932625]
 [76.96074 ]
 [74.239136]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 29. 11.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.92156982421875



buy possibilites: [-1] 
expected returns: [[68.78885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  8. 29. 11.  3.  3.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 78.71831512451172






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[43.710022]
 [44.40899 ]
 [44.964157]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.78884887695312



action possibilites: [-1] 
expected returns: [[18.044136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: 41.849937438964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.157871]
 [18.126858]
 [18.280235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.04413604736328






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.909843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.280235290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.37859 ]
 [41.606007]
 [41.04373 ]
 [40.3371  ]
 [42.480137]
 [41.802357]
 [41.24008 ]
 [40.53258 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.451324462890625



buy possibilites: [-1] 
expected returns: [[58.676167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.480140686035156






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11. 29.] 
adversary cards in discard: [ 8. 10. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11. 29.] 
adversary cards in discard: [ 8. 10. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 11. 29.] 
adversary cards in discard: [ 8. 10. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[60.580643]
 [64.63101 ]
 [62.646057]
 [64.63101 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11. 29.] 
cards in discard: [ 8. 10. 11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.67616653442383



action possibilites: [-1. 11. 29.] 
expected returns: [[15.816497]
 [17.090343]
 [18.31882 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.53587341308594



action possibilites: [-1. 11.] 
expected returns: [[19.838154]
 [21.224487]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.31882095336914



action possibilites: [-1] 
expected returns: [[14.637742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 21.64604949951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.071113]
 [15.838717]
 [15.487279]
 [15.045516]
 [15.64878 ]
 [16.379856]
 [15.963695]
 [17.554253]
 [15.846211]
 [15.612252]
 [16.613815]
 [15.173739]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.637742042541504



buy possibilites: [-1] 
expected returns: [[32.26215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 17.55425262451172






Player: 1 
cards in hand: [16.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[43.49435 ]
 [44.145798]
 [44.66479 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  3.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10  8 29 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.262149810791016



action possibilites: [-1] 
expected returns: [[1.0735106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 35.474822998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.1339197]
 [1.1117883]
 [1.2241564]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.0735106468200684






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  0. 16.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  0. 16.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  0. 16.  3.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29. 29.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 11.] 
expected returns: [[6.3978395]
 [8.298207 ]
 [8.298207 ]
 [7.009533 ]
 [7.33438  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.2241573333740234



action possibilites: [-1. 29.  8. 11. 11.] 
expected returns: [[-1.1210964 ]
 [ 0.41007614]
 [-0.61988926]
 [-0.3481493 ]
 [-0.3481493 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.050533294677734



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[-0.03567338]
 [ 0.5136528 ]
 [ 0.8051615 ]
 [ 0.8051615 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 0.4100770950317383



action possibilites: [-1] 
expected returns: [[0.8405056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 1.0730137825012207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[1.5412865]
 [2.1474848]
 [1.8700657]
 [1.5212884]
 [1.9976101]
 [2.5763192]
 [2.2475395]
 [3.494308 ]
 [2.1543674]
 [1.9701214]
 [2.7605662]
 [1.6262717]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.8405055999755859



buy possibilites: [-1] 
expected returns: [[4.4525557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.494307518005371






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[42.252644]
 [45.444084]
 [42.84172 ]
 [42.84172 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  8.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.4525556564331055



action possibilites: [-1. 10. 10.] 
expected returns: [[-2.192666 ]
 [-1.9283448]
 [-1.9283448]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.769256591796875



action possibilites: [-1. 10. 29.] 
expected returns: [[-1.7207472]
 [-1.4733744]
 [-0.210078 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -1.928344964981079



action possibilites: [-1. 10.  8.] 
expected returns: [[0.06476355]
 [0.355309  ]
 [0.59092045]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  3  3 29 11 10  8 29 11 10 29 10 29] -> size -> 14 
action values: 2 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -0.21007680892944336



action possibilites: [-1.] 
expected returns: [[0.23514628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: -1.211498737335205





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[0.21675992]
 [0.6073613 ]
 [0.4287579 ]
 [0.2041359 ]
 [0.8888831 ]
 [0.67346334]
 [0.4948597 ]
 [0.27625227]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  7.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.23514628410339355



buy possibilites: [-1] 
expected returns: [[11.476718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  6.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
   54    0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 0.8888821601867676






Player: 1 
cards in hand: [ 3. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3 16  0  0  0 11 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  6.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 29. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 29. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 29. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 29. 10. 29.  8.  0.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[7.0616245]
 [9.059867 ]
 [7.429681 ]
 [8.077828 ]
 [8.077828 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11. 11.] 
cards in discard: [11. 29. 10. 29.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.476717948913574



action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[10.574054]
 [10.918477]
 [11.526362]
 [11.526362]
 [12.446826]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29.] 
cards in discard: [11. 29. 10. 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.30574893951416



action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[13.442151 ]
 [13.721988 ]
 [14.2186365]
 [14.2186365]
 [14.970342 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.44682788848877



action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[14.763831]
 [15.043664]
 [15.540315]
 [15.540315]
 [15.540315]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.970341682434082



action possibilites: [-1] 
expected returns: [[16.162067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.77666187286377





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.609352]
 [17.189266]
 [16.923916]
 [16.590294]
 [17.045933]
 [17.59998 ]
 [17.285416]
 [18.477997]
 [17.19616 ]
 [17.020065]
 [17.776073]
 [16.69191 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.162067413330078



buy possibilites: [-1] 
expected returns: [[-0.37902594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 18.47800064086914






Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 29. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 29. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  0.  3. 11.  3. 16.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 29. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 29. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.  8.] 
expected returns: [[13.799493 ]
 [14.575978 ]
 [15.3530245]
 [14.079328 ]
 [14.306518 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.379025936126709



action possibilites: [-1. 11. 10.  8. 29.] 
expected returns: [[11.400616]
 [12.177101]
 [11.68045 ]
 [11.907641]
 [12.928803]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 15.241101264953613



action possibilites: [-1. 11. 10.  8. 10.] 
expected returns: [[18.35698 ]
 [19.209023]
 [18.66449 ]
 [18.91362 ]
 [18.66449 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.928805351257324



action possibilites: [-1] 
expected returns: [[19.662155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.467571258544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.127705]
 [20.689247]
 [20.432323]
 [20.10928 ]
 [21.087147]
 [20.782532]
 [20.5256  ]
 [20.208157]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  5.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.662155151367188



buy possibilites: [-1] 
expected returns: [[4.5501347]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.087146759033203






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  9.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 29.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 29.] 
expected returns: [[21.826527]
 [24.007812]
 [22.2289  ]
 [22.936317]
 [24.007812]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11. 29.] 
cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.550134658813477



action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[11.257508 ]
 [11.619544 ]
 [12.26365  ]
 [13.2566805]
 [13.2566805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 29.] 
cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 20.17586898803711



action possibilites: [-1. 10. 11. 29. 11.] 
expected returns: [[16.76424 ]
 [17.148258]
 [17.823338]
 [18.84586 ]
 [17.823338]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.256684303283691



action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[27.836567]
 [28.195663]
 [28.829556]
 [28.829556]
 [28.829556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.84585952758789



action possibilites: [-1] 
expected returns: [[21.618187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.15594482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.080555]
 [23.651981]
 [23.3905  ]
 [23.061745]
 [23.510727]
 [24.056507]
 [23.746563]
 [24.921738]
 [23.658657]
 [23.48508 ]
 [24.230083]
 [23.161438]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.618186950683594



buy possibilites: [-1] 
expected returns: [[-0.40821314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.] 
cards in discard: [10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   80    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.921733856201172






Player: 1 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  8.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  2. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  8.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 11. 10.  0.  8.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 11. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.  8.] 
expected returns: [[6.489609 ]
 [7.835948 ]
 [7.1733255]
 [6.7353973]
 [6.9356756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0.  8.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.40821313858032227



action possibilites: [-1. 11. 10.  8. 29.] 
expected returns: [[6.2438164]
 [6.8918724]
 [6.4766455]
 [6.6665306]
 [7.5200996]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.343247413635254



action possibilites: [-1. 11. 10.  8. 10.] 
expected returns: [[5.35483  ]
 [5.9420757]
 [5.5653744]
 [5.737608 ]
 [5.5653744]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 7.520101547241211



action possibilites: [-1] 
expected returns: [[-3.0263417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.116415977478027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-3.0001128]
 [-2.6893673]
 [-2.8314047]
 [-3.010065 ]
 [-2.467503 ]
 [-2.6362114]
 [-2.9511342]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  4.  9. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.026341676712036



buy possibilites: [-1] 
expected returns: [[-0.777802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 29. 11.  0. 10. 11. 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [16.  0.  1. 10.  0.] 
adversary cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -2.4675028324127197






Player: 1 
cards in hand: [16.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 10.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 10.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 10.  0.] 
cards in discard: [16.  1. 11.  0.  0.  3.  0. 10. 11. 10.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  3. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[15.4396715]
 [16.33086  ]
 [17.239883 ]
 [16.33086  ]
 [15.759435 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  3. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.7778019905090332



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[7.9082747]
 [8.627519 ]
 [8.627519 ]
 [8.167328 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  3. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.273695945739746



action possibilites: [-1] 
expected returns: [[10.673194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 8.873217582702637





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.779368]
 [13.079366]
 [12.761191]
 [13.424136]
 [12.858142]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  9. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.67319393157959



buy possibilites: [-1] 
expected returns: [[-8.1525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [29. 15.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.424134254455566






Player: 1 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 29. 11. 29. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 29. 11. 29. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 29. 11. 29. 11.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 29. 11.] 
expected returns: [[-3.1265883]
 [-2.2396407]
 [-2.2396407]
 [-2.676823 ]
 [-2.2396407]
 [-2.676823 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 29. 11.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.15250015258789



action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[-2.048401 ]
 [-1.5868485]
 [-1.0870795]
 [-1.5868485]
 [-1.887806 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.2052812576293945



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[-10.097734]
 [-10.000847]
 [-10.000847]
 [-10.097734]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.8000078201293945



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -9.914382934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.097734]
 [-10.078484]
 [-10.097734]
 [ -9.927469]
 [-10.097734]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  8. 10.  3. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  7. 10.  3. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  1. 16. 11.] 
adversary cards in discard: [0. 3. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -9.927467346191406






Player: 1 
cards in hand: [ 0. 16.  1. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 16. 11.] 
cards in discard: [0. 3. 3. 0. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  7. 10.  3. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 16.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  7. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1. 16.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  7. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1. 16.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 29.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8. 10.] 
expected returns: [[-9.742193 ]
 [-9.6017   ]
 [-8.96213  ]
 [-9.4853325]
 [-9.6017   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[-7.992201]
 [-7.831606]
 [-7.831606]
 [-7.831606]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.529208183288574



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-5.448781]
 [-5.288186]
 [-5.288186]
 [-4.999016]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -7.831605911254883



action possibilites: [-1. 10. 10.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.  8.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -4.866854667663574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]
 [-10.08609 ]
 [-10.097734]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.  8.
 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  6. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-7.63058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 11. 10. 29. 10. 15.  8. 29. 29. 11. 11. 10.  8.
 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10.  1.  0. 10. 10.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -10.086090087890625






Player: 1 
cards in hand: [10.  1.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 10. 10.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 10. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 10. 11.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  8.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 10.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 10.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 10.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 10. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[-3.934972 ]
 [-3.3257637]
 [-3.7163653]
 [-2.7348804]
 [-2.7348804]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.630579948425293



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[-0.950197 ]
 [-0.3409891]
 [-0.7315898]
 [-0.3409891]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.320101737976074



action possibilites: [-1] 
expected returns: [[-5.335292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [29. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.14384889602661133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-5.326892 ]
 [-5.169883 ]
 [-5.3361278]
 [-4.988098 ]
 [-5.280854 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [29. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  5. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.335291862487793



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [29. 15.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -4.988097190856934






Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 28. 30.  8. 10.  7.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  3.  3. 14.  8. 11.  0. 16.  1. 16. 16.  1. 10. 11.  1.
  0. 10. 10.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  6.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 11.  8. 10.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 10. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.  8. 10.] 
expected returns: [[-7.5757437]
 [-7.4151487]
 [-7.4151487]
 [-7.1259775]
 [-7.2829876]
 [-7.4151487]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  6.  3.  4. 10.  3.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-2.4372435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  6.  3.  4. 10.  3.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.993815898895264





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.6545982]
 [-2.6638336]
 [-2.60856  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  6.  3.  4. 10.  3.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.4372434616088867






Player: 1 
cards in hand: [ 3.  0.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  6.  3.  4. 10.  3.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11. 29. 10.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11. 29. 10.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  5.] 
adversary cards in hand: [15. 11. 29. 10.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15. 11. 29. 10.  0.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [15. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 10.] 
expected returns: [[-3.5554583]
 [-3.0185218]
 [-3.105693 ]
 [-2.6685104]
 [-3.3948636]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 29. 10.  0.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 14. 16.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.6085588932037354



action possibilites: [-1. 15. 11. 10. 10.] 
expected returns: [[0.3744886 ]
 [0.9114251 ]
 [0.82425404]
 [0.5350833 ]
 [0.5350833 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 14. 16.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.3123269081115723



action possibilites: [-1] 
expected returns: [[-8.705681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 14. 16.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 0.9114236831665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-8.785691]
 [-8.794927]
 [-8.739653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 14. 16.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.705680847167969






Player: 1 
cards in hand: [ 0.  0.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29.  8.  8. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 29. 15.] 
adversary cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[-10.097734]
 [ -9.71322 ]
 [ -9.71322 ]
 [ -9.943926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1. 15.  8.] 
expected returns: [[-5.1399193]
 [-4.5497074]
 [-4.81793  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-9.399938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -4.549708366394043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.463061]
 [-9.472483]
 [-9.416399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [29. 15.  8. 29. 11.  0. 10. 11. 15. 11. 10. 10.  8. 10.  0. 29. 15. 11.
 10. 10.  8.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.399937629699707






Player: 1 
cards in hand: [ 0.  0.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 29. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  3.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 29. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 29. 15. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 29. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 11. 29.] 
expected returns: [[-9.926852]
 [-9.533649]
 [-9.148727]
 [-9.456952]
 [-9.533649]
 [-9.148727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15. 11. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 16. 10.  1.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.416398048400879



action possibilites: [-1. 11. 15. 11. 10.] 
expected returns: [[-8.566626]
 [-8.11686 ]
 [-8.02969 ]
 [-8.11686 ]
 [-8.406031]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 10.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 16. 10.  1.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.715805053710938



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 16. 10.  1.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -8.02968978881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 16. 10.  1.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-8.279695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.] 
cards in discard: [29.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 16. 10.  1.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.097733497619629






Player: 1 
cards in hand: [ 0. 29. 16. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16. 10.  1.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 11. 10.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 29. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.  1.  8.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3  1 16  1 10 29  0
 14  8 16  1 16 16 15  1 29] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 11. 10.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 11. 10.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 11. 10.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [29. 10. 10. 11. 10.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11. 10.] 
expected returns: [[-0.8117869 ]
 [ 0.07516074]
 [-0.65119195]
 [-0.65119195]
 [-0.36202168]
 [-0.65119195]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11. 10.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  0.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.279694557189941



action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]
 [-10.000847]
 [-10.097734]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  0.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.5686547756195068



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  3.] 
adversary cards in hand: [16.  0.  0.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -9.914382934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  3.] 
adversary cards in hand: [16.  0.  0.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  3.] 
adversary cards in hand: [16.  0.  0.  3. 10.] 
adversary cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.097733497619629






Player: 1 
cards in hand: [16.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3. 10.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 15. 15. 11.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3. 11.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 15. 15. 11.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16
  1 16 16 15  1 29  0 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 15. 15. 11.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 15. 15. 11.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [16. 15. 11.  3.  0.  1.  0.  1. 14.  0.  0.  3. 16. 29.  0.  0.  1.  3.
 10.  0. 10.  8. 16. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0. 15. 15. 11.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15.  0. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 11.] 
expected returns: [[-3.6542778]
 [-3.0400133]
 [-3.0400133]
 [-3.0400133]
 [-3.1397445]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 15. 11.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8
 15  8 15  8 15  0 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-7.06999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -3.0400118827819824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-7.119529 ]
 [-6.8303585]
 [-6.96252  ]
 [-7.128765 ]
 [-6.623726 ]
 [-6.780735 ]
 [-7.0734906]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 11.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  3.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.069990158081055



buy possibilites: [-1] 
expected returns: [[-4.5504932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 11.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -6.623724937438965






Player: 1 
cards in hand: [16. 11.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1
 16 16 15  1 29  0 14  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.] 
cards in discard: [3. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.  8.] 
expected returns: [[1.7329831]
 [2.2813811]
 [1.9293051]
 [1.9293051]
 [2.0902557]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10.  8.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  3.] 
adversary cards in hand: [16. 11.  8. 10.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.550493240356445



action possibilites: [-1] 
expected returns: [[-5.7865615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [16. 11.  8. 10.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.3638715744018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.0060096]
 [-6.015245 ]
 [-5.9599714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [16. 11.  8. 10.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.786561489105225






Player: 1 
cards in hand: [16. 11.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  8. 10.  3.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16
 16 15  1 29  0 14  0  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8.  8.  8. 29.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8.  8.  8. 29.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 8.  8.  8.  8. 29.] 
adversary cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8. 29.] 
expected returns: [[-6.584776]
 [-6.262786]
 [-6.262786]
 [-6.262786]
 [-6.262786]
 [-5.610198]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8.  8. 29.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.959970951080322



action possibilites: [-1.  8.  8.  8. 29.] 
expected returns: [[-10.097734 ]
 [-10.0974045]
 [-10.0974045]
 [-10.0974045]
 [ -9.714853 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 29.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.317020416259766



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-8.679998]
 [-8.422527]
 [-8.422527]
 [-8.422527]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0 29 11  8 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15  8 15  8 15
  8 15  8 15  0 15  0 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-9.527319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -8.418661117553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-9.739834]
 [-9.619455]
 [-9.746773]
 [-9.478627]
 [-9.704435]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  4. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.527318954467773



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0. 29. 15. 11. 11. 10. 15. 15.  0. 29. 11. 10. 10. 10. 11. 15. 15.
 15. 11. 15. 11. 10.  0. 10.  8.  8. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 10. 16.  0.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
adversary owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -9.478626251220703






Player: 1 
cards in hand: [ 3. 10. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16.  0.  0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15
  1 29  0 14  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[-10.097734]
 [ -9.714852]
 [ -9.943926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 14.  0.  1.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1. 15. 11.] 
expected returns: [[-10.097734]
 [ -9.943926]
 [-10.000847]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15
  8 15  0 15  0 11 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 14.  0.  1.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 14.  0.  1.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -9.943925857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.000847 ]
 [-10.0974045]
 [ -9.771774 ]
 [ -9.714853 ]
 [-10.097734 ]
 [-10.023392 ]
 [-10.097734 ]
 [ -9.943926 ]
 [-10.097734 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  2.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 14.  0.  1.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [ 0. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 14.  0.  1.  0.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -83.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -9.714852333068848






Player: 1 
cards in hand: [ 1. 14.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  1.  0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11.  8. 11. 15. 10.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3. 10.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 15. 10.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[-10.097734]
 [-10.000847]
 [ -9.943926]
 [-10.097734]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
 1008    0] 
sum of rewards: 853 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -10.079080581665039



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -9.943925857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.097733497619629






Player: 1 
cards in hand: [29.  1.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 29. 10. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  1.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 29. 10. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11. 29. 10. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 11. 29. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 10. 15.] 
expected returns: [[-10.097734]
 [-10.000847]
 [-10.000847]
 [ -9.714853]
 [-10.097734]
 [ -9.943926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 10. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1. 11. 11. 15.] 
expected returns: [[-10.097734]
 [-10.000847]
 [-10.000847]
 [ -9.943926]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -9.943925857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0780325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.097733497619629






Player: 1 
cards in hand: [ 0. 16.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 10. 15.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16 15  1
 29  0 14  0  3  0  3 25 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  9.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 29. 11.  8. 29.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 29. 11.  8. 29.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 3.  0. 16. 11.  0. 16.  8. 16. 11.  3. 16.  3. 10.  0. 25. 14.  1.  0.
  1.  0. 29. 29.  1.  0.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 29. 11.  8. 29.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 29. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.  8. 29.] 
expected returns: [[-9.689762]
 [-8.803229]
 [-8.803229]
 [-9.240412]
 [-9.397421]
 [-8.803229]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  8. 29.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.078032493591309



action possibilites: [-1. 29. 29. 15.] 
expected returns: [[-10.097734]
 [ -9.714852]
 [ -9.714852]
 [ -9.943926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -9.359872817993164



action possibilites: [-1. 29.] 
expected returns: [[-9.027448]
 [-8.1405  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1.] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -9.073486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.097734 ]
 [-10.000847 ]
 [-10.0974045]
 [-10.097734 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0] -> size -> 34 
action values: 1 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  2.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -10.000847816467285






Player: 1 
cards in hand: [ 0. 16.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3. 14.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29.] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29. 15. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.  8. 15.] 
expected returns: [[-4.772564 ]
 [-3.617669 ]
 [-4.0826836]
 [-4.565089 ]
 [-4.3990555]
 [-4.0826836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10.  8. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.097733497619629



action possibilites: [-1. 15.  8. 15.] 
expected returns: [[-10.097734]
 [ -9.943926]
 [-10.097404]
 [ -9.943926]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -4.347332954406738



action possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -9.943925857543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.097734]
 [-10.097734]
 [-10.097734]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.097733497619629



buy possibilites: [-1] 
expected returns: [[-10.0977335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.] 
cards in discard: [ 0. 29. 29. 15.  0. 11. 11.  8.  0. 15. 11. 10. 10. 15.  0. 29. 15. 11.
 11. 11.  8. 15. 10.  8. 11. 29. 29. 29. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   40.    0.    0.    0.    0.  -10.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.097733497619629






Player: 1 
cards in hand: [ 0.  8. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  1.  1.] 
cards in discard: [ 0.  0. 16.  3.  3. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 29. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  1.  1.] 
cards in discard: [ 0.  0. 16.  3.  3. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 26. 30. 26. 30.  8. 10.  5.  1.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [11. 29. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 0 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 29. 10. 29. 10.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29 11 10 29 10 29 11 10 29 10 11 10 29 10 11 15 15  8 15  8 15  8
 15  0 15  0 11 15  8 29  0  0 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8. 10.  5.  0.  3.  8.  0.  8. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  8. 11.  1.  1.] 
adversary cards in discard: [ 0.  0. 16.  3.  3. 14. 11.] 
adversary owned cards: [ 0  0  3  3 16  0  0  0 11 10 11  3 16  1 10  0 14  8 16  1 16 16  1 29
  0 14  0  3  0  3 25 29 25  0 11] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000155 

action type: buy - action -1
Learning step: -300014.5
desired expected reward: -300024.59375



