 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.8836184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       40        0
        0        0        0     -260        0        0       27        0] 
sum of rewards: -3000228 

action type: gain_card_n - action 4
Learning step: -120000.0390625
desired expected reward: -120227.03125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  9.02809 ]
 [ 23.488598]
 [ 12.920485]
 [-64.00975 ]
 [ 18.687092]
 [ 11.447392]
 [ 15.901854]
 [  6.775014]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.673401832580566



buy possibilites: [-1] 
expected returns: [[14.2218075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 23.48859977722168






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.519926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.221807479858398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 14.99942 ]
 [ 29.934164]
 [ 19.212294]
 [-55.80079 ]
 [ 23.56157 ]
 [ 25.202972]
 [ 17.3212  ]
 [ 37.179623]
 [ 22.760658]
 [ 22.267288]
 [ 28.099316]
 [ 12.757805]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.029680252075195



buy possibilites: [-1] 
expected returns: [[2.800722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.179630279541016






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.9410021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.8007218837738037





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  2.654259 ]
 [ 16.89825  ]
 [  6.7060575]
 [-68.49569  ]
 [ 10.92472  ]
 [ 12.322735 ]
 [  4.7687473]
 [ 23.581633 ]
 [ 10.129253 ]
 [  9.686153 ]
 [ 15.050077 ]
 [  1.0339911]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.8692948818206787



buy possibilites: [-1] 
expected returns: [[25.155218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.581628799438477






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  1.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-14.246944]
 [  7.54068 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  1.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.15521812438965



action possibilites: [-1.] 
expected returns: [[5.734105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 7.306775093078613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.695264 ]
 [ 25.635359 ]
 [-21.99366  ]
 [ 15.795158 ]
 [-18.880253 ]
 [-62.709717 ]
 [ 20.021025 ]
 [ 21.5493   ]
 [ 14.199694 ]
 [ 27.453867 ]
 [ 32.111546 ]
 [ 19.33838  ]
 [ 24.345072 ]
 [ 18.891756 ]
 [ 10.2149725]
 [ 24.101038 ]
 [ 10.170778 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.734105110168457



buy possibilites: [-1] 
expected returns: [[-6.9044647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.111534118652344






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 11.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  1. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 6.448389]
 [27.761301]
 [27.761301]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.9044647216796875



action possibilites: [-1. 29.] 
expected returns: [[ 2.842859]
 [22.271261]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.265424728393555



action possibilites: [-1.] 
expected returns: [[1.7681792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.27126693725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  6.689801 ]
 [ 20.821909 ]
 [-28.683672 ]
 [ 11.020805 ]
 [-25.627394 ]
 [-68.188705 ]
 [ 15.4591465]
 [ 16.60435  ]
 [  8.522371 ]
 [ 22.30417  ]
 [ 26.645117 ]
 [ 14.682724 ]
 [ 19.454294 ]
 [ 14.294537 ]
 [  5.3569727]
 [ 19.125397 ]
 [  6.5781918]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.768179178237915



buy possibilites: [-1] 
expected returns: [[16.758358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.645126342773438






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  3.] 
adversary cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.1918209]
 [24.053139 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  3.] 
cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.758358001708984



action possibilites: [-1.] 
expected returns: [[8.625479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.57280158996582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  8.231656 ]
 [ 21.917833 ]
 [ 12.263408 ]
 [-58.80776  ]
 [ 16.4286   ]
 [ 17.554108 ]
 [  9.915754 ]
 [ 28.04105  ]
 [ 15.643333 ]
 [ 15.257338 ]
 [ 20.082832 ]
 [  7.7203093]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29.  1.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.625478744506836



buy possibilites: [-1] 
expected returns: [[7.209324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29. 29. 29.  1.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.041048049926758






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-1.1339571]
 [18.96972  ]
 [18.96972  ]
 [18.96972  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.209323883056641



action possibilites: [-1. 29. 29.] 
expected returns: [[-17.987204]
 [  3.401365]
 [  3.401365]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.569131851196289



action possibilites: [-1. 29.] 
expected returns: [[-12.492938]
 [  8.675444]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 3.401367425918579



action possibilites: [-1.] 
expected returns: [[10.550105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.675447463989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.1125965]
 [ 26.28988  ]
 [-21.934643 ]
 [ 16.598936 ]
 [-19.175072 ]
 [-60.299213 ]
 [ 20.896845 ]
 [ 22.398798 ]
 [ 14.358723 ]
 [ 28.107725 ]
 [ 32.601616 ]
 [ 20.244978 ]
 [ 25.092243 ]
 [ 19.809874 ]
 [ 10.928667 ]
 [ 24.862879 ]
 [ 11.314098 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.550105094909668



buy possibilites: [-1] 
expected returns: [[27.963488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 87.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.60160446166992






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  1.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  1.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  1.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  1.] 
adversary cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-3.911818]
 [15.947689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  1.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.96348762512207



action possibilites: [-1.] 
expected returns: [[24.070662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.58388900756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 29.76496  ]
 [ 43.846207 ]
 [ 33.72717  ]
 [ -2.3375425]
 [-44.605698 ]
 [ 38.199512 ]
 [ 39.53468  ]
 [ 32.322178 ]
 [ 45.454853 ]
 [ 50.21446  ]
 [ 37.4533   ]
 [ 42.40435  ]
 [ 37.032837 ]
 [ 28.003769 ]
 [ 42.10844  ]
 [ 28.82279  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.070661544799805



buy possibilites: [-1] 
expected returns: [[28.354641]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [29. 29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.2144660949707






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  3. 15.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[-34.298786]
 [-14.264707]
 [-14.264707]
 [-14.264707]
 [-14.264707]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.35464096069336



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[-29.161427]
 [-11.761923]
 [-11.761923]
 [-11.761923]
 [-11.761923]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -16.41657829284668



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-13.751113 ]
 [  6.2100163]
 [  6.2100163]
 [  6.2100163]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -11.761940002441406



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 7.0996914]
 [25.427431 ]
 [25.427431 ]
 [25.427431 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.210019111633301



action possibilites: [-1. 29. 29.] 
expected returns: [[11.213949]
 [29.890455]
 [29.890455]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.42742347717285



action possibilites: [-1. 29. 29.] 
expected returns: [[17.193525]
 [35.149734]
 [35.149734]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 5 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.890459060668945



action possibilites: [-1. 29.] 
expected returns: [[ 9.716364]
 [27.718607]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 6 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.14973449707031



action possibilites: [-1.] 
expected returns: [[44.670097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 7 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.718599319458008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 47.891365]
 [ 60.97582 ]
 [ 16.504238]
 [ 52.088055]
 [ 19.006678]
 [ 58.192966]
 [-19.133797]
 [ 56.07742 ]
 [ 57.39494 ]
 [ 49.825115]
 [ 62.583782]
 [ 66.686806]
 [ 55.468975]
 [ 59.86199 ]
 [ 55.079903]
 [ 46.87259 ]
 [ 59.640614]
 [ 47.482937]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 11 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  2. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.67009735107422



buy possibilites: [-1] 
expected returns: [[69.96002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 7 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0. 140.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 137.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 66.68682861328125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10.  9.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8. 10.  9.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [16.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[53.922325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.96002197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 56.737988]
 [ 70.51673 ]
 [ 61.095203]
 [-18.584631]
 [ 65.58954 ]
 [ 66.85215 ]
 [ 59.067036]
 [ 76.219925]
 [ 64.956856]
 [ 64.57399 ]
 [ 69.118256]
 [ 57.097996]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  1. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.56393814086914



buy possibilites: [-1] 
expected returns: [[81.816345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29. 29. 29. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.21993255615234






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [16.  3. 11.  3. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [16.  3. 11.  3. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-13.825994 ]
 [  6.2889614]
 [  6.2889614]
 [  6.2889614]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.81634521484375



action possibilites: [-1. 29.] 
expected returns: [[ 2.3114808]
 [21.898539 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.530787944793701



action possibilites: [-1.] 
expected returns: [[8.825586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.774934768676758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  9.654911]
 [ 23.450638]
 [ 13.991154]
 [-54.857513]
 [ 18.2177  ]
 [ 19.50244 ]
 [ 11.598398]
 [ 17.530245]
 [ 17.137548]
 [ 21.911219]
 [  9.515106]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.825586318969727



buy possibilites: [-1] 
expected returns: [[30.65383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 23.450624465942383






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [16.  3. 11.  3. 15.  0.  0.  3.  0.  3. 10.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0. 29. 29. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[24.489393]
 [42.5935  ]
 [42.5935  ]
 [42.5935  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 29. 29.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.65382957458496



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[31.713034]
 [50.3654  ]
 [50.3654  ]
 [50.3654  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.43196105957031



action possibilites: [-1. 29.] 
expected returns: [[40.085804]
 [57.176937]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.88119888305664



action possibilites: [-1.] 
expected returns: [[58.69878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.829471588134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[62.501728 ]
 [74.9506   ]
 [66.50044  ]
 [31.949179 ]
 [-6.6907663]
 [70.6068   ]
 [71.7126   ]
 [64.57609  ]
 [76.32086  ]
 [70.0449   ]
 [73.929276 ]
 [69.707985 ]
 [61.242313 ]
 [73.7152   ]
 [63.129696 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10. 10.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.69878005981445



buy possibilites: [-1] 
expected returns: [[67.93905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 76.32087707519531






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[46.21989]
 [61.28671]
 [61.28671]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 29.] 
cards in discard: [29.  3.  1. 29. 29.  0.  0.  3.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  3.  3.  3.  3.] 
adversary cards in discard: [10. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.93904876708984



action possibilites: [-1.] 
expected returns: [[4.8445587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  3.  3.  3.  3.] 
adversary cards in discard: [10. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.74759292602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  7.402872]
 [ 20.947273]
 [ 11.883862]
 [-59.08243 ]
 [ 16.087582]
 [ 17.386896]
 [  9.317646]
 [ 15.477715]
 [ 15.092037]
 [ 19.624174]
 [  7.561241]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  3.  3.  3.  3.] 
adversary cards in discard: [10. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.8445587158203125



buy possibilites: [-1] 
expected returns: [[35.400574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  3.  3.  3.  3.] 
adversary cards in discard: [10. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -31.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 20.94728660583496






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [16.  3.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  3.  3.] 
cards in discard: [10. 29. 15.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  1  0 29 15 10  3  0 16  3 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [10. 29. 15.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10. 29. 15.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[19.700413]
 [40.489017]
 [40.489017]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  1.  0.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.40057373046875



action possibilites: [-1. 29. 29.] 
expected returns: [[76.7186  ]
 [97.649216]
 [97.649216]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 29.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.285924911499023



action possibilites: [-1. 29. 29.] 
expected returns: [[60.28844]
 [79.27356]
 [79.27356]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.29417419433594



action possibilites: [-1.] 
expected returns: [[86.03459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.51700592041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 88.746796]
 [102.08048 ]
 [ 92.912445]
 [ 18.086672]
 [ 97.15795 ]
 [ 98.341095]
 [ 90.76413 ]
 [ 96.50287 ]
 [ 96.131546]
 [100.607574]
 [ 88.88068 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.03459167480469



buy possibilites: [-1] 
expected returns: [[79.46799]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 8.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 102.08049774169922






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0. 10. 10.  9. 10.  8.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [25. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[71.76903]
 [84.93646]
 [88.71976]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  3.  0.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 15.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.46798706054688



action possibilites: [-1. 25.] 
expected returns: [[78.30197 ]
 [91.956894]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8. 10.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 15.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 83.53877258300781



action possibilites: [-1] 
expected returns: [[76.91884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 27. 30.  8.  9.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 15.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.95687866210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[73.0787  ]
 [85.11877 ]
 [77.5996  ]
 [ 7.69991 ]
 [81.591736]
 [82.40041 ]
 [74.177345]
 [81.09114 ]
 [80.82664 ]
 [84.07109 ]
 [75.66216 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 27. 30.  8.  9.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 15.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.91883850097656



buy possibilites: [-1] 
expected returns: [[49.539196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [29.  1. 29.  0.  0.  0.  3.  1.  1. 29.  1. 29. 29. 29.  0.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 24. 30. 27. 30.  8.  9.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 15.] 
adversary cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 85.1187515258789






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 15.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  9.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 29. 15.  0.  0.  3. 16.  3.  3.  3. 14.  3.  0.  0.  0.  1.  6.  6.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-20.32129  ]
 [ -3.1259246]
 [ -3.1259246]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.5391960144043



action possibilites: [-1. 29.] 
expected returns: [[-25.351423]
 [ -7.319535]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.400032997131348



action possibilites: [-1.] 
expected returns: [[8.952429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.769841194152832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  9.411429]
 [ 21.968065]
 [ 13.649981]
 [-54.575123]
 [ 17.504587]
 [ 18.586557]
 [ 10.781614]
 [ 16.907082]
 [ 16.5678  ]
 [ 20.655687]
 [  9.913137]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 23. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.952428817749023



buy possibilites: [-1] 
expected returns: [[27.441706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  1.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [15.  6.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 48.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.968069076538086






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [15.  6.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 29. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 29. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 29. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  3. 29. 29.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 1.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-7.716399]
 [ 9.463371]
 [ 9.463371]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 29. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.44170570373535



action possibilites: [-1. 29. 29.] 
expected returns: [[-3.0088646]
 [14.992815 ]
 [14.992815 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.319093704223633



action possibilites: [-1.] 
expected returns: [[40.847675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.591779708862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 40.948708]
 [ 53.52296 ]
 [ 45.09358 ]
 [ 11.030972]
 [-27.30481 ]
 [ 49.141308]
 [ 50.14625 ]
 [ 42.564655]
 [ 54.803013]
 [ 48.537495]
 [ 52.426212]
 [ 48.212517]
 [ 39.99152 ]
 [ 52.18033 ]
 [ 41.86681 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  9.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.84767532348633



buy possibilites: [-1] 
expected returns: [[45.126526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 54.80303955078125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9. 10.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9.  9.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  1.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[41.826298]
 [57.73124 ]
 [54.072773]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 25.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9.  9.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  3.  1.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.12652587890625



action possibilites: [-1. 25.] 
expected returns: [[57.241825]
 [67.338425]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  8.  9.  9.  9.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  3.  1.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.93671417236328



action possibilites: [-1] 
expected returns: [[56.14089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  3.  1.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 67.33843994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 53.092697]
 [ 65.113846]
 [ 57.529575]
 [ 24.06209 ]
 [-12.4581  ]
 [ 61.422176]
 [ 62.397625]
 [ 54.427425]
 [ 66.3826  ]
 [ 60.942707]
 [ 64.306816]
 [ 60.6488  ]
 [ 52.556313]
 [ 64.12693 ]
 [ 54.90984 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  8.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  3.  1.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.14088821411133



buy possibilites: [-1] 
expected returns: [[4.8040037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [29.  1.  1. 29. 29.  0.  0.  3.  1. 29. 25. 29. 29.  0.  3.  1.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29. 16.  3.  1.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.3825912475586






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 16.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.  3.  1.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  1  0 29 15 10  3  0 16  3 15  3 14  6  6  1
  0  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-26.227741]
 [ -9.440412]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.804003715515137



action possibilites: [-1.] 
expected returns: [[-7.023341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.175198554992676





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  -6.2352905]
 [   6.6905136]
 [  -1.9329728]
 [-102.7764   ]
 [   2.0215218]
 [   3.1901677]
 [  -4.6770926]
 [   1.4099939]
 [   1.0503881]
 [   5.347231 ]
 [  -5.9715137]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 22. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.023341178894043



buy possibilites: [-1] 
expected returns: [[6.773718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 21. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 58.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.690511703491211






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 21. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  1.  3.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 21. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 21. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0. 15.  6.  6. 10.  3.  8.  0. 15.  0.  0. 11.  6. 22. 16.  0. 29.  3.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 20. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 6.957176]
 [24.97186 ]
 [24.97186 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0    0    0    0
 1049    0] 
sum of rewards: 1074 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -123.14060974121094



action possibilites: [-1. 29. 25.] 
expected returns: [[-9.912514 ]
 [ 9.30521  ]
 [ 5.1222296]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.590425491333008



action possibilites: [-1.] 
expected returns: [[8.468307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 20. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.5941154956817627





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[   8.294674]
 [  20.49085 ]
 [  12.728006]
 [-100.34074 ]
 [  16.831947]
 [  18.028713]
 [   9.692879]
 [  16.203241]
 [  15.824284]
 [  19.305853]
 [   8.017902]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 20. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.468306541442871



buy possibilites: [-1] 
expected returns: [[-10.940356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 78.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 20.490835189819336






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25. 29.  3.  1.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25. 29.  3.  1.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [25. 29.  3.  1.  1.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 29.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[74.634186]
 [87.182076]
 [90.73603 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  1.  1.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 14. 29.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.940356254577637



action possibilites: [-1. 25.] 
expected returns: [[40.36756]
 [53.54054]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 19. 30. 27. 30.  8.  7.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 14. 29.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.90572357177734



action possibilites: [-1] 
expected returns: [[104.096985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 19. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 14. 29.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.54051208496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[101.07008 ]
 [114.223434]
 [105.50551 ]
 [ 27.704222]
 [109.78951 ]
 [111.069885]
 [103.277885]
 [109.25968 ]
 [108.894005]
 [113.11104 ]
 [101.75357 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 19. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 14. 29.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.09698486328125



buy possibilites: [-1] 
expected returns: [[105.84979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 25. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  3. 14. 29.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 78.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 114.22343444824219






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  3. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 14. 29.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14. 29.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14. 29.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0.  0.  0. 29.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-17.17262  ]
 [ -0.6942971]
 [ -0.6942971]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [22.  3. 15.  0. 10.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.84979248046875



action possibilites: [-1. 29.] 
expected returns: [[-15.357386 ]
 [ -1.0550137]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [22.  3. 15.  0. 10.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.695634841918945



action possibilites: [-1.] 
expected returns: [[7.925599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [22.  3. 15.  0. 10.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.7858760356903076





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.050108 ]
 [ 19.560701 ]
 [ 11.067579 ]
 [-18.357264 ]
 [-53.30106  ]
 [ 14.832575 ]
 [ 15.805567 ]
 [  8.197658 ]
 [ 20.788889 ]
 [ 14.150259 ]
 [ 18.291506 ]
 [ 13.815876 ]
 [  6.372278 ]
 [ 17.99958  ]
 [  7.2865047]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  7.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [22.  3. 15.  0. 10.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.925599098205566



buy possibilites: [-1] 
expected returns: [[8.577728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1. 29.  3.  0.  0.  0.  3.  1.  1. 25.  1. 29. 29.  1.  1.  1. 29.
 25.  3.  1.  0. 25. 29. 29. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [22.  3. 15.  0. 10.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 20.788881301879883






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [22.  3. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 15.  0. 10.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  1.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10.  0. 15.  8.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  1.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 10.  0. 15.  8.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  9.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  1.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 10.  0. 15.  8.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  8.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 1.  1.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1.  1.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-31.539537]
 [-25.795341]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6.  9.  9.  8.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.577728271484375



action possibilites: [-1] 
expected returns: [[-11.371177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  9.  9.  8.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -25.79534339904785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -7.8676195]
 [  5.4832773]
 [-38.89901  ]
 [ -3.6359005]
 [-37.34644  ]
 [  2.9709003]
 [-89.831375 ]
 [  0.3961656]
 [  1.6146295]
 [ -6.2010612]
 [  6.984106 ]
 [ -0.282027 ]
 [  4.2253647]
 [ -0.6651685]
 [ -8.801368 ]
 [  3.956971 ]
 [ -8.146532 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 9 
card supply: [25. 18. 30. 27. 30.  8.  5.  9.  9.  8.  6.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.371176719665527



buy possibilites: [-1] 
expected returns: [[1.5085046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1.  0.  1. 29.] 
cards in discard: [25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 18. 30. 27. 30.  8.  5.  9.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 6.984119415283203






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  9.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 18. 30. 27. 30.  8.  5.  9.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 29.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-11.271725 ]
 [  5.7010174]
 [  5.7010174]
 [  1.8611839]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 25.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.5085046291351318



action possibilites: [-1. 29.] 
expected returns: [[ 9.425179]
 [26.80855 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.6053345203399658



action possibilites: [-1.] 
expected returns: [[1.9754932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.57499885559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  0.5342486]
 [ 13.4849415]
 [  4.7167006]
 [-29.028372 ]
 [-75.61391  ]
 [  8.799766 ]
 [  9.960549 ]
 [  2.3652232]
 [ 14.923756 ]
 [  8.184458 ]
 [ 12.359983 ]
 [  7.8256674]
 [ -0.513818 ]
 [ 12.121258 ]
 [  0.8198669]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  5.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.9754931926727295



buy possibilites: [-1] 
expected returns: [[-23.524384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  1.  6.] 
adversary cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 14.923755645751953






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 11.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  1.  6.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  8.  9.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  3. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  6.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  7.  9.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  3. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  6.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 18. 30. 27. 30.  8.  5.  7.  9.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  3. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  6.] 
cards in discard: [14.  0.  1.  0.  3.  3.  6.  0.  6.  3.  3. 14. 29.  8. 22.  3. 15.  0.
 10.  0. 15.  8.  6. 16.  0.  0.  6.  0.  0. 16. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  7.  8.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  3. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[103.68857]
 [116.67619]
 [120.2175 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3. 29.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  5.  7.  8.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0. 14.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.524383544921875



action possibilites: [-1. 25.] 
expected returns: [[54.01583]
 [66.48334]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  5.  7.  8.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0. 14.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.25791931152344



action possibilites: [-1] 
expected returns: [[58.745785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0. 14.  1. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.48332977294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[53.792843]
 [65.4396  ]
 [24.987677]
 [57.965046]
 [26.362444]
 [62.178593]
 [-8.702116]
 [61.750057]
 [62.569614]
 [54.91818 ]
 [66.52333 ]
 [61.224674]
 [64.52295 ]
 [60.952984]
 [53.24203 ]
 [64.304245]
 [55.647873]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  4.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0. 14.  1. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.745784759521484



buy possibilites: [-1] 
expected returns: [[33.44855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0. 14.  1. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.52334594726562






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11.  0. 14.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  1. 14.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 25. 29. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1. 14.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 25. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1. 14.] 
cards in discard: [6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 25. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1. 14.] 
cards in discard: [ 6. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 25. 29.] 
adversary cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-28.328638]
 [-15.804081]
 [-11.954841]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -127.24844360351562



action possibilites: [-1. 25.] 
expected returns: [[-34.31147]
 [-21.78691]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  4.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10] -> size -> 38 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.914148330688477



action possibilites: [-1] 
expected returns: [[-48.470913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  3.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -21.78691864013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -57.317814]
 [ -44.125065]
 [ -53.179646]
 [-115.140816]
 [ -47.398296]
 [ -48.889957]
 [ -58.187653]
 [ -48.570465]
 [ -48.505928]
 [ -47.15427 ]
 [ -49.69533 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 18. 30. 27. 30.  8.  3.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -48.47091293334961



buy possibilites: [-1] 
expected returns: [[-47.52908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.] 
cards in discard: [25. 25.  1.  1.  1.  0.  1. 29. 25.  1. 25. 29. 29.  0.  3.  1.  3. 25.
 29. 25.  0.  0.  0.  1.  1. 29. 29.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 17. 30. 27. 30.  8.  3.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6] -> size -> 39 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   40.    0.    0.    0.    0.  -10.
   0.    0.   13.5   0. ] 
sum of rewards: 158.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -44.12508010864258






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  3.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 17. 30. 27. 30.  8.  3.  7.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  3.  6.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 1. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-32.76424 ]
 [-17.412657]
 [-13.009342]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  3.  6.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8. 15.  3. 22.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -47.52907943725586



action possibilites: [-1. 25.] 
expected returns: [[32.71255]
 [47.32577]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 17. 30. 27. 30.  8.  3.  6.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8. 15.  3. 22.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -18.90842056274414



action possibilites: [-1] 
expected returns: [[3.9310596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8. 15.  3. 22.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.32575988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  2.3122618]
 [ 15.464708 ]
 [  6.7630825]
 [-28.109789 ]
 [-64.510155 ]
 [ 10.914305 ]
 [ 12.099022 ]
 [  4.0753784]
 [ 16.955431 ]
 [ 10.331984 ]
 [ 14.420382 ]
 [  9.975024 ]
 [  1.4162962]
 [ 14.200224 ]
 [  3.0049455]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  3.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8. 15.  3. 22.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.9310595989227295



buy possibilites: [-1] 
expected returns: [[-30.44599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [ 1. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8. 15.  3. 22.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -20   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 16.955411911010742






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  8. 15.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.  3. 22.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0
  8  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  0.  1. 29. 29.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 22.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  0.  1. 29. 29.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 22.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  0.  1. 29. 29.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 22.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  0.  1. 29. 29.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [25.  0.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[27.32381 ]
 [38.307537]
 [41.709675]
 [41.709675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1. 29. 29.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0] -> size -> 41 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.44598960876465



action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-28.039118]
 [-16.31225 ]
 [-12.766396]
 [-16.31225 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 25.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0] -> size -> 41 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.33102035522461



action possibilites: [-1. 25. 25.] 
expected returns: [[-56.96259]
 [-55.06705]
 [-55.06705]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 27. 30.  8.  2.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0] -> size -> 41 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.4221248626709



action possibilites: [-1] 
expected returns: [[-44.2088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  1.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 27. 30.  8.  1.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6] -> size -> 42 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -55.06709671020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -44.364197]
 [ -32.07988 ]
 [ -40.28197 ]
 [ -78.50308 ]
 [-104.48563 ]
 [ -36.62064 ]
 [ -35.701107]
 [ -43.447636]
 [ -30.900702]
 [ -37.28356 ]
 [ -33.300186]
 [ -37.603226]
 [ -44.77852 ]
 [ -33.58605 ]
 [ -43.60064 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  1.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 17. 30. 27. 30.  8.  1.  6.  8.  8.  2.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6] -> size -> 42 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.20880126953125



buy possibilites: [-1] 
expected returns: [[-9.8772135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29.  1.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  1.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6] -> size -> 42 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0 -30   0   0 250   0] 
sum of rewards: 485 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -30.90071678161621






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [16.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  6.  0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  1.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  1.  0.  0. 25.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  6.  0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 17. 30. 27. 30.  8.  1.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  1.  0.  0. 25.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  6.  0.] 
cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 17. 30. 27. 30.  8.  1.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [25.  1.  0.  0. 25.] 
adversary cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [25.  1.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[21.831705]
 [33.174442]
 [33.174442]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  0. 25.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 27. 30.  8.  1.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.  0. 16.  0. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6  0] -> size -> 43 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.877213478088379



action possibilites: [-1] 
expected returns: [[-37.540833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 25. 29.  0.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 27. 30.  8.  0.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.  0. 16.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.1744499206543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-40.01901 ]
 [-27.84095 ]
 [-35.936783]
 [-67.997314]
 [-32.28767 ]
 [-31.432182]
 [-39.22732 ]
 [-26.730894]
 [-32.95229 ]
 [-29.062033]
 [-33.259373]
 [-40.433334]
 [-29.354376]
 [-39.255455]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25. 29.  0.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 17. 30. 27. 30.  8.  0.  6.  8.  8.  1.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.  0. 16.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.54083251953125



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 10 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  0.  0. 25. 29.  0.] 
cards in discard: [ 1. 25. 29. 25.  0.  0.  1. 29. 29.  1. 29. 25. 29. 29. 25.  0. 25. 29.
  1. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29 29 29 29 29 29  1 25  1  1
  1  1 25 25  1  1  1 25 25 25 25  1 25 25 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 27. 30.  8.  0.  6.  8.  8.  0.  0.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 6. 10. 14. 11.  0.  1. 14.  6. 16.  3.  1.  0.  6.  0.  6.  0.  8.  6.
 15. 22.  6.  0. 16.  0. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  0 29 15 10  3  0 16  3 15  3 14  6  6  1  0  8
  6 22  1 14  6  0  8  6 16 16 11  6 10  6 16  6  0  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      20       0       0
       0       0     -40       0       0     125       0] 
sum of rewards: 3000340 

action type: buy - action 25.0
Learning step: 120014.6640625
desired expected reward: 119987.9296875



