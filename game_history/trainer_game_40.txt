 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.98206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -554 

action type: buy - action -1
Learning step: -27.543100357055664
desired expected reward: -30.681079864501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[322.0153 ]
 [329.6036 ]
 [328.1225 ]
 [311.84863]
 [326.63217]
 [337.87598]
 [330.70258]
 [336.64807]
 [321.30798]
 [329.3377 ]
 [329.65872]
 [345.06317]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.889337539672852
desired expected reward: 334.14739990234375



buy possibilites: [-1] 
expected returns: [[340.4327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -8.69544506072998
desired expected reward: 320.9081726074219






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[326.8755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.697393417358398
desired expected reward: 330.7353210449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[304.0933 ]
 [312.0601 ]
 [310.56635]
 [293.48145]
 [320.60724]
 [313.1916 ]
 [311.81686]
 [328.70743]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.57352352142334
desired expected reward: 320.392822265625



buy possibilites: [-1] 
expected returns: [[325.00885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.346879005432129
desired expected reward: 304.84466552734375






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [16. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[352.2206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  8. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.398089408874512
desired expected reward: 316.6107482910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.05002]
 [328.27658]
 [326.8678 ]
 [309.13947]
 [325.09668]
 [337.34842]
 [329.42142]
 [335.89856]
 [319.41757]
 [328.14816]
 [328.5329 ]
 [345.72165]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  8. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.386322021484375
desired expected reward: 343.05157470703125



buy possibilites: [-1] 
expected returns: [[334.57565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  8. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -7.2268829345703125
desired expected reward: 317.86981201171875






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  8. 11. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  8. 11. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  8. 11. 16.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [16.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[343.27286]
 [326.93057]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [16.  0.  1.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.296613693237305
desired expected reward: 325.279052734375



action possibilites: [-1] 
expected returns: [[299.13998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 2
Learning step: -8.126401901245117
desired expected reward: 307.0146179199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[280.83716]
 [271.8149 ]
 [302.651  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.6329345703125
desired expected reward: 291.5070495605469



buy possibilites: [-1] 
expected returns: [[300.7264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  0.  3.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -21.474401473999023
desired expected reward: 250.34051513671875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11  0  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [6. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[296.59732]
 [279.33328]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  8 16  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -8.650266647338867
desired expected reward: 292.0761413574219



action possibilites: [-1] 
expected returns: [[243.21396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11  8] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 9
Learning step: -9.250993728637695
desired expected reward: 286.4052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[216.02948]
 [208.52602]
 [233.7229 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11  8] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -7.466040134429932
desired expected reward: 235.7479248046875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  0.] 
cards in discard: [8. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16 11  0  8 11  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  0. 16.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 1.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[262.7166 ]
 [238.79271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -6.7428741455078125
desired expected reward: 226.9800262451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[232.84206]
 [242.36104]
 [240.82355]
 [220.53018]
 [238.7015 ]
 [252.91728]
 [243.65494]
 [251.24211]
 [232.19226]
 [242.28275]
 [242.76433]
 [262.3641 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 16  6] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  8.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -8.53772258758545
desired expected reward: 256.2839050292969



buy possibilites: [-1] 
expected returns: [[255.46948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 16.] 
cards in discard: [ 8.  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 16  6 16] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 17 

action type: buy - action 16.0
Learning step: -5.337013244628906
desired expected reward: 233.36453247070312






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 16  6 16] -> size -> 9 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 16  6 16] -> size -> 9 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [ 8.  8.  0.  0.  0. 11. 16.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 16  6 16] -> size -> 9 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 0. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[247.91188]
 [230.31943]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 16  6 16] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -8.134139060974121
desired expected reward: 247.33534240722656



action possibilites: [-1] 
expected returns: [[205.40778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  1  8 16 16  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -295 

action type: gain_card_n - action 2
Learning step: -21.496129989624023
desired expected reward: 205.8599853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[191.24406]
 [195.86171]
 [194.7059 ]
 [184.94301]
 [200.46503]
 [196.5986 ]
 [195.49445]
 [204.18938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  1  8 16 16  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -5.618405342102051
desired expected reward: 199.78936767578125






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  8.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 16 16  6] -> size -> 9 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  8.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 16 16  6] -> size -> 9 
adversary victory points: 0
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 16.  8.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
expected returns: [[198.13016]
 [185.97052]
 [185.97052]
 [188.66106]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  8.  1.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 16 16  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -6.6855788230896
desired expected reward: 197.5037841796875



action possibilites: [-1] 
expected returns: [[244.23038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  8 16  6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 3
Learning step: -5.076703071594238
desired expected reward: 200.36102294921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[216.05043]
 [219.94704]
 [208.95174]
 [222.0478 ]
 [231.56247]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  8 16  6] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -7.5617265701293945
desired expected reward: 236.6686553955078



buy possibilites: [-1] 
expected returns: [[216.66626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 13 

action type: buy - action 3.0
Learning step: -5.472361087799072
desired expected reward: 214.47467041015625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[280.4323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -5.264993190765381
desired expected reward: 211.40126037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[261.22934]
 [267.6991 ]
 [266.51028]
 [252.61615]
 [274.66016]
 [268.61496]
 [267.5275 ]
 [280.71362]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  8 16  6  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -8.766142845153809
desired expected reward: 272.0480651855469



buy possibilites: [-1] 
expected returns: [[247.11682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0  0] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 3 

action type: buy - action 1.0
Learning step: -7.216606140136719
desired expected reward: 251.31808471679688






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [16.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0. 11.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0  8 11  8 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  7.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  6.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8.  6.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 0. 11.  0.  3.  0.  0.  8. 11.  0.  0.  0. 16.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  6.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  1. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1.  1. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[252.6776 ]
 [233.32767]
 [237.294  ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 16.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  8 16  6  3  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  6.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -7.661709785461426
desired expected reward: 239.45510864257812



action possibilites: [-1] 
expected returns: [[218.96864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  8 16  6  3  1  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8.  6.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: gain_card_n - action 0
Learning step: -5.998157024383545
desired expected reward: 187.50086975097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[192.35999]
 [198.33807]
 [197.01451]
 [184.3329 ]
 [195.99808]
 [204.42033]
 [199.2279 ]
 [203.48619]
 [191.62909]
 [197.97601]
 [198.0734 ]
 [209.65215]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  8 16  6  3  1  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  8.  6.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -6.243655204772949
desired expected reward: 212.72499084472656



buy possibilites: [-1] 
expected returns: [[144.45015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 8.] 
cards in discard: [ 0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 37 

action type: buy - action 16.0
Learning step: -4.699776649475098
desired expected reward: 191.29830932617188






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [16.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[158.60622]
 [147.51736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6] -> size -> 19 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -3.9684224128723145
desired expected reward: 140.48171997070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.02954]
 [150.4159 ]
 [139.76227]
 [152.2313 ]
 [160.34024]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6] -> size -> 19 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.930046081542969
desired expected reward: 156.260986328125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  8. 16.  1.] 
adversary cards in discard: [16.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  8. 16.  1.] 
adversary cards in discard: [16.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  7.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  8. 16.  1.] 
adversary cards in discard: [16.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  8. 16.  1.] 
adversary cards in discard: [16.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  8. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[200.98087]
 [189.78976]
 [186.71252]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 16.  1.] 
cards in discard: [16.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 16  6  3  1  0 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -3.9202537536621094
desired expected reward: 156.4199676513672



action possibilites: [-1] 
expected returns: [[168.84686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [16.  0.  3.  6.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1 16  6  3  1  0 16 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: -5.570985317230225
desired expected reward: 212.82980346679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[154.04929]
 [158.56789]
 [157.34433]
 [149.87492]
 [148.1979 ]
 [156.6899 ]
 [163.20396]
 [159.31477]
 [167.77052]
 [162.61343]
 [153.37488]
 [155.62825]
 [158.14551]
 [150.89522]
 [158.25471]
 [167.06532]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [16.  0.  3.  6.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1 16  6  3  1  0 16 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -4.141794681549072
desired expected reward: 164.70506286621094



buy possibilites: [-1] 
expected returns: [[184.7221]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [16.  0.  3.  6.  0. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 25.0
Learning step: -0.9822792410850525
desired expected reward: 166.7882537841797






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  0.  0.  8. 11. 11.  0.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [ 0.  1. 16. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[143.33194]
 [125.5156 ]
 [142.42676]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16. 25.  1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  6  3  1  0 16 29 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  5.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: -5.900492191314697
desired expected reward: 178.8216094970703



action possibilites: [-1] 
expected returns: [[160.5131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 29 

action type: gain_card_n - action 3
Learning step: -2.1134088039398193
desired expected reward: 141.3856658935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.69618]
 [145.74913]
 [144.94351]
 [131.76418]
 [143.45305]
 [153.23833]
 [146.55518]
 [152.0259 ]
 [139.43912]
 [145.87473]
 [146.30594]
 [160.39313]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  1.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  7.  5.  6.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: -3.4877243041992188
desired expected reward: 157.025390625



buy possibilites: [-1] 
expected returns: [[146.15196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  1.] 
cards in discard: [ 8. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 57 

action type: buy - action 16.0
Learning step: -1.03423273563385
desired expected reward: 142.41880798339844






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 16.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  0. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3. 16.  0. 29.] 
adversary cards in discard: [ 8. 16. 16.  1. 25.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.  0. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  4.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3. 16.  0. 29.] 
adversary cards in discard: [ 8. 16. 16.  1. 25.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.  0. 16.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  3. 16.  0. 29.] 
adversary cards in discard: [ 8. 16. 16.  1. 25.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [ 6.  3. 16.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[106.62921]
 [ 95.31716]
 [101.13864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  0. 29.] 
cards in discard: [ 8. 16. 16.  1. 25.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8] -> size -> 22 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: -4.83777379989624
desired expected reward: 141.31419372558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.625626]
 [ 84.9211  ]
 [104.185486]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16.  0. 29.] 
cards in discard: [ 8. 16. 16.  1. 25.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  7.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8] -> size -> 22 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -2.845125913619995
desired expected reward: 101.13309478759766



buy possibilites: [-1] 
expected returns: [[28.418873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16.  0. 29.] 
cards in discard: [ 8. 16. 16.  1. 25.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  6.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8] -> size -> 22 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -18.90662956237793
desired expected reward: 66.01445770263672






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  6.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
adversary victory points: -1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
adversary victory points: -1
player victory points: -2 





Player: 0 
cards in hand: [ 6. 29. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[195.63612]
 [185.68605]
 [174.69923]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 16.  6.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: 2.8968560695648193
desired expected reward: 31.31572914123535



action possibilites: [-1. 16.] 
expected returns: [[176.93279]
 [165.21547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 26 

action type: take_action - action 29.0
Learning step: -4.003561019897461
desired expected reward: 179.11306762695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[159.07901]
 [163.2968 ]
 [162.39839]
 [153.67978]
 [161.59859]
 [168.51318]
 [163.99332]
 [167.77617]
 [158.70241]
 [163.17638]
 [163.42574]
 [173.14569]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: -3.9686686992645264
desired expected reward: 172.96414184570312



buy possibilites: [-1] 
expected returns: [[142.31482]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6.  0.  1.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 56 

action type: buy - action 14.0
Learning step: -1.9330379962921143
desired expected reward: 156.76937866210938






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 16. 16.  1.] 
adversary cards in discard: [14. 29.  6. 16.  6.  0.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6 14] -> size -> 14 
adversary victory points: -1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  3.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 16. 16.  1.] 
adversary cards in discard: [14. 29.  6. 16.  6.  0.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6 14] -> size -> 14 
adversary victory points: -1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 16. 16.  1.] 
adversary cards in discard: [14. 29.  6. 16.  6.  0.  1.] 
adversary owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6 14] -> size -> 14 
adversary victory points: -1
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25. 16. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 16.] 
expected returns: [[122.1157 ]
 [120.66182]
 [103.6353 ]
 [103.6353 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 16. 16.  1.] 
cards in discard: [14. 29.  6. 16.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16  6  3  1  0 16 29 25  8 16  6 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: -4.458010196685791
desired expected reward: 137.8568115234375



action possibilites: [-1] 
expected returns: [[132.56433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 16.] 
cards in discard: [14. 29.  6. 16.  6.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  5.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: gain_card_n - action 0
Learning step: -1.1087284088134766
desired expected reward: 74.27800750732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.28042 ]
 [114.013466]
 [133.12247 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 16.] 
cards in discard: [14. 29.  6. 16.  6.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  5.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 24 

action type: take_action - action -1
Learning step: -2.6742782592773438
desired expected reward: 129.89004516601562



buy possibilites: [-1] 
expected returns: [[77.58102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 16.] 
cards in discard: [14. 29.  6. 16.  6.  0.  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -287.0 

action type: buy - action 6.0
Learning step: -18.305099487304688
desired expected reward: 95.70836639404297






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 11.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 25.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
adversary victory points: -2
player victory points: -2 


action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  8.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 25.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
adversary victory points: -2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  8.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  2.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 25.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
adversary victory points: -2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  8.] 
cards in discard: [ 8.  0.  8. 16.  0. 16.  6. 11.  0.  0. 11.  0.  8.  6. 11.  0.  0.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 25.  1.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
adversary victory points: -2
player victory points: -2 





Player: 0 
cards in hand: [ 6. 25.  1.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[111.24176 ]
 [110.214554]
 [ 99.064064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8
  8] -> size -> 25 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[-5  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -7 

action type: buy - action -1
Learning step: -1.8255976438522339
desired expected reward: 75.75541687011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 89.92934]
 [ 95.12092]
 [ 82.58353]
 [ 96.82485]
 [109.27786]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8
  8] -> size -> 25 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[-5  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -3.7640743255615234
desired expected reward: 107.30757141113281



buy possibilites: [-1] 
expected returns: [[117.89964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  1.  8.  3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8
  8] -> size -> 25 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -37.0 

action type: buy - action 0.0
Learning step: -3.6937255859375
desired expected reward: 86.2356185913086






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  6  8 11 10  8  6  8
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
adversary victory points: -2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  6.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[72.620895]
 [61.48666 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  6.  0.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11. 11.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3  0] -> size -> 26 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -5.768753528594971
desired expected reward: 112.13088989257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.687378]
 [63.508087]
 [56.46222 ]
 [64.53264 ]
 [71.51093 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  6.  0.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  4.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11. 11.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3  0] -> size -> 26 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -3.468858480453491
desired expected reward: 67.4979476928711



buy possibilites: [-1] 
expected returns: [[113.5744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  6.  0.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  3.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  8. 11. 11.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3  0] -> size -> 26 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -338.0 

action type: buy - action 6.0
Learning step: -17.167686462402344
desired expected reward: 39.29454040527344






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 11. 11.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16 11  0 11  8 11  0  0 16  8  8 11 10  8  6  8  8
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  3.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16. 16. 29. 16.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6] -> size -> 17 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  3.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16. 16. 29. 16.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6] -> size -> 17 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  3.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16. 16. 29. 16.  0.] 
adversary cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.] 
adversary owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6] -> size -> 17 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [16. 16. 29. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 29. 16.] 
expected returns: [[142.71182]
 [130.22253]
 [130.22253]
 [137.05914]
 [130.22253]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 29. 16.  0.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  3.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -4.598750591278076
desired expected reward: 108.97565460205078



action possibilites: [-1] 
expected returns: [[113.99258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 16.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -329 

action type: gain_card_n - action 2
Learning step: -17.977783203125
desired expected reward: 63.874534606933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.82784 ]
 [100.44873 ]
 [113.906456]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 16.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1
Learning step: -4.751778602600098
desired expected reward: 109.24079895019531



buy possibilites: [-1] 
expected returns: [[83.640816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 16.] 
cards in discard: [ 0.  6. 25.  1.  8.  3.  6.  6.  0. 14.  6.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action 0.0
Learning step: -6.309473514556885
desired expected reward: 98.51836395263672






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 16. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[63.136665]
 [54.434563]
 [63.36212 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 25.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  2.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0. 16.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -5.296812534332275
desired expected reward: 78.34400177001953



action possibilites: [-1] 
expected returns: [[-3.5065336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  6.  8.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0. 16.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6] -> size -> 26 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -27 

action type: take_action - action 25.0
Learning step: -4.5476179122924805
desired expected reward: 57.82614517211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-3.353802 ]
 [-3.4010448]
 [-3.3960454]
 [-3.3382573]
 [-3.4560301]
 [-3.4069026]
 [-3.4028218]
 [-3.5065336]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  6.  8.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0. 16.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6] -> size -> 26 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1
Learning step: -1.3513094186782837
desired expected reward: -4.857842922210693



buy possibilites: [-1] 
expected returns: [[104.106575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  6.  8.  1.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  0. 16.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6] -> size -> 26 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -11 

action type: buy - action 10.0
Learning step: 1.9625389575958252
desired expected reward: -1.4402828216552734






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0. 16.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  6. 29.  0. 16.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0. 16.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  6. 29.  0. 16.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0. 16.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  6. 29.  0. 16.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 





Player: 0 
cards in hand: [16.  6. 29.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 16.] 
expected returns: [[8.604753]
 [8.968324]
 [9.006593]
 [8.968324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 29.  0. 16.] 
cards in discard: [10. 25.  3.  0. 16.  6.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  8.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6  0] -> size -> 27 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: -6.943856716156006
desired expected reward: 97.1627197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.978833]
 [10.149478]
 [ 9.479337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 29.  0. 16.] 
cards in discard: [10. 25.  3.  0. 16.  6.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  8.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6  0] -> size -> 27 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -2.183173418045044
desired expected reward: 6.924407005310059



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  8.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 16  0  8 11  0  0 16  8  8 11 10  8  6  8  8  3  0
  1  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  6.  6.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  6.  6.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  6.  6.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  0.  8.  8.  8.  1. 11.  8.  0.  0.  0.  6.  0.  0.
 10.  6.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  6.  6.] 
adversary cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 





Player: 0 
cards in hand: [ 6. 14.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[ 2.7946272]
 [-2.0556808]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  6.  6.] 
cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1.0
Learning step: -2.4196460247039795
desired expected reward: 7.059698104858398



action possibilites: [-1] 
expected returns: [[15.979657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action 14.0
Learning step: -0.4820351302623749
desired expected reward: -2.6504876613616943





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.26932 ]
 [12.006255]
 [11.663567]
 [ 8.002256]
 [13.914748]
 [12.258277]
 [11.940301]
 [15.942224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [10. 25.  3.  0. 16.  6.  8.  1. 16.  6. 29.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1
Learning step: -1.4769039154052734
desired expected reward: 14.502753257751465






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [0. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 28. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 27. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 27. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [ 6.  6.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[65.51356]
 [65.8105 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  1.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1.0
Learning step: -1.8124128580093384
desired expected reward: 14.12982177734375



action possibilites: [-1] 
expected returns: [[24.389015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 16. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0  6] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action 25.0
Learning step: -4.096715450286865
desired expected reward: 59.81264877319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.431587]
 [26.36465 ]
 [27.358807]
 [31.882195]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 16. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 27. 30.  8.  0.  4.  6.  1.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0  6] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1
Learning step: -2.048175811767578
desired expected reward: 22.340839385986328



buy possibilites: [-1] 
expected returns: [[32.623558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 16. 16.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0  6] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -21 

action type: buy - action 8.0
Learning step: -1.6839103698730469
desired expected reward: 25.674896240234375






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0. 10.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  6. 29.  6.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
adversary victory points: -4
player victory points: -1 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  6.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  6  8  8  3  0  1  6  0
  0  3  0  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  6. 29.  6.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
adversary victory points: -4
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0
  3  0  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  6. 29.  6.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  6. 29.  6.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  6. 29.  6.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
adversary owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  8.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[27.81947 ]
 [22.796932]
 [24.68898 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6. 29.  6.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  1  0 16 29 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -3.5540664196014404
desired expected reward: 29.06949234008789



action possibilites: [-1] 
expected returns: [[49.725655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.3151917457580566
desired expected reward: 18.36518669128418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.80955 ]
 [49.974205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1
Learning step: -2.868598222732544
desired expected reward: 46.8570556640625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [11.  8.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  0.  0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 14.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6.] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  6.  0.  0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 14.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6.] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  6.  0.  0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 14.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6.] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[39.256325]
 [33.997543]
 [31.958263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1. 14.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1.0
Learning step: -4.197643280029297
desired expected reward: 45.776546478271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[29.164566]
 [31.286205]
 [31.013489]
 [30.478992]
 [33.76704 ]
 [33.381413]
 [29.082855]
 [31.33672 ]
 [31.50423 ]
 [36.304646]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1. 14.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  6.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -3.470613956451416
desired expected reward: 31.26949119567871



buy possibilites: [-1] 
expected returns: [[37.759716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1. 14.] 
cards in discard: [ 8. 25.  6.  6.  0.  0. 16. 16.  8.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5.    0.   -4.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -44.5 

action type: buy - action 11.0
Learning step: -3.063758611679077
desired expected reward: 30.70328140258789






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [1. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 3. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  1  6  0  0  3
  0  6  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8. 11.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8 11] -> size -> 18 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8. 11.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8 11] -> size -> 18 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  8. 11.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8 11] -> size -> 18 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [16.  8. 11.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11. 16.] 
expected returns: [[46.062504]
 [39.209232]
 [40.650707]
 [43.31208 ]
 [39.209232]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 11.  6. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  1  0 16 25  8 16  6 14  0  6  0  6  6  0 10  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -3.4112484455108643
desired expected reward: 34.34846878051758



action possibilites: [-1] 
expected returns: [[61.076733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: trash_cards_n_from_hand - action 11
Learning step: -1.7578554153442383
desired expected reward: 42.883785247802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[48.980545]
 [57.636986]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -2.7520978450775146
desired expected reward: 58.32463455200195



buy possibilites: [-1] 
expected returns: [[66.74493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action 0.0
Learning step: -3.3472676277160645
desired expected reward: 45.63330078125






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 16. 14.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 16. 14.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 16. 14.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  0. 16.  0.  6.  0. 10. 16.  8.  0.  0. 11.  8.  6.  0.  0.
  8.  0.  3.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 16. 14.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  6. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[43.472824]
 [37.89403 ]
 [36.07601 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 16. 14.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10 10] -> size -> 29 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -4.356771945953369
desired expected reward: 62.388153076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[36.194237]
 [38.685295]
 [38.09942 ]
 [41.20746 ]
 [38.515366]
 [43.27617 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 16. 14.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  5.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10 10] -> size -> 29 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -3.1807868480682373
desired expected reward: 40.17509078979492



buy possibilites: [-1] 
expected returns: [[40.536964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 16. 14.] 
cards in discard: [ 0.  8. 16. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10 10] -> size -> 29 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -20 

action type: buy - action 11.0
Learning step: -2.14829158782959
desired expected reward: 39.059173583984375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  3  0  6  0  0  3  0
  6  0  0 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 10.  6.  0.] 
adversary cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 10.  6.  0.] 
adversary cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
adversary victory points: -3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 10.  6.  0.] 
adversary cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
adversary owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
adversary victory points: -3
player victory points: -1 





Player: 0 
cards in hand: [ 6. 25. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[29.43755 ]
 [29.70829 ]
 [27.229275]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 10.  6.  0.] 
cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
adversary victory points: -1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: buy - action -1
Learning step: -2.8109755516052246
desired expected reward: 37.725990295410156



action possibilites: [-1. 25.  8.] 
expected returns: [[45.21586 ]
 [46.43886 ]
 [47.126587]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  6.  0.  8.] 
cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  0 16 25  8 16 14  0  6  0  6  6  0 10  8  0 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
adversary victory points: -1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: take_action - action 10.0
Learning step: -0.6512311100959778
desired expected reward: 25.19976043701172



action possibilites: [-1. 25.] 
expected returns: [[17.112888]
 [16.901377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.] 
cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: trash_cards_n_from_hand - action 5
Learning step: -0.7963786125183105
desired expected reward: 45.7855224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.303172]
 [19.815884]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 23 

action type: take_action - action -1.0
Learning step: 0.6686684489250183
desired expected reward: 17.781570434570312



buy possibilites: [-1] 
expected returns: [[-0.61418056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 0.  8. 16. 11.  1.  0.  6. 16. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: buy - action 0.0
Learning step: -0.9626922607421875
desired expected reward: 12.34049129486084






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  3  0  6  0
  0 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
adversary victory points: -2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
adversary victory points: -2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
adversary victory points: -2
player victory points: -2 





Player: 0 
cards in hand: [ 0. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[138.39636]
 [132.7503 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 16.  0.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[-5  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -7 

action type: buy - action -1
Learning step: 2.6996188163757324
desired expected reward: 2.0854382514953613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[117.11786]
 [122.96133]
 [122.07539]
 [129.38284]
 [122.93462]
 [135.02888]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 27. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 16.  0.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
adversary victory points: -2
player victory points: -2 

Reward from previous game state: 
[-5  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -4.380535125732422
desired expected reward: 132.54981994628906



buy possibilites: [-1] 
expected returns: [[37.358253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 16.  0.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5.  0. -1. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 6.0 

action type: buy - action 3.0
Learning step: -4.9632086753845215
desired expected reward: 117.11217498779297






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 16.  0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16. 25. 10.  8.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
adversary victory points: -1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 16.  0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16. 25. 10.  8.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
adversary victory points: -1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 16.  0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16. 25. 10.  8.  6.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
adversary victory points: -1
player victory points: -2 





Player: 0 
cards in hand: [16. 25. 10.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 10.  8.] 
expected returns: [[37.305626]
 [30.381489]
 [37.602703]
 [31.353436]
 [32.09976 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25. 10.  8.  6.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10  0] -> size -> 27 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 4 

action type: buy - action -1
Learning step: -0.9056558609008789
desired expected reward: 36.452598571777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.680058]
 [38.00441 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25. 10.  8.  6.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10  0] -> size -> 27 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[-5  0 -1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -0.9150988459587097
desired expected reward: 36.44025421142578



buy possibilites: [-1] 
expected returns: [[4.4672475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 25. 10.  8.  6.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
adversary owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10  0] -> size -> 27 
adversary victory points: -2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1  10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action 0.0
Learning step: -2.6334900856018066
desired expected reward: 26.046571731567383






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  6  0  0  0  6  0  0
 10 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  1. 16.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
adversary victory points: -1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  1. 16.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  1. 16.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  1. 16.] 
adversary cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.] 
adversary owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
adversary victory points: -1
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0.  8.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[23.04976 ]
 [20.850594]
 [20.153324]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  1. 16.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 26. 30.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: -0.033344436436891556
desired expected reward: 4.433903217315674



action possibilites: [-1] 
expected returns: [[30.12941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 72 

action type: gain_card_n - action 3
Learning step: 3.787099599838257
desired expected reward: 13.60334587097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.224197]
 [24.740166]
 [32.654   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 3.  0. 11.  6.  0.  0.  0. 16. 25. 10.  8.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 10.  8.] 
adversary cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 1.4439048767089844
desired expected reward: 31.573314666748047






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  8.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  8.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  8.] 
cards in discard: [ 8. 10.  0.  8.  0.  0.  6.  0.  0. 11. 11. 16.  0.  0.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16.  0. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 8. 16.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10. 14.] 
expected returns: [[37.330425]
 [33.103733]
 [31.617058]
 [32.277897]
 [29.50063 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0. 10. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.4328983426094055
desired expected reward: 33.08689498901367



action possibilites: [-1.  8. 16. 14.] 
expected returns: [[21.49194 ]
 [18.809765]
 [17.740955]
 [16.225868]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0. 14.  4.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 25  8 16 14  0  0  6  6  0 10  8  0 11  0  3  0  4] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 26. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 10.0
Learning step: 1.2107349634170532
desired expected reward: 32.38222122192383



action possibilites: [-1.  8. 14.] 
expected returns: [[13.663535]
 [ 8.798785]
 [ 6.695324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  4.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 3.4912521839141846
desired expected reward: 20.168113708496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.992611 ]
 [15.9860115]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  4.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 25. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action -1.0
Learning step: 3.488699436187744
desired expected reward: 17.152225494384766



buy possibilites: [-1] 
expected returns: [[0.9932997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  4.] 
cards in discard: [3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  40   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 48 

action type: buy - action 0.0
Learning step: 2.0227184295654297
desired expected reward: 10.015335083007812






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11 10  8  8  8  0  0  0  0  6  0  0 10 10
  0  0  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 29.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.515839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  6. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: 0.6680497527122498
desired expected reward: 1.6613495349884033





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[11.062137]
 [12.038403]
 [11.471566]
 [13.051615]
 [11.75125 ]
 [13.984013]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  4.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  6. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -0.030005788430571556
desired expected reward: 14.090645790100098



buy possibilites: [-1] 
expected returns: [[12.827679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 16. 10.  6. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: 0.9360416531562805
desired expected reward: 13.987664222717285






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 8. 16. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10.  6. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10 10  0
  0  0  4] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 28.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  8.  0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  8.  0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  8.  0.] 
adversary cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[17.231205]
 [12.862317]
 [13.724373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  8.  0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8.  0. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -1.4113596677780151
desired expected reward: 11.416318893432617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.272564]
 [15.550522]
 [19.638626]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  8.  0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8.  0. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -1.5889288187026978
desired expected reward: 15.6422758102417



buy possibilites: [-1] 
expected returns: [[13.648179]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  8.  0.] 
cards in discard: [ 3.  0. 10. 16.  8. 14.  4. 11.  6.  0.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8.  0. 11.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -52.0 

action type: buy - action 0.0
Learning step: -3.0065441131591797
desired expected reward: 11.266019821166992






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  0. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0
  0  4  4] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16. 14. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16. 14. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 25. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16. 14. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 16. 14. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11. 16. 14. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14. 11. 25.] 
expected returns: [[53.004036]
 [49.56317 ]
 [44.248356]
 [41.560642]
 [49.56317 ]
 [52.96418 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 14. 11. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -1.2933357954025269
desired expected reward: 12.354843139648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[41.327564]
 [52.334045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16. 14. 11. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.947789430618286
desired expected reward: 45.140140533447266



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [11. 16. 14. 11. 25.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [11. 16. 14. 11. 25.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [11. 16. 14. 11. 25.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [16.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[20.119278]
 [13.740414]
 [14.481443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  3.  0.] 
cards in discard: [11. 16. 14. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.  0.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -3.8721015453338623
desired expected reward: 48.46194839477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.85919 ]
 [14.48056 ]
 [20.381863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  3.  0.] 
cards in discard: [11. 16. 14. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.  0.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.1735241413116455
desired expected reward: 16.502582550048828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.  0.
  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.  0.
  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 27. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 4. 10. 16.  0.  0.  0.  4. 16.  8.  6. 11.  3.  8.  0.  0. 11. 29.  0.
  0.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [8. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[36.010773]
 [31.518486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -1.8581997156143188
desired expected reward: 18.523664474487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[31.265812]
 [33.139244]
 [38.147552]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.6292951107025146
desired expected reward: 33.3814697265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [11.  0.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [4. 0. 6. 8. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [4. 0. 6. 8. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  8.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [4. 0. 6. 8. 0.] 
adversary cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [4. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[46.934177]
 [43.152046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 6. 8. 0.] 
cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -2.492905378341675
desired expected reward: 35.654632568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[43.55744 ]
 [45.223293]
 [49.82516 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 6. 8. 0.] 
cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 24. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.9052464962005615
desired expected reward: 44.028934478759766



buy possibilites: [-1] 
expected returns: [[76.45344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 6. 8. 0.] 
cards in discard: [11. 16. 14. 11. 25. 16.  0. 10.  3.  0.  8.  0.  3.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  8. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.] 
adversary owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -13 

action type: buy - action 3.0
Learning step: -0.9446203112602234
desired expected reward: 39.35183334350586






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 29.  0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  1.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0
  4  4  3 29  1  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 8. 10. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
expected returns: [[28.477472]
 [23.715317]
 [23.186605]
 [20.30177 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16 14  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  4.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -4.369294166564941
desired expected reward: 72.08414459228516



action possibilites: [-1] 
expected returns: [[47.87671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  4.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.10883235931396484
desired expected reward: 22.612335205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[40.49762 ]
 [42.744503]
 [48.632977]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  4.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -1.4522970914840698
desired expected reward: 46.42441177368164






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  4.  0.  0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  4  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  4.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  4.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  3.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  4.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  4.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 6. 25. 11.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[116.94781]
 [116.15812]
 [112.77776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 11.  0.  4.] 
cards in discard: [ 8. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16.  0.  3.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: 0.5556246042251587
desired expected reward: 49.1886100769043





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[103.059456]
 [115.53321 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25. 11.  0.  4.] 
cards in discard: [ 8. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16.  0.  3.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11] -> size -> 29 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -2.807067394256592
desired expected reward: 111.58367919921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  0.  3.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  4.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16. 16.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16. 16.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 23. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16. 16.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 16. 16.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 16. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 16.] 
expected returns: [[34.247814]
 [30.157797]
 [25.841393]
 [25.841393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16. 16.  6.] 
cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 4. 0. 0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.
 11.  0. 16.  0.  3.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -5.170894145965576
desired expected reward: 110.36227416992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.46364 ]
 [35.200893]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 16. 16.  6.] 
cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 4. 0. 0.] 
adversary cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.
 11.  0. 16.  0.  3.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.077336311340332
desired expected reward: 33.170467376708984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 0. 4. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 4. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.
 11.  0. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.  0. 11. 16. 16.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 4. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.
 11.  0. 16.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.  0. 11. 16. 16.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 4. 0. 0.] 
cards in discard: [ 0. 11.  0.  8.  0.  8.  0. 10.  8.  0. 14. 11. 16.  0.  0.  0. 16.  3.
 11.  0. 16.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.  0. 11. 16. 16.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.191826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.  0. 11. 16. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -0.23072806000709534
desired expected reward: 34.97015380859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[58.8955  ]
 [61.903873]
 [69.902664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  6. 25. 11.  0.  4.  0. 11. 16. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.125971555709839
desired expected reward: 68.06585693359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 25.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 25.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [15.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 25.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3. 25.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[29.541883]
 [29.743849]
 [23.096571]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -2.9492063522338867
desired expected reward: 66.95345306396484



action possibilites: [-1] 
expected returns: [[19.589296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 16.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -0.03348055109381676
desired expected reward: 28.451313018798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.753957]
 [18.847464]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  8. 16.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: 0.2837233543395996
desired expected reward: 19.87302017211914






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  4.  0.  6.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  4.  0.  6.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11.  4.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[4.305422]
 [4.483691]
 [4.483691]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  4.  0.  6.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -0.8927956819534302
desired expected reward: 17.954668045043945



action possibilites: [-1] 
expected returns: [[12.543484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  0.  6.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 35 

action type: gain_card_n - action 6
Learning step: 1.7921799421310425
desired expected reward: 6.593151569366455





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.458935]
 [12.975271]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  0.  6.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: 0.5871268510818481
desired expected reward: 13.130610466003418






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0 11  0  0 16  8 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4
  3  0  0 14 11 16  3  0 15  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [16.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[1.6195121]
 [1.3960695]
 [1.4675727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  8.  0.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 11.  8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -0.6650736331939697
desired expected reward: 12.310197830200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[5.932983 ]
 [5.4796004]
 [5.3180785]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  8.  0.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 11.  8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.005307042505592108
desired expected reward: 1.6142040491104126



buy possibilites: [-1] 
expected returns: [[8.443241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  8.  0.] 
cards in discard: [25.  3.  3.  0.  8. 16.  6. 14. 11. 11.  4.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  4.  0. 11.  8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -1.6566755771636963
desired expected reward: 4.276293754577637






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  4.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0. 11.  8.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 11.  8.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  0. 11.  8.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[6.382959 ]
 [6.5510716]
 [2.5273843]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16. 14.  0. 16.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -0.3637336790561676
desired expected reward: 8.079507827758789



action possibilites: [-1] 
expected returns: [[13.969433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16. 14.  0. 16.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: 0.9578992128372192
desired expected reward: 7.086158275604248





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 6.1593785]
 [ 7.903459 ]
 [ 7.5916753]
 [10.413122 ]
 [ 7.8989882]
 [13.316761 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [16. 14.  0. 16.  0.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: 0.45368996262550354
desired expected reward: 14.42312240600586






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [16. 14.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  0. 16.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.389305 ]
 [ 7.9974904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 2
Learning step: -0.36624234914779663
desired expected reward: 11.0294771194458





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 6.335075]
 [ 8.507584]
 [15.800812]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.5366811752319336
desired expected reward: 13.852620124816895



buy possibilites: [-1] 
expected returns: [[3.637175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 16.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.] 
adversary owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -1.7849174737930298
desired expected reward: 4.550161361694336






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 16.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 16.  6.  0.  0.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  8.] 
cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [16 11  0  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0
 14 11 16  3  0 15  1  0  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 16.  6.  0.  0.] 
adversary cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 


Game is draw!



Player 0 bought cards:
Copper: 9 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 4 
Workshop: 3 
Chapel: 2 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 4. 16.  6.  0.  0.] 
cards in discard: [25.  0.  0.  0. 10.  3. 16.  0. 11.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 25  8 16  0  6  6  0 10  8  0 11  0  3  0  4  3  0 11  0  3 14  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 27.  8.  0.  3.  2.  0.  9.  8.  7. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [15.  1. 11.  0.  0.  0.  6.  0.  3. 11.  0.  0.  0.  8.  3.  0.  0.  4.
  0. 11.  8.  0. 14. 16.  0. 16.  0.  0.] 
adversary owned cards: [16 11  0 16 11  8  8  8  0  0  0  0  6  0  0 10  0  0  0  4  3  0  0 14
 11 16  3  0 15  1  0  0  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -0.2318587601184845
desired expected reward: 3.4053163528442383



