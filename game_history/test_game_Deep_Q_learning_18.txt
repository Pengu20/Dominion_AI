 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[94.3402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        8        0] 
sum of rewards: -3000357 

action type: buy - action 8.0
Learning step: -120014.15625
desired expected reward: -120017.1875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[84.653015]
 [90.13219 ]
 [90.8459  ]
 [81.83339 ]
 [87.296745]
 [98.29726 ]
 [92.0811  ]
 [96.60816 ]
 [89.15484 ]
 [92.7948  ]
 [94.65729 ]
 [94.256134]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.96119689941406



buy possibilites: [-1] 
expected returns: [[99.81695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 8.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 98.29724884033203






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[107.25812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.81694793701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.232704]
 [103.55906 ]
 [104.26009 ]
 [ 95.48674 ]
 [111.89238 ]
 [105.52234 ]
 [106.25336 ]
 [107.75699 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.44551849365234



buy possibilites: [-1] 
expected returns: [[110.19756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.89238739013672






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[104.82735]
 [109.37888]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.19756317138672



action possibilites: [-1] 
expected returns: [[102.897575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 106.76348114013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 93.12221 ]
 [ 99.09134 ]
 [ 99.86534 ]
 [ 90.03938 ]
 [108.19401 ]
 [101.20471 ]
 [101.986465]
 [103.64247 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.89757537841797



buy possibilites: [-1] 
expected returns: [[106.08258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.19400787353516






Player: 1 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[115.67568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.08258056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.82722 ]
 [112.74128 ]
 [113.508156]
 [103.77295 ]
 [121.51731 ]
 [114.836365]
 [115.60324 ]
 [117.176   ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.83251190185547



buy possibilites: [-1] 
expected returns: [[126.64019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.51731872558594






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  1.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[131.02626]
 [135.57779]
 [135.57779]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 126.64019012451172



action possibilites: [-1] 
expected returns: [[132.5845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.92166137695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.533325]
 [129.54462 ]
 [119.327194]
 [130.93883 ]
 [133.3986  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.58450317382812






Player: 1 
cards in hand: [ 0.  1. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.  0.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[129.93878]
 [128.42168]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [10. 11.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.3986053466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[121.73269 ]
 [127.440285]
 [128.18782 ]
 [118.80419 ]
 [135.98424 ]
 [129.47964 ]
 [130.22719 ]
 [131.7443  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [10. 11.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  5. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 129.8136749267578



buy possibilites: [-1] 
expected returns: [[133.52303]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [10. 11.  0.  3. 11.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 135.98423767089844






Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  0.  1. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  0.  1. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  0.  1. 16.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3. 11.] 
adversary cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[126.597694]
 [131.61617 ]
 [131.61617 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.5230255126953



action possibilites: [-1] 
expected returns: [[138.77809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.53741455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.35343]
 [135.13708]
 [123.89507]
 [136.69456]
 [139.35205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [10. 11.  0.  3. 11.  0. 11. 10.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.77809143066406






Player: 1 
cards in hand: [0. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[152.12486]
 [156.67638]
 [150.46884]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.35205078125



action possibilites: [-1] 
expected returns: [[152.3188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 155.7192840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[143.38652]
 [149.59407]
 [150.39784]
 [140.18039]
 [158.80334]
 [151.79204]
 [152.59581]
 [154.25182]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  4. 10. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.3188018798828



buy possibilites: [-1] 
expected returns: [[149.55202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3. 10. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 158.8033447265625






Player: 1 
cards in hand: [ 0. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  0.] 
cards in discard: [0. 3. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3. 10. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  0.] 
cards in discard: [0. 3. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3. 10. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.  0.] 
cards in discard: [0. 3. 3. 3. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[155.8806 ]
 [154.33797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  1.] 
adversary cards in discard: [ 0.  3.  3.  3.  3.  8.  0. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 149.55201721191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.77058]
 [153.35521]
 [143.76079]
 [154.66351]
 [156.9624 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  1.] 
adversary cards in discard: [ 0.  3.  3.  3.  3.  8.  0. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 155.5500946044922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  1.] 
cards in discard: [ 0.  3.  3.  3.  3.  8.  0. 11.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  1.] 
cards in discard: [ 0.  3.  3.  3.  3.  8.  0. 11.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.  0. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[134.53304]
 [132.83472]
 [139.57727]
 [139.57727]
 [139.57727]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.  0. 10.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.96240234375



action possibilites: [-1] 
expected returns: [[166.17172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.  0. 10.  0.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 139.5374298095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.92122]
 [151.46104]
 [166.68065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.  0. 10.  0.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.17172241210938






Player: 1 
cards in hand: [ 3. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  9. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[147.56458]
 [152.37608]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 16.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.68064880371094



action possibilites: [-1] 
expected returns: [[156.85036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 16.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 152.672607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.65309]
 [154.81828]
 [144.3763 ]
 [156.24382]
 [158.7632 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 16.  3.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.85035705566406






Player: 1 
cards in hand: [ 3.  0.  1. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 16.  3.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 16.  3.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.62984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.76319885253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[147.927  ]
 [153.48033]
 [154.20068]
 [145.05928]
 [150.61581]
 [161.85478]
 [155.44734]
 [160.06393]
 [152.49408]
 [156.16772]
 [158.04741]
 [157.64124]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  3.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 155.7594451904297



buy possibilites: [-1] 
expected returns: [[152.0058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -21.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 161.8548126220703






Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  3.  3.  8.  0.  3.  0.  1. 16.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 11. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10. 11. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11. 10.] 
expected returns: [[150.75986]
 [149.2564 ]
 [155.37581]
 [155.37581]
 [155.37581]
 [149.2564 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.00579833984375



action possibilites: [-1] 
expected returns: [[178.94179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 155.0484161376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.63521]
 [163.1324 ]
 [178.70958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.94178771972656






Player: 1 
cards in hand: [ 0.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 10. 11. 11.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[141.59341]
 [140.23831]
 [140.23831]
 [145.93063]
 [145.93063]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.7095947265625



action possibilites: [-1] 
expected returns: [[165.34991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 145.18536376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.78908]
 [151.5034 ]
 [165.79816]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 11.  3.  0.  0.  0.  0. 10. 11. 10. 11. 11. 10.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.34991455078125






Player: 1 
cards in hand: [ 0.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[167.28355]
 [171.87378]
 [165.61537]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  8.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 165.7981719970703



action possibilites: [-1] 
expected returns: [[177.43156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  8.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 170.14295959472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.58492]
 [174.88301]
 [175.7041 ]
 [165.3526 ]
 [184.29482]
 [177.12962]
 [177.9507 ]
 [179.64902]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  2.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  8.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 177.4315643310547



buy possibilites: [-1] 
expected returns: [[170.06288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1. 16.  0.  0.  8.] 
adversary cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 184.29481506347656






Player: 1 
cards in hand: [ 1. 16.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  0.  8.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 16  3 29  8  8  1  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  9. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  0.  8. 29.  3.  0.  3.  0.  1.  3.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 11. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[148.51309]
 [146.95143]
 [153.31128]
 [153.31128]
 [146.95143]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 170.06288146972656



action possibilites: [-1] 
expected returns: [[161.25415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 152.63613891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[152.06831]
 [149.1309 ]
 [161.87138]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.254150390625






Player: 1 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10] -> size -> 28 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[143.28014]
 [148.18921]
 [141.69505]
 [141.69505]
 [141.69505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.8713836669922



action possibilites: [-1] 
expected returns: [[155.0751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 147.34246826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.56317]
 [141.30081]
 [155.56154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.07510375976562






Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [0. 1. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 29  8  8  1  0  3 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 1. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 1. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 1. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[146.7278 ]
 [152.0078 ]
 [152.0078 ]
 [144.94783]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 11.  0.] 
adversary cards in discard: [0. 1. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.56155395507812



action possibilites: [-1] 
expected returns: [[160.71117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  0.] 
adversary cards in discard: [0. 1. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 151.0895233154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.5513 ]
 [146.12889]
 [161.27603]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  0.] 
adversary cards in discard: [0. 1. 3. 0. 0. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.71116638183594






Player: 1 
cards in hand: [ 1.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11.  0.] 
cards in discard: [0. 1. 3. 0. 0. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11.  0.] 
cards in discard: [0. 1. 3. 0. 0. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11.  0.] 
cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[126.87322]
 [125.1121 ]
 [132.09859]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 11.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.27603149414062



action possibilites: [-1] 
expected returns: [[150.6484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.18988037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[138.83702]
 [135.1921 ]
 [151.09087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0. 10. 10. 11. 10. 11. 10.  0. 15. 11. 10. 10.  0.
 10. 15. 11.  0. 11. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.64840698242188






Player: 1 
cards in hand: [29. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [ 0.  1.  3.  0.  0.  0.  8.  3. 14.  1.  3.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 11. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10. 10. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11. 11.] 
expected returns: [[165.39447]
 [163.85258]
 [163.85258]
 [170.205  ]
 [170.205  ]
 [170.205  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.09088134765625



action possibilites: [-1] 
expected returns: [[178.02718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 169.62022399902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[167.23055]
 [164.15263]
 [178.34065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [8. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14  0] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.0271759033203






Player: 1 
cards in hand: [8. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 29  8  1  0  3 29  0 14  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10.  0. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[185.25478]
 [183.71288]
 [183.71288]
 [190.06529]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 11.] 
cards in discard: [15. 11. 10. 10. 11. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.3406524658203



action possibilites: [-1] 
expected returns: [[203.17247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 189.4622039794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[193.51772]
 [200.21126]
 [190.46207]
 [201.52751]
 [203.71782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 203.17247009277344






Player: 1 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [8. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 15. 10.  0.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [8. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 15. 10.  0.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [8. 3. 0. 4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 15. 10.  0.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[169.0876 ]
 [173.97694]
 [169.6657 ]
 [167.50513]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15. 10.  0.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [14.  0.  3. 29.  0.] 
adversary cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 203.71780395507812



action possibilites: [-1] 
expected returns: [[173.4738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  0.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [14.  0.  3. 29.  0.] 
adversary cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 173.12942504882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[163.44371]
 [160.23341]
 [174.17992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.  0.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [14.  0.  3. 29.  0.] 
adversary cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 173.4738006591797






Player: 1 
cards in hand: [14.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 29.  0.] 
cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  3.  3.  0. 15.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.] 
cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  3.  3.  0. 15.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 15.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 15.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 3. 0. 4. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 15.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[167.9109 ]
 [168.47282]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
  843    0] 
sum of rewards: 718 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: 241.7476043701172



action possibilites: [-1] 
expected returns: [[182.39989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 168.4728240966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[170.98509]
 [167.52492]
 [182.67659]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.39988708496094






Player: 1 
cards in hand: [ 0.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  0. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  0. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  0. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 10.  0. 11. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[133.65938]
 [132.0741 ]
 [138.4685 ]
 [138.4685 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 11.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29.  0.  1.  4.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 182.6765899658203



action possibilites: [-1] 
expected returns: [[189.58778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 29.  0.  1.  4.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 137.6007537841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[178.07408]
 [185.63629]
 [174.61935]
 [187.12881]
 [189.66017]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 29.  0.  1.  4.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 189.58778381347656






Player: 1 
cards in hand: [ 0. 29.  0.  1.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.  4.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 4. 0.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 0.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 0.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10. 11.] 
expected returns: [[133.32552]
 [131.61469]
 [131.61469]
 [131.61469]
 [131.61469]
 [138.39961]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10. 11.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 189.6602020263672



action possibilites: [-1] 
expected returns: [[164.02754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -10    0    0
   64    0] 
sum of rewards: -81 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 137.51718139648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[153.1653 ]
 [149.75322]
 [164.60158]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [15. 11. 10. 10. 11. 11. 15. 11. 10.  0. 10.  0. 15. 11.  3. 15. 10.  0.
  0. 15. 15.  3.  3. 15. 11.  0. 10.  0. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 22 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.0275421142578






Player: 1 
cards in hand: [ 0.  0.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  3.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [ 3.  3. 29.  0.  0. 11.  3.  0. 15. 29.  0.  1.  4.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  0. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[206.03542]
 [211.25983]
 [206.64317]
 [204.28557]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.6015625



action possibilites: [-1] 
expected returns: [[218.01524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -91 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 210.49159240722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[207.1504 ]
 [214.81548]
 [203.64885]
 [216.32709]
 [218.87709]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [29.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 218.01524353027344






Player: 1 
cards in hand: [29.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 11. 15. 11.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 11. 15. 11.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 11. 15. 11.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 15. 11.] 
expected returns: [[206.7671 ]
 [211.7717 ]
 [205.13158]
 [211.7717 ]
 [207.37485]
 [211.7717 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 15. 11.] 
cards in discard: [15. 11.  0. 15. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 218.87709045410156



action possibilites: [-1] 
expected returns: [[220.53914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 11.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -30    0    0
   64    0] 
sum of rewards: -131 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 204.2662811279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[209.2704 ]
 [205.848  ]
 [220.76295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15. 11.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 220.5391387939453






Player: 1 
cards in hand: [ 0.  0.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [15. 10. 10. 15. 10.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 10. 10. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 15. 10.] 
expected returns: [[193.83873]
 [194.4169 ]
 [192.15245]
 [192.15245]
 [194.4169 ]
 [192.15245]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 15. 10.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 11.  4.  0. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 220.76295471191406



action possibilites: [-1] 
expected returns: [[199.72855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15. 10.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 11.  4.  0. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 194.41690063476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[188.43388]
 [185.01431]
 [199.92784]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15. 10.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 11.  4.  0. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 199.72854614257812






Player: 1 
cards in hand: [ 3. 11.  4.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  4.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10.  0.  0.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  4.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10.  0.  0.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  4.  0. 15.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [11. 10. 10.  0.  0.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[167.86092]
 [172.58727]
 [166.32553]
 [166.32553]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.  0.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.  3. 11.  4.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 199.92784118652344



action possibilites: [-1] 
expected returns: [[192.06166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.  3. 11.  4.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -40    0    0
   64    0] 
sum of rewards: -141 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 165.50929260253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[181.30945]
 [188.89647]
 [177.96805]
 [190.40031]
 [192.93898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [ 8.  3. 14.  3.  0.] 
adversary cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.  3. 11.  4.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 192.06166076660156






Player: 1 
cards in hand: [ 8.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  3.  0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.  3. 11.  4.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3. 15.  3.  0.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  3.  0.] 
cards in discard: [ 3. 29.  0.  0.  3.  0.  1.  3. 29.  0.  0.  0.  0.  3. 11.  4.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3. 15.  3.  0.] 
adversary cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[176.94737]
 [177.533  ]
 [177.533  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3.  0.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10
 10 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3.  3.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 192.93898010253906



action possibilites: [-1] 
expected returns: [[179.99104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10 10
 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3.  3.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 177.5330047607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[168.51028]
 [175.20204]
 [176.07246]
 [165.05556]
 [185.12721]
 [177.56499]
 [180.09636]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10 10
 10 11 10 15 15 15 15 15 15 15 15 15 14 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  1.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3.  3.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 179.9910430908203



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 15.  3.] 
cards in discard: [15. 11.  0. 15. 10.  0. 14. 11. 10. 11. 15. 11. 15. 10. 10. 15. 10. 14.
 11. 10. 10.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 11 10 11 10 10 11 10 10 11 10 10
 10 11 10 15 15 15 15 15 15 15 15 15 14 14 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8. 10.  9.  0.  8. 10.  8.  7. 10.  0. 10.  0.] 
adversary cards in hand: [15.  3.  3.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3 29  8  1  0  3 29  0 14  0  4  0  3 15  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       20        0
        0        0        0      -40        0        0       27        0] 
sum of rewards: -3000178 

action type: buy - action 11.0
Learning step: -120014.5234375
desired expected reward: -119829.3984375



