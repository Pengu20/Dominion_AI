 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.66357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -5  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -600 

action type: buy - action -1.0
Learning step: -44.138465881347656
desired expected reward: 238.63082885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[314.38968]
 [318.59167]
 [318.897  ]
 [312.2296 ]
 [324.61227]
 [320.07532]
 [320.38068]
 [334.49396]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.607294082641602
desired expected reward: 327.6394958496094



buy possibilites: [-1] 
expected returns: [[289.8417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -8.909175872802734
desired expected reward: 315.7030944824219






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[315.74817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.464977264404297
desired expected reward: 282.3767395019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[303.20126]
 [306.4043 ]
 [306.5767 ]
 [301.51178]
 [306.1786 ]
 [310.88373]
 [307.48822]
 [311.86694]
 [305.8188 ]
 [307.6606 ]
 [309.04193]
 [318.31958]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.902673721313477
desired expected reward: 307.8576965332031



buy possibilites: [-1] 
expected returns: [[303.54486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.544650077819824
desired expected reward: 298.94354248046875






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[288.0924 ]
 [277.31134]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.302010536193848
desired expected reward: 294.24285888671875



action possibilites: [-1] 
expected returns: [[332.8216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 17 

action type: gain_card_n - action 9
Learning step: -6.60519552230835
desired expected reward: 292.2684326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[310.4944 ]
 [314.97885]
 [315.33224]
 [308.21597]
 [314.7234 ]
 [321.40732]
 [316.59286]
 [322.58295]
 [314.32373]
 [316.94623]
 [318.86926]
 [330.74725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -8.965591430664062
desired expected reward: 323.85601806640625






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [10. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[317.8862 ]
 [305.49973]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.035062789916992
desired expected reward: 320.7121887207031



action possibilites: [-1] 
expected returns: [[350.0926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 4
Learning step: -7.772853374481201
desired expected reward: 291.2258605957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[333.6296 ]
 [338.012  ]
 [331.50375]
 [339.17038]
 [353.20517]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -10.429384231567383
desired expected reward: 339.6632080078125



buy possibilites: [-1] 
expected returns: [[325.17322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -11.565081596374512
desired expected reward: 322.0644836425781






Player: 1 
cards in hand: [ 0. 14.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  3.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  3.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  3.] 
cards in discard: [1. 0. 0. 3. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[301.23294]
 [285.08704]
 [284.69415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -11.74051570892334
desired expected reward: 313.4327087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.99033]
 [284.17108]
 [276.56082]
 [285.50235]
 [302.04117]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -10.830201148986816
desired expected reward: 293.648681640625



buy possibilites: [-1] 
expected returns: [[302.9365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -24.4714412689209
desired expected reward: 246.27877807617188






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 6.  0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[282.4703 ]
 [275.91275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6.  0. 10.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -11.542709350585938
desired expected reward: 291.393798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.3889 ]
 [279.7475 ]
 [279.90518]
 [276.15887]
 [279.58856]
 [283.38937]
 [280.6354 ]
 [284.1795 ]
 [279.33524]
 [280.7931 ]
 [281.90762]
 [290.61667]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 6.  0. 10.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -10.546043395996094
desired expected reward: 273.84149169921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[287.4472]
 [271.4602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -11.351045608520508
desired expected reward: 279.265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[272.1437 ]
 [276.67914]
 [277.05377]
 [269.85635]
 [276.4413 ]
 [283.2612 ]
 [278.31793]
 [284.58856]
 [276.0638 ]
 [278.6926 ]
 [280.63242]
 [294.03787]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -11.326172828674316
desired expected reward: 278.8438415527344



buy possibilites: [-1] 
expected returns: [[288.66956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -63.0 

action type: buy - action 8.0
Learning step: -10.570834159851074
desired expected reward: 267.74713134765625






Player: 1 
cards in hand: [ 1.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 6.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6  8] -> size -> 14 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 6.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6  8] -> size -> 14 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 6.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6  8] -> size -> 14 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[322.6846 ]
 [310.89676]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 1
Learning step: -9.837847709655762
desired expected reward: 264.9945068359375



action possibilites: [-1] 
expected returns: [[314.03287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 0
Learning step: -9.814597129821777
desired expected reward: 293.7921142578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[293.5198 ]
 [291.11087]
 [314.60562]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -10.504140853881836
desired expected reward: 303.5287170410156



buy possibilites: [-1] 
expected returns: [[316.92795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 14.  0.] 
adversary cards in discard: [14.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action 0.0
Learning step: -10.745112419128418
desired expected reward: 282.7746887207031






Player: 1 
cards in hand: [ 3.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.  0.] 
cards in discard: [14.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[315.3055]
 [306.0065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [14.  1.  3.  3.  0.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: discard_down_to_3_cards - action 1
Learning step: -10.325943946838379
desired expected reward: 273.60467529296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[295.77014]
 [299.88666]
 [293.79666]
 [300.96902]
 [313.69485]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [14.  1.  3.  3.  0.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -12.137101173400879
desired expected reward: 304.6299133300781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.  3. 14.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.  3. 14.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  1.  3.  3.  0.  3. 14.  3.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[314.83853]
 [299.91782]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  8 10  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -11.92117977142334
desired expected reward: 301.773681640625



action possibilites: [-1] 
expected returns: [[230.87291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 8
Learning step: -11.368115425109863
desired expected reward: 275.8869934082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[209.34831]
 [207.2933 ]
 [229.09932]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -8.757750511169434
desired expected reward: 222.1151580810547






Player: 1 
cards in hand: [ 0.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[234.93794]
 [224.07603]
 [224.27806]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -9.966117858886719
desired expected reward: 219.1331787109375



action possibilites: [-1.  8.] 
expected returns: [[259.92212]
 [247.28233]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11  8 10  0  8  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -54 

action type: take_action - action 10.0
Learning step: -8.2289400100708
desired expected reward: 217.7742156982422



action possibilites: [-1.] 
expected returns: [[265.57962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  8 10  0  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  40   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 3
Learning step: -9.567239761352539
desired expected reward: 236.28836059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[245.46605]
 [243.61784]
 [262.27182]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  8 10  0  8  0] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  40   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -10.771932601928711
desired expected reward: 254.8076934814453



buy possibilites: [-1] 
expected returns: [[263.37103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  8 10  0  8  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 14.  3.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action 0.0
Learning step: -9.597455024719238
desired expected reward: 235.86859130859375






Player: 1 
cards in hand: [ 0.  3.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14.  3.] 
cards in discard: [11.  0.  3.  0. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 14.  3.] 
cards in discard: [11.  0.  3.  0. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 14.  3.] 
cards in discard: [11.  0.  3.  0. 14.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[256.35284]
 [242.89395]
 [247.04988]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -11.200006484985352
desired expected reward: 252.1710205078125



action possibilites: [-1] 
expected returns: [[202.98589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -46 

action type: gain_card_n - action 9
Learning step: -10.126513481140137
desired expected reward: 237.7473907470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[190.18216]
 [192.60333]
 [192.7595 ]
 [188.9304 ]
 [196.03694]
 [193.44263]
 [193.59879]
 [201.93782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -8.456265449523926
desired expected reward: 194.5296173095703






Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0. 14.  0.  0.  0.  3.  3. 14.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[233.07407]
 [217.49223]
 [217.86264]
 [217.49223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -8.724528312683105
desired expected reward: 193.21328735351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[213.65712]
 [218.04631]
 [211.6097 ]
 [219.18895]
 [233.3715 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -10.369229316711426
desired expected reward: 223.57177734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[232.6006 ]
 [220.50273]
 [220.50273]
 [224.10414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -10.264994621276855
desired expected reward: 223.10650634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[201.84622]
 [205.44943]
 [200.12245]
 [206.40327]
 [218.3195 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -9.823686599731445
desired expected reward: 206.99505615234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 8. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 8. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  8.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.  8.] 
expected returns: [[214.17377]
 [204.4554 ]
 [207.34653]
 [204.26134]
 [204.26134]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  8  0  0 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  1. 14. 14.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -9.928570747375488
desired expected reward: 208.39097595214844



action possibilites: [-1] 
expected returns: [[247.83133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  0 10] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  1. 14. 14.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 9
Learning step: -8.960322380065918
desired expected reward: 196.77020263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[225.793  ]
 [224.06425]
 [241.7934 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  0  0 10] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  1. 14. 14.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -11.338252067565918
desired expected reward: 236.49307250976562






Player: 1 
cards in hand: [ 3. 25.  1. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1. 14. 14.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  0 10] -> size -> 6 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1. 14.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [11 10  8  0  0 10] -> size -> 6 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  1. 14.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [11 10  8  0  0 10] -> size -> 6 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  1. 14.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [11 10  8  0  0 10] -> size -> 6 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[252.18646]
 [245.28935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  0 10] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10. 14.  3. 25.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -105 

action type: discard_down_to_3_cards - action 4
Learning step: -9.915521621704102
desired expected reward: 196.13272094726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[234.49745]
 [237.42427]
 [233.07301]
 [238.20729]
 [247.86885]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  0 10] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  9. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10. 14.  3. 25.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -12.410197257995605
desired expected reward: 239.981201171875



buy possibilites: [-1] 
expected returns: [[175.36815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [10. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  0 10  6] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10. 14.  3. 25.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -80.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -416.0 

action type: buy - action 6.0
Learning step: -28.50786781311035
desired expected reward: 204.56515502929688






Player: 1 
cards in hand: [ 3.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10. 14.  3. 25.  1. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  0 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [ 0.  0.  0.  8.  3.  3. 11.  0.  0.  3.  0.  3. 10. 14.  3. 25.  1. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  6. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  0  0 10  6] -> size -> 7 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[244.45088]
 [231.99008]
 [235.70544]
 [231.73517]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6. 11.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  0  0 10  6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -9.19665241241455
desired expected reward: 166.17149353027344



action possibilites: [-1] 
expected returns: [[269.24472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -176 

action type: trash_cards_n_from_hand - action 10
Learning step: -14.248086929321289
desired expected reward: 215.87376403808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[246.67151]
 [244.8449 ]
 [263.76218]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1
Learning step: -16.4738826751709
desired expected reward: 252.77084350585938






Player: 1 
cards in hand: [ 0.  1. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[253.75064]
 [239.49028]
 [239.81534]
 [239.81534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: -16.850187301635742
desired expected reward: 246.91201782226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[234.77895]
 [233.12398]
 [253.49667]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 25.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: take_action - action -1.0
Learning step: -16.408035278320312
desired expected reward: 237.64981079101562



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 25.  0.] 
cards in discard: [15.  0.  1. 14.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 25.  0.] 
cards in discard: [15.  0.  1. 14.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[288.15457]
 [276.7205 ]
 [276.7205 ]
 [276.4113 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: -15.529083251953125
desired expected reward: 237.9675750732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[249.54208]
 [247.69424]
 [265.4431 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: take_action - action -1.0
Learning step: -16.69072723388672
desired expected reward: 248.83892822265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.] 
adversary cards in discard: [0.] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 26. 30.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.] 
adversary cards in discard: [0.] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.] 
adversary cards in discard: [0.] 
adversary owned cards: [10  8  0 10] -> size -> 4 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[258.37302]
 [245.52551]
 [245.79173]
 [245.79173]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0 10] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -215 

action type: discard_down_to_3_cards - action 0
Learning step: -14.247784614562988
desired expected reward: 169.316162109375



action possibilites: [-1] 
expected returns: [[262.15884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -195 

action type: trash_cards_n_from_hand - action 1
Learning step: -16.078083038330078
desired expected reward: 228.4550323486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[235.31992]
 [233.62308]
 [254.13863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: -17.299633026123047
desired expected reward: 244.8592071533203






Player: 1 
cards in hand: [ 8. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  0.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10
 15  4] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [15.  0.  1. 14.  3.  0.  3.  3.  3. 25.  0.  4. 14.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[300.8798]
 [286.4932]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: -16.739229202270508
desired expected reward: 237.39938354492188



action possibilites: [-1] 
expected returns: [[241.37912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20   50    0    0  -90    0  -50    0
    0    0] 
sum of rewards: -175 

action type: trash_cards_n_from_hand - action 0
Learning step: -17.451580047607422
desired expected reward: 265.20062255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[215.07498]
 [213.42117]
 [233.9921 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20   50    0    0  -90    0  -50    0
    0    0] 
sum of rewards: -175 

action type: take_action - action -1
Learning step: -15.714568138122559
desired expected reward: 225.66455078125






Player: 1 
cards in hand: [ 3.  0. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  7.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [6. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[235.5574 ]
 [221.95242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10. 14.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: -15.6843900680542
desired expected reward: 218.30770874023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[217.2803 ]
 [215.44998]
 [235.46175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10. 14.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -185 

action type: take_action - action -1.0
Learning step: -15.988715171813965
desired expected reward: 221.63992309570312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 14.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14.  0.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[239.1286]
 [225.0762]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25. 14.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: -15.684882164001465
desired expected reward: 219.77685546875



action possibilites: [-1] 
expected returns: [[254.11606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25. 14.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -165 

action type: take_action - action 8.0
Learning step: -13.87199878692627
desired expected reward: 212.9202117919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[227.94217]
 [226.12271]
 [246.8247 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25. 14.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: -15.563074111938477
desired expected reward: 238.552978515625






Player: 1 
cards in hand: [ 0.  0.  3. 25. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25. 14.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  7. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  1.  4.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  1.  4.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  1.  4.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[281.07156]
 [269.62094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10 14] -> size -> 29 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0   50    0    0  -90    0  -50 -300
    0    0] 
sum of rewards: -496 

action type: buy - action -1.0
Learning step: -30.860763549804688
desired expected reward: 215.96395874023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[237.2599 ]
 [235.6545 ]
 [252.22101]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10 14] -> size -> 29 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0   50    0    0  -90    0  -50    0
    0    0] 
sum of rewards: -196 

action type: take_action - action -1.0
Learning step: -16.95311164855957
desired expected reward: 237.04673767089844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 8.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15
  4  6  8 10 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  8. 11.  3.  0.  0. 11. 10. 10. 14.  0.  3.  3.  0. 14. 25.  0.  0.
  3. 14.  1.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[218.0774]
 [207.2067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -16.55766487121582
desired expected reward: 235.66336059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[200.1327 ]
 [198.53036]
 [215.27374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -15.018617630004883
desired expected reward: 203.63607788085938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 26. 29.  8.  6. 10.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[228.84644]
 [217.92227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  6.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -14.462994575500488
desired expected reward: 200.81076049804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[210.95357]
 [209.40752]
 [226.24626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  6.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -15.32410717010498
desired expected reward: 214.3579559326172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [16. 14.  3.  0.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [16. 14.  3.  0.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  0.  6.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[224.29268]
 [212.47919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0. 11.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16 15] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -15.137222290039062
desired expected reward: 211.10902404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[205.73083]
 [203.9858 ]
 [222.25266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0. 11.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16 15] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -15.158004760742188
desired expected reward: 209.18894958496094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0. 11.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8 11  0 25  0 11 10 15  4  6  8
 10 14  0 16 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[213.13086]
 [199.95493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 25.  3.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -15.174418449401855
desired expected reward: 207.0782012939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[193.06937]
 [191.1661 ]
 [211.24344]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 25.  3.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -14.912550926208496
desired expected reward: 199.28981018066406



buy possibilites: [-1] 
expected returns: [[189.26273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 25.  3.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -226 

action type: buy - action 0.0
Learning step: -16.695056915283203
desired expected reward: 176.3743133544922






Player: 1 
cards in hand: [ 0.  0.  8. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 25.  3.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  6.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 4. 3.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  5.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 4. 3.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  5.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 4. 3.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  5.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[230.82204]
 [217.56966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  5.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10. 14. 11.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -90    0    0    0    0    0    0  -60    0  -50 -300
    0    0] 
sum of rewards: -507 

action type: buy - action -1
Learning step: -29.710493087768555
desired expected reward: 159.55223083496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.15372]
 [211.29877]
 [230.68713]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 26. 29.  8.  5.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10. 14. 11.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -207 

action type: take_action - action -1.0
Learning step: -16.83578872680664
desired expected reward: 213.68902587890625



buy possibilites: [-1] 
expected returns: [[178.71793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10. 14. 11.] 
adversary cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.    0.    0.    0.    0.  -60.    0.
    0. -300.    0.    0.] 
sum of rewards: -468.0 

action type: buy - action 6.0
Learning step: -29.94378662109375
desired expected reward: 181.35498046875






Player: 1 
cards in hand: [ 3.  3. 10. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 14. 11.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 6. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [16. 14.  3.  0.  0. 15. 15.  0.  1. 14.  0.  6.  8.  0. 10.  0.  0. 25.
  0.  0.  8.  3.  4.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[215.8178 ]
 [205.89584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -178 

action type: discard_down_to_3_cards - action 3
Learning step: -7.103102207183838
desired expected reward: 52.25717544555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[200.64287]
 [199.19171]
 [213.94112]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -178 

action type: take_action - action -1.0
Learning step: -14.925145149230957
desired expected reward: 199.5721893310547



buy possibilites: [-1] 
expected returns: [[226.08563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [6. 6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -110.    0.    0.    0.  -30.    0.    0.  -30.    0.
    0.    0.    0.    0.] 
sum of rewards: -178.0 

action type: buy - action 0.0
Learning step: -12.733171463012695
desired expected reward: 165.6687774658203






Player: 1 
cards in hand: [14.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 14.  3.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[229.6307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [4. 3. 8. 3. 8.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1
Learning step: -13.589726448059082
desired expected reward: 212.49591064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[205.12521]
 [209.05852]
 [203.23082]
 [210.20084]
 [223.47502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [4. 3. 8. 3. 8.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -148 

action type: take_action - action -1.0
Learning step: -13.899075508117676
desired expected reward: 213.41452026367188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [4. 3. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 8. 3. 8.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 8. 3. 8.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[222.88286]
 [210.46288]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1.0
Learning step: -13.682939529418945
desired expected reward: 209.79208374023438



action possibilites: [-1] 
expected returns: [[171.26347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -197 

action type: trash_cards_n_from_hand - action 3
Learning step: -16.253005981445312
desired expected reward: 188.8756561279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.85278]
 [150.3419 ]
 [166.11627]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0  -60    0  -50    0
    0    0] 
sum of rewards: -197 

action type: take_action - action -1
Learning step: -14.79759693145752
desired expected reward: 156.46588134765625



buy possibilites: [-1] 
expected returns: [[160.80731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20  -30    0    0  -30    0    0    0
    0    0] 
sum of rewards: -147 

action type: buy - action 0.0
Learning step: -11.32447338104248
desired expected reward: 140.52828979492188






Player: 1 
cards in hand: [ 0.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0] -> size -> 5 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [8 6 6 0 0] -> size -> 5 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [8 6 6 0 0] -> size -> 5 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [8 6 6 0 0] -> size -> 5 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[236.58885]
 [223.99304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0. 16.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -137 

action type: discard_down_to_3_cards - action 3
Learning step: -7.5879364013671875
desired expected reward: 111.10060119628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[217.6301 ]
 [215.9438 ]
 [234.19707]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 25. 29.  8.  4.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0. 16.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -13.442108154296875
desired expected reward: 220.9593505859375



buy possibilites: [-1] 
expected returns: [[212.76108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [6. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 0 6] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 25.  3.  0. 16.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -110.    0.    0.    0.    0.    0.    0.  -30.    0.
    0. -300.    0.    0.] 
sum of rewards: -448.0 

action type: buy - action 6.0
Learning step: -28.410064697265625
desired expected reward: 187.53370666503906






Player: 1 
cards in hand: [15. 25.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  3.  0. 16.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0 6] -> size -> 6 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 25.  3.  0. 16.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 0 6] -> size -> 6 
adversary victory points: -3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[198.3471 ]
 [182.08649]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 0 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0. 10.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -148 

action type: buy - action -1
Learning step: -13.705108642578125
desired expected reward: 199.05596923828125



action possibilites: [-1] 
expected returns: [[185.97438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0. 10.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -156 

action type: trash_cards_n_from_hand - action 2
Learning step: -12.224043846130371
desired expected reward: 159.94529724121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.28603]
 [164.75293]
 [181.67119]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0. 10.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -156 

action type: take_action - action -1
Learning step: -13.142361640930176
desired expected reward: 172.83201599121094






Player: 1 
cards in hand: [11.  1.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0. 10.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0. 10.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[191.75513]
 [182.06888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -12.555160522460938
desired expected reward: 146.6907958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[176.23306]
 [179.10597]
 [174.84097]
 [179.93611]
 [189.67415]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 25. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -14.130291938781738
desired expected reward: 175.4604034423828



buy possibilites: [-1] 
expected returns: [[152.03534]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -107 

action type: buy - action 3.0
Learning step: -10.884503364562988
desired expected reward: 168.22145080566406






Player: 1 
cards in hand: [ 3.  0. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 15.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0. 15.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  6.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0. 15.] 
cards in discard: [ 0. 14.  0.  0. 14.  3.  4.  3.  8.  3.  8. 15. 14.  0.  6.  0.  0. 15.
 25.  3.  0. 16. 11.  1.  3.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  5.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[192.42876]
 [180.10526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  5.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -9.15149974822998
desired expected reward: 142.8838348388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[169.87828]
 [173.77014]
 [168.02203]
 [174.92749]
 [187.65474]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  5.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8] -> size -> 33 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -11.18786334991455
desired expected reward: 178.89273071289062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  5.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  5.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3] -> size -> 5 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[173.16553]
 [159.56416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  0.  4.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -11.354022979736328
desired expected reward: 176.3007049560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.11684]
 [155.50696]
 [150.48909]
 [156.49086]
 [168.86528]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  0.  4.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -10.67676067352295
desired expected reward: 160.8807830810547



buy possibilites: [-1] 
expected returns: [[183.44936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  0.  4.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -9.228232383728027
desired expected reward: 142.88861083984375






Player: 1 
cards in hand: [ 3. 10.  3.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  4.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0] -> size -> 6 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  4.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0] -> size -> 6 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[184.91364]
 [169.59482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  3.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -9.393172264099121
desired expected reward: 174.05618286132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[157.73138]
 [161.79153]
 [162.04956]
 [155.6863 ]
 [167.82538]
 [163.28935]
 [163.5474 ]
 [178.1933 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 29.  8.  3.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  3.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -9.577971458435059
desired expected reward: 173.65106201171875



buy possibilites: [-1] 
expected returns: [[158.56267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0 6] -> size -> 7 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 24. 29.  8.  2.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  3.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -396.0 

action type: buy - action 6.0
Learning step: -24.016653060913086
desired expected reward: 131.6696319580078






Player: 1 
cards in hand: [15. 11.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.  0.  1.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 29.  8.  2.  9.  7.  4.  9. 10.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6] -> size -> 7 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  1.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 24. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6] -> size -> 7 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 24. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6] -> size -> 7 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 23. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6] -> size -> 7 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[170.09065]
 [160.02466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  6.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -9.5557279586792
desired expected reward: 149.00694274902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[153.9569 ]
 [156.50558]
 [152.7331 ]
 [157.24573]
 [165.74792]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 23. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  6.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -9.970816612243652
desired expected reward: 155.9575653076172



buy possibilites: [-1] 
expected returns: [[191.48393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0 6 3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  6.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -87 

action type: buy - action 3.0
Learning step: -7.866891384124756
desired expected reward: 148.63868713378906






Player: 1 
cards in hand: [ 0. 15.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6.  3.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6 3] -> size -> 8 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  6.  3.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 22. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6 3] -> size -> 8 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  6.  3.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 6 3 0 6 3] -> size -> 8 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [6. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[203.50299]
 [194.76472]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6 3 0 6 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [10.  8.  0. 14.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -10.30651569366455
desired expected reward: 181.1774139404297



action possibilites: [-1] 
expected returns: [[128.48045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0 6 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [10.  8.  0. 14.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 7
Learning step: -9.796083450317383
desired expected reward: 158.94178771972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.77457 ]
 [107.032425]
 [125.7545  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0 6 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [10.  8.  0. 14.  3.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3  3] -> size -> 37 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -7.989598274230957
desired expected reward: 120.49085235595703






Player: 1 
cards in hand: [10.  8.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 14.  3.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10
 14  0 16 15  0  3  0 15  8  8 14  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3] -> size -> 6 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3] -> size -> 6 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3] -> size -> 6 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[183.9806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  3.  8. 16.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -6.934821605682373
desired expected reward: 118.8196792602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[161.459  ]
 [164.6843 ]
 [164.85991]
 [159.8244 ]
 [169.31967]
 [165.86382]
 [166.04086]
 [177.19377]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  3.  8. 16.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -10.015242576599121
desired expected reward: 172.3360595703125



buy possibilites: [-1] 
expected returns: [[157.89459]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [14.  0.  3.  8. 16.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: -10.7703218460083
desired expected reward: 150.6886749267578






Player: 1 
cards in hand: [14.  0.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  8. 16.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 16.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 16.] 
cards in discard: [ 8. 14. 25.  0.  0.  0.  3. 10.  3.  0.  4. 14.  3. 11. 15.  3.  0.  1.
  3.  0. 15.  0.  6.  3.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[191.09511]
 [180.6064 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  8. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 3
Learning step: -4.114243984222412
desired expected reward: 68.04925537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[168.60039]
 [171.83551]
 [167.08   ]
 [172.78047]
 [183.23518]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 14.  8. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -10.328593254089355
desired expected reward: 181.13247680664062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  3 14  3  3  8  0 25  0 11 10 15  4  6  8 10 14  0
 16 15  0  3  0 15  8  8 14  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0] -> size -> 7 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[185.45819]
 [175.6832 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  0.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -9.78851318359375
desired expected reward: 173.44668579101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[162.51234]
 [165.54625]
 [161.06895]
 [166.43622]
 [176.2112 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 21. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  0.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -10.200532913208008
desired expected reward: 175.7025146484375



buy possibilites: [-1] 
expected returns: [[147.39636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  0.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -76 

action type: buy - action 3.0
Learning step: -8.760894775390625
desired expected reward: 156.7853546142578






Player: 1 
cards in hand: [ 0.  8. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0.  1.] 
cards in discard: [0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  0.  1.] 
cards in discard: [0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.39897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 15.  3.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -7.92889928817749
desired expected reward: 139.46746826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.39932]
 [151.71931]
 [148.25919]
 [152.41469]
 [160.92586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  3. 15.  3.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -8.772265434265137
desired expected reward: 153.04635620117188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  6.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 15.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 15.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[169.05003]
 [159.14873]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 6 3 0 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 25.  8.  3. 14.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -8.529959678649902
desired expected reward: 152.39593505859375



action possibilites: [-1] 
expected returns: [[128.1944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 25.  8.  3. 14.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: trash_cards_n_from_hand - action 8
Learning step: -13.965730667114258
desired expected reward: 142.44065856933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.50429]
 [114.4935 ]
 [125.03094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 25.  8.  3. 14.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -185 

action type: take_action - action -1
Learning step: -12.928041458129883
desired expected reward: 115.266357421875






Player: 1 
cards in hand: [ 8. 25.  8.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  3. 14.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [3.] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  8.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  4.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [3.] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  8.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  3.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [3.] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[132.09547 ]
 [123.829895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  3.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [14.  4. 16.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0  8] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -205 

action type: discard_down_to_3_cards - action 3
Learning step: -9.86218547821045
desired expected reward: 39.94289779663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.55614]
 [117.21223]
 [131.18327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  3.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [14.  4. 16.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0  8] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -205 

action type: take_action - action -1.0
Learning step: -13.922866821289062
desired expected reward: 116.4056396484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  4. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  4. 16.  0.  0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10 14  0 16 15  0  3
  0 15  8  8 14  3  3  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  3.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  2.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  2.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3] -> size -> 4 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[132.68703]
 [124.83921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -205 

action type: buy - action -1.0
Learning step: -13.93505573272705
desired expected reward: 117.24821472167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.48038]
 [119.34035]
 [131.36983]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  2.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -205 

action type: take_action - action -1.0
Learning step: -13.8809814453125
desired expected reward: 115.99273681640625



buy possibilites: [-1] 
expected returns: [[93.34363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -100.    0.    0.    0.    0.    0.    0.  -60.    0.
    0. -300.    0.    0.] 
sum of rewards: -466.0 

action type: buy - action 6.0
Learning step: -27.166784286499023
desired expected reward: 92.1735610961914






Player: 1 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  7.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  8.  0.  8. 15.  0.  1.  0.  6.  3. 15.  3.  8. 14.  8. 25.  8.  3.
  8.  8. 16.  4.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [6. 3. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.186775]
 [50.29104 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1
Learning step: -11.76755142211914
desired expected reward: 81.57608032226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.028633]
 [48.30166 ]
 [57.119286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -9.829200744628906
desired expected reward: 45.084590911865234



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6] -> size -> 5 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.22627 ]
 [51.059036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 15.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: buy - action -1.0
Learning step: -9.904337882995605
desired expected reward: 47.214942932128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.670845]
 [47.45864 ]
 [60.118446]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 15.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -60    0    0    0
    0    0] 
sum of rewards: -166 

action type: take_action - action -1.0
Learning step: -9.937278747558594
desired expected reward: 47.90269470214844



buy possibilites: [-1] 
expected returns: [[127.5845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 15.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -100.    0.    0.    0.  -30.    0.    0.  -30.    0.
    0.    0.    0.    0.] 
sum of rewards: -166.0 

action type: buy - action 0.0
Learning step: -7.862891674041748
desired expected reward: 40.80796432495117






Player: 1 
cards in hand: [ 3.  0. 14. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 15.  8.] 
cards in discard: [10.  0. 11.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0
 15  8  8 14  3  3  0  8  8  8 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6 0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.] 
cards in discard: [10.  0. 11.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6 0] -> size -> 6 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.] 
cards in discard: [10.  0. 11.  3.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6 0] -> size -> 6 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 3 6 0] -> size -> 6 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[83.45407]
 [75.12846]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 3 6 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  0.  4.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11  1] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0  -30    0    0    0
    0    0] 
sum of rewards: -136 

action type: buy - action -1
Learning step: -11.382437705993652
desired expected reward: 116.20206451416016



action possibilites: [-1] 
expected returns: [[107.6776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  0.  4.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11  1] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20   50    0    0  -90    0  -50    0
    0    0] 
sum of rewards: -176 

action type: trash_cards_n_from_hand - action 3
Learning step: -9.656249046325684
desired expected reward: 55.92364501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 98.18936 ]
 [ 97.05937 ]
 [108.700836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [16.  6.  0.  4.  8.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11  1] -> size -> 35 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20   50    0    0  -90    0  -50    0
    0    0] 
sum of rewards: -176 

action type: take_action - action -1
Learning step: -11.828115463256836
desired expected reward: 95.84947967529297






Player: 1 
cards in hand: [16.  6.  0.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  4.  8.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  4  6  8 10  0 16 15  0  3  0 15
  8  8 14  3  3  0  8  8  8 11  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6] -> size -> 4 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6] -> size -> 4 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[73.64311]
 [67.71613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  0.  8.  0.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0] -> size -> 34 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: buy - action -1.0
Learning step: -11.768890380859375
desired expected reward: 79.63164520263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.85035]
 [63.96639]
 [73.16735]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6] -> size -> 4 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  1.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  0.  8.  0.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0] -> size -> 34 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -176 

action type: take_action - action -1.0
Learning step: -10.863255500793457
desired expected reward: 61.90372085571289



buy possibilites: [-1] 
expected returns: [[64.79743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [11.  1.  0.  8.  0.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0] -> size -> 34 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -90    0    0    0   50    0    0  -90    0    0 -300
    0    0] 
sum of rewards: -437 

action type: buy - action 6.0
Learning step: -23.590377807617188
desired expected reward: 40.37601852416992






Player: 1 
cards in hand: [11.  1.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  8.  0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9. 10.  6. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9. 10.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9. 10.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[66.02132]
 [60.6055 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  3.  3.  0. 25.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -8.614523887634277
desired expected reward: 56.18290710449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[60.37686]
 [67.28707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  3.  3.  0. 25.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -8.723578453063965
desired expected reward: 58.18492126464844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  0. 25.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3.  0. 25.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[71.33625 ]
 [65.806755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 10.  8. 15.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.  8.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -8.618353843688965
desired expected reward: 58.668724060058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[65.44363]
 [73.21107]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 10.  8. 15.] 
adversary cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.  8.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -8.872586250305176
desired expected reward: 63.57737350463867



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8. 15.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.  8.  3.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8. 15.] 
cards in discard: [10.  0. 11.  3.  3.  3.  1. 15.  3. 14.  8.  0.  8. 16.  0. 15. 29. 11.
  1.  0.  8.  0.  8.  3.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [6. 6. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.845272]
 [52.384186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -9.236201286315918
desired expected reward: 63.9748649597168





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.170925]
 [57.43872 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -8.48813533782959
desired expected reward: 49.3580436706543



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8
 14  3  3  0  8  8  8 11  1  0 15 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3
  3  0  8  8  8 11  1  0 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3
  3  0  8  8  8 11  1  0 15 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[44.8503  ]
 [36.535294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  8. 15.  0.  3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3
  3  0  8  8  8 11  1  0 15 29] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -127 

action type: buy - action -1.0
Learning step: -8.281147956848145
desired expected reward: 49.15756607055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.02595 ]
 [45.147762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  8. 15.  0.  3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3
  3  0  8  8  8 11  1  0 15 29] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -127 

action type: take_action - action -1.0
Learning step: -7.601777076721191
desired expected reward: 36.39467239379883



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  8. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15.  0.  3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3
  3  0  8  8  8 11  1  0 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[108.94014]
 [100.44327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 10.  3. 10.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29  0] -> size -> 34 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -117 

action type: buy - action -1.0
Learning step: -5.734134197235107
desired expected reward: 39.41362380981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.23911]
 [109.1583 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 10.  3. 10.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29  0] -> size -> 34 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -117 

action type: take_action - action -1.0
Learning step: -8.855545043945312
desired expected reward: 98.92382049560547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3. 10.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  8  0 25  0 11 10  8 10  0 16 15  0  3  0 15  8  8 14  3  3
  0  8  8  8 11  1  0 15 29  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 3 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[76.204994]
 [65.93387 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 3 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [11.  0. 11.  3. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0  50   0   0 -90   0   0   0   0   0] 
sum of rewards: -107 

action type: buy - action -1.0
Learning step: -9.191145896911621
desired expected reward: 99.96717071533203



action possibilites: [-1] 
expected returns: [[66.62963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [11.  0. 11.  3. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -126 

action type: trash_cards_n_from_hand - action 5
Learning step: -7.3885064125061035
desired expected reward: 50.536983489990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.170284]
 [63.90956 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [11.  0. 11.  3. 14.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -126 

action type: take_action - action -1
Learning step: -8.228492736816406
desired expected reward: 58.40113830566406






Player: 1 
cards in hand: [11.  0. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3. 14.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3. 14.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[55.994713]
 [51.87523 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -146 

action type: buy - action -1.0
Learning step: -9.344362258911133
desired expected reward: 54.565185546875



action possibilites: [-1] 
expected returns: [[56.292652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -126 

action type: trash_cards_n_from_hand - action 0
Learning step: -7.697583198547363
desired expected reward: 45.58576583862305





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.922714]
 [56.69787 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -126 

action type: take_action - action -1
Learning step: -7.8680315017700195
desired expected reward: 48.42462158203125



buy possibilites: [-1] 
expected returns: [[71.15988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -9.245038032531738
desired expected reward: 42.67766571044922






Player: 1 
cards in hand: [3. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  6. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[73.2827 ]
 [64.96346]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [25.  3.  8. 16.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: -9.778724670410156
desired expected reward: 61.38115692138672



action possibilites: [-1] 
expected returns: [[54.881973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [25.  3.  8. 16.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 0
Learning step: -7.768558025360107
desired expected reward: 57.29947280883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.522713]
 [55.315414]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [25.  3.  8. 16.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -7.2726149559021
desired expected reward: 47.60935974121094






Player: 1 
cards in hand: [25.  3.  8. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  8. 16.  3.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  8. 16.  3.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  8. 16.  3.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.012016]
 [53.901405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [15.  8.  0. 29. 15.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0. 25.  3.  8. 16.  3.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -8.264729499816895
desired expected reward: 47.05067825317383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[53.17953 ]
 [55.947277]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [15.  8.  0. 29. 15.] 
adversary cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0. 25.  3.  8. 16.  3.] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: -8.316720008850098
desired expected reward: 47.85660171508789



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  8.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 29. 15.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0. 25.  3.  8. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0. 29. 15.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0. 25.  3.  8. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0. 29. 15.] 
cards in discard: [ 8.  0.  0.  0.  8.  8. 15.  0.  0. 10.  8.  0. 11.  0. 11.  3. 14. 14.
  3.  1.  0.  8.  0.  0. 25.  3.  8. 16.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[33.20535 ]
 [30.058508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [11.  8.  0. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0  0] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -8.824564933776855
desired expected reward: 47.12270736694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.694393]
 [33.09699 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [11.  8.  0. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0  0] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: -7.680751800537109
desired expected reward: 25.29132080078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  0. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 15. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0 11  8 10  0 16 15  0  3  0 15  8  8 14  3  3  0  8  8
  8 11  1  0 15 29  0  0 14  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.465776]
 [27.496279]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -135 

action type: buy - action -1.0
Learning step: -7.727919101715088
desired expected reward: 25.369062423706055



action possibilites: [-1] 
expected returns: [[20.479063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action 8.0
Learning step: -6.428690433502197
desired expected reward: 21.491905212402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[14.410878]
 [18.328049]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: -6.385444164276123
desired expected reward: 14.093618392944336



buy possibilites: [-1] 
expected returns: [[45.02404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -7.957503795623779
desired expected reward: 6.453383922576904






Player: 1 
cards in hand: [10.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  3.] 
cards in discard: [8. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1
  0 15 29  0  0 14  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [8. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [8. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[65.84365]
 [60.72309]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  8.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -145 

action type: buy - action -1
Learning step: -8.0642728805542
desired expected reward: 36.95976638793945



action possibilites: [-1] 
expected returns: [[20.700844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  8.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 0
Learning step: -7.784268856048584
desired expected reward: 52.21649169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[14.78449 ]
 [17.657516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  8.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: -5.905257225036621
desired expected reward: 14.795586585998535






Player: 1 
cards in hand: [ 8.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 14.] 
cards in discard: [ 8.  0.  0.  8. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [ 8.  0.  0.  8. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [ 8.  0.  0.  8. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  6.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[10.901419]
 [ 9.002103]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 14. 15.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: -6.905956268310547
desired expected reward: 10.751565933227539



action possibilites: [-1] 
expected returns: [[22.50206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 14. 15.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -105 

action type: take_action - action 8.0
Learning step: -5.178737640380859
desired expected reward: 3.5219430923461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.245626]
 [19.946022]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 14. 15.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20  50   0   0 -90   0 -50   0   0   0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: -5.942774772644043
desired expected reward: 16.559284210205078



buy possibilites: [-1] 
expected returns: [[46.77255]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 14. 15.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20 -30   0   0 -60   0 -50   0   0   0] 
sum of rewards: -155 

action type: buy - action 0.0
Learning step: -7.55989933013916
desired expected reward: 9.6857271194458






Player: 1 
cards in hand: [ 1.  0.  0. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 14. 15.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 14. 15.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  5.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 14. 15.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[74.063385]
 [68.60323 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -145 

action type: buy - action -1
Learning step: -7.9783196449279785
desired expected reward: 38.794227600097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.829178]
 [71.307785]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -60   0 -50   0   0   0] 
sum of rewards: -145 

action type: take_action - action -1.0
Learning step: -9.343276023864746
desired expected reward: 63.699195861816406



buy possibilites: [-1] 
expected returns: [[85.55159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
adversary owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0. -30.   0. -50.   0.
   0.   0.] 
sum of rewards: -145.0 

action type: buy - action 0.0
Learning step: -8.516548156738281
desired expected reward: 55.31262969970703






Player: 1 
cards in hand: [ 8. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  8.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 25  0  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8 11  1  0 15
 29  0  0 14  0  0  0 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.58332]
 [52.7022 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8. 15. 25.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -8.741325378417969
desired expected reward: 76.81026458740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[48.826828]
 [50.940315]
 [51.603302]
 [58.48442 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 8. 15. 25.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -7.464019298553467
desired expected reward: 51.66667938232422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 15. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 25.  0.  3.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 25.  0.  3.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 25.  0.  3.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[64.6898  ]
 [56.251587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.  0.  8. 15. 25.  0.  3.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -7.276393890380859
desired expected reward: 51.20802307128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[37.71841 ]
 [40.1988  ]
 [40.982235]
 [48.97711 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  1.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.  0.  8. 15. 25.  0.  3.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -7.202890872955322
desired expected reward: 42.18628692626953



buy possibilites: [-1] 
expected returns: [[46.695435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.  0.  8. 15. 25.  0.  3.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   8   0] 
sum of rewards: -107 

action type: buy - action 8.0
Learning step: -6.348464488983154
desired expected reward: 34.63376235961914






Player: 1 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [ 8.  0.  0.  8. 10.  3. 11. 14.  8.  8.  0.  0. 11.  1.  0.  0. 14. 15.
  8.  0.  8. 15. 25.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  6. 10.  6.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[55.550488]
 [51.926983]
 [51.926983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0 10] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -6.867974281311035
desired expected reward: 39.82746124267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[50.097088]
 [51.278194]
 [54.927273]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0. 11.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0.] 
adversary owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0 10] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -7.32409143447876
desired expected reward: 48.186012268066406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0. 11.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14
  0  0  0 11 11  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[59.122913]
 [51.252342]
 [51.252342]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -7.216269016265869
desired expected reward: 47.71099853515625



action possibilites: [-1] 
expected returns: [[36.993717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -95 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.271287441253662
desired expected reward: 40.801639556884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[30.89884 ]
 [31.52788 ]
 [34.275146]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: -5.853374481201172
desired expected reward: 31.140342712402344






Player: 1 
cards in hand: [ 0.  0. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 20. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 19. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8] -> size -> 3 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.431225]
 [31.200089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 19. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [15.  8.  8.  0.  0.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0  3] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: -7.222268104553223
desired expected reward: 27.052875518798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[28.282541]
 [29.284859]
 [32.884144]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 19. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [15.  8.  8.  0.  0.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0  3] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: -7.235107421875
desired expected reward: 26.598529815673828



buy possibilites: [-1] 
expected returns: [[35.108814]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [15.  8.  8.  0.  0.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
adversary owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0  3] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0 -30   0 -50   0   8   0] 
sum of rewards: -106 

action type: buy - action 3.0
Learning step: -5.974294662475586
desired expected reward: 23.310565948486328






Player: 1 
cards in hand: [15.  8.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  0.  0.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  0  3  0 15  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0
  0  0 11 11  0 10  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 10  3  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0  0  0 11
 11  0 10  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 10  3  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0  0  0 11
 11  0 10  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[39.949192]
 [35.224632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [10.  0.  8.  8.  8.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.
  8.  8.] 
adversary owned cards: [25  8 10  3  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0  0  0 11
 11  0 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -114 

action type: buy - action -1
Learning step: -6.5797119140625
desired expected reward: 28.529102325439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[31.720327]
 [32.66149 ]
 [37.173565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [10.  0.  8.  8.  8.] 
adversary cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.
  8.  8.] 
adversary owned cards: [25  8 10  3  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0  0  0 11
 11  0 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -114 

action type: take_action - action -1.0
Learning step: -6.906071662902832
desired expected reward: 33.13372039794922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  8.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8.  8.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.
  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 10  3  8  8 14  3  3  0  8  8  8  1  0 15 29  0  0 14  0  0  0 11
 11  0 10  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.
  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [ 0.  0. 10. 29.  3.  0.  0. 15.  3.  0. 11.  0.  3. 11.  0.  0. 14.  3.
  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3] -> size -> 4 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[32.562138]
 [25.98059 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -114 

action type: buy - action -1.0
Learning step: -6.8463454246521
desired expected reward: 30.32720375061035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.339872]
 [23.935745]
 [31.49383 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0 -30   0 -50   0   0   0] 
sum of rewards: -114 

action type: take_action - action -1.0
Learning step: -6.727972507476807
desired expected reward: 26.64573097229004



buy possibilites: [-1] 
expected returns: [[51.581715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0 -30   0   0   0   8   0] 
sum of rewards: -45 

action type: buy - action 3.0
Learning step: -2.0487074851989746
desired expected reward: 21.88703727722168






Player: 1 
cards in hand: [ 0. 14.  1.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  8. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8  1  0 15 29  0  0 14  0  0  0 11 11  0
 10  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[32.963936]
 [26.404154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14. 25.] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -4.529773235321045
desired expected reward: 47.05194091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.91112 ]
 [24.237299]
 [30.963766]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14. 25.] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -3.6669087409973145
desired expected reward: 29.404056549072266



buy possibilites: [-1] 
expected returns: [[54.744576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3 3 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [10.  8.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14. 25.] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -53.0 

action type: buy - action 0.0
Learning step: -2.563802719116211
desired expected reward: 20.347307205200195






Player: 1 
cards in hand: [10.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  3.] 
cards in discard: [ 0.  8. 14. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  3. 29.] 
cards in discard: [ 0.  8. 14. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  3. 29.] 
cards in discard: [ 0.  8. 14. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 8 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 0 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 3 3 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 29.  8.  0.  9.  4.  0.  9.  9.  5. 10.  5. 10.  6.] 
adversary cards in hand: [ 8.  0.  0.  3. 29.] 
adversary cards in discard: [ 0.  8. 14. 25.  0.] 
adversary owned cards: [25 10  3  8  8 14  3  3  8  8  8 15 29  0  0 14  0  0  0 11 11  0 10  0
  3  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5 -500    2  -20    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -523 

action type: buy - action -1
Learning step: -28.88722801208496
desired expected reward: 25.85734748840332



