 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.915956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.156988143920898
desired expected reward: 37.257347106933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.103706]
 [20.246813]
 [19.701046]
 [17.600473]
 [21.861088]
 [21.263748]
 [20.717985]
 [21.166815]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5736724138259888
desired expected reward: 20.73717498779297



buy possibilites: [-1] 
expected returns: [[21.52353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5019153952598572
desired expected reward: 20.76183319091797






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.37791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5584920048713684
desired expected reward: 20.965036392211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.09372 ]
 [22.236824]
 [21.691061]
 [19.590488]
 [21.514   ]
 [23.8511  ]
 [23.253765]
 [23.85968 ]
 [21.750528]
 [22.708   ]
 [22.893635]
 [23.156828]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5903288125991821
desired expected reward: 22.001468658447266



buy possibilites: [-1] 
expected returns: [[24.11419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  3.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.37638992071151733
desired expected reward: 23.270023345947266






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.998465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6487954258918762
desired expected reward: 23.46539306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.23596 ]
 [20.379065]
 [19.833298]
 [17.732727]
 [19.656239]
 [21.99334 ]
 [21.396002]
 [22.001917]
 [19.892769]
 [20.850237]
 [21.035873]
 [21.299068]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5738820433616638
desired expected reward: 20.819475173950195



buy possibilites: [-1] 
expected returns: [[25.59498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.41868987679481506
desired expected reward: 22.420604705810547






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[26.447304]
 [26.544237]
 [26.184109]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  3.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 15 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6381688714027405
desired expected reward: 24.956811904907227



action possibilites: [-1] 
expected returns: [[23.7563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 11
Learning step: -0.11530551314353943
desired expected reward: 27.042917251586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.97084 ]
 [20.467606]
 [24.033943]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.026094989851117134
desired expected reward: 23.730205535888672



buy possibilites: [-1] 
expected returns: [[23.016708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.032550256699323654
desired expected reward: 22.003389358520508






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.016272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6265764832496643
desired expected reward: 22.3901309967041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.649084]
 [19.776325]
 [19.238115]
 [17.166727]
 [19.0635  ]
 [21.37344 ]
 [20.779121]
 [21.382015]
 [19.296759]
 [20.24091 ]
 [20.424   ]
 [20.68354 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5496599078178406
desired expected reward: 19.824127197265625



buy possibilites: [-1] 
expected returns: [[25.740444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.4415489733219147
desired expected reward: 21.823564529418945






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 8. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 8. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 8. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.506962]
 [24.19944 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6693793535232544
desired expected reward: 25.071063995361328



action possibilites: [-1.  8.] 
expected returns: [[29.515722]
 [29.605747]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 29  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.029789714142680168
desired expected reward: 24.386205673217773



action possibilites: [-1] 
expected returns: [[22.285648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.4573763906955719
desired expected reward: 28.011472702026367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.423622]
 [18.96321 ]
 [22.437946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6016595959663391
desired expected reward: 22.88730812072754






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 0 3 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[11.822632]
 [12.499717]
 [12.499717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6900718212127686
desired expected reward: 21.747875213623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.104402]
 [10.67727 ]
 [ 8.676669]
 [12.180741]
 [12.092484]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  7. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3994114398956299
desired expected reward: 11.775923728942871



buy possibilites: [-1] 
expected returns: [[17.38836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.09284445643424988
desired expected reward: 12.087897300720215






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29  8] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29  8] -> size -> 10 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.202023]
 [16.290277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4979249835014343
desired expected reward: 16.89043426513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.407    ]
 [15.5009165]
 [14.978011 ]
 [12.97609  ]
 [17.063528 ]
 [16.484346 ]
 [15.956912 ]
 [16.39609  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47898611426353455
desired expected reward: 16.01336669921875



buy possibilites: [-1] 
expected returns: [[18.98997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29  8 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.0774887427687645
desired expected reward: 17.14101791381836






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29  8 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  6. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29  8 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29  0 29  8 11] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 8. 29.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[22.368134]
 [22.45816 ]
 [23.06061 ]
 [23.06061 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0. 29.] 
cards in discard: [11.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29  0 29  8 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47911375761032104
desired expected reward: 18.510854721069336



action possibilites: [-1] 
expected returns: [[17.881449]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [11.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 29  8 11] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.07197217643260956
desired expected reward: 23.585607528686523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.83529 ]
 [14.404381]
 [17.821293]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [11.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 29  8 11] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08555196225643158
desired expected reward: 17.96700096130371



buy possibilites: [-1] 
expected returns: [[17.34841]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [11.  0.  8.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 29  8 11  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.793285369873047
desired expected reward: 5.6110944747924805






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 8. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6] -> size -> 9 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 8. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6] -> size -> 9 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[17.07709 ]
 [17.172209]
 [17.76664 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 29  8 11  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.48461002111434937
desired expected reward: 16.863800048828125



action possibilites: [-1.  8. 11.] 
expected returns: [[20.44025 ]
 [20.534046]
 [21.107515]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8  0 29  8 11  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.12690512835979462
desired expected reward: 18.168563842773438



action possibilites: [-1] 
expected returns: [[22.712109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  8  0 29  8 11  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: gain_card_n - action 0
Learning step: 0.7347658276557922
desired expected reward: 19.191808700561523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.742891]
 [21.856094]
 [21.324398]
 [19.29972 ]
 [21.152695]
 [23.425173]
 [22.843668]
 [23.438097]
 [21.383389]
 [22.31197 ]
 [22.496595]
 [22.748549]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  8  0 29  8 11  6  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6019729375839233
desired expected reward: 23.3140811920166



buy possibilites: [-1] 
expected returns: [[20.16516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.5185914039611816
desired expected reward: 24.956687927246094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[20.088135]
 [20.183252]
 [20.183252]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 29  8 11  6  0 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5407550930976868
desired expected reward: 19.624404907226562



action possibilites: [-1] 
expected returns: [[12.924961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.05133521929383278
desired expected reward: 17.8638973236084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.97368 ]
 [ 9.583795]
 [12.934521]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1831912398338318
desired expected reward: 13.108152389526367



buy possibilites: [-1] 
expected returns: [[12.441499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.706877708435059
desired expected reward: 0.8769168853759766






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.  3.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [6. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[19.227472]
 [19.893518]
 [19.881075]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0.] 
cards in discard: [6. 8. 0. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3150070905685425
desired expected reward: 12.12649154663086



action possibilites: [-1. 11. 29.] 
expected returns: [[21.826754]
 [22.480352]
 [22.4928  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 29.] 
cards in discard: [6. 8. 0. 6. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  9.  5. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.08388130366802216
desired expected reward: 20.09699058532715



action possibilites: [-1] 
expected returns: [[19.775198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [6. 8. 0. 6. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 2
Learning step: 0.7963603138923645
desired expected reward: 20.172334671020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.089128]
 [19.164446]
 [18.650837]
 [16.678543]
 [18.484938]
 [20.680086]
 [20.118382]
 [20.692532]
 [18.707796]
 [19.604769]
 [19.783113]
 [20.026485]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [6. 8. 0. 6. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6616750955581665
desired expected reward: 20.436872482299805



buy possibilites: [-1] 
expected returns: [[33.292297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [ 6.  8.  0.  6.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.725523591041565
desired expected reward: 22.86037254333496






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [29. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[15.189659]
 [15.865385]
 [15.850479]
 [15.285324]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9823110103607178
desired expected reward: 32.30998611450195



action possibilites: [-1. 11.  8. 29.] 
expected returns: [[19.782322]
 [20.444115]
 [19.877987]
 [20.459093]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.17892934381961823
desired expected reward: 16.28620147705078



action possibilites: [-1] 
expected returns: [[16.928455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 29.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 4
Learning step: 1.1997805833816528
desired expected reward: 18.132051467895508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.049471]
 [15.614626]
 [13.630569]
 [17.08909 ]
 [16.993427]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 29.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7097070813179016
desired expected reward: 17.63816261291504



buy possibilites: [-1] 
expected returns: [[24.10062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 29.] 
cards in discard: [16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.8515724539756775
desired expected reward: 15.901041984558105






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [8. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  5. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  3.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.871956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6112114191055298
desired expected reward: 23.489408493041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.016014]
 [23.584167]
 [21.589586]
 [25.066458]
 [24.970268]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  5. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6467604637145996
desired expected reward: 24.28725814819336



buy possibilites: [-1] 
expected returns: [[28.713573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [16.  0. 29. 11.  3.  8.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3605011999607086
desired expected reward: 24.705957412719727






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.] 
cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.] 
cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.] 
cards in discard: [ 8.  3.  3. 29. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[18.458204]
 [19.137522]
 [19.137522]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.810891330242157
desired expected reward: 27.902681350708008



action possibilites: [-1. 29. 16.] 
expected returns: [[18.583597]
 [19.262915]
 [17.036743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.065788134932518
desired expected reward: 19.343690872192383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.079483]
 [18.162073]
 [17.64464 ]
 [15.660584]
 [17.478468]
 [19.692364]
 [19.124205]
 [19.707336]
 [17.700207]
 [18.60405 ]
 [18.786093]
 [19.02802 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  4. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.08694476634263992
desired expected reward: 18.670541763305664



buy possibilites: [-1] 
expected returns: [[29.028719]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 16.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.241075336933136
desired expected reward: 19.36528205871582






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0  3  8  0 10  8  0 29 29  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  6.  6.  3.  3.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.918982]
 [26.583324]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  3.  3.] 
cards in discard: [ 8. 29.  0.  0.  0. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7438752055168152
desired expected reward: 28.28484344482422



action possibilites: [-1] 
expected returns: [[20.792957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: -0.03384841978549957
desired expected reward: 23.371967315673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.93705 ]
 [17.535316]
 [20.83382 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03041965328156948
desired expected reward: 20.82337760925293






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [0. 8. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 8.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[20.27454 ]
 [20.388039]
 [20.968235]
 [20.388039]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  8.] 
cards in discard: [ 8. 29.  0.  0.  0. 29. 16.  0. 11.  6.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5583390593528748
desired expected reward: 20.275482177734375



action possibilites: [-1.  8.  8.] 
expected returns: [[20.31442 ]
 [20.427303]
 [20.427303]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.033950041979551315
desired expected reward: 21.041303634643555



action possibilites: [-1] 
expected returns: [[15.700674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.5739119052886963
desired expected reward: 21.938749313354492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.966958]
 [12.565226]
 [15.864893]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7310078740119934
desired expected reward: 16.431682586669922






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  3. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  2. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0. 11.] 
adversary cards in discard: [29.  8.  8.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [29.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[15.838522]
 [16.521448]
 [16.503508]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0. 11.] 
cards in discard: [29.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  2. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.45324769616127014
desired expected reward: 15.411646842956543



action possibilites: [-1. 11.] 
expected returns: [[20.54182 ]
 [21.206806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [29.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  2. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.17084558308124542
desired expected reward: 16.80527687072754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.761002]
 [19.826647]
 [19.313103]
 [17.359268]
 [19.153585]
 [21.319607]
 [20.767506]
 [21.33755 ]
 [19.36577 ]
 [20.253962]
 [20.431421]
 [20.654623]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [29.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  2. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.045535068958997726
desired expected reward: 20.58735466003418



buy possibilites: [-1] 
expected returns: [[24.415062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [29.  8.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.14333301782608032
desired expected reward: 20.910839080810547






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0.  8.] 
cards in discard: [8. 0. 0. 8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3. 29.] 
adversary cards in discard: [29.  8.  8.  8. 29.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.  0.  8.] 
cards in discard: [8. 0. 0. 8. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3. 29.] 
adversary cards in discard: [29.  8.  8.  8. 29.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.  0.  8.] 
cards in discard: [8. 0. 0. 8. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  6.  0.  3. 29.] 
adversary cards in discard: [29.  8.  8.  8. 29.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [16.  6.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[15.915256]
 [14.437249]
 [16.587706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  3. 29.] 
cards in discard: [29.  8.  8.  8. 29.  6.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  8.  3.  3.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7153218984603882
desired expected reward: 23.699739456176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.273419]
 [12.893177]
 [16.138004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  3. 29.] 
cards in discard: [29.  8.  8.  8. 29.  6.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  8.  3.  3.  0.  8.  0. 29.  0.  8.] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4747810959815979
desired expected reward: 15.52267837524414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  8.  3.  3.  0.  8.  0. 29.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  8.  3.  3.  0.  8.  0. 29.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  8.  3.  3.  0.  8.  0. 29.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  6. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
expected returns: [[13.64076 ]
 [14.323687]
 [12.142046]
 [13.753643]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6. 16.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  8 11  6  0 29  6  3 29 16  0  8  8  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 28. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4897695779800415
desired expected reward: 15.648234367370605



action possibilites: [-1] 
expected returns: [[9.204871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.3308979868888855
desired expected reward: 11.522669792175293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.7036552]
 [6.3742547]
 [9.499569 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2598198652267456
desired expected reward: 9.464691162109375



buy possibilites: [-1] 
expected returns: [[13.546753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.] 
cards in discard: [3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.3611312508583069
desired expected reward: 8.064786911010742






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 29.  8.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.] 
adversary owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 29.  8.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.] 
adversary owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 29.  8.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.] 
adversary owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8.  6. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[10.350964]
 [10.481112]
 [11.030733]
 [10.481112]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 29.  8.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4437748193740845
desired expected reward: 13.102977752685547



action possibilites: [-1] 
expected returns: [[10.275282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  8.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.3055877983570099
desired expected reward: 8.715675354003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.581538 ]
 [ 7.2611146]
 [10.379894 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  8.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2369624525308609
desired expected reward: 10.51224422454834



buy possibilites: [-1] 
expected returns: [[24.438232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  8.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.4491552412509918
desired expected reward: 9.030694007873535






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [8. 0. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[21.865555]
 [22.560913]
 [22.54049 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6476150751113892
desired expected reward: 23.790616989135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.210613]
 [20.752422]
 [18.817617]
 [22.196362]
 [22.063232]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  1. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5864138603210449
desired expected reward: 21.340713500976562



buy possibilites: [-1] 
expected returns: [[17.332722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [ 3.  0. 16.  0. 29.  6.  0.  8.  6. 29.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.39389726519584656
desired expected reward: 21.80246353149414






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 8.  0.  8. 29. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [29.  8. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.  8.] 
expected returns: [[7.9868565]
 [8.618684 ]
 [8.107835 ]
 [6.6785297]
 [8.107835 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 16.  3.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5843812227249146
desired expected reward: 16.748340606689453



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[10.202096]
 [10.324001]
 [10.324001]
 [10.842153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 29.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.3528826832771301
desired expected reward: 7.267534255981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.525521]
 [ 7.265129]
 [10.213069]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 29.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  8.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.23819494247436523
desired expected reward: 10.440290451049805



buy possibilites: [-1] 
expected returns: [[10.397283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 29.] 
cards in discard: [16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.656633377075195
desired expected reward: -1.3915047645568848






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29. 11.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29. 11.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  9.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29. 11.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29. 11.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[11.669385]
 [12.360923]
 [12.341528]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 29. 11.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  7.  9.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.33348923921585083
desired expected reward: 10.063793182373047



action possibilites: [-1] 
expected returns: [[11.714949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 29.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.7791884541511536
desired expected reward: 9.906468391418457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.173814]
 [ 8.931468]
 [11.825893]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 29.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2099931836128235
desired expected reward: 11.924942016601562



buy possibilites: [-1] 
expected returns: [[12.648549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 29.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.685133934020996
desired expected reward: 0.24633502960205078






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6. 11.  6.  0.  3. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16  6] -> size -> 21 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6. 11.  6.  0.  3. 29.] 
adversary owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16  6] -> size -> 21 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.603289]
 [26.760252]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6. 11.  6.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6  0 29  6  3 29 16  0  8  8  0  8  3  0  0  8  6 16  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2490934431552887
desired expected reward: 12.399456024169922



action possibilites: [-1] 
expected returns: [[20.223108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6. 11.  6.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.06087100878357887
desired expected reward: 24.04625129699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.705988]
 [17.348274]
 [20.478937]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [16.  6. 29.  8.  3.  8. 29. 16.  6. 11.  6.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04460546374320984
desired expected reward: 20.26771354675293






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3  8  0 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 11. 29.  0. 10.  3.  0.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  6.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [29.  6.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[10.0671625]
 [10.724666 ]
 [10.211221 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  6.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6538515686988831
desired expected reward: 19.825084686279297



action possibilites: [-1.  8.] 
expected returns: [[15.294985]
 [15.442988]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  6 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.37044745683670044
desired expected reward: 8.406523704528809



action possibilites: [-1] 
expected returns: [[11.830232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.7689799070358276
desired expected reward: 14.276894569396973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[10.435748]
 [10.949228]
 [ 9.107458]
 [12.185259]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8103052973747253
desired expected reward: 12.64053726196289






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  8.  3.] 
adversary cards in discard: [16. 29.  8.  6.  0.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  8.  3.] 
adversary cards in discard: [16. 29.  8.  6.  0.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  8.  3.] 
adversary cards in discard: [16. 29.  8.  6.  0.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[17.036911]
 [17.739523]
 [17.190844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  8.  3.] 
cards in discard: [16. 29.  8.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [ 0. 29.  0. 11.  0.  0.] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.33226510882377625
desired expected reward: 11.852993965148926





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.825155]
 [13.475775]
 [16.58175 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  8.  3.] 
cards in discard: [16. 29.  8.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [ 0. 29.  0. 11.  0.  0.] 
adversary owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.488308846950531
desired expected reward: 16.138427734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [29.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  8.] 
cards in discard: [ 0. 29.  0. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  6.] 
adversary cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [ 0. 29.  0. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10  8  0 29  0  0  0  8  0  0 29  0 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  6.] 
adversary cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  6.] 
adversary cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  6.] 
adversary cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8.  0. 16.  6.] 
adversary cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [11.  8.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[17.1739  ]
 [17.849909]
 [17.340311]
 [15.811456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 16.  6.] 
cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.46600666642189026
desired expected reward: 16.11574363708496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.523444]
 [14.178682]
 [17.253004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0. 16.  6.] 
cards in discard: [16. 29.  8.  6.  0.  0. 29.  6.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.49977508187294006
desired expected reward: 16.749584197998047



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [29.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 8. 29.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 29.] 
expected returns: [[11.16173 ]
 [11.320467]
 [11.827283]
 [11.320467]
 [11.827283]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.  3. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 29  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0. 10.  3. 11.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5449663996696472
desired expected reward: 16.708040237426758



action possibilites: [-1] 
expected returns: [[13.323411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0. 10.  3. 11.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.2916194796562195
desired expected reward: 10.234162330627441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.7911415]
 [10.43021  ]
 [13.547738 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 29.  0. 10.  3. 11.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1789013296365738
desired expected reward: 13.502312660217285






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 29.  0. 10.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  6.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 29.  0. 10.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  6.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 29.  0. 10.  3. 11. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  6.] 
adversary cards in discard: [8. 8. 3.] 
adversary owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[13.400026]
 [12.016273]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  6.] 
cards in discard: [8. 8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  6  3 29 16  8  8  0  8  3  0  0  8  6 16  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4206208884716034
desired expected reward: 13.127118110656738



action possibilites: [-1] 
expected returns: [[13.800159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 8. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 2
Learning step: -8.696440696716309
desired expected reward: 1.014967918395996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[12.358847]
 [12.874355]
 [11.005205]
 [14.113384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 8. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17137207090854645
desired expected reward: 13.971531867980957






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 6. 11.  8. 29.  6.] 
adversary cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 6. 11.  8. 29.  6.] 
adversary cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 6. 11.  8. 29.  6.] 
adversary cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  5.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 6. 11.  8. 29.  6.] 
adversary cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6. 11.  8. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[13.401615]
 [14.0882  ]
 [13.570634]
 [14.106604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8. 29.  6.] 
cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  5.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0. 11.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4273812472820282
desired expected reward: 13.686002731323242



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[18.470547]
 [19.160742]
 [18.640463]
 [18.640463]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  8.] 
cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  5.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0. 11.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.2960096597671509
desired expected reward: 12.014126777648926



action possibilites: [-1] 
expected returns: [[18.28892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8.] 
cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  4.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0. 11.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -265 

action type: gain_card_n - action 3
Learning step: -8.260258674621582
desired expected reward: 8.482802391052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.668898]
 [15.313014]
 [18.383217]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  4.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0. 11.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6809595823287964
desired expected reward: 18.969879150390625



buy possibilites: [-1] 
expected returns: [[18.459713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [ 8.  8.  3.  6. 16.  0.  0.  3.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 22.  0.  0. 11.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.21556282043457
desired expected reward: 7.097451210021973






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0. 11.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  9.] 
adversary cards in hand: [ 6.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  0.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6  6] -> size -> 18 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [ 6.  8.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
expected returns: [[11.423892]
 [11.594636]
 [11.594636]
 [10.185093]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29 16  8  8  0  8  3  0  0  8  6 16  6  6  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5844649076461792
desired expected reward: 17.875247955322266



action possibilites: [-1] 
expected returns: [[9.781061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.2833051085472107
desired expected reward: 9.263172149658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.374325]
 [ 7.061756]
 [10.057043]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  3.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24906869232654572
desired expected reward: 10.030129432678223



buy possibilites: [-1] 
expected returns: [[12.776814]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.62769603729248
desired expected reward: -1.5659403800964355






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [29.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0.  0.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  6. 29.  6.] 
adversary cards in discard: [6. 8. 6. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  6. 29.  6.] 
adversary cards in discard: [6. 8. 6. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  6. 29.  6.] 
adversary cards in discard: [6. 8. 6. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8. 16. 29.  3.  0.  0.  0. 15. 11.  0. 22.  0.  0. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  8.  6. 29.  6.] 
adversary cards in discard: [6. 8. 6. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [ 6.  8.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[9.334598 ]
 [9.5063925]
 [9.989579 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6. 29.  6.] 
cards in discard: [6. 8. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [22.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4313695728778839
desired expected reward: 12.345444679260254



action possibilites: [-1.] 
expected returns: [[15.56113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0.] 
cards in discard: [6. 8. 6. 8. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [22.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.35088443756103516
desired expected reward: 9.1011323928833





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.037833]
 [14.522601]
 [12.742078]
 [15.677371]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0.] 
cards in discard: [6. 8. 6. 8. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [22.  0. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.13574634492397308
desired expected reward: 15.69687557220459






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [22.  0. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 14.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3. 11.  3. 16.] 
adversary cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3. 11.  3. 16.] 
adversary cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 30. 30. 27. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3. 11.  3. 16.] 
adversary cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 10.  8.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 30. 30. 26. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3. 11.  3. 16.] 
adversary cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3. 11.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[15.418626]
 [16.097124]
 [14.097684]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  3. 16.] 
cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 30. 30. 26. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.45861491560935974
desired expected reward: 15.218755722045898



action possibilites: [-1] 
expected returns: [[11.3651285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 16.] 
cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 26. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.1566675752401352
desired expected reward: 13.912209510803223





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.793498]
 [ 8.502854]
 [11.440125]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 16.] 
cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 30. 30. 26. 30.  8.  2.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2163325548171997
desired expected reward: 11.581460952758789



buy possibilites: [-1] 
expected returns: [[10.2940855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 16.] 
cards in discard: [ 6.  8.  6.  8.  8. 29.  6.  6.  6.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 26. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.684211730957031
desired expected reward: -0.6075544357299805






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 26. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 29. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 30. 26. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 29. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
adversary victory points: -5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 29. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
adversary victory points: -5
player victory points: 4 





Player: 0 
cards in hand: [ 6. 29. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[13.001257 ]
 [13.6875105]
 [13.671965 ]
 [13.189554 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0. 29.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3173968493938446
desired expected reward: 9.976688385009766



action possibilites: [-1. 11.  8.] 
expected returns: [[18.024485]
 [18.70572 ]
 [18.215742]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  8.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0. 29.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 4
Learning step: 0.3245202898979187
desired expected reward: 10.944866180419922



action possibilites: [-1] 
expected returns: [[15.783371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [ 3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0. 29.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 7
Learning step: 1.215027093887329
desired expected reward: 17.238304138183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.337085]
 [14.819494]
 [13.034962]
 [15.971693]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [ 3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0. 29.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7321822047233582
desired expected reward: 16.515552520751953



buy possibilites: [-1] 
expected returns: [[11.464014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [ 3. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15. 16.  0. 29.] 
adversary cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.7402596473693848
desired expected reward: 15.077342987060547






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 16.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 16.  0. 29.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
adversary victory points: -5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.] 
cards in discard: [ 3. 22. 11.  0. 14.  0. 10.  8.  0.  0.  3.  3. 29.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
adversary victory points: -5
player victory points: 4 





Player: 0 
cards in hand: [ 6.  0.  8.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[12.905472]
 [13.090384]
 [11.64382 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.36075565218925476
desired expected reward: 11.10325813293457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.461719]
 [10.177066]
 [13.067047]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 30. 30. 25. 30.  8.  1.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4133581221103668
desired expected reward: 12.519150733947754



buy possibilites: [-1] 
expected returns: [[9.73519]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 30. 30. 25. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
adversary victory points: 4
player victory points: -6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.353092193603516
desired expected reward: 0.8239736557006836






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 25. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0  6] -> size -> 22 
adversary victory points: -6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 30. 30. 25. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0  6] -> size -> 22 
adversary victory points: -6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0  6] -> size -> 22 
adversary victory points: -6
player victory points: 5 





Player: 0 
cards in hand: [6. 8. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[10.932169]
 [11.107562]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3. 6.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8  6 16  6  6  6  6  6  0  6 14  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11. 14. 22.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3261037766933441
desired expected reward: 9.409086227416992



action possibilites: [-1] 
expected returns: [[14.054987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11. 14. 22.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.3290209472179413
desired expected reward: 9.280900001525879





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.6430025]
 [14.277611 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11. 14. 22.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17139993607997894
desired expected reward: 14.226387023925781



buy possibilites: [-1] 
expected returns: [[11.179142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 3. 14.  0. 29. 11.  6.  0.  8.  6.  6.  0.  8.  6. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 11. 14. 22.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.18859736621379852
desired expected reward: 12.8316011428833






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 14. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 14. 22.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [3. 8. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 22.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 22.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  9.  9.  8.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 22.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  8.  9.  8.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.065422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 15.  0. 16.  3.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10] -> size -> 23 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 0
Learning step: -0.383597195148468
desired expected reward: 11.99240779876709





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.573708]
 [13.206182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  8.  9.  8.] 
adversary cards in hand: [ 8. 15.  0. 16.  3.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0.] 
adversary owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10] -> size -> 23 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.41157129406929016
desired expected reward: 12.701088905334473



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 16.  3.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  8. 10.  8.  9.  8.] 
adversary cards in hand: [14.  6.  6.  8.  6.] 
adversary cards in discard: [8. 8. 3. 0. 6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  6.  6.  8.  6.] 
adversary cards in discard: [8. 8. 3. 0. 6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  6.  6.  8.  6.] 
adversary cards in discard: [8. 8. 3. 0. 6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [14.  6.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[7.3288665]
 [6.3294644]
 [7.5022445]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  8.  6.] 
cards in discard: [8. 8. 3. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3. 29.  0.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14. 16.  8. 15.  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4707261025905609
desired expected reward: 12.735454559326172



action possibilites: [-1] 
expected returns: [[8.064259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6.] 
cards in discard: [8. 8. 3. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10. 29.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14. 16.  8. 15.  0.  3.
  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.34354910254478455
desired expected reward: 6.714402675628662





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[6.6053567]
 [7.038594 ]
 [8.104061 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6.] 
cards in discard: [8. 8. 3. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10. 29.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14. 16.  8. 15.  0.  3.
  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.28598520159721375
desired expected reward: 8.35024356842041






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14. 16.  8. 15.  0.  3.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.] 
cards in discard: [ 3.  0. 29.  0.  3.  0. 10. 14.  3. 11. 22.  0. 14. 16.  8. 15.  0.  3.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
adversary victory points: -4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[11.333189]
 [12.003519]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  3.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2698725163936615
desired expected reward: 7.834188461303711



action possibilites: [-1] 
expected returns: [[13.815009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 5
Learning step: 0.7795073390007019
desired expected reward: 10.631183624267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[12.475302]
 [13.460849]
 [12.963137]
 [14.814175]
 [13.828629]
 [14.133338]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  8.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1810051053762436
desired expected reward: 13.996014595031738



buy possibilites: [-1] 
expected returns: [[15.152752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.7046786546707153
desired expected reward: 15.518854141235352






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [16. 29.  8.  6.  6.] 
adversary cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 30. 30. 24. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [16. 29.  8.  6.  6.] 
adversary cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  3.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [16. 29.  8.  6.  6.] 
adversary cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [16. 29.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.] 
expected returns: [[12.294641]
 [10.998538]
 [12.997225]
 [12.486846]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  8.  6.  6.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15. 16. 11.  0. 29.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4748561680316925
desired expected reward: 14.677895545959473



action possibilites: [-1. 16.] 
expected returns: [[12.243771]
 [10.999327]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.  8.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  6  0  6 14  0  6  0 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15. 16. 11.  0. 29.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.22456660866737366
desired expected reward: 11.850110054016113



action possibilites: [-1] 
expected returns: [[10.7099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.  8.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15. 16. 11.  0. 29.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: gain_card_n - action 0
Learning step: 0.8056194186210632
desired expected reward: 12.700103759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.223304]
 [10.763522]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  8.  3.  0.  6. 14.  6.  6.  8.  6. 29. 11. 11.  0.  0.  0.  3.  8.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15. 16. 11.  0. 29.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8352510333061218
desired expected reward: 11.545150756835938






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [15. 16. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 11. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16. 11.  0. 29.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 29.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 29.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 23. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 29.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 22. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 





Player: 0 
cards in hand: [8. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[16.502037]
 [16.689812]
 [16.689812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 22. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3] -> size -> 24 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2977745234966278
desired expected reward: 10.465747833251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.976272]
 [15.438873]
 [16.547935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 30. 30. 22. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  0.  0.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3] -> size -> 24 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47999632358551025
desired expected reward: 16.061458587646484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.  0.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 22. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  8. 14. 16.] 
adversary cards in discard: [8. 0. 6. 0. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0.  0.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 30. 30. 22. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  8. 14. 16.] 
adversary cards in discard: [8. 0. 6. 0. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0.  0.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  8. 14. 16.] 
adversary cards in discard: [8. 0. 6. 0. 8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [ 0.  3.  8. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16.] 
expected returns: [[7.363467 ]
 [7.5444245]
 [6.343523 ]
 [6.2060595]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 14. 16.] 
cards in discard: [8. 0. 6. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6 14  0  6  0 29 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5726812481880188
desired expected reward: 15.975255966186523



action possibilites: [-1] 
expected returns: [[10.803502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [ 8.  0.  6.  0.  8. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.6056756973266602
desired expected reward: 15.197713851928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.602054]
 [11.160377]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [ 8.  0.  6.  0.  8. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 22.] 
adversary cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23653395473957062
desired expected reward: 11.04003620147705






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 22.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 11. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.  3.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 11. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.  3.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 11. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.  3.] 
cards in discard: [ 3.  0. 14. 10.  3.  0.  3. 15. 16. 11. 29.  3.  0.  8. 14.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0.  0. 11. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [ 8.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[15.5255  ]
 [15.720875]
 [16.20225 ]
 [16.20225 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 11.] 
cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.31711968779563904
desired expected reward: 10.843255996704102



action possibilites: [-1] 
expected returns: [[9.968612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.5647518634796143
desired expected reward: 16.228702545166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.537028]
 [ 9.004031]
 [10.141275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2497488409280777
desired expected reward: 10.218360900878906






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 29.  6.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 29.  6.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 30. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 29.  6.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 29.  6.] 
adversary cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [ 3.  6.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.3491335]
 [15.0422735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 29.  6.] 
cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [22.  8.  0.  3. 29.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1] -> size -> 27 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.29920557141304016
desired expected reward: 9.842069625854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.741211]
 [14.365395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 29.  6.] 
cards in discard: [ 8.  0.  6.  0.  8. 14. 16.  0.  3.  8. 15. 11.  8.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [22.  8.  0.  3. 29.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1] -> size -> 27 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.436458945274353
desired expected reward: 13.912674903869629



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [22.  8.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  0.  3. 29.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  8.  0.  3. 29.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  8.  0.  3. 29.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [ 6.  6.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.122474]
 [13.797606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 29.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 14. 14. 15.  0.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4384813904762268
desired expected reward: 13.92691421508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.409992]
 [12.955263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 29.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3. 14. 14. 15.  0.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4101509749889374
desired expected reward: 12.579553604125977



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3. 14. 14. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 14. 15.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  3. 16.  6.  3.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 15.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 15.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 15.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [6. 6. 3.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 





Player: 0 
cards in hand: [6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[5.4744883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0  0] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.3511013090610504
desired expected reward: 8.27018928527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[4.2734456]
 [5.5560536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 10.  3.  0.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.] 
adversary owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0  0] -> size -> 29 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2614409625530243
desired expected reward: 5.2183122634887695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [16.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  3.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  0  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3
  3  0  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  0. 14.  8.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
adversary owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [ 8.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
expected returns: [[13.156218]
 [13.366747]
 [12.073088]
 [13.366747]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  8.  0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.17948956787586212
desired expected reward: 5.376564025878906



action possibilites: [-1] 
expected returns: [[7.2664113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.15160022675991058
desired expected reward: 12.641502380371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[6.132879 ]
 [6.5395875]
 [7.528642 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3043808937072754
desired expected reward: 7.570792198181152



buy possibilites: [-1] 
expected returns: [[13.725046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  3. 10.  3.  3.] 
adversary cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.6379253268241882
desired expected reward: 7.177513599395752






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [11.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  3.  3.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10.  3.  3.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10.  3.  3.] 
cards in discard: [ 0.  3.  1. 29.  0.  0.  0.  0. 22.  8.  0.  3. 29.  0. 14.  3. 14. 15.
  0.  3.  0. 16. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 0.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[ 9.669437]
 [ 9.870369]
 [10.343607]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29.  0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4563562273979187
desired expected reward: 13.26869010925293



action possibilites: [-1.  8.] 
expected returns: [[8.615871]
 [8.813768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.3114778995513916
desired expected reward: 7.985994338989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[7.1298776]
 [8.014977 ]
 [7.5629287]
 [9.256617 ]
 [8.343554 ]
 [8.611578 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  7.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.27945011854171753
desired expected reward: 8.895319938659668



buy possibilites: [-1] 
expected returns: [[12.292622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6.  6.  0. 29.  6.  3. 16.  6.  6.  3.  3.  8.  0. 14.  0.  0. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  6.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.8413740396499634
desired expected reward: 10.097990989685059






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  6.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  6.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0.  6. 11. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6. 11. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
expected returns: [[14.100151]
 [14.786417]
 [13.957735]
 [14.31068 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 15.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0 11] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3675819933414459
desired expected reward: 11.925039291381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.570368]
 [14.177216]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11. 15.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.] 
adversary owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0 11] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43123453855514526
desired expected reward: 13.680316925048828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [11.  0.  0. 16.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 29  8  0  0 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3
  0  1  0  0  3  0  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  6. 11. 15.  8.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  0. 16.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  6. 11. 15.  8.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  0. 16.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  6. 11. 15.  8.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  0. 16.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [ 0.  6. 11. 15.  8.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.00825 ]
 [10.662797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [ 0.  6. 11. 15.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3. 14. 10. 29.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.46182316541671753
desired expected reward: 13.572625160217285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.656514]
 [ 9.095747]
 [10.135798]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [ 0.  6. 11. 15.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14.  3. 14. 10. 29.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.35087576508522034
desired expected reward: 9.657374382019043



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [14.  3. 14. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 14. 10. 29.] 
cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.] 
cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.] 
cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
adversary owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
adversary victory points: -2
player victory points: 7 





Player: 0 
cards in hand: [3. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.292176]
 [14.51689 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 3.] 
cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 29  8  8  3  0  0  8 16  6  6  6  0  6  0  6  0 29 11  0 14 15  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.  0. 29.  3. 10. 11.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30259039998054504
desired expected reward: 9.833208084106445



action possibilites: [-1] 
expected returns: [[10.58027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 29  8  8  3  0  0  8 16  6  6  0  6  0  6  0 29 11  0 14 15  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.  0. 29.  3. 10. 11.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.22263918817043304
desired expected reward: 11.504426956176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.322599]
 [10.836527]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 29  8  8  3  0  0  8 16  6  6  0  6  0  6  0 29 11  0 14 15  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.  0. 29.  3. 10. 11.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24001696705818176
desired expected reward: 10.820286750793457



Player 1 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 0 
Workshop: 3 
Chapel: 6 
Witch: 0 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 3.] 
cards in discard: [ 0.  6. 11. 15.  8. 11.  0.  3.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 29  8  8  3  0  0  8 16  6  6  0  6  0  6  0 29 11  0 14 15  3 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 29. 30. 19. 30.  8.  0.  7.  5.  0. 10.  2.  6. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0. 16.  3.  0.  0.  8.  3. 14. 14.  0. 29.  3. 10. 11.] 
adversary owned cards: [10 29  8 29  0 11  0  0  0 22 16 15 14  3  3  3 10 14  3  3  3  0  1  0
  0  3  0  0 11  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -485 

action type: buy - action 0.0
Learning step: -14.82967758178711
desired expected reward: -5.507079124450684



