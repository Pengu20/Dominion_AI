 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[319.27188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    5  -70    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -541 

action type: buy - action 10.0
Learning step: -25.91034507751465
desired expected reward: -48.703407287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[296.658  ]
 [308.57516]
 [304.6473 ]
 [270.7859 ]
 [302.3562 ]
 [317.6226 ]
 [305.64078]
 [307.97485]
 [285.4642 ]
 [304.0238 ]
 [299.231  ]
 [322.68338]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.421996116638184
desired expected reward: 313.47015380859375



buy possibilites: [-1] 
expected returns: [[305.7571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.802831172943115
desired expected reward: 296.844482421875






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.49567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.729191780090332
desired expected reward: 298.0279235839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.55142]
 [311.82175]
 [306.0991 ]
 [277.3062 ]
 [317.49194]
 [309.7115 ]
 [305.12854]
 [318.4971 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.450840950012207
desired expected reward: 307.4897766113281



buy possibilites: [-1] 
expected returns: [[294.61505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 27 

action type: buy - action 10.0
Learning step: -7.277590274810791
desired expected reward: 297.8509826660156






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[295.11276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.6413445472717285
desired expected reward: 286.97369384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[267.88705]
 [278.39102]
 [273.79663]
 [253.87585]
 [246.07909]
 [272.79736]
 [284.98816]
 [276.1853 ]
 [293.8536 ]
 [277.85867]
 [257.4021 ]
 [263.83966]
 [273.26556]
 [252.11697]
 [268.99326]
 [287.79608]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.188648223876953
desired expected reward: 286.8961486816406



buy possibilites: [-1] 
expected returns: [[260.58478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 59 

action type: buy - action 22.0
Learning step: -3.7926909923553467
desired expected reward: 248.32427978515625






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[300.62598]
 [279.3697 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.084964752197266
desired expected reward: 254.49981689453125



action possibilites: [-1.] 
expected returns: [[339.85654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -4.765931606292725
desired expected reward: 272.4881286621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[315.78564]
 [284.82532]
 [340.486  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -8.452664375305176
desired expected reward: 331.40386962890625



buy possibilites: [-1] 
expected returns: [[314.44394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -8.76429557800293
desired expected reward: 307.0213928222656






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [22.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[243.79486]
 [199.21823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -10.24944019317627
desired expected reward: 304.1944885253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[214.30586]
 [227.25594]
 [222.41766]
 [188.80832]
 [235.83502]
 [223.88614]
 [221.03395]
 [239.86156]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.762842655181885
desired expected reward: 237.68162536621094



buy possibilites: [-1] 
expected returns: [[272.15894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 8.0
Learning step: -4.520733833312988
desired expected reward: 219.36546325683594






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [11.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 22.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [11.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 22.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [11.  0.  0.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 22.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[263.41602]
 [246.49602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 8. 22.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.456852912902832
desired expected reward: 264.70208740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[228.5265 ]
 [240.95668]
 [235.64163]
 [203.85503]
 [248.61128]
 [238.25386]
 [234.81818]
 [251.63884]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 8. 22.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.778524875640869
desired expected reward: 244.0613250732422



buy possibilites: [-1] 
expected returns: [[239.9215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 8. 22.  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -19.894515991210938
desired expected reward: 183.96044921875






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.  0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.72595]
 [200.98596]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 22  0  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.922461032867432
desired expected reward: 231.99903869628906



action possibilites: [-1] 
expected returns: [[227.05243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 6
Learning step: -5.084567070007324
desired expected reward: 184.78036499023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[198.94667]
 [174.80621]
 [221.33981]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -7.562034606933594
desired expected reward: 219.49038696289062



buy possibilites: [-1] 
expected returns: [[205.60268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -7.521273136138916
desired expected reward: 191.42538452148438






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.  0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  6.  0. 10.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[252.48344]
 [235.48088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -6.550980567932129
desired expected reward: 199.05169677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[228.6451 ]
 [236.00763]
 [205.3469 ]
 [236.82161]
 [251.83023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.93616008758545
desired expected reward: 240.544921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3. 11.  0.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3. 11.  0.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9. 10. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  1. 10.  0.  6.  3. 11.  0.  1.  0.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[225.68964]
 [189.50798]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 22.  0.] 
cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -9.619134902954102
desired expected reward: 242.21107482910156



action possibilites: [-1] 
expected returns: [[248.6058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 22.0
Learning step: -4.495198726654053
desired expected reward: 184.28138732910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[227.38794]
 [238.96066]
 [234.99829]
 [205.1107 ]
 [232.79161]
 [247.54247]
 [235.95822]
 [238.05957]
 [216.92099]
 [234.07893]
 [229.14015]
 [252.8107 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -7.868150234222412
desired expected reward: 240.73765563964844



buy possibilites: [-1] 
expected returns: [[272.23093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  6.  0. 10.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -9.5 

action type: buy - action 10.0
Learning step: -6.053750514984131
desired expected reward: 228.02516174316406






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.] 
cards in discard: [ 0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[199.32468]
 [182.81816]
 [185.2958 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -11.092755317687988
desired expected reward: 261.13818359375



action possibilites: [-1.  8.] 
expected returns: [[179.04086]
 [167.8846 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -5.772161483764648
desired expected reward: 174.8623046875



action possibilites: [-1.] 
expected returns: [[166.3275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.6023635864257812
desired expected reward: 149.29226684570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.4734 ]
 [150.12016]
 [121.99127]
 [151.40381]
 [163.60669]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  9.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.7078471183776855
desired expected reward: 161.61965942382812



buy possibilites: [-1] 
expected returns: [[185.25082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   8   0] 
sum of rewards: 14 

action type: buy - action 8.0
Learning step: -2.702047109603882
desired expected reward: 148.70176696777344






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[157.98271]
 [143.99687]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 8. 10.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.583583354949951
desired expected reward: 177.667236328125



action possibilites: [-1.] 
expected returns: [[162.94788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 10.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -4.174184799194336
desired expected reward: 138.6360626220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[143.43579]
 [154.31023]
 [151.0223 ]
 [121.92576]
 [162.65639]
 [151.45493]
 [150.25046]
 [167.12007]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 10.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.446187496185303
desired expected reward: 157.50169372558594



buy possibilites: [-1] 
expected returns: [[217.88466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -4.469385147094727
desired expected reward: 138.96640014648438






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  8. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3. 6.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3. 6.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  8.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3. 6.] 
cards in discard: [ 0. 11. 11.  1.  0.  3. 10. 14.  0.  0.  1.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[92.2868 ]
 [67.19173]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 22.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -345 

action type: buy - action -1
Learning step: -26.353961944580078
desired expected reward: 191.53070068359375



action possibilites: [-1] 
expected returns: [[165.82787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6.  0.  0. 10.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: LIBRARY: skip_action_card - action 1
Learning step: -3.538022756576538
desired expected reward: 136.84495544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[141.75908 ]
 [152.41884 ]
 [148.19975 ]
 [128.81493 ]
 [121.848694]
 [146.58861 ]
 [159.47842 ]
 [149.6659  ]
 [168.33757 ]
 [151.20908 ]
 [132.13216 ]
 [138.39804 ]
 [147.12979 ]
 [127.51417 ]
 [142.83307 ]
 [162.31822 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6.  0.  0. 10.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8.  7. 10.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -5.252872467041016
desired expected reward: 160.5749969482422



buy possibilites: [-1] 
expected returns: [[129.17088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6.  0.  0. 10.] 
cards in discard: [ 6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 3.0 

action type: buy - action 16.0
Learning step: -4.273085117340088
desired expected reward: 142.3155059814453






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [25.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[133.10388]
 [119.74143]
 [119.74143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8.  3. 10. 11.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.00648832321167
desired expected reward: 123.16439819335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.514755]
 [113.702   ]
 [ 88.61751 ]
 [114.7818  ]
 [128.41554 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  7.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8.  3. 10. 11.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.162423610687256
desired expected reward: 122.19831085205078



buy possibilites: [-1] 
expected returns: [[110.17811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 6. 16. 22. 10.  0.  0.  0.  6.  0.  0. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  8.  3. 10. 11.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11] -> size -> 24 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -19.565231323242188
desired expected reward: 69.0522689819336






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10. 11.] 
cards in discard: [11. 25.  0.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[190.49982]
 [174.13965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -4.3073859214782715
desired expected reward: 105.87071990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.45644]
 [179.50478]
 [175.36163]
 [150.35913]
 [186.63214]
 [176.56247]
 [174.26326]
 [189.49074]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.108209609985352
desired expected reward: 177.18505859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [22. 10.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [22. 10.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [22. 10.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [22. 10.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.  8.] 
expected returns: [[120.49288]
 [ 92.01175]
 [107.06035]
 [107.25385]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  6.  0.  8.] 
cards in discard: [ 0. 16.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11. 14.  1.  0.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -9.911738395690918
desired expected reward: 179.57899475097656



action possibilites: [-1. 22.  8.] 
expected returns: [[97.10549]
 [68.89079]
 [86.53223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  0.  8.  0.] 
cards in discard: [ 0. 16.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11. 14.  1.  0.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -5.088364601135254
desired expected reward: 99.86648559570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 80.96753]
 [ 87.07556]
 [ 64.03594]
 [ 86.80736]
 [100.10063]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  0.  8.  0.] 
cards in discard: [ 0. 16.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11. 14.  1.  0.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.750396251678467
desired expected reward: 92.35509490966797



buy possibilites: [-1] 
expected returns: [[105.666466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  0.  8.  0.] 
cards in discard: [ 0. 16.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11. 14.  1.  0.] 
adversary cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: -2.8262832164764404
desired expected reward: 84.24928283691406






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 14.  1.  0.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  1.  0.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  0.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  7.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  0.] 
cards in discard: [11. 25.  0.  3.  0.  1. 10.  0. 11.  0.  8.  3. 10.  0.  0.  0.  3.  3.
  1.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  6.  8.  0.  3.] 
adversary cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [10.  6.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[63.465683]
 [54.887314]
 [56.256874]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  0.  3.] 
cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 22  0  8  6  0 10  8  0  6 16  6  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.717475891113281
desired expected reward: 98.94898986816406



action possibilites: [-1] 
expected returns: [[116.10292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 14
Learning step: -1.4968156814575195
desired expected reward: 45.68581008911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[102.70873 ]
 [ 86.78034 ]
 [118.657845]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -5.225038051605225
desired expected reward: 110.87788391113281



buy possibilites: [-1] 
expected returns: [[63.032104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 16.  0.  0.  3.  3. 10. 22.  6.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action 0.0
Learning step: -6.967215061187744
desired expected reward: 95.74152374267578






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  0.  6.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.48106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -4.135280132293701
desired expected reward: 58.89682388305664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[66.84116 ]
 [73.11243 ]
 [71.34654 ]
 [57.433933]
 [78.10512 ]
 [71.35714 ]
 [70.86648 ]
 [80.97104 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0] -> size -> 30 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.060363292694092
desired expected reward: 73.4429931640625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  8.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  6.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[124.23138]
 [107.17836]
 [105.54722]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [6. 0. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.8726539611816406
desired expected reward: 77.098388671875



action possibilites: [-1.  8.  8.] 
expected returns: [[123.16482 ]
 [112.135635]
 [112.135635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [6. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -3.679403781890869
desired expected reward: 97.19940948486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.10851 ]
 [116.323166]
 [ 88.75109 ]
 [117.17927 ]
 [128.32294 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [6. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.865860939025879
desired expected reward: 118.29894256591797



buy possibilites: [-1] 
expected returns: [[93.48917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [6. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -5.740285396575928
desired expected reward: 96.13554382324219






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 11.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  5.  9.  7.  6.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3. 16. 22.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3. 16. 22.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 25. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3. 16. 22.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  3. 16. 22.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3. 16. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
expected returns: [[52.18522 ]
 [42.104027]
 [30.45291 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16. 22.  0.] 
cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 11.  1.  3.  3.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.476249694824219
desired expected reward: 87.0129165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[38.400925]
 [42.589294]
 [26.313114]
 [42.966866]
 [51.431335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16. 22.  0.] 
cards in discard: [ 6.  0.  0.  0.  6.  0. 10.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 11.  1.  3.  3.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.438380718231201
desired expected reward: 47.746822357177734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10. 11.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1.  3.  3.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 22. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 22. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 22. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  6. 10. 22. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6.  6. 10. 22. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 16.] 
expected returns: [[74.09385 ]
 [63.45349 ]
 [48.987946]
 [62.995712]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10. 22. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 22  0  8  0 10  8  0  6 16  6  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 25.  3.  3.  1.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.96561861038208
desired expected reward: 47.465702056884766



action possibilites: [-1] 
expected returns: [[68.74645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 25.  3.  3.  1.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -20 

action type: gain_card_n - action 3
Learning step: -4.7936859130859375
desired expected reward: 102.01593780517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.814323]
 [38.124092]
 [71.048584]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 23. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 25.  3.  3.  1.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -3.380781888961792
desired expected reward: 65.36566925048828



buy possibilites: [-1] 
expected returns: [[111.29949]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.] 
cards in discard: [3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 25.  3.  3.  1.] 
adversary cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action 0.0
Learning step: -2.9864776134490967
desired expected reward: 52.82784652709961






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 25.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  3.  1.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  5.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.] 
adversary owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3  0] -> size -> 18 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  1.  0. 10.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  1.  0. 10.] 
cards in discard: [ 0.  8. 14.  0.  0.  6.  6. 11.  0.  0.  0.  8.  8.  3. 11.  1.  0.  0.
  3.  0. 10. 11.  1.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[62.292885]
 [53.14147 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -355 

action type: buy - action -1
Learning step: -22.010883331298828
desired expected reward: 89.28860473632812



action possibilites: [-1] 
expected returns: [[43.912247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.062925338745117
desired expected reward: 23.95609474182129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.707312 ]
 [12.9597435]
 [43.560898 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -3.2954413890838623
desired expected reward: 40.61680603027344



buy possibilites: [-1] 
expected returns: [[82.10124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action 0.0
Learning step: -2.788088321685791
desired expected reward: 24.919233322143555






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 17 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[35.530518]
 [26.80534 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1.  6. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.148582458496094
desired expected reward: 75.9526596069336



action possibilites: [-1] 
expected returns: [[49.35333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1.  6. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.9578579664230347
desired expected reward: 13.408295631408691





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[42.566086]
 [46.052956]
 [31.444645]
 [45.9469  ]
 [52.35157 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 23. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1.  6. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -3.7746894359588623
desired expected reward: 45.57863998413086



buy possibilites: [-1] 
expected returns: [[11.67314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 16.  6.  6. 10.  6.  0.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1.  6. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 3.0
Learning step: -3.390002489089966
desired expected reward: 42.66295623779297






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [10.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[51.041233]
 [42.64782 ]
 [44.68481 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.317546844482422
desired expected reward: 9.355592727661133



action possibilites: [-1.  8.] 
expected returns: [[37.045437]
 [29.065224]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  0 10  8  0  6 16  6  3  0  0  3  0  6  0  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -3.068074941635132
desired expected reward: 38.26346206665039



action possibilites: [-1.] 
expected returns: [[51.612007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 4
Learning step: -1.8220409154891968
desired expected reward: 20.844181060791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.19394 ]
 [46.0887  ]
 [31.565903]
 [47.72538 ]
 [52.95072 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -3.423431873321533
desired expected reward: 48.188575744628906



buy possibilites: [-1] 
expected returns: [[98.27729]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -67.0 

action type: buy - action 0.0
Learning step: -3.2984580993652344
desired expected reward: 39.895477294921875






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  9. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.100871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 11. 11.  1.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -8.579684257507324
desired expected reward: 89.6976089477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-1.4547867]
 [ 0.7627382]
 [-4.0591574]
 [ 1.169256 ]
 [ 8.06087  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 11. 11.  1.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.230593681335449
desired expected reward: 3.955219268798828



buy possibilites: [-1] 
expected returns: [[57.627605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 0. 10.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 11. 11.  1.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -107.0 

action type: buy - action 0.0
Learning step: -3.980639696121216
desired expected reward: -5.435426235198975






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8. 11. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  1.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 6.  0. 16.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0. 16.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  1.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  5.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0. 16.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  1.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0. 16.  0.  8.] 
adversary cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[71.62322]
 [56.45103]
 [58.23859]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  0.  8.] 
cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 10  8  0  6 16  6  0  0  0  6  0  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.322685241699219
desired expected reward: 52.3049201965332



action possibilites: [-1] 
expected returns: [[67.94099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 12
Learning step: -2.84051513671875
desired expected reward: 38.54323196411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.067074]
 [43.89613 ]
 [68.1789  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10.  8.  0.  0.  0.  6.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -4.44282865524292
desired expected reward: 63.4981575012207






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[73.54418 ]
 [67.302185]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  0  0  0  6  0  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 14.  8.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -4.732674598693848
desired expected reward: 55.839019775390625



action possibilites: [-1] 
expected returns: [[97.04109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 14.  8.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 5
Learning step: -3.3923211097717285
desired expected reward: 62.12259292602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.83338]
 [72.53993]
 [93.82237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 25. 14.  8.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -5.26315975189209
desired expected reward: 91.7779312133789






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 14.  8.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [8. 6. 8. 3.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  8.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.  0.  1.  6. 10.  3. 25.  0.  0.  3.  0.  1.
 15.  8. 11.  8. 11.  1.  3. 10.  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [8. 6. 8. 3.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.87536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [8. 6. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 1. 10.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: discard_down_to_3_cards - action 4
Learning step: -3.587650775909424
desired expected reward: 10.085918426513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.360247  ]
 [  0.91993356]
 [-18.668411  ]
 [ -1.3868145 ]
 [ 18.701326  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [8. 6. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 22. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 1. 10.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -4.199504375457764
desired expected reward: 13.401731491088867



buy possibilites: [-1] 
expected returns: [[107.37429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [8. 6. 8. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 1. 10.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -47 

action type: buy - action 3.0
Learning step: 0.019924795255064964
desired expected reward: 0.9398569464683533






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  4.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  8.  3.] 
cards in discard: [15.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[73.55078]
 [65.20369]
 [64.49862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [15.  0. 11.  6.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.625465393066406
desired expected reward: 100.74882507324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[57.9402  ]
 [62.64182 ]
 [45.442703]
 [62.518383]
 [71.215164]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  4.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [15.  0. 11.  6.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.977940082550049
desired expected reward: 66.82766723632812



buy possibilites: [-1] 
expected returns: [[29.788277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [15.  0. 11.  6.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -366.0 

action type: buy - action 6.0
Learning step: -19.901899337768555
desired expected reward: 25.540803909301758






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [15.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  6.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11
 10  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  3.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [8. 6. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  3.  0.  0. 10.] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [8. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[11.818116]
 [10.377327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 6. 0.] 
cards in discard: [ 6.  8.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -4.538856506347656
desired expected reward: 25.249420166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.324764]
 [ 6.256838]
 [13.455787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 6. 0.] 
cards in discard: [ 6.  8.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.661520004272461
desired expected reward: 8.156593322753906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  6.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  6.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
adversary victory points: -1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  6.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[40.065487]
 [28.659382]
 [28.659382]
 [29.79829 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  6  6  0  3  0  0  3  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [10.  8. 25. 10. 14.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -3.2570736408233643
desired expected reward: 10.198715209960938



action possibilites: [-1] 
expected returns: [[71.595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 3 0 0 3 6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [10.  8. 25. 10. 14.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 5
Learning step: -1.7609302997589111
desired expected reward: 22.620216369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.961983]
 [52.214817]
 [72.25879 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 3 0 0 3 6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [10.  8. 25. 10. 14.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -4.490733623504639
desired expected reward: 67.1042709350586



buy possibilites: [-1] 
expected returns: [[76.21389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0 3 0 0 3 6 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [10.  8. 25. 10. 14.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -357 

action type: buy - action 6.0
Learning step: -18.745929718017578
desired expected reward: 33.468902587890625






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [10.  8. 25. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 25. 10. 14.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 6.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6] -> size -> 10 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8. 25. 10. 14.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10. 14.  8.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 6.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6] -> size -> 10 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8. 10. 14.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 14.  8. 11.  8.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 6. 6.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 14.  8.  8.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 6. 6.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 14.  8.  8.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [6. 8. 6. 6. 6.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.771374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 8. 6. 6. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  1. 25.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -80    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -388 

action type: buy - action -1
Learning step: -22.27083969116211
desired expected reward: 53.943050384521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.04768 ]
 [35.71403 ]
 [23.995975]
 [35.3895  ]
 [41.829636]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [6. 8. 6. 6. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  1. 25.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -5.718594551086426
desired expected reward: 36.05278015136719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 25.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 25.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
adversary victory points: -3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.939106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1.0
Learning step: -5.666421413421631
desired expected reward: 36.16321563720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.91586 ]
 [27.1918  ]
 [ 2.199522]
 [24.412437]
 [38.105476]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 21. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -5.7200117111206055
desired expected reward: 30.949329376220703



buy possibilites: [-1] 
expected returns: [[-2.3470285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -69 

action type: buy - action 3.0
Learning step: -4.862398624420166
desired expected reward: 22.329416275024414






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9. 10.  3.  9.  7.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [3. 3. 6. 6. 0. 0.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[63.290203]
 [59.802452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [3. 3. 6. 6. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 10.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0. 23. 10.  0.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -2.3457772731781006
desired expected reward: -4.692805767059326





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.86643 ]
 [37.117157]
 [63.796215]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [3. 3. 6. 6. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 10.  0.] 
adversary cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0. 23. 10.  0.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -5.846215724945068
desired expected reward: 57.4439811706543



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 10.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0. 23. 10.  0.  0.  1.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 10.  0.] 
cards in discard: [15.  8. 11.  1. 10.  8.  3.  8. 15. 11.  6.  0.  0.  0.  3.  3.  0. 15.
 10. 25. 11.  8. 10. 14.  8.  8.  3.  3.  1. 25.  0. 23. 10.  0.  0.  1.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[71.32787 ]
 [61.246532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -5.569558143615723
desired expected reward: 58.22665786743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.63773 ]
 [42.930927]
 [71.22872 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0.  1.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -6.057882785797119
desired expected reward: 64.06025695800781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10.  0.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 27. 30. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 1.] 
cards in discard: [2.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 6. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3.] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.376506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0. 10. 11. 15.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2] -> size -> 45 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -7.132965087890625
desired expected reward: 64.09575653076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.692145]
 [ 7.322254]
 [13.675981]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 29. 20. 30.  8.  1.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0. 10. 11. 15.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2] -> size -> 45 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -4.227436542510986
desired expected reward: 8.149068832397461



buy possibilites: [-1] 
expected returns: [[26.874962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0. 10. 11. 15.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2] -> size -> 45 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -388.0 

action type: buy - action 6.0
Learning step: -19.161428451538086
desired expected reward: -11.839174270629883






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 15.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3 6] -> size -> 13 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 15.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3 6] -> size -> 13 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 15.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0 3 0 0 3 6 6 6 3 6] -> size -> 13 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [0. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[39.468754]
 [34.701115]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0 3 0 0 3 6 6 6 3 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 25.  6.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -4.906495571136475
desired expected reward: 21.96846580505371



action possibilites: [-1] 
expected returns: [[45.209763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 25.  6.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 6
Learning step: -3.9475185871124268
desired expected reward: 19.34724235534668





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.40152]
 [43.74975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 25.  6.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -5.165060043334961
desired expected reward: 40.044700622558594






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 25.  6.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10
  0  0  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 6. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 6. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 6. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 6. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[56.403526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 3.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [25.  0. 11.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0] -> size -> 45 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -5.253491401672363
desired expected reward: 38.49625015258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[43.984562]
 [53.60731 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 3.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [25.  0. 11.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0] -> size -> 45 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -5.938569068908691
desired expected reward: 48.905696868896484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [25.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11.  0.  3.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 11.  0.  3.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  2.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 11.  0.  3.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[5.617923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 11. 10.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -6.867138862609863
desired expected reward: 46.74017333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.79584694]
 [2.961493  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 11. 10.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.508054256439209
desired expected reward: 0.5242457389831543



buy possibilites: [-1] 
expected returns: [[67.300316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8.  0.  8. 11. 10.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -2.825535535812378
desired expected reward: -2.0296881198883057






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 11. 10.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 6. 0. 3. 8.] 
adversary cards in discard: [0. 6. 3. 6. 3. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0] -> size -> 11 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 11. 10.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 6. 0. 3. 8.] 
adversary cards in discard: [0. 6. 3. 6. 3. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0] -> size -> 11 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.600471]
 [14.996314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 8.] 
cards in discard: [0. 6. 3. 6. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.761211395263672
desired expected reward: 61.53910446166992





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.498099]
 [21.211933]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 8.] 
cards in discard: [0. 6. 3. 6. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.4349372386932373
desired expected reward: 17.16553497314453



buy possibilites: [-1] 
expected returns: [[-1.7739367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 8.] 
cards in discard: [0. 6. 3. 6. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -5.0148186683654785
desired expected reward: 8.483282089233398






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 10.  3.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[38.158722]
 [32.53585 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [15. 23.  1.  3.  8.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -1.9189977645874023
desired expected reward: -3.692934513092041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.380318]
 [28.772442]
 [29.664055]
 [34.900818]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [15. 23.  1.  3.  8.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.024688720703125
desired expected reward: 33.949317932128906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [15. 23.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 23.  1.  3.  8.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 8.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  3.  8.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 8.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  8.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 29. 20. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 8.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  3.  8.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 8.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.5885143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: -4.896799564361572
desired expected reward: 30.004018783569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[3.6566477]
 [5.6603756]
 [5.1373277]
 [7.2098494]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  1.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.5054261684417725
desired expected reward: 3.0830881595611572



buy possibilites: [-1] 
expected returns: [[-2.4901464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 8. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  8.  0. 15.  0.] 
adversary cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -58 

action type: buy - action 8.0
Learning step: -3.212895154953003
desired expected reward: 1.9244410991668701






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [10.  8.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 15.  0.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.  8. 15. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0. 14.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0
  3  8  0  6  8  3  0 10 10 25 15  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 2. 10.  0.  1.  8.  0.  1.  0. 11.  3.  0. 10. 15.  0.  8. 25.  6.  8.
 25.  0. 11.  0.  3.  8.  0.  8. 11. 10. 10.  6.  0.  3.  3.  0.  3. 15.
 23.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.359264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [23.  8.  2. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -2.749171018600464
desired expected reward: -5.239317417144775





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[2.4772568]
 [4.568459 ]
 [9.237314 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [23.  8.  2. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.683168888092041
desired expected reward: 6.513495922088623



buy possibilites: [-1] 
expected returns: [[-4.3805156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [23.  8.  2. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -96.0 

action type: buy - action 0.0
Learning step: -5.022424221038818
desired expected reward: -2.545175552368164






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [23.  8.  2. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  2. 15.  3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 0. 8. 0.] 
adversary cards in discard: [0. 6. 0. 0. 6. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0] -> size -> 14 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  2. 15.  3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 6. 0. 8. 0.] 
adversary cards in discard: [0. 6. 0. 0. 6. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0] -> size -> 14 
adversary victory points: -1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ -9.6239  ]
 [-11.947527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 0.] 
cards in discard: [0. 6. 0. 0. 6. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 15.  3. 14.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -3.322267532348633
desired expected reward: -7.702783107757568





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.803488]
 [-11.94574 ]
 [ -9.366562]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8. 0.] 
cards in discard: [0. 6. 0. 0. 6. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 29. 19. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 15.  3. 14.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -3.0793850421905518
desired expected reward: -12.703286170959473



buy possibilites: [-1] 
expected returns: [[4.3018064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8. 0.] 
cards in discard: [0. 6. 0. 0. 6. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 18. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 15.  3. 14.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -47 

action type: buy - action 3.0
Learning step: -1.655922293663025
desired expected reward: -13.601659774780273






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3. 14.  0.] 
cards in discard: [23.  8.  2. 15.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3
  8  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 18. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 0. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.] 
cards in discard: [23.  8.  2. 15.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 29. 18. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 0. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.] 
cards in discard: [23.  8.  2. 15.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 29. 18. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 0. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.] 
cards in discard: [23.  8.  2. 15.  3.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [3. 0. 3. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-7.228549]
 [-7.802384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.6338462829589844
desired expected reward: 0.6679601669311523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.270155 ]
 [-6.9940915]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -3.0488805770874023
desired expected reward: -10.277430534362793



buy possibilites: [-1] 
expected returns: [[51.793453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 6.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -3.221139669418335
desired expected reward: -10.491294860839844






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6. 10.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10.  1.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 8.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 10  1  1 11  1  3  6  3 25  0 11 14  8 11 10  0  0  3  8
  0  6  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 45 
action values: 3 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  7.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[0.05209446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  1. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -6.338500499725342
desired expected reward: 45.454952239990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-4.989859 ]
 [-2.1727874]
 [ 2.9939146]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  1. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -3.778644323348999
desired expected reward: -3.7265498638153076



buy possibilites: [-1] 
expected returns: [[32.95186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8. 10.  1. 10.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: -4.259090423583984
desired expected reward: -9.248945236206055






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  1. 10.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  1. 10.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 29. 17. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  1. 10.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [6. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[2.6470294]
 [2.898726 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 10.  0.  8.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -5.835053443908691
desired expected reward: 27.116806030273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[2.0506988]
 [3.3042126]
 [4.64008  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 10.  0.  8.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.305828094482422
desired expected reward: -1.6588196754455566



buy possibilites: [-1] 
expected returns: [[-21.087524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 8. 6. 0. 0. 6. 6. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [11.  1. 10.  0.  8.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -6.327004432678223
desired expected reward: -4.276307582855225






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [11.  1. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  0.  8.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10.  0.  8.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10.  0.  8.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [8. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [8. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.185791]
 [16.123123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3. 25. 11.  0.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -2.749188184738159
desired expected reward: -23.836711883544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.478655]
 [20.978079]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3. 25. 11.  0.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.038488864898682
desired expected reward: 18.147302627563477



buy possibilites: [-1] 
expected returns: [[29.964165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [ 3. 25. 11.  0.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -5.402792930603027
desired expected reward: 1.136932373046875






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3. 25. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11.  0.  0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  3.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 29. 16. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 15. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [6. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.9121041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [0. 8. 3. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 15. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -6.313730716705322
desired expected reward: 23.650434494018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-3.0234575]
 [-4.020386 ]
 [-3.4911015]
 [-4.1621943]
 [-3.1360724]
 [-4.3600836]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [0. 8. 3. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 29. 15. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -4.686814785003662
desired expected reward: -7.598918914794922



buy possibilites: [-1] 
expected returns: [[-0.29820085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [0. 8. 3. 0. 3. 6. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -82.0 

action type: buy - action 3.0
Learning step: -3.932154417037964
desired expected reward: -7.42325496673584






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6. 3. 6. 0. 0. 6. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6. 3. 6. 0. 0. 6. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [0. 8. 3. 0. 3. 6. 3. 6. 0. 0. 6. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [0. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.41098 ]
 [13.424249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [0. 8. 3. 0. 3. 6. 3. 6. 0. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 6.  8.  8. 25.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -3.8239707946777344
desired expected reward: -4.122171401977539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.424791]
 [15.14918 ]
 [19.905766]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [0. 8. 3. 0. 3. 6. 3. 6. 0. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 6.  8.  8. 25.  0.] 
adversary cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.75958776473999
desired expected reward: 13.651390075683594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 25.  0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 0. 0. 0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 0. 0. 0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  6.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 0. 0. 0.] 
cards in discard: [23.  8.  2. 15.  3.  3. 15.  8.  3. 14. 11. 10. 10.  8.  0.  1.  3.  3.
  8. 10.  1. 10.  0. 11.  1. 10.  0.  8. 10.  3. 11.  3. 25.  0.  0.  1.
 11.  0.  0.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.7556388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 1.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1 11] -> size -> 50 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.133286952972412
desired expected reward: 14.772480010986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-0.43373513]
 [ 1.2110295 ]
 [ 0.8309841 ]
 [ 1.9764717 ]
 [ 0.47077632]
 [ 1.8236434 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 29. 14. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 1.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1 11] -> size -> 50 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.314547061920166
desired expected reward: -1.558908224105835



buy possibilites: [-1] 
expected returns: [[-6.1008916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 1.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1 11] -> size -> 50 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -71.0 

action type: buy - action 3.0
Learning step: -3.7288193702697754
desired expected reward: -2.8978304862976074






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6
  8  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3
  1 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  8. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [25.] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.244727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [23.  8.  1. 11. 10.] 
adversary cards in discard: [25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -3.417961835861206
desired expected reward: -9.518853187561035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.1231384]
 [-5.3832483]
 [-4.7593346]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [23.  8.  1. 11. 10.] 
adversary cards in discard: [25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -3.608966588973999
desired expected reward: -6.85369348526001



buy possibilites: [-1] 
expected returns: [[84.34231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [23.  8.  1. 11. 10.] 
adversary cards in discard: [25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -2.946141242980957
desired expected reward: -9.069276809692383






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [23.  8.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 11. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  1. 11. 10.] 
cards in discard: [25. 15.  1.  3.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1.  8. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11. 10.  0.] 
cards in discard: [25. 15.  1.  3.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7. 10.  9.  9.  2.  9.  7.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 10.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 10.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29] -> size -> 51 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  5.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
adversary victory points: 2
player victory points: 9 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 10.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
adversary owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [8. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[5.808221]
 [2.012285]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  8.  0.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -7.776872158050537
desired expected reward: 76.56543731689453



action possibilites: [-1] 
expected returns: [[-14.593204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  8.  0.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.039957284927368
desired expected reward: -1.8077521324157715





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.515519]
 [-12.956822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  8.  0.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -2.2284743785858154
desired expected reward: -16.821678161621094






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  8.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3. 8. 6. 0. 3.] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  8.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 29. 13. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3. 8. 6. 0. 3.] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  8.  0.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3. 8. 6. 0. 3.] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [0. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-7.1651673]
 [-7.9938574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3. 8. 6. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 15.  2. 10.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -3.499464511871338
desired expected reward: -19.911075592041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-14.462207]
 [-13.999473]
 [-13.728972]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [3. 3. 0. 3. 0. 0. 0. 6. 0. 3. 0. 3. 8. 6. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 15.  2. 10.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3] -> size -> 53 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.107772350311279
desired expected reward: -11.272941589355469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 15.  2. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  2. 10.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  2. 10.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  9.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  2. 10.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  8.  9.  9.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.4593053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  8.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  0. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29] -> size -> 54 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -3.5413856506347656
desired expected reward: -17.270360946655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.572628 ]
 [-3.845673 ]
 [-3.4715667]
 [-3.0399745]
 [-3.5163894]
 [-2.4895408]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 3 6 6 6 3 6 0 0 8 0 3 0 0 0 0 3 3 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  8.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  0. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29] -> size -> 54 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.054351806640625
desired expected reward: -7.513657093048096



buy possibilites: [-1] 
expected returns: [[-13.085864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8. 11.  0. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29] -> size -> 54 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -65 

action type: buy - action 10.0
Learning step: -3.368612289428711
desired expected reward: -6.88500452041626






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  9.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  8.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 29. 12. 30.  8.  0.  8.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.36021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  1.  0. 10.  3.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -2.7001020908355713
desired expected reward: -15.785965919494629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[32.794464]
 [34.689404]
 [33.767056]
 [35.52844 ]
 [33.605915]
 [35.356686]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  4.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  1.  0. 10.  3.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -5.1450018882751465
desired expected reward: 30.215208053588867



buy possibilites: [-1] 
expected returns: [[-12.416976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3.  1.  0. 10.  3.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -65 

action type: buy - action 11.0
Learning step: -5.30580472946167
desired expected reward: 30.222652435302734






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 3. 8. 6.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [0. 3. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 2.898713 ]
 [-1.9151742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 6.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3. 25.  3. 10. 25.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -3.515216827392578
desired expected reward: -15.9321928024292





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.7035167]
 [ 4.7290125]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 6.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3. 25.  3. 10. 25.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -4.2677178382873535
desired expected reward: -1.3690094947814941



buy possibilites: [-1] 
expected returns: [[-12.214547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 6.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [ 3. 25.  3. 10. 25.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -113.0 

action type: buy - action 0.0
Learning step: -5.789651870727539
desired expected reward: -8.493162155151367






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3. 25.  3. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 10. 25.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 8. 3.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 25.  3.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 8. 3.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 25.  3.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 8. 3.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 25.  3.  3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [6. 0. 0. 8. 3.] 
adversary cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
adversary owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [6. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 2.2779484]
 [-5.011073 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 3.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  3  6  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [10.  8.  0.  8.  6.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -3.5656754970550537
desired expected reward: -15.78022289276123



action possibilites: [-1] 
expected returns: [[34.47519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [10.  8.  0.  8.  6.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: trash_cards_n_from_hand - action 5
Learning step: -1.9672298431396484
desired expected reward: -10.108795166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[32.809467]
 [33.92959 ]
 [36.373478]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 29. 12. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [10.  8.  0.  8.  6.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1
Learning step: -4.09802770614624
desired expected reward: 30.377161026000977



buy possibilites: [-1] 
expected returns: [[-6.577171]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  6.  0.  3.  0.  0. 11.  0.  0.  3.  3.  0.  0.  0.  3.  3.  8.  6.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [10.  8.  0.  8.  6.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
adversary owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -44 

action type: buy - action 3.0
Learning step: -4.006118297576904
desired expected reward: 29.92346954345703






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.  6.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 3.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  6  8
  3  0 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1
 11 25 29 11  3 29 16  0  1  0] -> size -> 58 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0
 10 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25
 29 11  3 29 16  0  1  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [3. 8. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-5.109179]
 [-9.322168]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [14.  0.  0.  8. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.] 
adversary owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -3.4309825897216797
desired expected reward: -10.008153915405273





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.624444 ]
 [-5.4488273]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [14.  0.  0.  8. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.] 
adversary owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: take_action - action -1.0
Learning step: -3.5116264820098877
desired expected reward: -8.620802879333496



buy possibilites: [-1] 
expected returns: [[-19.192501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [14.  0.  0.  8. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.] 
adversary owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -102 

action type: buy - action 0.0
Learning step: -5.050609111785889
desired expected reward: -14.675054550170898






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  8. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [0. 3. 8. 3. 3. 6.] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3  0] -> size -> 24 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  8. 11.] 
cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [0. 3. 8. 3. 3. 6.] 
adversary owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3  0] -> size -> 24 
adversary victory points: 3
player victory points: 10 


Player 1 won the game! 



Player 0 bought cards:
Copper: 19 
Silver: 0 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 1 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [0. 3. 8. 3. 3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3  6  6  3  6  0  0  8  0  3  0  0  0  0  3  3  0 10 11  0  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 29. 11. 30.  8.  0.  8.  3.  0.  7.  8.  9.  9.  1.  9.  7.] 
adversary cards in hand: [14.  0.  0.  8. 11.] 
adversary cards in discard: [25. 15.  1.  3.  3. 29. 11. 23. 11.  8.  1. 10.  0.  3.  3.  1. 10.  8.
  0. 29.  0.  8. 15.  2. 10. 16.  0. 11.  0.  8.  0. 11.  1.  3.  1.  0.
 10.  3.  0. 25.  3.  3. 10. 25.  3.  3. 10.  8.  8.  0.] 
adversary owned cards: [ 3 10  1  1 11  1  3  3 25  0 11 14  8 11 10  0  0  3  8  0  8  3  0 10
 10 25  8 10 15  8  8 15 23  2  0  0  8  3  3 11  3  0 10  3  1 11 25 29
 11  3 29 16  0  1  0  0] -> size -> 56 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -70    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -572 

action type: buy - action -1
Learning step: -27.6403751373291
desired expected reward: -46.83287811279297



