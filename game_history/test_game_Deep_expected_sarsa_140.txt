 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.973778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000165 

action type: take_action - action 25.0
Learning step: -119999.015625
desired expected reward: -120188.6015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 39.98825  ]
 [ 82.52813  ]
 [ 55.161545 ]
 [-28.025352 ]
 [ 74.39038  ]
 [ 80.07952  ]
 [ 64.90622  ]
 [ 97.928024 ]
 [ -4.0681353]
 [ 37.53965  ]
 [ 36.14747  ]
 [ 49.466515 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.29019546508789



buy possibilites: [-1] 
expected returns: [[55.893764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.92803192138672






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.798077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.89376449584961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 53.006844]
 [ 92.44794 ]
 [ 67.39061 ]
 [-11.193373]
 [ 90.726814]
 [ 76.34304 ]
 [ 51.285694]
 [ 63.895817]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.49765396118164



buy possibilites: [-1] 
expected returns: [[66.69032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 92.44792938232422






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[57.275158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.69032287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 49.625954 ]
 [ 92.09359  ]
 [ 65.29986  ]
 [  4.049041 ]
 [-23.06123  ]
 [ 84.11939  ]
 [ 89.6668   ]
 [ 74.81889  ]
 [150.1863   ]
 [107.13753  ]
 [  1.5600386]
 [ 55.53986  ]
 [ 47.122936 ]
 [ 11.403459 ]
 [ 45.697926 ]
 [ 59.59184  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.24911117553711



buy possibilites: [-1] 
expected returns: [[54.072968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 150.18634033203125






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[51.789955]
 [96.68772 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [25.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.072967529296875



action possibilites: [-1.] 
expected returns: [[80.97053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  0.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 96.06909942626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 68.67918  ]
 [108.103325 ]
 [ 83.15293  ]
 [  3.9826612]
 [100.64988  ]
 [106.55017  ]
 [ 92.0764   ]
 [123.10345  ]
 [ 26.75819  ]
 [ 67.126    ]
 [ 66.18235  ]
 [ 80.20739  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  0.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.97052764892578



buy possibilites: [-1] 
expected returns: [[75.30735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [25.  0.  1.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.10344696044922






Player: 1 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[41.64478]
 [87.90271]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.3073501586914



action possibilites: [-1.] 
expected returns: [[56.597393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.02338409423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 47.525967 ]
 [ 86.67845  ]
 [ 61.439632 ]
 [  7.9682417]
 [-16.128284 ]
 [ 79.12709  ]
 [ 84.31337  ]
 [ 70.39976  ]
 [141.77321  ]
 [100.88415  ]
 [  5.820755 ]
 [ 52.742237 ]
 [ 45.383736 ]
 [ 14.172727 ]
 [ 44.183506 ]
 [ 56.56426  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.59739303588867



buy possibilites: [-1] 
expected returns: [[67.06222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.77322387695312






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 25.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 38.570057]
 [ 78.22477 ]
 [114.8555  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 25.] 
cards in discard: [25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.06221771240234



action possibilites: [-1] 
expected returns: [[66.67853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  1.  3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 114.23387908935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 60.10938 ]
 [ 97.071465]
 [ 73.70049 ]
 [ 12.936919]
 [ 90.08955 ]
 [ 95.65394 ]
 [ 82.062805]
 [111.17912 ]
 [ 28.939014]
 [ 58.691845]
 [ 57.82797 ]
 [ 71.07397 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  1.  3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.67852783203125



buy possibilites: [-1] 
expected returns: [[93.43685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  1.  3.] 
cards in discard: [25. 29.  0.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 111.1791000366211






Player: 1 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  3.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.777077]
 [65.96996 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.43685150146484



action possibilites: [-1.] 
expected returns: [[44.751125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 64.8312759399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 37.443027]
 [ 73.02309 ]
 [ 49.258537]
 [-19.781155]
 [ 65.83101 ]
 [ 71.39382 ]
 [ 57.540318]
 [ 87.33061 ]
 [  3.334138]
 [ 36.357464]
 [ 35.703587]
 [ 47.633587]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.75112533569336



buy possibilites: [-1] 
expected returns: [[88.22184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.33065032958984






Player: 1 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 25.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[110.61113]
 [142.25206]
 [173.19662]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 25.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  9. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  6.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.22183990478516



action possibilites: [-1] 
expected returns: [[122.545586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  0.  3.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  6.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 172.20799255371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.54746 ]
 [150.70346 ]
 [133.61378 ]
 [ 96.12083 ]
 [ 79.24218 ]
 [145.46472 ]
 [149.9279  ]
 [139.68393 ]
 [192.02615 ]
 [162.2388  ]
 [ 95.3399  ]
 [128.04279 ]
 [122.76748 ]
 [101.10836 ]
 [122.261955]
 [132.54137 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  0.  3.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  8.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  6.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.54558563232422



buy possibilites: [-1] 
expected returns: [[138.83139]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  0.  3.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  6.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 192.02615356445312






Player: 1 
cards in hand: [ 3.  3.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  6.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[ 48.71103]
 [ 82.61153]
 [115.97416]
 [ 82.61153]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8.  8. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.83139038085938



action possibilites: [-1] 
expected returns: [[62.65144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8.  7. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.22089385986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.617184]
 [86.908905]
 [68.67327 ]
 [ 9.964454]
 [86.289444]
 [75.233345]
 [56.997726]
 [68.259094]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8.  7. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.65143966674805



buy possibilites: [-1] 
expected returns: [[80.394135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  7. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 86.90888214111328






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  7. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 25.  1.  0.  0.] 
adversary cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 29. 30.  8.  7. 10.  8. 10.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 25.  1.  0.  0.] 
adversary cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11. 11.  0.  0.  6.  1. 15.  3.  3.  6.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 29. 30.  8.  7. 10.  8.  9.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 25.  1.  0.  0.] 
adversary cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 78.15567]
 [136.25449]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  0.  0.] 
cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  7. 10.  8.  9.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  1. 11.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.39413452148438



action possibilites: [-1] 
expected returns: [[90.814705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 25.  3.] 
cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  1. 11.  1.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.40695190429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.17512 ]
 [113.131584]
 [ 95.56127 ]
 [ 43.99662 ]
 [107.87481 ]
 [112.24437 ]
 [101.8582  ]
 [124.32044 ]
 [ 58.39625 ]
 [ 84.28792 ]
 [ 83.72485 ]
 [ 94.17546 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 25.  3.] 
cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  1. 11.  1.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.81470489501953



buy possibilites: [-1] 
expected returns: [[102.87405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 25.  3.] 
cards in discard: [ 1. 25.  0. 29. 29.  0.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  1. 11.  1.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 124.3204116821289






Player: 1 
cards in hand: [11.  1. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  1.  1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  1.] 
cards in discard: [ 6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.  1.] 
cards in discard: [ 6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1.  1.] 
cards in discard: [ 6. 15. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[35.506527]
 [71.47613 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.8740463256836



action possibilites: [-1. 25.] 
expected returns: [[ 76.04167]
 [138.88931]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 29. 30.  8.  6. 10.  8.  9.  7.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.27921295166016



action possibilites: [-1] 
expected returns: [[111.92881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 29. 30.  8.  5. 10.  8.  9.  7.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 138.8892822265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[107.39537 ]
 [136.78635 ]
 [ 89.085884]
 [118.47685 ]
 [ 77.555046]
 [ 59.24558 ]
 [131.29384 ]
 [136.1448  ]
 [125.0633  ]
 [179.36748 ]
 [148.534   ]
 [ 76.91351 ]
 [112.53504 ]
 [106.75382 ]
 [ 83.14406 ]
 [106.3045  ]
 [117.999535]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 25. 30. 29. 30.  8.  5. 10.  8.  9.  7.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.9288101196289



buy possibilites: [-1] 
expected returns: [[147.51248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 25.  1.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 29. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 179.3675079345703






Player: 1 
cards in hand: [3. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 29.  1.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 25. 30. 29. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 29.  1.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 29.  1.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 77.48517]
 [103.57824]
 [103.57824]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  1.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.51248168945312



action possibilites: [-1. 29.] 
expected returns: [[ 84.974594]
 [116.00146 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1.  3.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.81656646728516



action possibilites: [-1. 25.] 
expected returns: [[111.9425]
 [177.8026]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  3. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 28. 30.  8.  5. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.0014419555664



action possibilites: [-1] 
expected returns: [[99.112434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  3. 29. 29.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.80259704589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 86.77921 ]
 [115.15727 ]
 [ 97.29878 ]
 [ 58.10684 ]
 [ 40.466938]
 [109.75788 ]
 [114.16748 ]
 [103.63093 ]
 [158.03181 ]
 [126.217476]
 [ 57.318638]
 [ 91.50438 ]
 [ 85.99101 ]
 [ 63.34489 ]
 [ 85.47811 ]
 [ 96.268295]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  3. 29. 29.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  6.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.11243438720703



buy possibilites: [-1] 
expected returns: [[106.425804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  3. 29. 29.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0. 25.  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 158.03176879882812






Player: 1 
cards in hand: [ 0. 15.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  8.  0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 11 11  6 15  1  6  1  6  8  6 15 14  6
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 75.56038 ]
 [106.762474]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.4258041381836



action possibilites: [-1. 29.] 
expected returns: [[ 78.115776]
 [108.25144 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.4591293334961



action possibilites: [-1.] 
expected returns: [[114.847786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.25141143798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.64883 ]
 [138.47507 ]
 [ 90.08236 ]
 [119.88387 ]
 [ 79.0504  ]
 [ 60.84242 ]
 [132.89836 ]
 [137.81993 ]
 [126.573906]
 [181.29088 ]
 [150.37689 ]
 [ 78.39305 ]
 [113.852455]
 [107.993706]
 [ 84.33047 ]
 [107.53634 ]
 [119.395164]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  5.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.84778594970703



buy possibilites: [-1] 
expected returns: [[150.19751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 247.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 181.29092407226562






Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  9.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 15. 14. 11.  1. 11.  1.  1.  6.  3.  3.  6.  0.  6.  0.  6.  0.  8.
  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 87.62374]
 [153.06046]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.  3.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  4. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.197509765625



action possibilites: [-1] 
expected returns: [[102.72132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3.  3. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 151.23080444335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.07086 ]
 [115.15887 ]
 [ 97.39316 ]
 [ 40.557037]
 [114.072586]
 [103.75032 ]
 [ 85.984604]
 [ 95.36774 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  3. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.72132110595703



buy possibilites: [-1] 
expected returns: [[55.76144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3.  3. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 115.15886688232422






Player: 1 
cards in hand: [11. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.  0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 25. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.] 
cards in discard: [6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 25. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.] 
cards in discard: [6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 25. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25. 29.  1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[11.572812]
 [61.07873 ]
 [36.635674]
 [61.07873 ]
 [61.07873 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 25. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  3. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 14.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.76144027709961



action possibilites: [-1] 
expected returns: [[29.459923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25. 25. 29.  1.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 14.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.07870864868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 25.088303 ]
 [ 49.896473 ]
 [ 34.28805  ]
 [-15.060539 ]
 [ 45.22837  ]
 [ 49.08881  ]
 [ 39.889072 ]
 [ 59.52178  ]
 [ -0.5675254]
 [ 24.280636 ]
 [ 23.773289 ]
 [ 33.020653 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25. 25. 29.  1.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  5.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 14.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.459922790527344



buy possibilites: [-1] 
expected returns: [[36.813786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25. 25. 29.  1.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  3.  1. 25.  0.  0.  0.  3.  3. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  6. 14.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.521785736083984






Player: 1 
cards in hand: [ 3.  0.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 14.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 29.] 
adversary cards in discard: [25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  8.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 29.] 
adversary cards in discard: [25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 29.] 
adversary cards in discard: [25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[59.33092]
 [87.18084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.] 
cards in discard: [25. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11] -> size -> 29 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -33.38819122314453



action possibilites: [-1. 29.] 
expected returns: [[ 97.29963 ]
 [126.890434]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.] 
cards in discard: [25. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11] -> size -> 29 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.14266204833984



action possibilites: [-1. 25.] 
expected returns: [[100.22904]
 [157.16649]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.] 
cards in discard: [25. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  2. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11] -> size -> 29 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.89041900634766



action possibilites: [-1] 
expected returns: [[130.11584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 29.] 
cards in discard: [25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.16647338867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[120.33509 ]
 [146.35468 ]
 [105.31668 ]
 [130.10016 ]
 [ 96.33386 ]
 [ 82.696724]
 [141.32133 ]
 [145.69728 ]
 [135.8739  ]
 [185.90228 ]
 [157.47116 ]
 [ 96.08402 ]
 [124.92617 ]
 [119.84    ]
 [100.70914 ]
 [119.47872 ]
 [129.90686 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 29.] 
cards in discard: [25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  4.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.1158447265625



buy possibilites: [-1] 
expected returns: [[135.08434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 29.] 
cards in discard: [25. 29. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 8. 6. 3. 6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 327.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 185.90231323242188






Player: 1 
cards in hand: [6. 8. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3. 6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [29. 25.  0.  1.  1.] 
adversary cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3. 6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [29. 25.  0.  1.  1.] 
adversary cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[114.154655]
 [138.97937 ]
 [163.29268 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  1.  1.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  1. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3.  6. 15.  6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.08433532714844



action possibilites: [-1] 
expected returns: [[96.30654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  1.  0.  3.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3.  6. 15.  6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 163.29263305664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.89611 ]
 [113.73644 ]
 [ 73.28963 ]
 [ 98.12993 ]
 [ 63.562756]
 [109.06754 ]
 [112.9605  ]
 [103.72669 ]
 [148.73845 ]
 [123.40504 ]
 [ 62.7868  ]
 [ 92.96797 ]
 [ 88.120186]
 [ 68.127625]
 [ 87.62712 ]
 [ 96.9485  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  1.  0.  3.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  3.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3.  6. 15.  6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.3065414428711



buy possibilites: [-1] 
expected returns: [[108.63895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  1.  0.  3.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3.  6. 15.  6.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 148.73843383789062






Player: 1 
cards in hand: [ 1.  3.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 15.  6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 25.  3. 25. 25.] 
adversary cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25. 25. 29.  0.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 15.  6.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 25.  3. 25. 25.] 
adversary cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25. 25. 29.  0.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[100.54776]
 [146.129  ]
 [146.129  ]
 [146.129  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 25. 25.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25. 25. 29.  0.  1.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.63894653320312



action possibilites: [-1] 
expected returns: [[88.1282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 25. 29.  0.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25. 25. 29.  0.  1.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.12901306152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[81.74494]
 [88.80457]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25. 25. 29.  0.] 
cards in discard: [25. 29. 25. 29. 29. 25.  0.  1.  0. 29. 25. 25. 29.  0.  1.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 1. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.1281967163086






Player: 1 
cards in hand: [1. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  4.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 0.] 
cards in discard: [ 6.  0. 11. 11.  0.  8.  0.  6. 11. 14.  3.  0.  3.  6.  6.  6.  8.  6.
  3.  6.  6.  1.  3.  6. 15.  6. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  3.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[57.362568]
 [80.71086 ]
 [80.71086 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  3.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.80457305908203



action possibilites: [-1. 25.] 
expected returns: [[ 85.77065]
 [134.34648]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  3.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.36237335205078



action possibilites: [-1] 
expected returns: [[134.65912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  3.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.34649658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[125.11614 ]
 [153.5423  ]
 [135.95055 ]
 [148.25558 ]
 [153.12639 ]
 [142.29199 ]
 [165.09674 ]
 [ 97.792915]
 [124.700264]
 [124.36555 ]
 [136.1612  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  3.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.65911865234375



buy possibilites: [-1] 
expected returns: [[125.369316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 433 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 165.0967559814453






Player: 1 
cards in hand: [6. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  7.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 1. 0.] 
cards in discard: [11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  0. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 25.] 
expected returns: [[ 79.0765 ]
 [129.76437]
 [129.76437]
 [129.76437]
 [129.76437]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 25. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  6. 29.  6.  6.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.36931610107422



action possibilites: [-1] 
expected returns: [[76.892265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 25. 29. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  6. 29.  6.  6.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.76431274414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[69.1155 ]
 [76.84692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 25. 29. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  6. 29.  6.  6.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.89226531982422






Player: 1 
cards in hand: [ 1.  6. 29.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 29.  6.  6.] 
cards in discard: [11.  6.  3.  6.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 6.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  0.  3.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[34.152397]
 [63.801105]
 [63.801105]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  0.  3.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.8469009399414



action possibilites: [-1. 29.] 
expected returns: [[70.45635]
 [96.53523]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.66400146484375



action possibilites: [-1. 25.] 
expected returns: [[ 69.302025]
 [132.20102 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 87.38594818115234



action possibilites: [-1] 
expected returns: [[74.88741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.20101928710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 69.261345]
 [ 97.014725]
 [ 80.495476]
 [ 91.982155]
 [ 95.82557 ]
 [ 86.260704]
 [106.97104 ]
 [ 36.093624]
 [ 67.48859 ]
 [ 66.47876 ]
 [ 76.56202 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  2.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.88741302490234



buy possibilites: [-1] 
expected returns: [[116.0417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  0.  3.  3. 25.  0. 25. 25. 25. 29. 25.  1.  1.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 453 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 106.9710464477539






Player: 1 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 29. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[ 93.98252 ]
 [119.484184]
 [119.484184]
 [144.93433 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  1.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  6.  3. 14.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.04170227050781



action possibilites: [-1] 
expected returns: [[104.20652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  6.  3. 14.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.93435668945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 96.60372 ]
 [124.58468 ]
 [107.125786]
 [123.9273  ]
 [113.40521 ]
 [ 95.94634 ]
 [106.52356 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  1.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  6.  3. 14.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.2065200805664



buy possibilites: [-1] 
expected returns: [[92.306725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  1.  0. 25. 29.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  8.  6.  3. 14.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 124.58467864990234






Player: 1 
cards in hand: [ 0.  8.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  3. 14.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  1. 25. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [25. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [25. 25.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 89.56977]
 [140.00647]
 [140.00647]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8. 15.  3.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -144.94839477539062



action possibilites: [-1] 
expected returns: [[100.60741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 25.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8. 15.  3.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.00643920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 94.56379]
 [101.18557]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25. 25.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 11.  8. 15.  3.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.60740661621094






Player: 1 
cards in hand: [ 3. 11.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8. 15.  3.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  3.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  3.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[118.50459]
 [142.25021]
 [142.25021]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 6. 6. 0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.18551635742188



action possibilites: [-1. 29.] 
expected returns: [[ 97.80455]
 [126.25434]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 6. 6. 0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.67941284179688



action possibilites: [-1.] 
expected returns: [[93.30919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 6. 6. 0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 116.4134292602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 87.34332 ]
 [110.86709 ]
 [ 95.986115]
 [106.42338 ]
 [109.95827 ]
 [101.315445]
 [119.84408 ]
 [ 65.23536 ]
 [ 86.43449 ]
 [ 85.921776]
 [ 94.30671 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  1.  9. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 6. 6. 0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.30918884277344



buy possibilites: [-1] 
expected returns: [[86.934235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 6. 6. 0.] 
adversary cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 433 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.84406280517578






Player: 1 
cards in hand: [6. 1. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 6. 0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0. 25.  1.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 6. 0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0. 25.  1.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 6. 0.] 
cards in discard: [11.  6.  3.  6.  1.  0.  0. 10. 29.  1.  6.  6.  6.  0.  0. 11. 11.  0.
  0. 14.  0.  8.  6.  3. 15.  3. 11.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [29.  0. 25.  1.  0.] 
adversary cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[114.97625]
 [136.79932]
 [158.25641]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1.  0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.93423461914062



action possibilites: [-1] 
expected returns: [[90.70243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0. 25.  0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.25636291503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 87.000206]
 [105.36996 ]
 [ 93.74354 ]
 [ 69.09352 ]
 [101.81943 ]
 [105.31475 ]
 [ 97.84758 ]
 [132.79031 ]
 [ 68.83095 ]
 [ 90.24178 ]
 [ 86.737686]
 [ 72.545876]
 [ 86.52685 ]
 [ 94.46172 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0. 25.  0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  2.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.70243072509766



buy possibilites: [-1] 
expected returns: [[104.3808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0. 25.  0.] 
cards in discard: [ 1. 25. 29. 29.  1.  0. 25. 29. 29.  1. 25. 25.  0. 25. 25. 29.  3. 29.
 29. 29.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  1.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1. 11. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 535 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 132.790283203125






Player: 1 
cards in hand: [ 0.  1. 11. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 14.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  1.  0.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  6.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  6.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 22. 30. 28. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  6.] 
cards in discard: [14.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 94.545616]
 [148.38939 ]
 [148.38939 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 25.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.38079833984375



action possibilites: [-1] 
expected returns: [[140.95444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.38937377929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[134.32053]
 [161.35176]
 [144.2973 ]
 [160.35368]
 [150.37694]
 [133.43031]
 [142.87083]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 22. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.95443725585938



buy possibilites: [-1] 
expected returns: [[103.46429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  3. 25.  3.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 161.35174560546875






Player: 1 
cards in hand: [ 6. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  6.] 
cards in discard: [14.  3. 11.  0.  1. 14.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 27. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 25.  0.  1. 29.] 
adversary cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [14.  3. 11.  0.  1. 14.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 25.  0.  1. 29.] 
adversary cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [14.  3. 11.  0.  1. 14.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29. 25.  0.  1. 29.] 
adversary cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[ 87.988304]
 [115.9546  ]
 [144.54105 ]
 [115.9546  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  1. 29.] 
cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29.  6.  6.  1.  0.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.  3. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.46428680419922



action possibilites: [-1] 
expected returns: [[108.74444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1. 29.  0.  0.] 
cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29.  6.  6.  1.  0.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.  3. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.54100036621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.8142  ]
 [129.57834 ]
 [114.00326 ]
 [ 79.56014 ]
 [124.9201  ]
 [128.77174 ]
 [119.5827  ]
 [164.45274 ]
 [ 78.83591 ]
 [108.83718 ]
 [104.007614]
 [ 84.123405]
 [103.499756]
 [112.83689 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1. 29.  0.  0.] 
cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  1.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29.  6.  6.  1.  0.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.  3. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.74443817138672



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 5 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  0.  1. 29.  0.  0.] 
cards in discard: [ 1. 25.  0.  1. 25.  3. 25.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 25 29 29 25  1 29 25 25 25  1
 29 25 25 29 29  1 29 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 26. 30.  8.  0. 10.  6.  8.  0.  0.  8. 10.  9. 10.  8.] 
adversary cards in hand: [29.  6.  6.  1.  0.] 
adversary cards in discard: [14.  3. 11.  0.  1. 14.  6.  3. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 11 11  6  1  6  1  6  8  6 15 14  6  3  6  0
  8  6  0  6 11  6  6 29 11 10  0  1 14  3  3] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     210       0       0      20       0       0
       0       0       0       0       0     125       0] 
sum of rewards: 3000350 

action type: buy - action 25.0
Learning step: 120007.4140625
desired expected reward: 120171.8671875



