 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.919567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action -1
Learning step: -120003.2109375
desired expected reward: -120047.84375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.066591 ]
 [21.052837 ]
 [16.85635  ]
 [-6.8214226]
 [25.105629 ]
 [18.312183 ]
 [14.116785 ]
 [15.570969 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.000276565551758



buy possibilites: [-1] 
expected returns: [[17.605501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 25.105621337890625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.262415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.605501174926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.878759  ]
 [26.019508  ]
 [22.197306  ]
 [ 0.80731153]
 [24.019995  ]
 [29.774057  ]
 [23.447458  ]
 [29.891401  ]
 [ 7.793676  ]
 [19.62526   ]
 [17.919905  ]
 [21.269196  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.848052978515625



buy possibilites: [-1] 
expected returns: [[26.892864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.891401290893555






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.111567]
 [27.736942]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.892864227294922



action possibilites: [-1] 
expected returns: [[25.029627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.959856033325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.048256]
 [29.277697]
 [25.496332]
 [ 2.380012]
 [33.143745]
 [26.693192]
 [22.911833]
 [25.573828]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.029626846313477



buy possibilites: [-1] 
expected returns: [[17.506422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 33.14374542236328






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[48.408012]
 [58.69943 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.50642204284668



action possibilites: [-1.] 
expected returns: [[25.682226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.469329833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.216362 ]
 [30.864756 ]
 [27.187174 ]
 [11.838329 ]
 [ 8.933817 ]
 [28.923605 ]
 [34.489304 ]
 [28.374243 ]
 [46.10267  ]
 [34.598953 ]
 [14.3167515]
 [23.618347 ]
 [24.696669 ]
 [14.834497 ]
 [23.06898  ]
 [26.28417  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.682226181030273



buy possibilites: [-1] 
expected returns: [[27.937178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 205 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 46.10266876220703






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[27.92029 ]
 [25.780369]
 [50.0447  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.937177658081055



action possibilites: [-1] 
expected returns: [[13.070269]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.13746643066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.123583 ]
 [22.067627 ]
 [17.846783 ]
 [-5.4546766]
 [26.14691  ]
 [19.31501  ]
 [15.132824 ]
 [16.551113 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.070268630981445



buy possibilites: [-1] 
expected returns: [[43.67454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0. 11.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.14690589904785






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [11.  3.  3.  0.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [11.  3.  3.  0.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [11.  3.  3.  0.  1.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [11. 25. 10.  0.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[29.47883 ]
 [39.393906]
 [39.006863]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 11.] 
cards in discard: [11. 25. 10.  0.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.67454147338867



action possibilites: [-1. 11.] 
expected returns: [[38.88916 ]
 [46.516823]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [11. 25. 10.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.15556716918945



action possibilites: [-1] 
expected returns: [[51.830208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  3.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.107826232910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.398052]
 [52.794823]
 [49.245743]
 [32.4993  ]
 [29.0399  ]
 [50.999428]
 [56.349216]
 [50.50153 ]
 [67.49965 ]
 [56.600883]
 [36.053677]
 [45.94833 ]
 [46.952442]
 [36.551582]
 [45.45045 ]
 [49.28566 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  3.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.83020782470703



buy possibilites: [-1] 
expected returns: [[57.73182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25. 10.  0.  0.  3.  0. 11. 10. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.49964904785156






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6. 10.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[35.58571 ]
 [56.266457]
 [43.77029 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.73181915283203



action possibilites: [-1] 
expected returns: [[26.717909]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.893165588378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.022177]
 [32.38352 ]
 [28.806108]
 [ 8.584436]
 [35.857452]
 [30.073519]
 [26.496107]
 [27.792933]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.71790885925293



buy possibilites: [-1] 
expected returns: [[40.246483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 35.85744094848633






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25. 11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[46.00077 ]
 [44.108856]
 [44.108856]
 [54.43505 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 29.] 
cards in discard: [11. 25. 11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.246482849121094



action possibilites: [-1. 10. 10.] 
expected returns: [[58.159515]
 [56.64219 ]
 [56.64219 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [11. 25. 11.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.97299575805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.68478 ]
 [59.209793]
 [55.576557]
 [35.06743 ]
 [57.403584]
 [62.998985]
 [56.8428  ]
 [63.276276]
 [42.03449 ]
 [53.209568]
 [51.54087 ]
 [55.52832 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [11. 25. 11.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.15949630737305



buy possibilites: [-1] 
expected returns: [[42.950123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [11. 25. 11.  0.  3.  3.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 63.276268005371094






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [11. 25. 11.  0.  3.  3.  0.  0. 29. 29. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [11. 25. 11.  0.  3.  3.  0.  0. 29. 29. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 8. 10.  3.  0.  0.  0.  3.  6. 11.  0.  0.  3.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 25.  3.] 
adversary cards in discard: [11. 25. 11.  0.  3.  3.  0.  0. 29. 29. 10.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 11. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[82.75342]
 [88.74129]
 [88.74129]
 [99.11822]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 25.  3.] 
cards in discard: [11. 25. 11.  0.  3.  3.  0.  0. 29. 29. 10.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.95012283325195



action possibilites: [-1] 
expected returns: [[25.852287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.52812194824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.786816 ]
 [23.567362 ]
 [ 7.4168735]
 [24.619265 ]
 [22.39855  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  9.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.85228729248047



buy possibilites: [-1] 
expected returns: [[43.20839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3. 29.  0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 24.619264602661133






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 92.17307 ]
 [113.34503 ]
 [ 91.225555]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 10.  3.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  0.  0.] 
adversary cards in discard: [6. 0. 6. 0. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.20838928222656



action possibilites: [-1] 
expected returns: [[45.989494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  0.  0.] 
adversary cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.00828552246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.05841 ]
 [48.990593]
 [44.928932]
 [21.562073]
 [46.847202]
 [53.512306]
 [46.30238 ]
 [53.925804]
 [29.704733]
 [42.240753]
 [40.6369  ]
 [46.58149 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  0.  0.] 
adversary cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.98949432373047



buy possibilites: [-1] 
expected returns: [[-8.775366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  0.  0.] 
adversary cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.92578125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  0.  0.] 
cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29. 11.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29. 11.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [6. 0. 6. 0. 3. 1. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29. 11.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 6.] 
cards in discard: [6. 0. 6. 0. 3. 1. 6. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 29. 11.] 
adversary cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[ 98.316986]
 [103.08123 ]
 [103.34885 ]
 [103.08123 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29. 11.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.775365829467773



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[54.56093 ]
 [59.72151 ]
 [59.72151 ]
 [50.282883]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 10.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.34883117675781



action possibilites: [-1] 
expected returns: [[34.702007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.06575012207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.693022]
 [31.251081]
 [16.907434]
 [31.880941]
 [33.177467]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [ 8. 25.  0. 11. 11.  3. 29.  0. 29. 25.  0.  0. 10.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.70200729370117






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  0.] 
cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  0.  3.  1.  6.  8. 10.  3.  1.  0.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
expected returns: [[39.47486 ]
 [39.454544]
 [36.188286]
 [45.572792]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.177459716796875



action possibilites: [-1.  8. 10.] 
expected returns: [[41.14892 ]
 [41.578037]
 [38.906494]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 11 10 25 11 29  8 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.37413024902344



action possibilites: [-1] 
expected returns: [[4.146113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 48.06410217285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.26082945]
 [ 4.3767877 ]
 [-9.780218  ]
 [ 4.9550424 ]
 [ 5.1345057 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 6. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.14611291885376






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 6. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 11.  0.] 
adversary cards in discard: [29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 11. 11.  0.] 
adversary cards in discard: [29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[36.061775]
 [41.72338 ]
 [41.577293]
 [41.577293]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 11.  0.] 
cards in discard: [29.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10. 29.  3.  0.] 
adversary cards in discard: [8. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.134511470794678



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[48.34211 ]
 [52.58059 ]
 [52.58059 ]
 [46.005215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0. 10.] 
cards in discard: [29.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 10. 29.  3.  0.] 
adversary cards in discard: [8. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.85615158081055



action possibilites: [-1] 
expected returns: [[33.10947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [29.  8.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10. 29.  3.  0.] 
adversary cards in discard: [8. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.87794494628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.386473]
 [36.188103]
 [19.674585]
 [37.119663]
 [35.414234]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [29.  8.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  6.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10. 29.  3.  0.] 
adversary cards in discard: [8. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.10947036743164



buy possibilites: [-1] 
expected returns: [[35.169456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [29.  8.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6. 10. 29.  3.  0.] 
adversary cards in discard: [8. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.119667053222656






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 6. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 29.  3.  0.] 
cards in discard: [8. 6. 8. 3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  1.] 
cards in discard: [8. 6. 8. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [8. 6. 8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [8. 6. 8. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 0.] 
cards in discard: [8. 6. 8. 3. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[26.129251]
 [31.252005]
 [22.898539]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  0.] 
cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.169456481933594



action possibilites: [-1] 
expected returns: [[17.519907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.199928283691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 8.986645]
 [15.608328]
 [-6.780426]
 [16.87206 ]
 [16.333574]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  5.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.519906997680664



buy possibilites: [-1] 
expected returns: [[-1.1826248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 16.8720645904541






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 27. 30.  8.  6. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 6 
card supply: [29. 28. 30. 27. 30.  8.  6. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 25.  0. 29.  0.] 
adversary cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [25. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[32.764687]
 [46.656513]
 [46.656513]
 [38.70606 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.  0.] 
cards in discard: [29.  8.  0. 10.  8. 29. 11.  3. 11.  0. 10. 10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  6. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.1826248168945312



action possibilites: [-1] 
expected returns: [[31.827692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.656494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.525822]
 [26.454735]
 [10.831427]
 [26.963028]
 [28.227736]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  3.  0.  6.] 
adversary cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.82769203186035






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11.  8.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  0.  6.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  1 11  6 10  8  6 29  6  6  8  8
  3  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 8.  6.  8.  3.  3.  3. 29. 10.  6.  3.  0.  1.  0.  0.  0.  1.  0.  0.
  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 10.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[27.627085]
 [24.867847]
 [24.867847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 1. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.227724075317383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.87604 ]
 [27.557045]
 [24.405687]
 [ 5.963533]
 [30.879251]
 [25.349604]
 [22.198252]
 [24.957474]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  5.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 1. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.28480339050293



buy possibilites: [-1] 
expected returns: [[67.30109]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 1. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.87925910949707






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 6. 1. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 6. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  3.  8. 10.  8.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 6. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  3.  8. 10.  8.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11] -> size -> 25 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.  8.] 
expected returns: [[40.015354]
 [46.42726 ]
 [39.442528]
 [35.430088]
 [39.442528]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 10.  8.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.30108642578125



action possibilites: [-1] 
expected returns: [[2.1502652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  8.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.43970489501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.1707428]
 [-15.530289 ]
 [  2.2607646]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  8.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.1502652168273926






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [3. 6. 1. 6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [3. 6. 1. 6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3. 6. 1. 6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  8.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[ 9.4830265]
 [ 7.130071 ]
 [15.354456 ]
 [10.0511055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  8.  0.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.260779857635498



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[4.5569587]
 [1.8491359]
 [4.67956  ]
 [9.751162 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0. 11.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 15.354471206665039



action possibilites: [-1] 
expected returns: [[6.225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.581596374511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 2.2167768]
 [ 7.1927066]
 [-9.553444 ]
 [ 8.147152 ]
 [ 6.614139 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  4.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.224999904632568



buy possibilites: [-1] 
expected returns: [[16.995672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.] 
cards in discard: [25. 25.  0. 29.  0. 11. 11. 11.  0.  0. 10.  0. 10. 10. 11.  3.  8. 10.
  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 8.14715576171875






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 6. 1. 6. 3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29.] 
expected returns: [[57.49488 ]
 [60.262253]
 [60.262253]
 [60.262253]
 [60.61998 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 11. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  1. 10.  0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.99567222595215



action possibilites: [-1. 11. 11. 11.  8.] 
expected returns: [[30.007338]
 [33.506138]
 [33.506138]
 [33.506138]
 [28.631693]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  1. 10.  0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.321624755859375



action possibilites: [-1] 
expected returns: [[20.359179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  1. 10.  0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.06515884399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.00848 ]
 [20.809755]
 [ 5.619166]
 [21.449387]
 [21.730114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  1. 10.  0.] 
adversary cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.35917854309082






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 10.  0.] 
cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10.  0.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1. 10.  0.] 
cards in discard: [3. 6. 1. 6. 3. 8. 0. 0. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10.  0.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1. 10.  0.] 
cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 10.  0.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[16.95463 ]
 [25.36521 ]
 [16.234499]
 [16.234499]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 10.  0.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  8.  3. 29.  3.] 
adversary cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.73011589050293



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[15.046051]
 [15.158937]
 [15.158937]
 [29.880663]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 25.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  8.  3. 29.  3.] 
adversary cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.50984764099121



action possibilites: [-1] 
expected returns: [[38.860626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0. 11.  3.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  8.  3. 29.  3.] 
adversary cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.88067054748535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.262968]
 [40.73297 ]
 [36.93413 ]
 [16.00033 ]
 [44.926075]
 [38.028145]
 [34.22931 ]
 [39.093197]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 11.  3.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  8.  3. 29.  3.] 
adversary cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.860626220703125



buy possibilites: [-1] 
expected returns: [[34.433796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0. 11.  3.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  8.  3. 29.  3.] 
adversary cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 44.92610168457031






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 29.  3.] 
cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1  6 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.] 
cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.] 
cards in discard: [ 3.  6.  1.  6.  3.  8.  0.  0.  8.  6. 29.  0.  6.  1. 10.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[38.0186  ]
 [34.5561  ]
 [43.261868]
 [52.759243]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 25.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  4. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.43379592895508



action possibilites: [-1] 
expected returns: [[28.06037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3.  0.  8.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.759239196777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.68694 ]
 [28.461058]
 [12.127003]
 [29.389631]
 [27.95664 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3.  0.  8.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  3.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.06036949157715



buy possibilites: [-1] 
expected returns: [[0.19340229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3.  0.  8.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  3.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 29.38962745666504






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.  3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8. 11.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8. 25.
 10.  0. 29.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.  3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8. 11.] 
adversary cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8. 25.
 10.  0. 29.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8] -> size -> 31 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 11.] 
expected returns: [[17.046213]
 [15.96755 ]
 [13.867308]
 [15.96755 ]
 [20.316916]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8. 11.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8. 25.
 10.  0. 29.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [6. 6. 8. 0. 1.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.19340229034423828



action possibilites: [-1] 
expected returns: [[30.65436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8. 25.
 10.  0. 29.  3.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 6. 8. 0. 1.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.47461700439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.079134]
 [14.408325]
 [31.425737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  8.] 
cards in discard: [10. 29. 11.  0. 11. 11.  8. 11. 29. 25.  0. 10. 10.  0. 11.  3.  8. 25.
 10.  0. 29.  3.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [6. 6. 8. 0. 1.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.654359817504883






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 1.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 1.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0. 1.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 3.  8. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 10.] 
expected returns: [[15.3933735]
 [12.033907 ]
 [11.053415 ]
 [11.053415 ]
 [11.053415 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 8.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.425729751586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.577887 ]
 [ 1.7539678]
 [14.840509 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [1. 0. 3. 6. 8.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.031469345092773



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 8.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 8.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 8.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[-4.572483 ]
 [ 1.3038793]
 [-3.023265 ]
 [ 1.3033319]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11.  0.  0.] 
cards in discard: [ 3.  8. 10. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.84050178527832



action possibilites: [-1. 11.] 
expected returns: [[1.8591056]
 [7.6923804]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.2034733295440674



action possibilites: [-1] 
expected returns: [[-6.393078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.287576675415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[-11.070195  ]
 [ -3.2687533 ]
 [ -6.157981  ]
 [-22.341394  ]
 [ -4.892274  ]
 [ -0.39114666]
 [ -5.30324   ]
 [ -0.33685946]
 [-17.207676  ]
 [ -9.403895  ]
 [ -6.046361  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.393077850341797



buy possibilites: [-1] 
expected returns: [[11.475161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -0.3368687629699707






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 6.  0.  8. 10.  3.  3.  0.  6.  6.  8.  0.  1.  3.  1.  0.  3.  6.  8.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[13.613132]
 [12.313372]
 [ 9.05809 ]
 [12.313372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.475160598754883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 7.3515763]
 [12.653788 ]
 [-3.472345 ]
 [13.245689 ]
 [15.369175 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10. 11.  0.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.613142013549805



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  3.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.] 
expected returns: [[44.170563]
 [41.94936 ]
 [50.631477]
 [50.631477]
 [45.13076 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3.  8.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.369186401367188



action possibilites: [-1] 
expected returns: [[69.36918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  8.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.808433532714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.692696]
 [53.617455]
 [69.135254]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  8.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.36917877197266






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 10. 29. 10.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 10. 29. 10.] 
adversary cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 10. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29. 10.] 
expected returns: [[21.164036]
 [23.695585]
 [20.640358]
 [20.640358]
 [26.033453]
 [20.640358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 29. 10.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.13525390625



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[25.339369]
 [21.690748]
 [21.690748]
 [21.690748]
 [29.155539]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 29.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.4070987701416



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[37.511986]
 [36.697807]
 [36.697807]
 [43.622017]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.16166877746582



action possibilites: [-1] 
expected returns: [[46.0606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.  8. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.149993896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.648865]
 [46.026314]
 [28.158957]
 [46.824486]
 [46.130966]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.  8. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  2.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.06060028076172



buy possibilites: [-1] 
expected returns: [[30.725954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 3.  8. 10. 10. 10.  8. 15. 29. 29. 11.  0.  0.  0.  0. 11. 10. 11.  0.
 15. 11. 10. 11.  3.  8.  8. 10. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 46.824485778808594






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  8. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 26. 30.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  8. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 28. 30. 26. 30.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15.  8. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [15.  8. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 25. 25.] 
expected returns: [[-21.186205 ]
 [-25.64501  ]
 [-20.946774 ]
 [ -4.1345625]
 [ -4.1345625]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  3. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.725954055786133



action possibilites: [-1] 
expected returns: [[-5.169355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 25.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.134566307067871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.487154 ]
 [ -5.639763 ]
 [-18.03157  ]
 [ -5.2022405]
 [ -5.3597803]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 25.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  1.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.1693549156188965



buy possibilites: [-1] 
expected returns: [[7.5566077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 25.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -5.202251434326172






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 3.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  3  1 10  8  6 29  6  6  8  8  3  0  6  0 29  6  0  6
  0  3  0 11  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  8. 10. 15.  8.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0
 11  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  8. 10. 15.  8.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0
 11  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  8. 10. 15.  8.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10.  8. 10. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 15.  8.] 
expected returns: [[-0.75960445]
 [-5.0734367 ]
 [-2.2035398 ]
 [-5.0734367 ]
 [-5.8268523 ]
 [-2.2035398 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 15.  8.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [1. 3. 8. 8. 6.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.] 
adversary owned cards: [ 0  3  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0
 11  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.556607723236084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.245771  ]
 [-19.486874  ]
 [ -0.60404634]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10. 15.  8.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [1. 3. 8. 8. 6.] 
adversary cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.] 
adversary owned cards: [ 0  3  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0
 11  0  6] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.7596139907836914



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [1. 3. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 8. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0
 11  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  0. 10. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  0. 10. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  0. 10. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 6.] 
cards in discard: [29. 11. 29.  0.  3.  0. 10.  3.  6.  6.  3.  6.  0.  0.  3.  0.  0.  0.
  6.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 10.  0. 10. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 10.] 
expected returns: [[ 3.3689857]
 [ 2.181819 ]
 [-0.3588767]
 [-0.3588767]
 [-0.3588767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 10. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.6040515899658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -2.574449 ]
 [-11.877272 ]
 [  3.4589844]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 10. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.3689818382263184



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  1.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-7.984051]
 [-7.387232]
 [-3.704288]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  3. 29.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.] 
adversary owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0 15] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.4589858055114746



action possibilites: [-1. 15.] 
expected returns: [[-3.0273435]
 [-5.4134536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.] 
adversary owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0 15] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.795269012451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -7.2839026]
 [-15.807091 ]
 [ -3.3895266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.] 
adversary owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0 15] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.0273382663726807






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [15.  6.  0.  0. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11
  0  6  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8. 29. 11. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [15.  6.  0.  0. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8. 29. 11. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [15.  6.  0.  0. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8. 29. 11. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11.  8. 29. 11. 10.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  8. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 11. 10.] 
expected returns: [[25.318773]
 [28.30974 ]
 [24.219007]
 [28.422998]
 [28.30974 ]
 [22.188637]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 11. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.389526605606079



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[43.911823]
 [47.207726]
 [47.207726]
 [37.635674]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.919763565063477



action possibilites: [-1] 
expected returns: [[33.93563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 82 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 43.33154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.924059]
 [21.751646]
 [33.535427]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.935630798339844






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [1. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 11. 10. 11.] 
adversary cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11.] 
expected returns: [[18.482195]
 [21.899275]
 [21.607813]
 [14.360369]
 [21.607813]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 11.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  3.  8.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.53544616699219



action possibilites: [-1. 11. 11.] 
expected returns: [[ 4.9336047]
 [10.070627 ]
 [10.070627 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  3.  8.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.61037826538086



action possibilites: [-1] 
expected returns: [[19.050276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10. 11. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  3.  8.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 7.023016452789307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.993036 ]
 [17.112366 ]
 [ 1.6504846]
 [19.050276 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [ 8. 25. 15.  8. 25.  0.  0. 11. 10.  8. 10. 15.  8.  8. 10.  0. 10. 10.
  8.  0. 29.  3.  3. 15.  8. 10.  1. 29. 11. 11. 10. 11. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29.  3.  0.  3.  8.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.050275802612305






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  8.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  8.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  8.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  8.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[-0.9413748]
 [-4.216048 ]
 [-4.216048 ]
 [ 1.5600781]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.050275802612305



action possibilites: [-1.  8.  8.] 
expected returns: [[19.798166]
 [16.659973]
 [16.659973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1.] 
cards in discard: [ 0. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.107858419418335





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[1.0184736e+01]
 [1.8117586e+01]
 [1.5440842e+01]
 [1.2306690e-02]
 [2.1524559e+01]
 [1.9965868e+01]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1.] 
cards in discard: [ 0. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  2.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.798147201538086



buy possibilites: [-1] 
expected returns: [[-8.499365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1.] 
cards in discard: [ 0. 10. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.52455711364746






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10.  6.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [15.  6.  0.  0. 11.  1.  3.  8.  6.  0.  0. 14.  1.  0.  6.  0.  3. 29.
  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[-0.6661434]
 [ 1.6773238]
 [ 6.869471 ]
 [16.619486 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 25.  0.  0.] 
cards in discard: [ 0. 10. 11. 29.  8.  8.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  2. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.499364852905273



action possibilites: [-1] 
expected returns: [[-11.086552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  8. 29.] 
cards in discard: [ 0. 10. 11. 29.  8.  8.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  6. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.619497299194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-18.694338]
 [-13.837509]
 [-29.047642]
 [-12.231508]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  8. 29.] 
cards in discard: [ 0. 10. 11. 29.  8.  8.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  6. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.086551666259766






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6. 29.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [6. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [6. 6. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6. 6. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 6. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 6. 0. 0. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  8.  0. 10.] 
adversary cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[36.035065]
 [49.346382]
 [36.12349 ]
 [33.663544]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  0. 10.] 
cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  1. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  0.  3.  8.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  3. 29. 29. 15.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -12.231513977050781



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 7 
Witch: 2 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  8.  0. 10.  3. 29.] 
cards in discard: [ 0. 10. 11. 29.  8.  8.  1. 25.  8. 29.  0.  0.  8. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 11 25 11 10 25 11 29  8 29 10 10  8 10  8
 11 10 10  8 10 11  8 10 15 29 15 15  8  8  1  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  0. 10.  1.  0.  8.  4.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 14.  0.  3.  8.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  3. 29. 29. 15.  6.] 
adversary owned cards: [ 0  3  1  3  1 10  8 29  6  8  8  3  0  6  0 29  6  0  6  0  3  0 11  0
  6  0 15  3 14  6  3  6] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000075 

action type: take_action - action 25.0
Learning step: 120001.0234375
desired expected reward: 120050.3671875



