 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.083755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0       20        0
        0        0        0        0        0     -300        0        0] 
sum of rewards: -3000495 

action type: buy - action 6.0
Learning step: -120018.2265625
desired expected reward: -120057.359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 96.76    ]
 [107.49163 ]
 [100.97641 ]
 [ 79.2379  ]
 [105.89911 ]
 [109.09325 ]
 [104.863174]
 [113.35348 ]
 [ 87.22273 ]
 [ 98.39609 ]
 [ 97.705154]
 [101.68247 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.13475799560547



buy possibilites: [-1] 
expected returns: [[91.762436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.35348510742188






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.879196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.76243591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[86.45265 ]
 [96.52445 ]
 [90.42598 ]
 [70.413315]
 [98.03878 ]
 [94.071075]
 [87.977585]
 [90.659096]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.32536315917969



buy possibilites: [-1] 
expected returns: [[102.6014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 98.03877258300781






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[76.022964]
 [86.62795 ]
 [82.68969 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.60140228271484



action possibilites: [-1. 11.] 
expected returns: [[79.20881]
 [85.68245]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.396240234375



action possibilites: [-1] 
expected returns: [[106.05874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.03900909423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.6137  ]
 [111.45699 ]
 [105.01712 ]
 [ 83.73219 ]
 [109.7129  ]
 [113.17954 ]
 [108.776146]
 [117.219864]
 [ 91.2018  ]
 [102.33627 ]
 [101.67946 ]
 [106.40396 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.0587387084961



buy possibilites: [-1] 
expected returns: [[109.89653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.21986389160156






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.84349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.89653015136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.054565]
 [107.2501  ]
 [102.41093 ]
 [ 85.57723 ]
 [108.71571 ]
 [105.24013 ]
 [100.40097 ]
 [103.47593 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.29423522949219



buy possibilites: [-1] 
expected returns: [[103.80568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.7156982421875






Player: 1 
cards in hand: [1. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[119.94889]
 [130.64772]
 [115.70009]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.80567932128906



action possibilites: [-1. 10. 29.] 
expected returns: [[101.62969 ]
 [ 95.135574]
 [109.82526 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.47683715820312



action possibilites: [-1. 10.] 
expected returns: [[117.51373]
 [111.49042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.82524871826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[109.7881  ]
 [120.83407 ]
 [114.32839 ]
 [ 98.56101 ]
 [ 92.42818 ]
 [118.99217 ]
 [122.90863 ]
 [118.031364]
 [137.22798 ]
 [126.66397 ]
 [100.6087  ]
 [112.13979 ]
 [111.71206 ]
 [101.51987 ]
 [111.234726]
 [117.70196 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.51371765136719



buy possibilites: [-1] 
expected returns: [[113.70913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 137.22796630859375






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [25. 29. 29.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [25. 29. 29.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [25. 29. 29.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[104.045425]
 [109.861664]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [25. 29. 29.  3. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.7091293334961



action possibilites: [-1] 
expected returns: [[129.19827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [25. 29. 29.  3. 10.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 115.25245666503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.62694]
 [129.30267]
 [110.26407]
 [132.61014]
 [129.63644]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [25. 29. 29.  3. 10.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.19827270507812



buy possibilites: [-1] 
expected returns: [[125.32175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [25. 29. 29.  3. 10.  0.  0.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 132.610107421875






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 8. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 8. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  8.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[108.37663]
 [114.58743]
 [114.58743]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.32174682617188



action possibilites: [-1] 
expected returns: [[122.64746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 121.79180908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[114.46308 ]
 [123.59703 ]
 [118.45873 ]
 [100.010994]
 [125.32144 ]
 [121.32581 ]
 [116.18751 ]
 [121.83725 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.6474609375



buy possibilites: [-1] 
expected returns: [[121.15697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 125.32144165039062






Player: 1 
cards in hand: [11.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  6.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[125.272766]
 [134.50851 ]
 [146.789   ]
 [134.50851 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 29.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.15696716308594



action possibilites: [-1] 
expected returns: [[111.46594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.  0.  8.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  5.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 11.  3.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 147.2562713623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.43956]
 [110.98402]
 [ 89.29288]
 [114.9194 ]
 [113.16678]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29.  0.  8.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  5.  8.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 11.  3.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.4659423828125



buy possibilites: [-1] 
expected returns: [[133.31897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29.  0.  8.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11. 11.  3.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 114.91940307617188






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 11.  3.  8.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  8. 25.  3.  0. 29. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 11.  3.  8.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  8. 25.  3.  0. 29. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11. 11.  3.  8.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.  8. 25.  3.  0. 29. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[113.65273]
 [107.39429]
 [107.39429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  8. 25.  3.  0. 29. 29.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.3189697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.250626]
 [ 85.017166]
 [113.98262 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.  8. 25.  3.  0. 29. 29.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.11529541015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[128.32114 ]
 [131.3835  ]
 [126.906555]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.98261260986328



action possibilites: [-1] 
expected returns: [[133.002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.12640380859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.77991 ]
 [131.65616 ]
 [114.638306]
 [134.19978 ]
 [135.86673 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29 10] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.0019989013672






Player: 1 
cards in hand: [ 0.  0.  6.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  8. 11.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11  6 11 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10. 29.  0.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10. 29.  0.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  7.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10. 29.  0.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 10. 29.  0.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10. 29. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 29.] 
expected returns: [[151.2475 ]
 [144.87895]
 [161.60701]
 [144.87895]
 [161.60701]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 29.  0.] 
cards in discard: [10. 11.  0.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 135.86672973632812



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[155.99025]
 [148.70654]
 [148.70654]
 [165.79172]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0.  3.] 
cards in discard: [10. 11.  0.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 161.02734375



action possibilites: [-1. 10. 10.] 
expected returns: [[155.8451 ]
 [146.51369]
 [146.51369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [10. 11.  0.  3.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 165.79171752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[145.84837]
 [160.2029 ]
 [151.92249]
 [121.12074]
 [157.78928]
 [162.7298 ]
 [156.65811]
 [167.8818 ]
 [133.61693]
 [148.3777 ]
 [147.67264]
 [156.70837]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [10. 11.  0.  3.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 155.84506225585938



buy possibilites: [-1] 
expected returns: [[144.70227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  0.] 
cards in discard: [10. 11.  0.  3.  8.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 167.88182067871094






Player: 1 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  6.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 10. 11.  0.  0.  0.  3.  8.  8.  0.  0. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 11. 10.  0.  8.] 
adversary cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 11. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.  8.] 
expected returns: [[146.86731]
 [150.97589]
 [150.97589]
 [139.71382]
 [146.03503]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.  8.] 
cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.7022705078125



action possibilites: [-1] 
expected returns: [[179.10773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8.] 
cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 157.8458251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[169.93666]
 [155.41507]
 [179.01082]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  8.] 
cards in discard: [10. 11.  0.  3.  8.  0. 29. 29. 29. 10. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 179.10772705078125






Player: 1 
cards in hand: [ 0. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[118.85669]
 [133.55513]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  9. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 179.0108184814453



action possibilites: [-1] 
expected returns: [[122.15958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.9447021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[116.98604 ]
 [126.817245]
 [121.27082 ]
 [101.75612 ]
 [128.79654 ]
 [124.32399 ]
 [118.88731 ]
 [125.46466 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  8. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.15957641601562



buy possibilites: [-1] 
expected returns: [[131.28937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 128.7965545654297






Player: 1 
cards in hand: [ 0.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  8. 10. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  8. 10. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  8. 10. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11.] 
expected returns: [[120.944405]
 [114.19722 ]
 [120.570404]
 [114.19722 ]
 [125.75267 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10. 11.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.28936767578125



action possibilites: [-1] 
expected returns: [[117.89644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.54840087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.04919]
 [ 91.74315]
 [119.7032 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.89643859863281






Player: 1 
cards in hand: [ 0.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  5.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [ 1.  0. 11.  0.  8.  0.  6.  0.  0.  0. 11.  3.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11. 11.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[162.43106]
 [169.08008]
 [155.4172 ]
 [165.54889]
 [165.54889]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11. 11.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.70319366455078



action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[164.9132 ]
 [161.04454]
 [170.24765]
 [170.24765]
 [173.81964]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 169.080078125



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[177.34238]
 [174.79619]
 [183.12724]
 [183.12724]
 [174.79619]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 173.81959533691406



action possibilites: [-1] 
expected returns: [[202.4502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 188.1759033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[196.78995]
 [207.52698]
 [201.18394]
 [180.6644 ]
 [209.2821 ]
 [204.88814]
 [198.54514]
 [202.82477]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 202.4501953125



buy possibilites: [-1] 
expected returns: [[190.93106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  2.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 209.28211975097656






Player: 1 
cards in hand: [ 0.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  2.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11. 29. 29.
 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11. 29. 29.
 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11. 29. 29.
 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 29.] 
adversary cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11. 29. 29.
 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
expected returns: [[124.596176]
 [119.71219 ]
 [114.38247 ]
 [128.614   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 29.] 
cards in discard: [11. 25.  3.  3.  0.  0.  3.  0. 10. 11. 10.  0.  8. 10. 10. 11. 29. 29.
 11.  0. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 190.93106079101562



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[152.9268 ]
 [151.09149]
 [144.66368]
 [155.80931]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.61398315429688



action possibilites: [-1] 
expected returns: [[134.60506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 161.4805450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[125.873795]
 [135.7097  ]
 [130.2049  ]
 [110.87487 ]
 [137.74243 ]
 [133.23985 ]
 [127.82208 ]
 [134.8845  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  2.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.6050567626953



buy possibilites: [-1] 
expected returns: [[108.06169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 137.742431640625






Player: 1 
cards in hand: [ 8.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 11.  0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0. 29.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[92.25532 ]
 [94.81236 ]
 [94.81236 ]
 [97.746445]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0. 29.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.06169128417969



action possibilites: [-1. 11. 11.] 
expected returns: [[102.52218]
 [105.07822]
 [105.07822]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  3.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.74645233154297



action possibilites: [-1] 
expected returns: [[128.84973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.7448959350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.23718 ]
 [123.907364]
 [102.78265 ]
 [127.25487 ]
 [128.4601  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.8497314453125






Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [25.  0. 29. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.  8.] 
expected returns: [[152.8386 ]
 [167.81296]
 [159.05278]
 [147.83894]
 [152.55241]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 10.  8.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.46011352539062



action possibilites: [-1] 
expected returns: [[148.00485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8. 10. 10.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0 11  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 167.81297302246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.1078 ]
 [132.71954]
 [149.08337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  8. 10. 10.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0 11  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.00485229492188






Player: 1 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3
  0 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [14.  3. 11.  0.  0. 29.  3.  0.  8.  3. 11.  0. 11. 10.  3.  0.  0.  0.
 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[106.41116]
 [ 92.59087]
 [108.06002]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.08334350585938



action possibilites: [-1] 
expected returns: [[167.98076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 104.6566390991211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[162.28613]
 [170.79544]
 [166.0078 ]
 [148.5502 ]
 [168.60863]
 [169.43623]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.9807586669922



buy possibilites: [-1] 
expected returns: [[182.01456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 11. 29. 11.  8.  0.  0. 10. 10. 29. 11.  3. 11.  0.  3. 25.  0. 29.
 10.  8. 10. 10.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 170.79544067382812






Player: 1 
cards in hand: [ 3.  0. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  8.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 29. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[97.79002 ]
 [96.619026]
 [88.678635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.] 
cards in discard: [11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  3. 11.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 550   0] 
sum of rewards: 575 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 151.3665313720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.65822 ]
 [74.62626 ]
 [97.887726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.] 
cards in discard: [11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  3. 11.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.79000091552734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  3. 11.] 
cards in discard: [16. 14.  3.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 29. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[100.47594]
 [100.89709]
 [ 95.16107]
 [105.1582 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.  0.] 
cards in discard: [11. 10. 11. 10.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  0. 11.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.88771057128906



action possibilites: [-1] 
expected returns: [[104.38933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  0. 11.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 103.37179565429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.155365]
 [ 99.94859 ]
 [ 79.5815  ]
 [103.178566]
 [105.31062 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  0. 11.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.38932800292969






Player: 1 
cards in hand: [ 0. 29.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0. 11.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1. 11. 10.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1. 11. 10.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1. 11. 10.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  1. 11. 10.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  3.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[128.5397 ]
 [121.37009]
 [130.23776]
 [121.37009]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 11. 10.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.31063842773438



action possibilites: [-1] 
expected returns: [[148.25793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 10.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 128.57662963867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[141.05418]
 [144.807  ]
 [129.22308]
 [146.98389]
 [150.23935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1. 10.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0.  3.] 
adversary cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.2579345703125






Player: 1 
cards in hand: [11.  0.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  4.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  3.] 
cards in discard: [16. 14.  3.  0.  8.  1. 29.  3. 11.  8.  0.  0.  3.  8. 11.  3. 29.  0.
  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10. 29.  0. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[125.76567]
 [118.26593]
 [118.26593]
 [132.6325 ]
 [132.6325 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0. 29.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.2393798828125



action possibilites: [-1. 10. 10.] 
expected returns: [[153.92792]
 [143.51544]
 [143.51544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 126.95210266113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.4591 ]
 [145.56073]
 [124.48154]
 [148.3415 ]
 [153.30322]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 153.92791748046875






Player: 1 
cards in hand: [ 3.  3. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 26. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  3.  0.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[137.017  ]
 [134.60866]
 [139.50055]
 [155.0725 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25.  3.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  8. 29.  8.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3  0] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.30322265625



action possibilites: [-1] 
expected returns: [[159.99503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0.  0.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  8. 29.  8.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3  0  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.07249450683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[149.53293]
 [158.67274]
 [153.91025]
 [136.12909]
 [156.32803]
 [160.29141]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  0.  0.  0.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  8. 29.  8.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3  0  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.99502563476562






Player: 1 
cards in hand: [14.  3.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 29.  8.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 29 10  8  0  8  1  6  0  8 14  3  0 11
  6 16 29  3  3  8  3  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  1. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0. 25.  8. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  1. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0. 25.  8. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  1. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0. 25.  8. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 10. 10.  1. 29.] 
adversary cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0. 25.  8. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[89.52487]
 [94.61204]
 [87.4185 ]
 [87.4185 ]
 [97.09319]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  1. 29.] 
cards in discard: [11. 10. 11. 10.  3.  1. 11.  8.  0. 10.  0.  1. 11. 10.  3.  1. 10.  0.
 29. 29. 10. 10.  0. 25.  8. 11.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  1.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.29141235351562



action possibilites: [-1. 10.] 
expected returns: [[78.264435]
 [70.811005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.] 
cards in discard: [11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  1.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.58642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[69.960236]
 [79.196754]
 [74.21633 ]
 [56.664516]
 [76.88949 ]
 [79.36652 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.] 
cards in discard: [11. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  1.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.26443481445312






Player: 1 
cards in hand: [11.  0.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  1.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 11 10  0  8  1  6  0  8  3  0 11  6 16 29
  3  3  8  3  0  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 26. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[71.9397  ]
 [67.3549  ]
 [67.3549  ]
 [75.030106]
 [77.67299 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 29.] 
cards in discard: [11. 10. 29. 10.  1.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.36653137207031



action possibilites: [-1. 10. 10.] 
expected returns: [[113.76004]
 [105.9082 ]
 [105.9082 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 25. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.63935089111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[103.90275 ]
 [109.2748  ]
 [ 77.580536]
 [113.05818 ]
 [113.96941 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 25. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [16.  3.  0.  8.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0  3] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.76004791259766






Player: 1 
cards in hand: [16.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  8.  0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3
  8  3  0  6  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  6.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 11.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[78.35374]
 [73.12787]
 [80.27008]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.  1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.96943664550781



action possibilites: [-1] 
expected returns: [[86.26783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 79.88333129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[79.40021 ]
 [88.347664]
 [83.53489 ]
 [67.53951 ]
 [86.06304 ]
 [89.17867 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.26782989501953






Player: 1 
cards in hand: [ 0. 11.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  6.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  3.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  8. 11.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  8. 11.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 10.  8. 11.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8. 11.] 
expected returns: [[92.42434 ]
 [87.01573 ]
 [95.36621 ]
 [87.01573 ]
 [91.702286]
 [95.36621 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8. 11.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.17868041992188



action possibilites: [-1] 
expected returns: [[79.68502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 11.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 93.806396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.449   ]
 [50.507183]
 [79.932785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8. 11.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.68502044677734






Player: 1 
cards in hand: [ 0. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3.  0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 25. 11.  8.  0.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  3.  0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 25. 11.  8.  0.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  3.  0.] 
cards in discard: [ 3.  0. 11.  3.  3.  0. 10.  6.  0.  8.  3.  3.  8.  0.  0.  6. 16.  3.
  8.  0.  8. 11.  0.  6.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 25. 11.  8.  0.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10. 25. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.  8.] 
expected returns: [[135.54605]
 [126.87039]
 [141.65387]
 [133.24788]
 [129.8608 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11.  8.  0.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  5.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.93278503417969



action possibilites: [-1] 
expected returns: [[50.305733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0.  0.  0.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 141.6538543701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[32.423775 ]
 [55.184742 ]
 [42.790424 ]
 [ 4.2713346]
 [49.389008 ]
 [57.103638 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  0.  0.  0.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.30573272705078






Player: 1 
cards in hand: [ 3.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  2.  9.  5.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  2.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  2.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 6. 15.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  1.] 
adversary cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.559212]
 [25.223034]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.10361862182617



action possibilites: [-1.] 
expected returns: [[23.672897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.892478942871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[  9.678737 ]
 [ 24.075882 ]
 [ 16.080551 ]
 [-10.115134 ]
 [ 21.406414 ]
 [ 20.36335  ]
 [ 30.404018 ]
 [ -1.7853627]
 [ 12.079566 ]
 [ 23.672909 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.672897338867188



buy possibilites: [-1] 
expected returns: [[46.19323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [11. 10. 29. 10.  1.  3. 11.  1. 29.  0. 10. 10.  1. 11.  3.  0. 10.  1.
  1. 11. 10. 10.  8. 11. 25. 10. 11.  8.  0.  0.  0.  0. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.404003143310547






Player: 1 
cards in hand: [0. 3. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10.] 
expected returns: [[80.506676]
 [84.16395 ]
 [81.359566]
 [81.359566]
 [74.099205]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.19322967529297



action possibilites: [-1. 11. 10.] 
expected returns: [[73.00697]
 [75.71965]
 [66.85104]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [11.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.81885528564453



action possibilites: [-1] 
expected returns: [[71.30609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11.  1.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 74.21509552001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.468983]
 [66.10832 ]
 [44.484306]
 [68.558426]
 [71.599594]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [11.  1.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
adversary owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.30609130859375






Player: 1 
cards in hand: [11.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  3.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  0.  0.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  8.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  3  0  0  0 11 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8
  3  0  6  0  3  6  8  0  6 15  8  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  0.  0.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  0.  0.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  0.  0.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10.  0.  0.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[61.58518 ]
 [62.360943]
 [65.33629 ]
 [53.483856]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  0.  0.] 
cards in discard: [11.  1.  1. 29. 11.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
adversary owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.59956359863281



action possibilites: [-1. 11. 10.] 
expected returns: [[31.990696]
 [35.26652 ]
 [26.537327]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 21. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
adversary owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.37379837036133



action possibilites: [-1] 
expected returns: [[83.13679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
adversary owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 33.678653717041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.4734  ]
 [80.413734]
 [67.34782 ]
 [82.229904]
 [84.05844 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
adversary owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.13678741455078






Player: 1 
cards in hand: [0. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  1. 11.  1.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.  1. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 30. 25. 30.  8.  4.  9.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  1. 11.  1.] 
adversary cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.  1. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 2 
Witch: 1 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  3.  1. 11.  1.] 
cards in discard: [11.  1.  1. 29. 11.  0. 10.  0.  1.  1. 29. 11. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 25 10  8 10 11  8 10 29 10
 11 10 10 11 10 11 10  1  1  1  1  1  1 29  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 25. 30.  8.  4.  9.  0.  0.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 6. 15.  8. 11.  3.  0.  3.  0.  0.  0.  3.  6.  3.  3.  0. 10.  8.  8.] 
adversary owned cards: [ 3  0  0  0 11 10  0  8  6  0  8  3  0 11  6 16 29  3  3  8  3  0  6  0
  3  6  8  0  6 15  8  0  0  8] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000055 

action type: buy - action -1.0
Learning step: 119998.8359375
desired expected reward: 120082.890625



