 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[38.695187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     150       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000145 

action type: buy - action -1.0
Learning step: 300012.46875
desired expected reward: 300033.09375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.964504]
 [71.6637  ]
 [52.86035 ]
 [17.096045]
 [71.44901 ]
 [55.084152]
 [40.567234]
 [37.80836 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.505836486816406



buy possibilites: [-1] 
expected returns: [[39.963135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 71.66368865966797






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.62592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.963134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 52.57143 ]
 [ 91.998985]
 [ 69.801285]
 [ 25.436852]
 [ 87.89022 ]
 [ 91.93955 ]
 [ 73.54463 ]
 [141.6513  ]
 [ 41.175076]
 [ 53.02077 ]
 [ 77.69428 ]
 [ 47.87882 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.688072204589844



buy possibilites: [-1] 
expected returns: [[14.707741]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 141.65130615234375






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 9.116084]
 [57.429897]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.707740783691406



action possibilites: [-1.] 
expected returns: [[55.592747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 54.62950897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 62.294533]
 [ 95.568634]
 [ 47.89888 ]
 [ 75.29767 ]
 [ 54.781734]
 [ 40.236774]
 [ 92.27479 ]
 [ 94.81173 ]
 [ 78.98236 ]
 [154.71762 ]
 [140.68253 ]
 [ 53.077854]
 [ 95.94607 ]
 [ 61.92926 ]
 [ 62.533485]
 [ 82.39326 ]
 [ 57.03362 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.59274673461914



buy possibilites: [-1] 
expected returns: [[31.098995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 154.71762084960938






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.38637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.098995208740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.49749 ]
 [64.38458 ]
 [49.70289 ]
 [16.095505]
 [64.965965]
 [51.861507]
 [37.591736]
 [34.15848 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.40699005126953



buy possibilites: [-1] 
expected returns: [[16.780184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  1.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 29.  3.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.96597290039062






Player: 1 
cards in hand: [10. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  0.  0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  0.  0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3.  0.  0.] 
cards in discard: [8. 0. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-16.280005]
 [ 24.574669]
 [ 31.242577]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.780183792114258



action possibilites: [-1] 
expected returns: [[13.582058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.546180725097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.67263 ]
 [34.634186]
 [23.287127]
 [-8.739028]
 [36.032074]
 [24.661554]
 [13.238802]
 [12.443781]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.58205795288086



buy possibilites: [-1] 
expected returns: [[6.0735645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.  3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.03207015991211






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  3.] 
adversary cards in discard: [11. 25. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.183601]
 [35.624546]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  3.] 
cards in discard: [11. 25. 29.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8. 29.] 
adversary cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.073564529418945



action possibilites: [-1] 
expected returns: [[9.257081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [11. 25. 29.  0.  0.  3.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8. 29.] 
adversary cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.389217376708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.709885]
 [32.891132]
 [24.615353]
 [ 7.556121]
 [31.574318]
 [33.13741 ]
 [26.085695]
 [51.05094 ]
 [13.706854]
 [18.310614]
 [27.387405]
 [15.599468]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [11. 25. 29.  0.  0.  3.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8. 29.] 
adversary cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.257081031799316



buy possibilites: [-1] 
expected returns: [[47.372902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [11. 25. 29.  0.  0.  3.  0.  3. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8. 29.] 
adversary cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 51.050933837890625






Player: 1 
cards in hand: [ 0.  0. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8. 29.] 
cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29.  3.] 
cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6. 3. 3. 3. 0. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 8.630057]
 [46.777218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.372901916503906



action possibilites: [-1. 11.] 
expected returns: [[32.72799 ]
 [64.107506]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.07086181640625



action possibilites: [-1] 
expected returns: [[62.92327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.8713607788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 80.09582 ]
 [106.93162 ]
 [ 64.31757 ]
 [ 90.281715]
 [ 72.57614 ]
 [ 55.157818]
 [105.603004]
 [104.77455 ]
 [ 93.77927 ]
 [157.42416 ]
 [144.36243 ]
 [ 70.03009 ]
 [107.95606 ]
 [ 78.13008 ]
 [ 80.64208 ]
 [ 95.9302  ]
 [ 71.53072 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.92327117919922



buy possibilites: [-1] 
expected returns: [[53.30008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 157.42416381835938






Player: 1 
cards in hand: [29.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[53.116505]
 [89.84547 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.300079345703125



action possibilites: [-1] 
expected returns: [[27.76569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.74869537353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.745335]
 [44.195896]
 [20.820457]
 [46.20474 ]
 [32.194687]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  8.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.765689849853516



buy possibilites: [-1] 
expected returns: [[22.292963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  8.] 
adversary cards in discard: [29.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 46.20471954345703






Player: 1 
cards in hand: [10.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  8.] 
cards in discard: [29.  3.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  8  3  6  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [29.  3.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [29.  3.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29.  0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-20.68776  ]
 [-18.802996 ]
 [  7.6749964]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  0.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.2929630279541



action possibilites: [-1. 10. 25.] 
expected returns: [[ 2.229094 ]
 [ 3.4652367]
 [41.807346 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 25.] 
cards in discard: [10. 25. 29. 11.  0.  1.  0.  0. 10.  8. 11.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 5.060683250427246



action possibilites: [-1] 
expected returns: [[68.79786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.80733108520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 86.87228 ]
 [119.26867 ]
 [101.2508  ]
 [ 58.730328]
 [117.669365]
 [117.059425]
 [104.876564]
 [157.93375 ]
 [ 74.69455 ]
 [ 85.899956]
 [107.40284 ]
 [ 78.914185]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.79785919189453



buy possibilites: [-1] 
expected returns: [[42.82709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.  0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 157.93374633789062






Player: 1 
cards in hand: [3. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 29  8  3  6  3  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  3.  6.  0.  0.  8. 10.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10. 25.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[ 82.08779 ]
 [ 84.558205]
 [127.99662 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 25.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.827091217041016



action possibilites: [-1] 
expected returns: [[90.41386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 10. 29.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.28082275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.204025]
 [ 99.107414]
 [ 75.36744 ]
 [100.323814]
 [ 89.55798 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 10. 29.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.41385650634766



buy possibilites: [-1] 
expected returns: [[90.83694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 10. 29.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 100.3238296508789






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  0.] 
adversary cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 84.59934]
 [ 98.1022 ]
 [115.07521]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 11.  0.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.8369369506836



action possibilites: [-1] 
expected returns: [[40.921227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 133.70925903320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[36.403633]
 [64.093956]
 [51.31684 ]
 [24.949722]
 [58.579514]
 [67.65666 ]
 [52.204247]
 [93.797386]
 [31.33728 ]
 [40.479794]
 [56.473747]
 [41.84602 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.921226501464844



buy possibilites: [-1] 
expected returns: [[50.589874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0.] 
cards in discard: [29. 29. 25. 10.  0.  3.  0.  3.  0.  8. 25.  0.  0.  3. 10. 10. 29. 10.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.79739379882812






Player: 1 
cards in hand: [ 0. 29.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6.  3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 10.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 8.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0 10 29  8  3  6  3  8  6  0  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29. 25.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10. 29. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25. 11.] 
expected returns: [[ 45.772568]
 [ 49.16798 ]
 [ 96.16478 ]
 [104.1142  ]
 [ 69.08229 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  7. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.589874267578125



action possibilites: [-1] 
expected returns: [[71.70315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.41564178466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.48061 ]
 [ 99.69106 ]
 [ 71.708466]
 [102.20801 ]
 [ 86.68898 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.7031478881836



buy possibilites: [-1] 
expected returns: [[59.680847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 11. 10.  0.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 102.20800018310547






Player: 1 
cards in hand: [8. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  3.] 
adversary cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 29. 29. 29.  3.] 
adversary cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 29.] 
expected returns: [[49.999214]
 [57.3467  ]
 [75.97037 ]
 [75.97037 ]
 [75.97037 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 29.  3.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.68084716796875



action possibilites: [-1.  8. 29. 29. 10.] 
expected returns: [[55.044827]
 [61.295982]
 [80.86957 ]
 [80.86957 ]
 [55.60253 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  3. 10.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.18228912353516



action possibilites: [-1.  8. 29. 10.  8.] 
expected returns: [[54.732193]
 [58.55348 ]
 [78.58896 ]
 [53.93042 ]
 [58.55348 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 10.  8.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.86956024169922



action possibilites: [-1.  8. 10.  8.] 
expected returns: [[35.02803 ]
 [41.581844]
 [32.61045 ]
 [41.581844]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  8.  0.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 11 11 10 29 10 25 10  8 29  8 10
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.58898162841797



action possibilites: [-1] 
expected returns: [[105.441246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 63.93772888183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.478294]
 [113.10717 ]
 [107.98646 ]
 [ 93.15178 ]
 [114.95877 ]
 [108.26353 ]
 [104.1257  ]
 [104.39258 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  8.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.44124603271484



buy possibilites: [-1] 
expected returns: [[70.51132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  7.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 8.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.95878601074219






Player: 1 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [6. 8. 3. 0. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  7.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [6. 8. 3. 0. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  7.  5.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  7.  5.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [25. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[20.611248]
 [41.79952 ]
 [14.045805]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  3.  0.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  6. 10.  7.  5.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  8. 10.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.51132202148438



action possibilites: [-1] 
expected returns: [[68.78853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.  0.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  8. 10.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.7289924621582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[61.09082 ]
 [83.119125]
 [75.131226]
 [46.968163]
 [78.17745 ]
 [87.69308 ]
 [75.05482 ]
 [96.61126 ]
 [58.53478 ]
 [67.21776 ]
 [78.764595]
 [72.73314 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.  0.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  8. 10.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.78852844238281



buy possibilites: [-1] 
expected returns: [[44.844284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  0.  0.] 
cards in discard: [ 8. 25. 10. 29.  0. 11. 10.  0. 11. 29. 29. 29.  8.  3.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  3.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  8. 10.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.61121368408203






Player: 1 
cards in hand: [10. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  3.] 
cards in discard: [ 6.  8.  3.  0.  6.  8. 10.  0.  0.  6.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  7.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[122.222 ]
 [151.7406]
 [151.7406]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  1.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  8.  8.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.84428405761719



action possibilites: [-1] 
expected returns: [[94.59548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  3.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  8.  8.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 158.7919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[111.882095]
 [140.72476 ]
 [125.042046]
 [ 87.00942 ]
 [138.92975 ]
 [128.37561 ]
 [111.12529 ]
 [105.14061 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  3.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  8.  8.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.5954818725586



buy possibilites: [-1] 
expected returns: [[74.24458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.  3.] 
cards in discard: [10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  6. 10.  8.  8.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 140.72479248046875






Player: 1 
cards in hand: [ 3.  6. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  8.  8.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 29. 25. 10.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 8. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  8  6  3  8  6  0  6  3  6 10  6 11] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 29. 25. 10.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 29. 25. 10.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 29. 25. 10.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 29. 25. 10.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 11. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 25. 10.] 
expected returns: [[14.79427 ]
 [14.640209]
 [26.301933]
 [37.599297]
 [43.95137 ]
 [14.640209]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 25. 10.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0] -> size -> 19 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.24458312988281



action possibilites: [-1] 
expected returns: [[28.10452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 10.  0.  3.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6] -> size -> 20 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.20211410522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.457565]
 [ 4.372836]
 [25.678316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29. 10.  0.  3.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6] -> size -> 20 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.104520797729492






Player: 1 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  3.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  3.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [11. 10. 29.  0.  0.  3.  0.  0. 10.  8.  3.  6.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  3.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[23.345844]
 [24.15525 ]
 [57.690594]
 [57.690594]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 29.  3.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.67831802368164



action possibilites: [-1.  8. 29. 29.] 
expected returns: [[ 68.735695]
 [ 76.16268 ]
 [110.68587 ]
 [110.68587 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  3. 29.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.69059753417969



action possibilites: [-1.  8. 29. 29.] 
expected returns: [[ 79.29088]
 [ 77.91962]
 [100.96426]
 [100.96426]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 29. 29.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.68586730957031



action possibilites: [-1.  8. 29.  8.] 
expected returns: [[ 71.570015]
 [ 74.70835 ]
 [104.937965]
 [ 74.70835 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 29.  8.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.96426391601562



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[65.81081 ]
 [73.41831 ]
 [73.41831 ]
 [63.628136]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  8. 10.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10  8 29  8 10 29  8
 11 29 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.93798828125



action possibilites: [-1] 
expected returns: [[55.606907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 99.6236801147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.36553 ]
 [64.38802 ]
 [57.788654]
 [29.607796]
 [58.54726 ]
 [71.195496]
 [56.780415]
 [85.03916 ]
 [39.814896]
 [50.181046]
 [61.035393]
 [54.86918 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.60690689086914



buy possibilites: [-1] 
expected returns: [[75.94265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0 128   0] 
sum of rewards: 403 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.0391845703125






Player: 1 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  0.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3. 29. 29. 29. 29.
 29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  0.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3. 29. 29. 29. 29.
 29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  8.  0.] 
adversary cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3. 29. 29. 29. 29.
 29.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ 53.31909]
 [100.54513]
 [ 68.61564]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  8.  0.] 
cards in discard: [10.  1. 11.  0. 11.  1.  3. 25. 10. 11. 29. 10.  0.  3. 29. 29. 29. 29.
 29.  8.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  4. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0] -> size -> 22 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.9426498413086



action possibilites: [-1] 
expected returns: [[99.97582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 25. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  3. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 100.54511260986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.7581  ]
 [121.424446]
 [111.33964 ]
 [ 86.777664]
 [121.60715 ]
 [113.0256  ]
 [102.94081 ]
 [ 99.94602 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 25. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  3. 10.  6.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.97582244873047



buy possibilites: [-1] 
expected returns: [[56.67279]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 25. 10.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  6.] 
adversary cards in discard: [0. 6. 3. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.60713958740234






Player: 1 
cards in hand: [10.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  6.] 
cards in discard: [0. 6. 3. 3. 0. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  6.] 
cards in discard: [0. 6. 3. 3. 0. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  6.] 
cards in discard: [0. 6. 3. 3. 0. 0. 6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1.  3. 29.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 29.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[62.451927]
 [95.610466]
 [95.610466]
 [95.610466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  3. 29.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.67279052734375



action possibilites: [-1. 29. 29. 10.] 
expected returns: [[21.911438]
 [51.184616]
 [51.184616]
 [ 8.061237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 29. 10.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 95.61046600341797



action possibilites: [-1. 29. 10.] 
expected returns: [[40.895744]
 [89.555405]
 [39.09692 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 10.  0.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.18461227416992



action possibilites: [-1. 10. 10.] 
expected returns: [[128.83176]
 [128.38156]
 [128.38156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0. 10.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.55538940429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[120.20611]
 [147.76865]
 [111.00179]
 [135.16418]
 [111.32502]
 [ 97.76015]
 [142.33273]
 [151.71588]
 [136.03403]
 [189.00192]
 [176.63443]
 [114.74946]
 [146.45093]
 [125.14416]
 [118.39689]
 [139.92145]
 [126.09705]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0. 10.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  8.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 128.83172607421875



buy possibilites: [-1] 
expected returns: [[100.72668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0. 10.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  8.  3.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 297.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 189.00192260742188






Player: 1 
cards in hand: [ 6. 29.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  8.  3.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  8. 11. 11.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  6.  8.  3.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  8. 11. 11.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
adversary victory points: 3
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 29.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 11. 11.] 
expected returns: [[-3.6303537]
 [ 6.1374617]
 [ 6.1374617]
 [ 2.720076 ]
 [ 1.4127398]
 [ 1.4127398]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8. 11. 11.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.72667694091797



action possibilites: [-1. 29.  8. 11. 11.] 
expected returns: [[22.603899]
 [50.99348 ]
 [29.706024]
 [38.121025]
 [38.121025]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11. 11.  3.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.137456893920898



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[36.55008]
 [46.68268]
 [61.01641]
 [61.01641]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  3.  3.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.99348449707031



action possibilites: [-1] 
expected returns: [[90.48783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 262 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.96632385253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.47927 ]
 [97.85881 ]
 [63.899834]
 [97.88226 ]
 [90.864944]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  5.  7.  3. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.48783111572266



buy possibilites: [-1] 
expected returns: [[95.49924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  6.  0.  6.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 251 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 97.88224792480469






Player: 1 
cards in hand: [11.  6.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6.  0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0. 29.  1.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.
  8. 29. 29. 11.  8. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.
 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  1.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.
  8. 29. 29. 11.  8. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  6.  3. 10.  0. 10.  0.  6.  6. 29.  6.  8.  3.
 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  1.] 
adversary cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.
  8. 29. 29. 11.  8. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-8.390374 ]
 [ 5.6610603]
 [-8.683018 ]
 [22.595535 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29.  1.] 
cards in discard: [11. 25.  0.  0.  8.  0. 25. 10. 25. 29. 29. 29.  1.  3. 10.  0. 10. 10.
  8. 29. 29. 11.  8. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.49923706054688



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[37.84691 ]
 [51.839714]
 [40.637127]
 [46.969692]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.59551239013672



action possibilites: [-1] 
expected returns: [[19.364462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.207427978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.541885]
 [46.085697]
 [34.045105]
 [ 7.641595]
 [44.754524]
 [45.11209 ]
 [36.47617 ]
 [71.25758 ]
 [16.055012]
 [22.79257 ]
 [38.276913]
 [13.440496]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  3. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.36446189880371



buy possibilites: [-1] 
expected returns: [[92.509056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8.] 
cards in discard: [10. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 71.25758361816406






Player: 1 
cards in hand: [ 6.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 29. 29.  0. 29.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 29. 29.  0. 29.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
adversary victory points: 3
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 29.] 
expected returns: [[-34.12042 ]
 [ 29.815948]
 [ 87.78079 ]
 [ 87.78079 ]
 [ 87.78079 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0. 29.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.5090560913086



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[ 5.3080654]
 [55.47964  ]
 [86.84792  ]
 [86.84792  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29.  3.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.78075408935547



action possibilites: [-1. 11. 29.] 
expected returns: [[ 33.516335]
 [ 77.156075]
 [104.784935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.84790802001953



action possibilites: [-1. 11. 10.] 
expected returns: [[ 94.41059]
 [127.7434 ]
 [ 96.27149]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.78494262695312



action possibilites: [-1] 
expected returns: [[66.145195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 140.09939575195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 59.019375]
 [ 79.68641 ]
 [ 70.11356 ]
 [ 54.46457 ]
 [ 50.634514]
 [ 75.95139 ]
 [ 82.11811 ]
 [ 70.89274 ]
 [109.3561  ]
 [100.48884 ]
 [ 57.00456 ]
 [ 78.85483 ]
 [ 57.99423 ]
 [ 73.80749 ]
 [ 64.888565]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  7.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.14519500732422



buy possibilites: [-1] 
expected returns: [[113.180176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  3.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 505 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.35609436035156






Player: 1 
cards in hand: [ 3.  8. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  3.] 
cards in discard: [ 6.  6.  3. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  3.] 
cards in discard: [ 6.  6.  3. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  3. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  3.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  3. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10. 25.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 25.] 
expected returns: [[72.38318]
 [78.09767]
 [78.09767]
 [69.34164]
 [85.39646]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10. 25.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  3. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.18017578125



action possibilites: [-1] 
expected returns: [[70.28552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10. 25.  3.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.39647674560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.419426]
 [55.70532 ]
 [70.2271  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 10. 25.  3.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.2855224609375






Player: 1 
cards in hand: [ 0. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  1.  8. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  1.  8. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[36.87918 ]
 [33.293495]
 [45.426254]
 [29.759388]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 11. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.22708129882812



action possibilites: [-1] 
expected returns: [[58.23095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.39857482910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.653717]
 [55.99331 ]
 [27.496887]
 [54.348434]
 [55.83886 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.23094940185547



buy possibilites: [-1] 
expected returns: [[16.898396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 251 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 55.993282318115234






Player: 1 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 25. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.  3. 11.  3.  1.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8.  2. 10.  5.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 25. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.  3. 11.  3.  1.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  2. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 25. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.  3. 11.  3.  1.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 10.] 
expected returns: [[-39.304314]
 [-40.932636]
 [-28.859028]
 [-35.43015 ]
 [-41.47872 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25. 11. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  1.  8. 10. 25. 29. 29. 29. 11.  0.  3.  0. 10.
 25. 29.  0. 29. 10. 25.  3. 15.  3. 11.  3.  1.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  2. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 11. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.898395538330078



action possibilites: [-1] 
expected returns: [[112.29854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 11. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -28.859039306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.0501 ]
 [ 93.3234 ]
 [114.18676]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 11. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.29853820800781






Player: 1 
cards in hand: [ 6. 11. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.  0.  6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25.  3.  1.  8.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.  0.  6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25.  3.  1.  8.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.  0.  6.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  8. 29.  0.  3.  6.  0. 10.  0.  3.  6. 11.
  0.  6.  0.  0.  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25.  3.  1.  8.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
adversary victory points: 4
player victory points: -5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  3.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ 67.73953]
 [119.17681]
 [ 72.86698]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  8.  0.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  1. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0] -> size -> 30 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.1867904663086



action possibilites: [-1] 
expected returns: [[83.105736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8.  0. 15. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.17679595947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 72.248535]
 [ 97.16761 ]
 [ 87.891685]
 [103.22591 ]
 [ 87.58275 ]
 [ 82.01879 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8.  0. 15. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  4.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.1057357788086



buy possibilites: [-1] 
expected returns: [[64.30126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8.  0. 15. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  6.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.22588348388672






Player: 1 
cards in hand: [ 6.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  0. 11.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  0. 29. 10.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
adversary victory points: 4
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6.  0. 11.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  0. 29. 10.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
adversary victory points: 4
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[170.76718]
 [168.25836]
 [168.25836]
 [188.3789 ]
 [168.25836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 29. 10.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6. 29. 11.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.30126190185547



action possibilites: [-1. 10. 25.] 
expected returns: [[ 96.10642 ]
 [ 93.440216]
 [137.34793 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6. 29. 11.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 176.58181762695312



action possibilites: [-1] 
expected returns: [[137.74576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6. 29. 11.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.347900390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[124.93781]
 [138.84296]
 [137.78998]
 [139.21002]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  6. 29. 11.  0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.74575805664062






Player: 1 
cards in hand: [15.  6. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 29. 11.  0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  2. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
adversary victory points: 4
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 29.  0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
adversary victory points: 4
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6. 29.  0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
adversary victory points: 4
player victory points: -6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[ 37.791473]
 [101.45605 ]
 [ 70.99611 ]
 [ 38.137974]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  0.  0.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6. 10.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.21002197265625



action possibilites: [-1] 
expected returns: [[38.07359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 29. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6. 10.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.45600891113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.696379]
 [37.927605]
 [35.674698]
 [37.540436]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 29. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6. 10.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.07358932495117



buy possibilites: [-1] 
expected returns: [[17.246859]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 29. 29.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.  6. 10.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 37.92760467529297






Player: 1 
cards in hand: [ 6. 10.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6. 10.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 29. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  6.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 29. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  6.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 29. 11. 11.] 
adversary cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
adversary victory points: 5
player victory points: -6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10. 10. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 11. 11.] 
expected returns: [[-19.637558]
 [-22.864264]
 [-22.864264]
 [ -6.864211]
 [ -9.717077]
 [ -9.717077]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 11. 11.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.246858596801758



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[ -8.278114  ]
 [-16.359514  ]
 [-16.359514  ]
 [ -0.43130398]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.957109451293945



action possibilites: [-1] 
expected returns: [[-8.833181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29. 11. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 342 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -8.9816255569458





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.418354]
 [ -8.833181]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [25.  8.  0. 11. 10. 29.  3. 11. 25.  3.  1.  8.  0. 15. 29. 10. 10. 29.
 25.  0. 10.  8.  3.  3. 25. 11. 10.  0.  0. 29. 29. 11. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.833181381225586






Player: 1 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10. 29.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[71.0299  ]
 [65.760666]
 [83.66392 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.833181381225586



action possibilites: [-1. 10.] 
expected returns: [[66.13711]
 [64.11709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [1. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 75.26805877685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.471245]
 [67.63511 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [1. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.13712310791016






Player: 1 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29.  8.  8. 25. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  4.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29.  8.  8. 25. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 6.  6.  0.  6.  0. 11. 29. 11. 15.  6. 29.  0. 10.  6.  0.  6. 10.  6.
  0.  0.  3.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29.  8.  8. 25. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29.  8.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 25. 11.] 
expected returns: [[-17.641634 ]
 [ 71.36363  ]
 [  2.8193493]
 [  2.8193493]
 [ 84.90772  ]
 [ 23.052294 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 25. 11.] 
cards in discard: [ 1.  1. 29. 10.  3.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29  8] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.6351089477539



action possibilites: [-1] 
expected returns: [[59.415897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 11. 10. 25.] 
cards in discard: [ 1.  1. 29. 10.  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29  8] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.90771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[53.481724]
 [60.261063]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8. 11. 10. 25.] 
cards in discard: [ 1.  1. 29. 10.  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [6. 8. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29  8] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.415897369384766






Player: 1 
cards in hand: [6. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 29  6  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3
 15  0  6 11  6  0  6 29  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11.  1. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11.  1. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11.  1. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25. 11. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 11.] 
expected returns: [[35.157074]
 [83.13185 ]
 [56.71351 ]
 [56.71351 ]
 [56.71351 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11.  1. 11.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.26105499267578



action possibilites: [-1] 
expected returns: [[86.2322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1. 11. 29. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.13185119628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 89.97941 ]
 [102.132484]
 [105.43349 ]
 [ 85.43185 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1. 11. 29. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  3.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.2322006225586



buy possibilites: [-1] 
expected returns: [[167.02734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1. 11. 29. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 105.43348693847656






Player: 1 
cards in hand: [ 0.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [8. 6. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  3. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
adversary victory points: 5
player victory points: -5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  3. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  3. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [8. 6. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  3. 11.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[24.179167]
 [79.90475 ]
 [31.59932 ]
 [50.200798]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3. 11.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8.  6.  6.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.02734375



action possibilites: [-1.  8. 29.] 
expected returns: [[29.984169]
 [42.788643]
 [83.0672  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8.  6.  6.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 65.73480987548828



action possibilites: [-1.] 
expected returns: [[13.039682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8.  6.  6.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 54.793312072753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 5.3502274]
 [18.783983 ]
 [14.933645 ]
 [23.396564 ]
 [14.222996 ]
 [13.674765 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  3.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8.  6.  6.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.039682388305664



buy possibilites: [-1] 
expected returns: [[11.754414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8.  6.  6.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 319 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 23.396568298339844






Player: 1 
cards in hand: [15.  8.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  6.  6.  0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  6  0  6  3  6 10  6 11  0  6  3  0  6  3 15  0
  6 11  6  0  6 29  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25. 10.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[-41.56121]
 [-38.17099]
 [-46.96319]
 [-43.83145]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 29.  3.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 11.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.754413604736328



action possibilites: [-1] 
expected returns: [[9.638129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 10. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 11.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -38.17100143432617





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.354727]
 [  9.638112]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3. 10. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  6.  0.  3. 11.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.638129234313965






Player: 1 
cards in hand: [11.  6.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3. 11.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15. 29.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 11.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0. 10.] 
adversary cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10.] 
expected returns: [[-18.805613]
 [-18.848038]
 [ -9.267336]
 [-23.936932]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  0. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.638129234313965



action possibilites: [-1. 15. 10.] 
expected returns: [[-38.0068  ]
 [-29.399149]
 [-41.508755]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -18.229732513427734



action possibilites: [-1] 
expected returns: [[-64.00244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -29.399131774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-79.930885]
 [-64.00244 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 1.  1. 29. 10.  3.  3. 25. 29.  8.  8. 11. 10. 25.  8. 25. 11. 11.  1.
 11. 29. 10.  3. 11.  8.  0. 11. 29. 29.  0. 25. 10.  0. 29.  3. 10. 10.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -64.00244140625






Player: 1 
cards in hand: [ 0.  6. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3.  0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  3.  0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  3.  0.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 29. 25. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25. 29. 10.] 
expected returns: [[ 82.25924 ]
 [ 93.55364 ]
 [119.687805]
 [126.01032 ]
 [119.687805]
 [ 84.519165]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 25. 29. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  6.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -64.00244140625



action possibilites: [-1] 
expected returns: [[43.321358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  6.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.01033782958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.455845]
 [43.180397]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 29. 10. 10. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  6.] 
adversary cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.32135772705078






Player: 1 
cards in hand: [ 0.  0. 29.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6.  6.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  1.  1. 10. 10.] 
adversary cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  1.  1. 10. 10.] 
adversary cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  1.  1. 10. 10.] 
adversary cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 8.  6.  3.  0. 10.  0.  3.  0.  6.  0.  8.  0. 15. 11.  6.  0.  3. 11.
  0.  0.  6. 29.  3.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  1.  1. 10. 10.] 
adversary cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  1. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[82.72544]
 [77.26592]
 [77.26592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 10. 10.] 
cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.180389404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 69.13371 ]
 [105.659584]
 [ 94.93791 ]
 [ 98.74974 ]
 [111.6737  ]
 [ 94.88473 ]
 [133.00491 ]
 [ 59.703873]
 [ 99.57534 ]
 [ 86.026855]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 10. 10.] 
cards in discard: [25.  8. 29. 29. 10. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  1. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.72547149658203



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 2 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 5 
Witch: 4 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1.  1. 10. 10.] 
cards in discard: [25.  8. 29. 29. 10. 10. 10. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 25 11 11 29 10 25 10 29  8 10 29  8 11 29
 10  1 29 11 25 10  8 10 29 10 25 15  3 11  3  1  8 11 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  0. 10.  2.  2.  6.  0. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 29  3  8  0  3  6 10  6 11  0  6  3  0  6  3  0  6 11  6
  0  6 29  8  0 15  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     240       0       0       0       0       0
       0       0     -80       0       0      64       0] 
sum of rewards: 3000219 

action type: buy - action 29.0
Learning step: 300008.59375
desired expected reward: 300141.59375



