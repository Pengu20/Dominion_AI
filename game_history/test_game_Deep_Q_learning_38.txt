 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.32082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0       20        0
        0        0        0     -150        0        0       27        0] 
sum of rewards: -3000348 

action type: gain_card_n - action 7
Learning step: -120013.1640625
desired expected reward: -120031.96875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[75.96699 ]
 [83.748146]
 [83.21947 ]
 [68.304375]
 [94.403534]
 [86.51541 ]
 [85.98342 ]
 [88.189125]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.1004409790039



buy possibilites: [-1] 
expected returns: [[94.95401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.40351867675781






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.29635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.95401000976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 86.313774]
 [ 94.28946 ]
 [ 93.82068 ]
 [ 78.03792 ]
 [ 92.37106 ]
 [104.59138 ]
 [ 96.89061 ]
 [103.2777  ]
 [ 88.612305]
 [ 96.42183 ]
 [ 96.58798 ]
 [ 98.292854]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.57596588134766



buy possibilites: [-1] 
expected returns: [[103.15286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -21.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.59138488769531






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.80899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.15286254882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 87.8696  ]
 [ 96.53256 ]
 [ 95.9577  ]
 [ 80.27645 ]
 [ 79.3466  ]
 [ 94.560745]
 [107.56527 ]
 [ 99.391525]
 [115.06469 ]
 [106.331   ]
 [ 90.359985]
 [ 94.19218 ]
 [ 98.81665 ]
 [ 85.52922 ]
 [ 99.02296 ]
 [101.24666 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.28286743164062



buy possibilites: [-1] 
expected returns: [[87.48775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 115.06468200683594






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[109.2896 ]
 [116.05711]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.48774719238281



action possibilites: [-1] 
expected returns: [[102.41203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.10565948486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 91.69444 ]
 [ 99.547485]
 [ 83.66007 ]
 [103.018715]
 [105.04984 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.41203308105469






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  8. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 87.96794]
 [100.84813]
 [ 93.78619]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 11.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.04984283447266



action possibilites: [-1] 
expected returns: [[94.349625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 100.68663024902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.12636 ]
 [92.623375]
 [77.06597 ]
 [95.855156]
 [97.57202 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.34962463378906






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [25.  3.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [25.  3.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 10.  3.  0.  0.  0.  3.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [25.  3.  3. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[80.9814  ]
 [87.13002 ]
 [79.060974]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [25.  3.  3. 11.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.572021484375



action possibilites: [-1] 
expected returns: [[83.162506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25.  3.  3. 11.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.96915435791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[73.09116 ]
 [81.636185]
 [81.038414]
 [65.38735 ]
 [93.239586]
 [84.65826 ]
 [84.06047 ]
 [86.54493 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25.  3.  3. 11.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  7. 10.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.16250610351562



buy possibilites: [-1] 
expected returns: [[111.525406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25.  3.  3. 11.  3.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 93.23959350585938






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[94.26471]
 [91.65617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.52540588378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 80.83615 ]
 [ 89.83536 ]
 [ 89.220764]
 [ 71.722916]
 [101.33504 ]
 [ 92.82464 ]
 [ 92.21004 ]
 [ 94.83061 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  6. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.16871643066406



buy possibilites: [-1] 
expected returns: [[111.69107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.33505249023438






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 25.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  5. 10.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 25.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 25.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[116.81558]
 [114.60616]
 [130.46489]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 25.] 
cards in discard: [11.  3.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.69107055664062



action possibilites: [-1] 
expected returns: [[118.510574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3. 11.] 
cards in discard: [11.  3.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.86329650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.77633 ]
 [116.373405]
 [ 98.568565]
 [119.86912 ]
 [121.41747 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3. 11.] 
cards in discard: [11.  3.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.51057434082031






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  6.  3.  3.  0.  0.  6.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[89.37426]
 [96.08581]
 [96.08581]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  8.  1.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.41746520996094



action possibilites: [-1] 
expected returns: [[107.57255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  1.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.90682983398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 94.247025]
 [103.73479 ]
 [103.04873 ]
 [ 85.21384 ]
 [115.46945 ]
 [106.89211 ]
 [106.206055]
 [109.18673 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  1.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.57254791259766



buy possibilites: [-1] 
expected returns: [[96.32952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  8.  1.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.46944427490234






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  1.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  1.  1. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1.  1. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1.  1. 10.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[115.74147]
 [122.39147]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.32952117919922



action possibilites: [-1] 
expected returns: [[96.88609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.63516235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 87.800156]
 [ 95.886284]
 [ 95.364204]
 [ 79.495094]
 [107.0892  ]
 [ 98.77223 ]
 [ 98.21341 ]
 [100.52022 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  4.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.88609313964844



buy possibilites: [-1] 
expected returns: [[100.84754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  6.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 107.08920288085938






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  6.] 
cards in discard: [14.  6.  8.  1.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [14.  6.  8.  1.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [14.  6.  8.  1.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 25.] 
adversary cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[100.93042]
 [ 98.62805]
 [105.76288]
 [ 98.62805]
 [111.93521]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10. 25.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  8. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.84754180908203



action possibilites: [-1] 
expected returns: [[114.036415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  3.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.93521118164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.468704]
 [ 96.71913 ]
 [114.87305 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  3.  3.] 
cards in discard: [10. 11. 11.  0. 11.  0.  0. 10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.03641510009766






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [25. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[124.45682]
 [137.87112]
 [130.536  ]
 [121.919  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.87303924560547



action possibilites: [-1] 
expected returns: [[67.283165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 139.5733184814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.070084]
 [53.722008]
 [68.93811 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.28316497802734






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [25. 11. 10.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [25. 11. 10.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14.  6.  8.  1.  1. 10. 25. 29.  0.  0.  0.  6.  0.  6.  1.  0.  3.  0.
  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0. 11.] 
adversary cards in discard: [25. 11. 10.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[63.1295  ]
 [61.553116]
 [68.59754 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 11.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.9381103515625



action possibilites: [-1] 
expected returns: [[71.62749]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 68.35059356689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.58628 ]
 [67.96725 ]
 [52.387997]
 [71.05419 ]
 [72.62188 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.62748718261719






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10. 11.] 
adversary cards in discard: [25. 11. 10.  3.  0. 10. 11. 10. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10. 11.] 
adversary cards in discard: [25. 11. 10.  3.  0. 10. 11. 10. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[55.098824]
 [59.914284]
 [52.677414]
 [59.914284]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10. 11.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11. 10. 11.  0.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [1. 6. 6. 3. 0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.62187194824219



action possibilites: [-1] 
expected returns: [[82.7545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11. 10. 11.  0.  3. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [1. 6. 6. 3. 0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 60.456459045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.36346 ]
 [78.274704]
 [63.854584]
 [81.35217 ]
 [83.253586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25. 11. 10.  3.  0. 10. 11. 10. 11.  0.  3. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [1. 6. 6. 3. 0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.75450134277344






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [1. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  3.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[73.51849]
 [71.82146]
 [78.26543]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  1.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.25358581542969



action possibilites: [-1] 
expected returns: [[105.25233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  1.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.78285217285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.96902]
 [100.7733 ]
 [ 85.80541]
 [103.81999]
 [105.91772]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  8.  1.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.25232696533203






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  1.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 28. 30.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  3. 11. 10.  0.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[79.62074]
 [77.21884]
 [85.17677]
 [77.21884]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 10.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.91771697998047



action possibilites: [-1] 
expected returns: [[92.54473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.73591613769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.19389 ]
 [73.90654 ]
 [92.935486]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.54473114013672






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  3.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3. 10.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[ 96.718185]
 [101.18416 ]
 [101.18416 ]
 [ 94.7789  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3. 10.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  1.  0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.93548583984375



action possibilites: [-1] 
expected returns: [[96.74171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  1.  0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.63313293457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.49689]
 [79.63023]
 [96.69979]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 10.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  1.  0.] 
adversary cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.74170684814453






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  1.  0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0. 25.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  1.  0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0. 25.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  1.  0.] 
cards in discard: [ 0.  6.  3.  0. 11. 11.  1.  6.  6.  3.  0.  4. 29.  0.  0.  8.  1.  0.
  0. 10.  6.  0.  3.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0. 25.] 
adversary cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[69.30908]
 [66.66028]
 [66.66028]
 [80.64337]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 25.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  6. 10.  2.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.69978332519531



action possibilites: [-1] 
expected returns: [[108.87252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0. 11.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  2.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.64337158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[100.91354 ]
 [107.25445 ]
 [106.679794]
 [ 93.99914 ]
 [115.27866 ]
 [109.430115]
 [111.610634]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0. 11.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  2.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.87252044677734



buy possibilites: [-1] 
expected returns: [[105.50586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0. 11.] 
cards in discard: [10. 11. 10.  3.  0.  0. 10. 11. 10.  3. 10.  0. 10. 11. 11.  0.  3. 10.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0. 25.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.27865600585938






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 25.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0. 25.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[67.73097 ]
 [79.049576]
 [64.75713 ]
 [72.21323 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 10. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  5. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.505859375



action possibilites: [-1] 
expected returns: [[81.18989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  4. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.04956817626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[72.47628 ]
 [78.488174]
 [66.08525 ]
 [81.187   ]
 [82.65033 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  4. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [29. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.18988800048828






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [29. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  6.  0.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  4. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 10.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 10.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  9.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 10.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0. 10.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[63.930847]
 [61.817657]
 [61.817657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 10.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  8.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.65032196044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.005367]
 [60.74929 ]
 [46.639187]
 [63.71692 ]
 [65.53973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 10.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  8.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.93083953857422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.  8.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.  8.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.  8.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11.  0. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[86.30512]
 [84.16332]
 [90.72731]
 [84.16332]
 [90.72731]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10. 11.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.53972625732422



action possibilites: [-1] 
expected returns: [[52.484787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 14.  3.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.21014404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.307045]
 [38.344395]
 [53.361694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 11.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 14.  3.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.48478698730469






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  0.  6.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[80.7754 ]
 [78.35567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 57.34745788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.525604]
 [62.460823]
 [80.69927 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.77540588378906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  8.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10. 10. 10. 11.] 
adversary cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[50.559303]
 [48.506775]
 [48.506775]
 [48.506775]
 [55.841934]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 11.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0. 10.  4.  1.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.69927978515625



action possibilites: [-1] 
expected returns: [[70.57694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 10.  4.  1.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.38254928588867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.449684]
 [55.227943]
 [70.89461 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10.] 
cards in discard: [25.  0.  0. 10. 11. 11. 11. 10.  3.  0.  0. 10. 15. 11. 10.  0. 10. 11.
  3. 11.  0. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 10.  4.  1.  0.] 
adversary cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.57694244384766






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  4.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  4.  1.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  4.  1.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  4.  1.  0.] 
cards in discard: [ 6. 14.  3.  0.  0. 25.  6.  3.  8. 11. 29.  6.  0.  0.  0.  0. 11.  3.
  6.  8. 22. 14.  1.  3.  0.  6.  8.  3.  0.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[86.432205]
 [89.93446 ]
 [89.93446 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 11.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.89461517333984



action possibilites: [-1] 
expected returns: [[90.69594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 11.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.40837097167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.01237]
 [87.46351]
 [73.77314]
 [90.24535]
 [91.85224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 11.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.69593811035156






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15. 10.  3. 15.  0.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [15. 10.  3. 15.  0.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6.] 
cards in discard: [15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [15. 10.  3. 15.  0.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [15. 10.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15.] 
expected returns: [[48.9585  ]
 [46.3478  ]
 [46.127975]
 [46.3478  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 15.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 25.  3. 14.  1.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.85223388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.072876]
 [33.959084]
 [49.815216]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3. 15.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 25.  3. 14.  1.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.95848846435547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0. 25.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 14.  1.] 
cards in discard: [15. 11.  3.  3.  0.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [11. 10. 10.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  1.] 
cards in discard: [15. 11.  3.  3.  0.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  1.] 
cards in discard: [15. 11.  3.  3.  0.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  1.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  1.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[59.633484]
 [58.089493]
 [64.01079 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 8. 10.  8.  3. 29.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 62.11011505126953



action possibilites: [-1] 
expected returns: [[59.30961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  8.  3. 29.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 58.45874786376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.796886]
 [43.628265]
 [59.671753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  8.  3. 29.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.309608459472656






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3. 29.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3. 29.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[40.11535 ]
 [38.08407 ]
 [44.358765]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  5.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.67174530029297



action possibilites: [-1] 
expected returns: [[102.629425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  4.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 38.528236389160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.49603]
 [ 99.82874]
 [ 86.21782]
 [102.83541]
 [105.10044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  4.] 
adversary cards in hand: [6. 8. 0. 3. 6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.62942504882812






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 10. 10. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.
 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 3. 6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  4.] 
adversary cards in hand: [10.  0. 10. 10. 11.] 
adversary cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.
 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[66.63619 ]
 [64.81968 ]
 [64.81968 ]
 [64.81968 ]
 [71.394485]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 11.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.
 11. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.1004409790039



action possibilites: [-1] 
expected returns: [[104.28581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.
 11. 10.  0.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 65.24712371826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 94.84218]
 [ 89.27437]
 [104.68989]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [15. 11.  0.  0. 11.  3. 15. 10.  3. 15.  0. 11. 10. 15. 11. 10.  0. 15.
 11. 10.  0.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  0.  0. 22.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.28581237792969






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  3.] 
adversary cards in hand: [10. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  8. 10.  0.  9.  3.] 
adversary cards in hand: [10. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 22.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [10. 11. 10. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10. 25.] 
expected returns: [[87.70172]
 [84.91004]
 [92.88753]
 [84.91004]
 [84.91004]
 [99.85472]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  4. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.68988037109375



action possibilites: [-1] 
expected returns: [[81.08236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.85472106933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.32567]
 [70.82075]
 [81.91955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.08235931396484






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 10. 15. 11.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 27. 29.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 10. 15. 11.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [15. 10. 10. 15. 11.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [15. 10. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 15. 11.] 
expected returns: [[61.094322]
 [59.893143]
 [59.775856]
 [59.775856]
 [59.893143]
 [65.30963 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 15. 11.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  3.] 
adversary cards in hand: [0. 6. 0. 6. 1.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.91954803466797



action possibilites: [-1] 
expected returns: [[80.177986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 15.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 6. 0. 6. 1.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 60.10486602783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.451836]
 [65.62822 ]
 [80.46008 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10. 15.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 6. 0. 6. 1.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.17798614501953






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0. 11. 11.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0. 11. 11.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 1.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0. 11. 11.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [10.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[47.92077 ]
 [46.11511 ]
 [51.596443]
 [51.596443]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11.  0.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  2.] 
adversary cards in hand: [14.  0. 11.  4.  6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.4600830078125



action possibilites: [-1] 
expected returns: [[97.5822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [14.  0. 11.  4.  6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 46.544403076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 91.47165]
 [ 96.4223 ]
 [ 86.04706]
 [ 98.70366]
 [100.11437]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [14.  0. 11.  4.  6.] 
adversary cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.58219909667969






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [14.  0. 11.  4.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  4.  6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0. 11. 10. 15. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  4.  6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  4.  6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  4.  6.] 
cards in discard: [15. 11.  3.  3.  0.  6. 11. 14.  0. 25.  3.  1.  8. 10.  8.  3. 29.  6.
  8.  0.  3.  6. 14.  0.  0.  0.  0. 22.  6.  4.  1.  3.  0.  0.  0.  0.
  0.  6.  0.  6.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[69.84252]
 [68.85164]
 [68.75086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3] -> size -> 47 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 14.71116828918457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.46657 ]
 [60.900818]
 [72.23261 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3] -> size -> 47 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 69.84253692626953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  7.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0. 10.] 
cards in discard: [8.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  6.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[ 96.598206]
 [100.816666]
 [ 95.108665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.  0. 15. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  6.  8.  9.  7. 10.  0.  9.  1.] 
adversary cards in hand: [ 0. 11.  8.  0.  8.] 
adversary cards in discard: [ 8.  0.  8. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3  8] -> size -> 48 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.23262786865234



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10.  0. 11. 15. 11. 15. 10. 10. 15. 15. 11. 10.  0. 11.
  0. 11. 10.  0. 15. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 25 10 10 11 11 10 11 10 11 10 10 10
 10 10 11 15 15 15 15 15 15 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  3. 10.  0.  6.  8.  9.  7. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 11.  8.  0.  8.] 
adversary cards in discard: [ 8.  0.  8. 14.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 11  6  1 29  8  6  1  0 14 25
  6  1  6  0 11  4  0 14  6  6  3  8  0 22  8  0 15 11 14  6  4  0  3  8] -> size -> 48 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0      -10        0        0       64        0] 
sum of rewards: -3000021 

action type: gain_card_n - action 8
Learning step: -120004.6484375
desired expected reward: -119909.296875



