 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 509 

action type: buy - action -1.0
Learning step: 25.973526000976562
desired expected reward: 15.502986907958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[264.03793]
 [280.73505]
 [273.62625]
 [236.11327]
 [270.7436 ]
 [289.18436]
 [274.68802]
 [276.78528]
 [249.18332]
 [270.9156 ]
 [265.09793]
 [293.7872 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.554939270019531
desired expected reward: 287.6470947265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.3349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.430731296539307
desired expected reward: 286.3564758300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[291.11462]
 [309.14197]
 [301.7558 ]
 [257.7435 ]
 [318.43085]
 [302.46378]
 [298.38925]
 [323.02728]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.432787895202637
desired expected reward: 317.61737060546875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [8. 0. 0. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.87344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.242383003234863
desired expected reward: 313.784912109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.67517]
 [297.70142]
 [291.2467 ]
 [258.29047]
 [289.34848]
 [304.6762 ]
 [293.05426]
 [294.75595]
 [269.85785]
 [289.3515 ]
 [284.40817]
 [308.16656]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.95401382446289
desired expected reward: 302.5562744140625



buy possibilites: [-1] 
expected returns: [[309.52957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 1.0
Learning step: -7.795655727386475
desired expected reward: 289.90576171875






Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[325.36447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 3. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.270977973937988
desired expected reward: 301.25860595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[298.21478]
 [313.97525]
 [307.4364 ]
 [269.46857]
 [323.4631 ]
 [307.94662]
 [304.55197]
 [328.36072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 3. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.182884216308594
desired expected reward: 315.50604248046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [3. 0. 3. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [3. 0. 3. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [3. 0. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.76242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.7982816696167
desired expected reward: 318.56243896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[284.1619 ]
 [294.82266]
 [289.52588]
 [261.58356]
 [288.707  ]
 [299.84387]
 [291.66034]
 [293.136  ]
 [272.88312]
 [288.6713 ]
 [284.7916 ]
 [302.84045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.383845329284668
desired expected reward: 290.2719421386719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.69888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.913693428039551
desired expected reward: 294.9267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[298.0173 ]
 [315.85004]
 [308.7454 ]
 [266.3978 ]
 [305.2638 ]
 [324.50293]
 [309.02426]
 [311.12653]
 [281.22913]
 [305.12448]
 [298.8491 ]
 [328.82614]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.252921104431152
desired expected reward: 316.45062255859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.2142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.50485897064209
desired expected reward: 318.3212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.12506]
 [282.34348]
 [276.85013]
 [247.76317]
 [275.54385]
 [288.24786]
 [278.44577]
 [279.9345 ]
 [258.99118]
 [275.5297 ]
 [271.75842]
 [292.80875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.732124328613281
desired expected reward: 281.7767028808594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 1. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.2347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 1. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.314993858337402
desired expected reward: 284.4937744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[280.69888]
 [297.49344]
 [289.5496 ]
 [249.87486]
 [287.24933]
 [306.46683]
 [291.16818]
 [292.97406]
 [264.6051 ]
 [286.6927 ]
 [280.96863]
 [310.1417 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 1. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.269710540771484
desired expected reward: 298.52783203125



buy possibilites: [-1] 
expected returns: [[269.83154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  1.  3.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 20 

action type: buy - action 14.0
Learning step: -5.4282755851745605
desired expected reward: 244.56143188476562






Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8  0 11  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.07007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.2619218826293945
desired expected reward: 263.5696105957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.46802]
 [285.82144]
 [279.2855 ]
 [242.8376 ]
 [277.28564]
 [292.20346]
 [280.82043]
 [282.2668 ]
 [256.43423]
 [276.65466]
 [271.3315 ]
 [293.87006]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.361452102661133
desired expected reward: 295.1788024902344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  3.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8  8  0 11  3  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 8 8 0 3 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 8 8 0 3 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 8. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 8 8 0 3 0 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[284.4727 ]
 [251.84418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 8 8 0 3 0 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -7.538066387176514
desired expected reward: 286.3320007324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[269.77905]
 [275.90643]
 [245.71924]
 [278.5531 ]
 [289.94693]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 8 8 0 3 0 0 0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.076114177703857
desired expected reward: 279.0023498535156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 8 8 0 3 0 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 8 8 0 3 0 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.70624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -6.969435214996338
desired expected reward: 282.9775390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[263.96655]
 [280.6691 ]
 [273.50415]
 [243.18983]
 [232.0194 ]
 [270.7373 ]
 [288.38797]
 [274.62793]
 [300.42868]
 [276.37015]
 [247.4584 ]
 [258.04044]
 [270.3551 ]
 [240.3347 ]
 [264.32947]
 [291.51755]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.431050777435303
desired expected reward: 287.1428527832031



buy possibilites: [-1] 
expected returns: [[224.77686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 68 

action type: buy - action 25.0
Learning step: -6.563954830169678
desired expected reward: 293.8647155761719






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [25.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [25.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [25.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [25.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[286.7905]
 [244.7125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [25.  0.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -4.168609619140625
desired expected reward: 220.60824584960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[261.50104]
 [277.03586]
 [269.48   ]
 [227.2595 ]
 [282.63528]
 [271.8395 ]
 [266.21262]
 [282.61377]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [25.  0.  3.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.117127895355225
desired expected reward: 277.0701904296875



buy possibilites: [-1] 
expected returns: [[303.3001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [25.  0.  3.  0.  1.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 11.0
Learning step: -5.507514953613281
desired expected reward: 277.1278381347656






Player: 1 
cards in hand: [8. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8  8  0  3  0  0  0 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[255.25775]
 [215.65872]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -8.756305694580078
desired expected reward: 294.5437927246094



action possibilites: [-1] 
expected returns: [[261.90872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action 14.0
Learning step: -2.997610569000244
desired expected reward: 212.8135223388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[231.30385]
 [246.12033]
 [239.92291]
 [213.70453]
 [204.47517]
 [237.32262]
 [253.13007]
 [240.67738]
 [263.6978 ]
 [242.24689]
 [217.39511]
 [226.23932]
 [237.07555]
 [211.45364]
 [231.73177]
 [256.87158]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -5.579831123352051
desired expected reward: 256.3288879394531



buy possibilites: [-1] 
expected returns: [[280.43597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3. 0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 121 

action type: buy - action 4.0
Learning step: 1.6745834350585938
desired expected reward: 215.37908935546875






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 29.  8. 10. 10.  8.  7.  9. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  8.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8. 10. 10.  8.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[251.33772]
 [271.79767]
 [254.23447]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11.  0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8. 10. 10.  8.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -5.489117622375488
desired expected reward: 274.9468688964844



action possibilites: [-1] 
expected returns: [[291.2179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.  3.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: -2.9932687282562256
desired expected reward: 259.920166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.60477]
 [289.71555]
 [283.3571 ]
 [247.22334]
 [281.33   ]
 [295.74048]
 [284.63623]
 [285.9932 ]
 [261.11774]
 [280.57388]
 [275.42432]
 [297.89087]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  3.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: -4.504794597625732
desired expected reward: 286.7131042480469



buy possibilites: [-1] 
expected returns: [[303.93692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.  3.] 
cards in discard: [ 4. 14.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.   0.   6.  50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 75.5 

action type: buy - action 10.0
Learning step: -3.415112257003784
desired expected reward: 277.15875244140625






Player: 1 
cards in hand: [ 0. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.  0.] 
cards in discard: [6. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[233.24748]
 [229.38411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  1.  0. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: -6.940204620361328
desired expected reward: 296.9967041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[207.6394 ]
 [221.37738]
 [215.69815]
 [181.16226]
 [228.3486 ]
 [216.22816]
 [213.21127]
 [232.35065]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  8.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  1.  0. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -3.531911611557007
desired expected reward: 228.769775390625



buy possibilites: [-1] 
expected returns: [[207.5846]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.  3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  1.  0. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: -2.7967758178710938
desired expected reward: 225.55178833007812






Player: 1 
cards in hand: [8. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [ 6.  1.  0. 10. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  4. 14. 10.  0.] 
adversary cards in discard: [11.  0. 11.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 8. 0.] 
cards in discard: [ 6.  1.  0. 10. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  4. 14. 10.  0.] 
adversary cards in discard: [11.  0. 11.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  4. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[249.00545]
 [213.54768]
 [232.29155]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 14. 10.  0.] 
cards in discard: [11.  0. 11.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: -1.9875701665878296
desired expected reward: 205.59703063964844



action possibilites: [-1] 
expected returns: [[225.65643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 10.  0.] 
cards in discard: [11.  0. 11.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action 14.0
Learning step: -1.391791582107544
desired expected reward: 208.98944091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[199.36028]
 [216.52988]
 [209.72252]
 [166.84529]
 [206.33043]
 [223.88675]
 [209.69916]
 [211.54091]
 [182.64821]
 [205.91386]
 [199.73503]
 [227.22235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 10.  0.] 
cards in discard: [11.  0. 11.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 0.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: -2.363264560699463
desired expected reward: 223.2931671142578






Player: 1 
cards in hand: [1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3.  1.  3. 14.  0.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3.  1.  3. 14.  0.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0.  6. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [11.  0. 11.  3.  1.  3. 14.  0.  4. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[175.07141]
 [181.96309]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [11.  0. 11.  3.  1.  3. 14.  0.  4. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  9. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  6. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -4.268439769744873
desired expected reward: 222.9539031982422



action possibilites: [-1] 
expected returns: [[256.3641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14  6] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 83 

action type: take_action - action 25.0
Learning step: 0.8589081168174744
desired expected reward: 182.04458618164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[223.77873]
 [238.92728]
 [232.1236 ]
 [202.0699 ]
 [189.77812]
 [230.08429]
 [244.49939]
 [233.88884]
 [256.1705 ]
 [235.13329]
 [205.45644]
 [217.37971]
 [228.83774]
 [198.17714]
 [223.11046]
 [245.6058 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  9. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14  6] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: -3.340994358062744
desired expected reward: 253.0231170654297



buy possibilites: [-1] 
expected returns: [[167.2374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14  6] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 131 

action type: buy - action 25.0
Learning step: -2.495684862136841
desired expected reward: 253.6748504638672






Player: 1 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  3  0  0  0 10  8  0 10  6  1 14  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  4.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  4.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  6. 14.  1.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  4.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  6. 14.  1.  0.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  4.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  0. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[128.80194]
 [ 93.82647]
 [128.81223]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 11.  4.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: -2.527345657348633
desired expected reward: 164.71005249023438



action possibilites: [-1] 
expected returns: [[195.20601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  4.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 90 

action type: gain_card_n - action 9
Learning step: 2.1406686305999756
desired expected reward: 136.72259521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[171.09215]
 [180.28564]
 [144.6801 ]
 [179.445  ]
 [196.6396 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  4.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: -1.528218150138855
desired expected reward: 193.67779541015625






Player: 1 
cards in hand: [ 0.  3. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  3.  1.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10. 11.  0. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10] -> size -> 19 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  3.  1.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10. 11.  0. 14.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10] -> size -> 19 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[114.549995]
 [101.982346]
 [113.05822 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3.  1.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10. 11.  0. 14.  0.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  6.  1.] 
adversary cards in discard: [ 0.  3. 10.  0.  8.] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -4.409876346588135
desired expected reward: 192.22972106933594



action possibilites: [-1] 
expected returns: [[186.80708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  1.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10. 11.  0. 14.  0.  4. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  6.  1.] 
adversary cards in discard: [ 0.  3. 10.  0.  8.] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 90 

action type: gain_card_n - action 9
Learning step: 3.2485196590423584
desired expected reward: 112.34131622314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[169.92993]
 [174.82303]
 [148.7962 ]
 [177.21725]
 [185.28014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  0. 10. 11.  0. 14.  0.  4. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  6.  1.] 
adversary cards in discard: [ 0.  3. 10.  0.  8.] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: -1.2750542163848877
desired expected reward: 185.5320281982422






Player: 1 
cards in hand: [ 3. 14.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  6.  1.] 
cards in discard: [ 0.  3. 10.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  6.  1.] 
cards in discard: [ 0.  3. 10.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[158.37149]
 [156.31386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  4.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -2.738030195236206
desired expected reward: 182.5420684814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[133.86844 ]
 [146.77556 ]
 [140.95221 ]
 [111.965935]
 [152.43593 ]
 [142.0094  ]
 [138.32445 ]
 [154.34213 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  4.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.] 
adversary owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -1.382177710533142
desired expected reward: 153.60446166992188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3  0  0  0  8  0 10  6  1 14  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3. 10.  0.  8.  3. 14.  0.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[196.62581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 0.  0. 11.  4.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -0.7741188406944275
desired expected reward: 153.5679931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[175.22798]
 [190.17221]
 [184.39914]
 [146.4528 ]
 [181.29614]
 [197.3941 ]
 [184.2278 ]
 [185.82442]
 [160.62466]
 [181.17494]
 [175.78914]
 [200.51895]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 0.  0. 11.  4.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -2.9215447902679443
desired expected reward: 192.32232666015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 14. 10. 11.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 14. 10. 11.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 14. 10. 11.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 14. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 10. 11.] 
expected returns: [[201.30423]
 [185.05276]
 [166.43909]
 [185.05276]
 [199.31055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14. 10. 11.] 
cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  3.  8. 10.  8.] 
adversary cards in discard: [1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: -3.143298387527466
desired expected reward: 197.37562561035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[178.0547 ]
 [152.40215]
 [199.4955 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14. 10. 11.] 
cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  3.  8. 10.  8.] 
adversary cards in discard: [1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -3.193871259689331
desired expected reward: 196.47210693359375



buy possibilites: [-1] 
expected returns: [[201.2956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14. 10. 11.] 
cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  7. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  3.  8. 10.  8.] 
adversary cards in discard: [1. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0  1] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5    0    5   40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -260 

action type: buy - action 6.0
Learning step: -16.090957641601562
desired expected reward: 136.3112030029297






Player: 1 
cards in hand: [14.  3.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 10.  8.] 
cards in discard: [1. 3. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  0  0  0  8  0 10  1 14  6  3  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  7. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 25. 25.  0.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.  6.  3. 10. 14. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [1. 3. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  7. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 25. 25.  0.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.  6.  3. 10. 14. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [1. 3. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  7. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 25. 25.  0.] 
adversary cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.  6.  3. 10. 14. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[192.56859]
 [175.9462 ]
 [201.9114 ]
 [201.9114 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25. 25.  0.] 
cards in discard: [ 0.  0. 11.  4.  0.  3.  0.  0.  3.  1.  6.  3. 10. 14. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  7. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -3.7258870601654053
desired expected reward: 197.5697021484375



action possibilites: [-1] 
expected returns: [[144.50626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 61 

action type: take_action - action 25.0
Learning step: -3.554885149002075
desired expected reward: 193.5706329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.8873 ]
 [142.52   ]
 [135.56865]
 [105.62242]
 [146.29607]
 [138.65045]
 [133.04495]
 [145.22995]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 25.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 28. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: -1.0612205266952515
desired expected reward: 143.44503784179688



buy possibilites: [-1] 
expected returns: [[182.85455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 25.  0. 11.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 73.0 

action type: buy - action 3.0
Learning step: 1.005702257156372
desired expected reward: 136.5743408203125






Player: 1 
cards in hand: [14.  1.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  1.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 8 
card supply: [24. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 8 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[108.32119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  60   0   0   0 -60   0   0   0   0   0   0 128   0] 
sum of rewards: 129 

action type: discard_down_to_3_cards - action 5
Learning step: 2.8867766857147217
desired expected reward: 123.49502563476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 86.37939 ]
 [ 93.79773 ]
 [ 65.90213 ]
 [ 92.829666]
 [109.748024]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  7.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -0.18167991936206818
desired expected reward: 109.47117614746094



buy possibilites: [-1] 
expected returns: [[76.56068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
adversary owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 69 

action type: buy - action 8.0
Learning step: 0.5311332941055298
desired expected reward: 93.36077117919922






Player: 1 
cards in hand: [6. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  8  0  1 14  6  3  0  1  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  1.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  1.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0. 14.  1.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  1.  3.  0.] 
adversary cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [14. 10.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[44.387783]
 [20.497301]
 [33.704693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  1.  3.  0.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1
Learning step: 0.5721378326416016
desired expected reward: 77.1328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.136482]
 [41.08561 ]
 [35.841206]
 [13.604244]
 [44.640144]
 [37.70757 ]
 [33.842564]
 [44.991096]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  1.  3.  0.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  5. 10. 10.] 
adversary cards in hand: [1. 1. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: 2.294611930847168
desired expected reward: 45.546142578125



buy possibilites: [-1] 
expected returns: [[50.117104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  1.  3.  0.] 
cards in discard: [ 3. 25.  0. 10. 25.  0. 11.  0. 10.  3.  8.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  4. 10. 10.] 
adversary cards in hand: [1. 1. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 89 

action type: buy - action 10.0
Learning step: 3.885507583618164
desired expected reward: 37.728050231933594






Player: 1 
cards in hand: [1. 1. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  1 14  6  3  0  1  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10] -> size -> 24 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10] -> size -> 24 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  4. 10. 10.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10] -> size -> 24 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[120.63101 ]
 [107.218056]
 [119.91528 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  4.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [8. 1. 0. 3.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1
Learning step: 3.6724109649658203
desired expected reward: 53.789512634277344



action possibilites: [-1] 
expected returns: [[129.1617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  4.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [8. 1. 0. 3.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 100 

action type: gain_card_n - action 9
Learning step: 1.8240422010421753
desired expected reward: 123.46595764160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.08683]
 [ 90.33934]
 [131.62772]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  4.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  6. 14.] 
adversary cards in discard: [8. 1. 0. 3.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action -1
Learning step: 0.8359733819961548
desired expected reward: 129.99766540527344






Player: 1 
cards in hand: [ 0.  0.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 14.] 
cards in discard: [8. 1. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 14.] 
cards in discard: [8. 1. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 14.] 
cards in discard: [8. 1. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[145.70325]
 [130.58748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10. 11. 10.  6.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: 0.13402175903320312
desired expected reward: 131.76173400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[129.48674]
 [141.73856]
 [136.90521]
 [106.64919]
 [134.43323]
 [147.1538 ]
 [136.72612]
 [137.82974]
 [117.3218 ]
 [133.83867]
 [129.35313]
 [149.31288]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10. 11. 10.  6.  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1.0
Learning step: -0.47917404770851135
desired expected reward: 143.8221893310547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8. 14. 11. 25.  3.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8. 14. 11. 25.  3.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8. 14. 11. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11. 25.] 
expected returns: [[72.692566]
 [63.373787]
 [48.836   ]
 [71.31179 ]
 [78.84985 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 11. 25.  3.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25 11  4 10 11 25 10 10  6  3  8 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: -2.3083279132843018
desired expected reward: 147.00454711914062



action possibilites: [-1] 
expected returns: [[115.88929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  3.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: trash_cards_n_from_hand - action 0
Learning step: 4.158026695251465
desired expected reward: 63.822174072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.93369]
 [ 78.14338]
 [120.08653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  3.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action -1
Learning step: 1.2462199926376343
desired expected reward: 117.13551330566406






Player: 1 
cards in hand: [6. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [ 0. 14.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 10.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [ 0. 14.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [25.  0.  3.  3. 10.] 
adversary cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[106.4448 ]
 [113.59566]
 [ 97.31886]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  3. 10.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: buy - action -1.0
Learning step: -0.058047104626894
desired expected reward: 120.02849578857422



action possibilites: [-1. 25. 10.] 
expected returns: [[119.20242 ]
 [127.537346]
 [107.96233 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  3. 10.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action 10.0
Learning step: 2.5971546173095703
desired expected reward: 97.01599884033203



action possibilites: [-1. 25.] 
expected returns: [[ 99.84173 ]
 [107.274956]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  3.  3.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  6. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action 10.0
Learning step: 2.525024175643921
desired expected reward: 110.48735809326172



action possibilites: [-1.] 
expected returns: [[125.87374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1. 0.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6] -> size -> 12 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 60  0  0  0  0  0  0  0  0  3] 
sum of rewards: 134 

action type: take_action - action 25.0
Learning step: 4.168412685394287
desired expected reward: 111.44335174560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.387375]
 [108.62105 ]
 [104.040794]
 [ 79.375374]
 [102.41478 ]
 [113.636086]
 [104.754265]
 [105.68718 ]
 [ 88.22524 ]
 [101.92838 ]
 [ 98.25775 ]
 [115.9031  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1. 0.] 
cards in discard: [10. 11. 10.  6.  4.  0.  0.  0.  0. 10.  0.  8. 14. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [14.  0.  0.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6] -> size -> 12 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 70  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 131 

action type: take_action - action -1.0
Learning step: 2.7099416255950928
desired expected reward: 128.58367919921875






Player: 1 
cards in hand: [14.  0.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  8.  1.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  8.  1.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  8.  1.] 
cards in discard: [ 6. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 0. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[78.36952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  0.  0.  8.  1.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: buy - action -1.0
Learning step: -0.03384094312787056
desired expected reward: 115.86924743652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.275436]
 [61.603634]
 [31.330442]
 [62.652508]
 [76.92752 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  0.  0.  8.  1.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1.0
Learning step: 1.7644577026367188
desired expected reward: 77.8228530883789



buy possibilites: [-1] 
expected returns: [[93.469765]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 4. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  0.  0.  8.  1.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 51.0 

action type: buy - action 0.0
Learning step: 1.939296007156372
desired expected reward: 56.21477127075195






Player: 1 
cards in hand: [6. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [ 6. 14. 14.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [0. 3. 3. 0. 4. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [ 6. 14. 14.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [0. 3. 3. 0. 4. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[193.4463 ]
 [156.26718]
 [174.73232]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 10.] 
cards in discard: [0. 3. 3. 0. 4. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: buy - action -1
Learning step: 3.4089558124542236
desired expected reward: 96.87872314453125



action possibilites: [-1. 14. 25.] 
expected returns: [[146.81009 ]
 [106.741196]
 [155.39345 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 25.] 
cards in discard: [0. 3. 3. 0. 4. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 101 

action type: take_action - action 10.0
Learning step: -0.1369979828596115
desired expected reward: 169.36734008789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[124.81277]
 [133.84158]
 [ 97.45874]
 [134.03212]
 [150.2464 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0. 25.] 
cards in discard: [0. 3. 3. 0. 4. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 14. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 0.8482017517089844
desired expected reward: 147.65826416015625






Player: 1 
cards in hand: [ 0. 14. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  6.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 14.  8.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  5.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  3.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[90.900955]
 [79.46906 ]
 [79.46906 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  3.] 
cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  5.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 1.] 
adversary cards in discard: [ 8.  0. 14. 14.  8.  0.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8] -> size -> 14 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: buy - action -1.0
Learning step: -1.6383975744247437
desired expected reward: 148.60801696777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[76.298584]
 [81.60418 ]
 [55.280964]
 [83.98146 ]
 [90.70641 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.  3.] 
cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  5.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 1.] 
adversary cards in discard: [ 8.  0. 14. 14.  8.  0.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8] -> size -> 14 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1.0
Learning step: 1.7122917175292969
desired expected reward: 86.41909790039062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 1.] 
cards in discard: [ 8.  0. 14. 14.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  5.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 25.  8.  0.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 1.] 
cards in discard: [ 8.  0. 14. 14.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  5.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 25.  8.  0.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 1.] 
cards in discard: [ 8.  0. 14. 14.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [10. 25.  8.  0.  1.] 
adversary cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 25.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.] 
expected returns: [[120.17979]
 [109.42179]
 [132.75809]
 [114.95558]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  8.  0.  1.] 
cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  5. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8] -> size -> 15 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: buy - action -1.0
Learning step: 2.3585751056671143
desired expected reward: 93.06500244140625



action possibilites: [-1] 
expected returns: [[90.641106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  1.  6. 11.] 
cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 101 

action type: take_action - action 25.0
Learning step: 0.4326332211494446
desired expected reward: 133.27484130859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.139248]
 [57.057476]
 [52.87687 ]
 [35.539024]
 [61.694515]
 [53.291317]
 [50.937428]
 [63.3858  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  1.  6. 11.] 
cards in discard: [ 0.  3.  3.  0.  4.  0. 10.  0. 14.  3.  0. 25.  0. 10.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 101 

action type: take_action - action -1
Learning step: 1.829352617263794
desired expected reward: 92.470458984375






Player: 1 
cards in hand: [0. 1. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [25. 10.  0.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7. 10.  3. 10. 10.] 
adversary cards in hand: [25. 10.  0.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [ 6. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6 23] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25. 10.  0.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25. 10.  0.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[89.00381 ]
 [95.377174]
 [74.695755]
 [74.695755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  4. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [14.  3.  6.  8.  0.] 
adversary cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6 23] -> size -> 17 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: buy - action -1.0
Learning step: 3.300982713699341
desired expected reward: 66.68678283691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.51208]
 [47.86807]
 [86.22101]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0.  4. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 29.  8.  4. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [14.  3.  6.  8.  0.] 
adversary cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6 23] -> size -> 17 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action -1.0
Learning step: 2.035154342651367
desired expected reward: 87.05420684814453



buy possibilites: [-1] 
expected returns: [[111.218605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0.  4. 10.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [14.  3.  6.  8.  0.] 
adversary cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6 23] -> size -> 17 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -220.0 

action type: buy - action 6.0
Learning step: -10.890985488891602
desired expected reward: 36.977088928222656






Player: 1 
cards in hand: [14.  3.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  8.  0.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 14  6  3  0  1  6  0  0  6 14  8  8  6 23] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
expected returns: [[69.57216 ]
 [54.993374]
 [54.993374]
 [40.34229 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10. 14.] 
cards in discard: [ 6. 25. 10.  0.  4. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  0.  8.] 
adversary cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0] -> size -> 15 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: buy - action -1
Learning step: -0.24807320535182953
desired expected reward: 110.97053527832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.79117]
 [33.06335]
 [68.69398]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 10. 14.] 
cards in discard: [ 6. 25. 10.  0.  4. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  0.  8.] 
adversary cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0] -> size -> 15 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action -1.0
Learning step: 2.0755813121795654
desired expected reward: 67.51009368896484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 14.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  8.  0.  8.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  8.  0.  8.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  8.  0.  8.] 
cards in discard: [ 6. 23.  0.  1.  6.  0.  0.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  8.  6.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[6.269044 ]
 [1.0355327]
 [3.3995636]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  6.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: buy - action -1.0
Learning step: 0.5581383109092712
desired expected reward: 69.2520980834961



action possibilites: [-1.  8.] 
expected returns: [[43.941425]
 [35.53037 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  6  3  8 10 10
  0  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 80  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 101 

action type: take_action - action 10.0
Learning step: 6.197573184967041
desired expected reward: 2.1021595001220703



action possibilites: [-1.] 
expected returns: [[61.038624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 131 

action type: trash_cards_n_from_hand - action 1
Learning step: 5.976731777191162
desired expected reward: 44.90946578979492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[45.367607]
 [53.55171 ]
 [50.86452 ]
 [32.48514 ]
 [58.40094 ]
 [49.91185 ]
 [49.117947]
 [61.835873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  8. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 131 

action type: take_action - action -1.0
Learning step: 4.7623491287231445
desired expected reward: 65.80097198486328






Player: 1 
cards in hand: [ 0.  8. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  8  0  0  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 16 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0] -> size -> 13 
action values: 0 
buys: 2 
player value: 2 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  4.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 29.  8.  3. 10.  7.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 29.  8.  3. 10.  7.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [25.  3.  3.  0.  1.] 
adversary cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[46.947285]
 [51.988407]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  0.  1.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 29.  8.  3. 10.  7.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  6.  0.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0] -> size -> 15 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: buy - action -1.0
Learning step: 2.55354380607605
desired expected reward: 64.38941192626953



action possibilites: [-1] 
expected returns: [[83.02475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1.  0. 11.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 29.  8.  2. 10.  7.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  6.  0.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.  6.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 112 

action type: take_action - action 25.0
Learning step: 4.9725189208984375
desired expected reward: 54.8832893371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.84645 ]
 [78.265076]
 [74.03693 ]
 [53.6023  ]
 [73.221306]
 [81.21826 ]
 [75.345375]
 [75.93467 ]
 [60.750145]
 [72.27166 ]
 [69.09922 ]
 [81.53399 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1.  0. 11.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 27. 29.  8.  2. 10.  7.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  6.  0.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.  6.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action -1
Learning step: 3.130290985107422
desired expected reward: 86.15504455566406



buy possibilites: [-1] 
expected returns: [[64.359764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1.  0. 11.] 
cards in discard: [ 6. 25. 10.  0.  4. 10. 10.  3.  3. 10. 14. 10.  8.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 6. 14.  8.  6.  0.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.  6.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6] -> size -> 16 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5.   0.   6.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 115.5 

action type: buy - action 11.0
Learning step: 3.162182569503784
desired expected reward: 84.38043212890625






Player: 1 
cards in hand: [ 6. 14.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  8.  6.  0.] 
cards in discard: [ 8.  0. 23.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  8.  6.  0.] 
cards in discard: [ 8.  0. 23.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  8.  6.  0.] 
cards in discard: [ 8.  0. 23.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[103.40696]
 [ 94.05997]
 [ 85.74998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 1. 8. 6.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.  6.  0.  6. 14.  8.  6.  0.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1
Learning step: 3.993309497833252
desired expected reward: 68.35307312011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.6204  ]
 [ 95.82653 ]
 [ 80.31398 ]
 [ 96.90829 ]
 [104.837265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 1. 8. 6.] 
adversary cards in discard: [ 8.  0. 23.  8.  0.  6.  0.  6. 14.  8.  6.  0.] 
adversary owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 17 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 2.1878929138183594
desired expected reward: 104.26435852050781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 6.] 
cards in discard: [ 8.  0. 23.  8.  0.  6.  0.  6. 14.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  6  0  0  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10. 25. 25. 11.  0.] 
adversary cards in discard: [ 3. 10. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0. 23.  8.  0.  6.  0.  6. 14.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10. 25. 25. 11.  0.] 
adversary cards in discard: [ 3. 10. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0. 23.  8.  0.  6.  0.  6. 14.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [10. 25. 25. 11.  0.] 
adversary cards in discard: [ 3. 10. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 25. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25. 11.] 
expected returns: [[56.76351 ]
 [45.116222]
 [61.3612  ]
 [61.3612  ]
 [55.009857]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 25. 11.  0.] 
cards in discard: [ 3. 10. 14.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  2. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 23.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: buy - action -1.0
Learning step: 0.5632385611534119
desired expected reward: 105.4005355834961



action possibilites: [-1] 
expected returns: [[49.08831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11.  0.  3.  0.] 
cards in discard: [ 3. 10. 14.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 23.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 112 

action type: take_action - action 25.0
Learning step: 3.783583164215088
desired expected reward: 62.201663970947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.760414]
 [49.325623]
 [31.049673]
 [47.716343]
 [57.568687]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25. 11.  0.  3.  0.] 
cards in discard: [ 3. 10. 14.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 23.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6] -> size -> 14 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action -1
Learning step: 4.2634100914001465
desired expected reward: 53.35171890258789






Player: 1 
cards in hand: [ 8.  0.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 23.  6.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6] -> size -> 14 
action values: 0 
buys: 2 
player value: 3 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [ 6. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 8.] 
cards in discard: [ 6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 11.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[51.236313]
 [50.74598 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [14.  8.  0.  8.  6.] 
adversary cards in discard: [ 6. 10.  0. 23.  8.  0.  0.  6.  8.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 3.2866952419281006
desired expected reward: 60.85539627075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.78098 ]
 [45.17505 ]
 [40.530025]
 [22.54697 ]
 [17.94617 ]
 [38.62928 ]
 [49.290215]
 [41.17476 ]
 [56.48837 ]
 [41.797607]
 [24.638784]
 [31.064459]
 [38.112892]
 [21.107437]
 [34.417084]
 [49.709057]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  8. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [14.  8.  0.  8.  6.] 
adversary cards in discard: [ 6. 10.  0. 23.  8.  0.  0.  6.  8.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 3.621481418609619
desired expected reward: 53.296913146972656



buy possibilites: [-1] 
expected returns: [[62.911148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [14.  8.  0.  8.  6.] 
adversary cards in discard: [ 6. 10.  0. 23.  8.  0.  0.  6.  8.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 151 

action type: buy - action 25.0
Learning step: 6.141081809997559
desired expected reward: 62.62946319580078






Player: 1 
cards in hand: [14.  8.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  8.  6.] 
cards in discard: [ 6. 10.  0. 23.  8.  0.  0.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 6.  3.  4.  3. 10.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0. 25.  0.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.  8.  6.] 
cards in discard: [ 6. 10.  0. 23.  8.  0.  0.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 6.  3.  4.  3. 10.] 
adversary cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0. 25.  0.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  4.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[38.68853 ]
 [32.220924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  4.  3. 10.] 
cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0. 25.  0.  1.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 8. 23. 14.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1
Learning step: 2.7396562099456787
desired expected reward: 65.65080261230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.662268]
 [22.74496 ]
 [37.878746]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  4.  3. 10.] 
cards in discard: [ 3. 10. 14.  0.  0. 25. 10. 25. 11.  0.  3.  0. 25.  0.  1.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 8. 23. 14.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 3.882934331893921
desired expected reward: 42.571449279785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 23. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 14.  0.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [1. 0. 8.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0] -> size -> 16 
action values: 0 
buys: 2 
player value: 5 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2. 10. 10.] 
adversary cards in hand: [1. 0. 8.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [1. 0. 8.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0.] 
cards in discard: [22.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [1. 0. 8.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[88.65495]
 [78.4363 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14 25  4 10 11 25 10 10  3  8 10 10  0
  6 11 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0 -90   0   0   0   0   0   0 179   0] 
sum of rewards: 190 

action type: discard_down_to_3_cards - action 3
Learning step: 11.06679916381836
desired expected reward: 16.870441436767578



action possibilites: [-1] 
expected returns: [[41.654404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 121 

action type: trash_cards_n_from_hand - action 1
Learning step: 3.131718873977661
desired expected reward: 80.2418212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.63689 ]
 [23.587591]
 [42.62262 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 121 

action type: take_action - action -1
Learning step: 4.824392795562744
desired expected reward: 46.478797912597656






Player: 1 
cards in hand: [ 0. 10.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  8.  0.] 
cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 10.  4. 11.  0.] 
adversary cards in discard: [10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 10.  4. 11.  0.] 
adversary cards in discard: [10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 10.  4. 11.  0.] 
adversary cards in discard: [10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [22.  0. 23. 14.  8.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 10.  4. 11.  0.] 
adversary cards in discard: [10. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  4. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[69.82199 ]
 [55.32485 ]
 [69.056465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  4. 11.  0.] 
cards in discard: [10. 10.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 19 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 4.328728199005127
desired expected reward: 46.95135498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.987114]
 [31.70215 ]
 [67.08739 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  4. 11.  0.] 
cards in discard: [10. 10.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [8. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 19 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 3.1103408336639404
desired expected reward: 68.20291137695312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[72.300804]
 [78.04093 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  3.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 8. 23.  0.  6. 14.] 
adversary cards in discard: [0. 8. 0. 6. 8.] 
adversary owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: buy - action -1.0
Learning step: 2.6442573070526123
desired expected reward: 74.62975311279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[52.260426]
 [60.583836]
 [29.069101]
 [60.85975 ]
 [71.42031 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 25.  3.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 8. 23.  0.  6. 14.] 
adversary cards in discard: [0. 8. 0. 6. 8.] 
adversary owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 91 

action type: take_action - action -1.0
Learning step: 2.502244710922241
desired expected reward: 71.97859954833984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 23.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  6. 14.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 25. 10. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1.  8. 14. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 14. 22.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 11. 25. 10. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 22.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 25. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 22.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0] -> size -> 19 
action values: 0 
buys: 2 
player value: 4 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  7.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 25. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 22.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 25. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 22.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 3. 25. 25.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[60.332256]
 [66.76584 ]
 [66.76584 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  1. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.] 
adversary owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0] -> size -> 21 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  90   0   0   0   0   0   0   0   0   0   0 170   0] 
sum of rewards: 261 

action type: discard_down_to_3_cards - action 1
Learning step: 13.434622764587402
desired expected reward: 35.318885803222656



action possibilites: [-1] 
expected returns: [[39.354797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  6.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
adversary owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 112 

action type: take_action - action 25.0
Learning step: 3.1471924781799316
desired expected reward: 69.91300201416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.898643]
 [40.29335 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  6.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
adversary owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 111 

action type: take_action - action -1
Learning step: 4.459434509277344
desired expected reward: 43.814231872558594






Player: 1 
cards in hand: [ 0. 10.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  8.  0.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 14. 10.  0.  0.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 14  8  8  6 23  0  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 14. 10.  0.  0.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 14. 10.  0.  0.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 14. 10.  0.  0.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  8.  0.  6.  8. 14.  0. 23. 14.  8.  0.  6. 22.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 14. 10.  0.  0.] 
adversary cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[ 4.201024  ]
 [-7.2152863 ]
 [-0.74180484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  0.  0.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 6. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 3.070366859436035
desired expected reward: 43.363704681396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.327016  ]
 [ 1.6592243 ]
 [-0.70915556]
 [ 3.296275  ]
 [-0.7493818 ]
 [-3.174955  ]
 [ 2.7365096 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  0.  0.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  6.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 6. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 4.873061656951904
desired expected reward: 9.074075698852539



buy possibilites: [-1] 
expected returns: [[42.14043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  0.  0.] 
cards in discard: [10. 10.  8.  0.  3. 10.  4. 11.  0.  0.  0.  3. 25.  3. 11. 10. 25.  3.
 25.  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 6. 22.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 6.733346462249756
desired expected reward: 10.02961540222168






Player: 1 
cards in hand: [ 6. 22.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10. 10.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10. 10.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10. 10.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[92.01259]
 [83.38492]
 [83.38492]
 [83.38492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [23.  6.  0.  0. 10.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1] -> size -> 23 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1
Learning step: 4.867936611175537
desired expected reward: 47.008365631103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[80.095  ]
 [91.29399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [23.  6.  0.  0. 10.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1] -> size -> 23 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 2.6084721088409424
desired expected reward: 91.29959869384766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  0.  0. 10.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10.  0. 25. 11. 25.] 
adversary cards in discard: [10. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.  0. 10.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10.  0. 25. 11. 25.] 
adversary cards in discard: [10. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.  0. 10.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [10.  0. 25. 11. 25.] 
adversary cards in discard: [10. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [10.  0. 25. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11. 25.] 
expected returns: [[80.661865]
 [69.19035 ]
 [84.18137 ]
 [78.78202 ]
 [84.18137 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 11. 25.] 
cards in discard: [10. 10.  0. 10.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 8. 14.  8.  8. 14.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 2.265759229660034
desired expected reward: 93.55975341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.1426 ]
 [77.92802]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25. 11. 25.] 
cards in discard: [10. 10.  0. 10.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 8. 14.  8.  8. 14.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 2.8266208171844482
desired expected reward: 80.74882507324219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 14.  8.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  8.  8. 14.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0. 14. 10.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  8.  8. 14.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0. 14. 10.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  8.  8. 14.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [11.  3.  0. 14. 10.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.] 
expected returns: [[46.29547 ]
 [45.48771 ]
 [30.941984]
 [39.014874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 14. 10.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.  8. 14.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 2.131312608718872
desired expected reward: 80.0593490600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.020733]
 [45.313915]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 14. 10.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.  8. 14.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: take_action - action -1.0
Learning step: 3.6986443996429443
desired expected reward: 49.99409484863281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.  8. 14.  8.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [25.  0.  3.  4.  0.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.  8. 14.  8.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [25.  0.  3.  4.  0.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [ 1.  6. 22.  0.  0.  0.  0. 23.  6.  0.  0. 10.  0.  8. 14.  8.  8. 14.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [25.  0.  3.  4.  0.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[51.269566]
 [56.378693]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  4.  0.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 101 

action type: buy - action -1.0
Learning step: 4.024956703186035
desired expected reward: 49.338863372802734



action possibilites: [-1] 
expected returns: [[76.04751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 0. 3. 8.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 121 

action type: take_action - action 25.0
Learning step: 4.821872234344482
desired expected reward: 63.605812072753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[66.931435]
 [69.86486 ]
 [70.90709 ]
 [75.71817 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3. 8.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 27. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 121 

action type: take_action - action -1
Learning step: 3.898233413696289
desired expected reward: 79.94573974609375



buy possibilites: [-1] 
expected returns: [[26.612648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3. 8.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 140 

action type: buy - action 3.0
Learning step: 4.105541229248047
desired expected reward: 73.97041320800781






Player: 1 
cards in hand: [0. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3] -> size -> 28 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 25. 30. 26. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3] -> size -> 28 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[31.071692]
 [27.919281]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9. 10.] 
adversary cards in hand: [14.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1
Learning step: 4.451285362243652
desired expected reward: 31.063934326171875



action possibilites: [-1] 
expected returns: [[26.000628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [14.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 138 

action type: gain_card_n - action 9
Learning step: 5.950578689575195
desired expected reward: 36.63928985595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.014136]
 [18.270773]
 [15.036332]
 [21.7607  ]
 [15.587321]
 [13.537673]
 [22.22671 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 10.  0. 10.  6. 10.  0. 25. 11. 25. 11.  3.  0. 14. 10.  3. 25.  0.
  3.  4.  0.  3.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [14.  0.  0.  0.  1.] 
adversary cards in discard: [3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action -1
Learning step: 5.240609169006348
desired expected reward: 31.24123764038086






Player: 1 
cards in hand: [14.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  1.] 
cards in discard: [3. 0. 0. 1. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [3. 0. 0. 1. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [3. 0. 0. 1. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[74.98435 ]
 [69.231094]
 [67.10262 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [6. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0 195   0] 
sum of rewards: 297 

action type: discard_down_to_3_cards - action 6
Learning step: 16.98217010498047
desired expected reward: 6.558894157409668





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.279232]
 [72.95661 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [6. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: take_action - action -1.0
Learning step: 3.003340482711792
desired expected reward: 76.71126556396484



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  0  8  0  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3. 25. 25.  0. 25.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3. 25. 25.  0. 25.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3. 25. 25.  0. 25.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3. 25. 25.  0. 25.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[41.98716 ]
 [46.306507]
 [46.306507]
 [46.306507]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  0. 25.] 
cards in discard: [ 6.  0.  8.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 14. 23. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1.0
Learning step: 2.482285261154175
desired expected reward: 75.43890380859375



action possibilites: [-1] 
expected returns: [[11.9997015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 25. 10. 15.] 
cards in discard: [ 6.  0.  8.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 14. 23. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action 25.0
Learning step: 4.054666996002197
desired expected reward: 50.3611946105957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 2.8042066]
 [11.48724  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 25. 10. 15.] 
cards in discard: [ 6.  0.  8.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 14. 23. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action -1
Learning step: 5.711114883422852
desired expected reward: 17.7108154296875



buy possibilites: [-1] 
expected returns: [[53.70287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 25. 10. 15.] 
cards in discard: [ 6.  0.  8.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 14. 23. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7. 100.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 92.0 

action type: buy - action 0.0
Learning step: 5.668105602264404
desired expected reward: 8.472278594970703






Player: 1 
cards in hand: [ 0. 22. 14. 23. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 14. 23. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [3. 4. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22. 14. 23. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [3. 4. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 4. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[47.54461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0. 0. 3.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.  0. 22. 14.
 23. 10.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1
Learning step: 3.484610080718994
desired expected reward: 57.18748092651367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[41.627018]
 [42.912228]
 [44.08855 ]
 [45.52431 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 0. 3.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.  0. 22. 14.
 23. 10.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: take_action - action -1.0
Learning step: 3.7253975868225098
desired expected reward: 51.2700080871582



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.  0. 22. 14.
 23. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.  0. 22. 14.
 23. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 3.  0.  0.  1.  0.  6. 14.  0.  0.  0.  1.  0.  8.  8.  0.  0. 22. 14.
 23. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0. 11. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 14.] 
expected returns: [[85.68132]
 [77.69328]
 [83.68581]
 [77.69328]
 [70.96802]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10. 14.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [6. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1.0
Learning step: 4.44942045211792
desired expected reward: 54.59132385253906



action possibilites: [-1] 
expected returns: [[94.219376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [3. 8. 8.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action 14.0
Learning step: 4.671533107757568
desired expected reward: 75.63957977294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[85.051926]
 [89.70113 ]
 [89.023796]
 [92.997055]
 [87.13985 ]
 [87.82873 ]
 [95.92502 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [3. 8. 8.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0  0] -> size -> 27 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action -1
Learning step: 3.4790711402893066
desired expected reward: 97.69844818115234






Player: 1 
cards in hand: [3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[10.53914 ]
 [ 9.600512]
 [ 9.600512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  1. 22.  6.  0.] 
adversary cards in discard: [6. 0. 0. 8. 8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 112 

action type: buy - action -1.0
Learning step: 1.0340534448623657
desired expected reward: 96.95906066894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-2.0451298 ]
 [-0.71963644]
 [-1.3372098 ]
 [ 5.611252  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  1. 22.  6.  0.] 
adversary cards in discard: [6. 0. 0. 8. 8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 112 

action type: take_action - action -1.0
Learning step: 5.142198085784912
desired expected reward: 15.681331634521484



buy possibilites: [-1] 
expected returns: [[72.050766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [ 6.  0.  8.  0. 10.  0. 25.  3. 25.  0. 25. 10. 15.  3.  4.  0.  0.  3.
 14. 10.  0. 11. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  1. 22.  6.  0.] 
adversary cards in discard: [6. 0. 0. 8. 8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7. 110.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 82.0 

action type: buy - action 0.0
Learning step: 5.823398113250732
desired expected reward: 3.778280019760132






Player: 1 
cards in hand: [ 0.  1. 22.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  6.  0.] 
cards in discard: [6. 0. 0. 8. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 0. 6. 8.] 
cards in discard: [6. 0. 0. 8. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0. 6. 8.] 
cards in discard: [6. 0. 0. 8. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0. 6. 8.] 
cards in discard: [ 6.  0.  0.  8.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22. 14. 23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[88.714775]
 [80.19901 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 112 

action type: buy - action -1
Learning step: 3.947093963623047
desired expected reward: 75.99786376953125



action possibilites: [-1. 10.] 
expected returns: [[79.14536]
 [71.62442]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 132 

action type: take_action - action 10.0
Learning step: 4.3297953605651855
desired expected reward: 84.52881622314453



action possibilites: [-1. 11.] 
expected returns: [[73.79804]
 [72.35954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 152 

action type: take_action - action 10.0
Learning step: 5.671390056610107
desired expected reward: 77.2957763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[64.74243 ]
 [66.88232 ]
 [67.137955]
 [72.067314]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  1.  0.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 110   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 152 

action type: take_action - action -1.0
Learning step: 5.484050273895264
desired expected reward: 79.2820816040039






Player: 1 
cards in hand: [ 0.  0. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1.  0.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [10.  4.  0.  3.  0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 4. 25. 30. 25. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 4. 25. 30. 24. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.74143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 24. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0 190   0] 
sum of rewards: 292 

action type: discard_down_to_3_cards - action 3
Learning step: 16.636316299438477
desired expected reward: 23.043643951416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 86.50639 ]
 [ 94.59628 ]
 [ 92.65431 ]
 [107.812065]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 24. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: take_action - action -1.0
Learning step: 2.153207778930664
desired expected reward: 106.89463806152344



buy possibilites: [-1] 
expected returns: [[76.434265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 3.03995680809021
desired expected reward: 97.63623809814453






Player: 1 
cards in hand: [0. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [10. 11. 25. 14. 25.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [10. 11. 25. 14. 25.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 6.  0.  0.  8.  8. 10. 22. 14. 23. 10.  0.  1.  6.  0.  0.  6.  8.  3.
 14.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [10. 11. 25. 14. 25.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [10. 11. 25. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 14. 25.] 
expected returns: [[31.872555]
 [28.10923 ]
 [31.940048]
 [33.67883 ]
 [23.188488]
 [33.67883 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25. 14. 25.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1
Learning step: 2.5504143238067627
desired expected reward: 78.98468017578125



action possibilites: [-1] 
expected returns: [[30.304539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 14. 25. 25.  3.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action 25.0
Learning step: 5.467067241668701
desired expected reward: 39.14589309692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.792068]
 [30.177597]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 14. 25. 25.  3.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action -1
Learning step: 5.778938293457031
desired expected reward: 36.08347702026367






Player: 1 
cards in hand: [ 0.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  5.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[38.105167]
 [24.01923 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6
 11 25 11  3 15  0  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1.0
Learning step: 4.921652317047119
desired expected reward: 35.0992546081543



action possibilites: [-1] 
expected returns: [[71.90432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action 15.0
Learning step: 7.066884517669678
desired expected reward: 31.086122512817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[59.72605 ]
 [64.90991 ]
 [58.1883  ]
 [63.413925]
 [54.422436]
 [61.635735]
 [68.08033 ]
 [62.322662]
 [71.68586 ]
 [63.194847]
 [56.277573]
 [59.29544 ]
 [62.18992 ]
 [54.353355]
 [60.715954]
 [70.66988 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  7. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action -1
Learning step: 4.5614237785339355
desired expected reward: 76.46574401855469



buy possibilites: [-1] 
expected returns: [[112.98947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  8. 10.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    8.  110.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 145.5 

action type: buy - action 25.0
Learning step: 6.23297119140625
desired expected reward: 77.91880798339844






Player: 1 
cards in hand: [ 8.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10.  0.] 
cards in discard: [11.  0.  0.  0. 14.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8. 11. 10.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3. 25. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 10.  0.] 
cards in discard: [11.  0.  0.  0. 14.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 8. 11. 10.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3. 25. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[-6.7041965]
 [-2.4348965]
 [-4.397628 ]
 [-4.744023 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3. 25. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  8.  0. 14.  6.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1
Learning step: -0.0775531753897667
desired expected reward: 112.91191864013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.9617999]
 [-6.6068697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  3. 11. 10.  4.  3.  0.  3.  0. 25. 10. 11. 14. 25.
 25.  3. 25. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  8.  0. 14.  6.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: take_action - action -1.0
Learning step: 5.881641864776611
desired expected reward: -0.8225693702697754



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 14.  6.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.327232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1] -> size -> 32 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0 206   0] 
sum of rewards: 319 

action type: discard_down_to_3_cards - action 2
Learning step: 17.312503814697266
desired expected reward: 9.559691429138184





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.968983]
 [37.552425]
 [35.468426]
 [40.141197]
 [35.904995]
 [34.91618 ]
 [41.483135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1] -> size -> 32 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: take_action - action -1.0
Learning step: 4.367220878601074
desired expected reward: 47.694454193115234



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [11.  3. 25.  8.  4.] 
adversary cards in discard: [3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  3.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [11.  3. 25.  8.  4.] 
adversary cards in discard: [3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [11.  3. 25.  8.  4.] 
adversary cards in discard: [3. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [11.  3. 25.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[70.9696  ]
 [68.268135]
 [74.86271 ]
 [61.733284]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.  8.  4.] 
cards in discard: [3. 6. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 22. 23.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1.0
Learning step: 5.195842742919922
desired expected reward: 46.6789665222168



action possibilites: [-1] 
expected returns: [[51.54457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  4. 10.  3.] 
cards in discard: [3. 6. 0. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 22. 23.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action 25.0
Learning step: 4.066617488861084
desired expected reward: 78.92932891845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.4956 ]
 [50.87925]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  4. 10.  3.] 
cards in discard: [3. 6. 0. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 22. 23.  0.] 
adversary cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action -1
Learning step: 5.155460357666016
desired expected reward: 56.70003128051758






Player: 1 
cards in hand: [ 6.  0. 22. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 23.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 22. 23.  0.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 23.  0.  1.  0. 10.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 23.  0.  1.  0. 10.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  2.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 23.  0.  1.  0. 10.] 
cards in discard: [11.  0.  0.  0. 14.  0.  8.  0.  8. 10.  0.  1. 14.  6.  8.  0.  6.  8.
  0.  6.  3.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[67.7971  ]
 [67.86892 ]
 [54.034584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  9.] 
adversary cards in hand: [10. 23.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1.0
Learning step: 4.582517623901367
desired expected reward: 55.46179962158203



action possibilites: [-1] 
expected returns: [[20.824783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [10. 23.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 4.350394248962402
desired expected reward: 73.91915893554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.944445]
 [16.29434 ]
 [15.75195 ]
 [19.652813]
 [13.827159]
 [14.465093]
 [21.685616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [10. 23.  6.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action -1
Learning step: 6.0371880531311035
desired expected reward: 26.861970901489258






Player: 1 
cards in hand: [10. 23.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  6.  1.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
action values: 2 
buys: 1 
player value: 1 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8] -> size -> 34 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  6. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 10.  0.] 
cards in discard: [25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 23. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 10.  0.] 
cards in discard: [25.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [15. 25.  0. 25. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [15. 25.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 25. 10.] 
expected returns: [[72.82553]
 [64.34673]
 [77.60577]
 [77.60577]
 [66.52189]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0. 25. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 0. 1. 6. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1.0
Learning step: 6.248304843902588
desired expected reward: 27.933942794799805



action possibilites: [-1] 
expected returns: [[53.601547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 25. 10. 25.  0.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 0. 1. 6. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 134 

action type: take_action - action 25.0
Learning step: 4.025745868682861
desired expected reward: 81.63153076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[44.589214]
 [48.122524]
 [47.553654]
 [53.814396]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 25. 10. 25.  0.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 24. 30. 23. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 0. 1. 6. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 133 

action type: take_action - action -1
Learning step: 5.122987270355225
desired expected reward: 58.72453308105469



buy possibilites: [-1] 
expected returns: [[36.44159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 25. 10. 25.  0.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 22. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 0. 1. 6. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 152 

action type: buy - action 3.0
Learning step: 6.0138092041015625
desired expected reward: 54.13633346557617






Player: 1 
cards in hand: [0. 0. 1. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 22. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 22. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [11.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[32.48637 ]
 [29.687845]
 [23.78526 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1
Learning step: 4.567046165466309
desired expected reward: 41.008636474609375



action possibilites: [-1. 11. 10.] 
expected returns: [[43.78495 ]
 [42.788853]
 [33.063564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action 10.0
Learning step: 6.453288555145264
desired expected reward: 30.23855209350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.659323]
 [44.894493]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0. 10.] 
cards in discard: [ 3.  6.  0.  0.  0. 25. 11.  3.  8.  4. 10.  3. 15. 11.  0.  0.  0. 10.
  3. 25. 15.  0. 25. 10. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0  3] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action -1.0
Learning step: 5.443231105804443
desired expected reward: 49.22817611694336






Player: 1 
cards in hand: [0. 6. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  0  6 10  0 22  0  0  0 14  0  6  0  1  0  0  1
  0  0  0 10  3  0 11  1  8  8 25  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[70.57032 ]
 [53.655346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1.0
Learning step: 4.950843334197998
desired expected reward: 49.845314025878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.961697]
 [63.70773 ]
 [64.52967 ]
 [71.82813 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  8.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: take_action - action -1.0
Learning step: 3.713200807571411
desired expected reward: 74.28352355957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  6. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.  8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0. 10.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  6. 10. 15. 11.] 
adversary cards in discard: [ 0.  0.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  6. 10. 15. 11.] 
adversary cards in discard: [ 0.  0.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  6. 10. 15. 11.] 
adversary cards in discard: [ 0.  0.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[66.021164]
 [55.814087]
 [53.88458 ]
 [62.555767]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 15. 11.] 
cards in discard: [ 0.  0.  3.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  8.] 
adversary cards in hand: [ 0. 22.  8. 14.  1.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1.0
Learning step: 3.523679733276367
desired expected reward: 75.35181427001953



action possibilites: [-1] 
expected returns: [[82.621086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 15.] 
cards in discard: [ 0.  0.  3.  3. 14. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 0. 22.  8. 14.  1.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 150 

action type: gain_card_n - action 9
Learning step: 6.273732662200928
desired expected reward: 67.97856903076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[68.74049]
 [82.56164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10. 15.] 
cards in discard: [ 0.  0.  3.  3. 14. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 0. 22.  8. 14.  1.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action -1
Learning step: 4.351192951202393
desired expected reward: 86.97228240966797






Player: 1 
cards in hand: [ 0. 22.  8. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8. 14.  1.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0
  0 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  1.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  4.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  1.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[42.661144]
 [36.525745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1.0
Learning step: 2.4983277320861816
desired expected reward: 85.0599594116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[35.357628]
 [41.074688]
 [39.165794]
 [44.232445]
 [38.34036 ]
 [37.770638]
 [46.575542]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 24. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: take_action - action -1.0
Learning step: 4.5470805168151855
desired expected reward: 47.20822525024414



buy possibilites: [-1] 
expected returns: [[44.763798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0  -1   0   0  18   0] 
sum of rewards: 131 

action type: buy - action 1.0
Learning step: 5.099758148193359
desired expected reward: 54.24829864501953






Player: 1 
cards in hand: [ 0.  8.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  0.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0 14  0  6  0  1  0  0  1  0  0  0
 10  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [15. 10. 25. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [15. 10. 25. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 23. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [15. 10. 25. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 23. 10.  6.  1.  0. 10.  0.  3.  0.  0.  1.  6.  8.  0.  8.  6.
  8. 16. 11.  0.  0.  6.  8. 11.  8.  0. 22.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [15. 10. 25. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [15. 10. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 25. 10.] 
expected returns: [[56.725838]
 [47.932156]
 [49.724857]
 [58.898365]
 [49.724857]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25. 10.  0.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 8. 23.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1
Learning step: 4.718326091766357
desired expected reward: 49.48212432861328



action possibilites: [-1. 15. 25. 10. 25.] 
expected returns: [[28.87207 ]
 [24.333334]
 [31.15455 ]
 [25.410753]
 [31.15455 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 10.  0. 25.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 8. 23.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action 10.0
Learning step: 4.882339000701904
desired expected reward: 54.60720443725586



action possibilites: [-1. 15. 10. 25. 10.] 
expected returns: [[92.89308 ]
 [83.99409 ]
 [86.22835 ]
 [97.370636]
 [86.22835 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 25. 10.  4.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 8. 23.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 154 

action type: take_action - action 25.0
Learning step: 8.245534896850586
desired expected reward: 39.40008544921875



action possibilites: [-1] 
expected returns: [[152.85246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 10.  4.  0.  3.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 8. 23.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  60   0   0   0   0   0   0   0   0   1] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 7.32064962387085
desired expected reward: 104.6912612915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[142.84941]
 [146.86295]
 [147.20955]
 [153.64465]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0. 10.  4.  0.  3.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 8. 23.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 174 

action type: take_action - action -1
Learning step: 4.448892116546631
desired expected reward: 157.30136108398438






Player: 1 
cards in hand: [ 8. 23.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 3. 25. 11. 10. 25.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0. 10.
 25. 25. 15. 10.  0. 10.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [ 3. 25. 11. 10. 25.] 
adversary cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0. 10.
 25. 25. 15. 10.  0. 10.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
adversary victory points: 9
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 25.] 
expected returns: [[42.859127]
 [43.10599 ]
 [40.81174 ]
 [33.768074]
 [43.10599 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11. 10. 25.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0. 10.
 25. 25. 15. 10.  0. 10.  4.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  7.] 
adversary cards in hand: [1. 0. 8. 3. 6.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 114 

action type: buy - action -1.0
Learning step: -1.0382652282714844
desired expected reward: 152.6063690185547



action possibilites: [-1] 
expected returns: [[70.006035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10. 25.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0. 10.
 25. 25. 15. 10.  0. 10.  4.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [1. 0. 8. 3. 6.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: 148 

action type: gain_card_n - action 9
Learning step: 7.027711391448975
desired expected reward: 45.976200103759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[44.957024]
 [67.79556 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 10. 25.] 
cards in discard: [ 0.  0.  3.  3. 14. 15. 11.  0.  6. 10. 15.  1.  0.  3.  8.  0.  0. 10.
 25. 25. 15. 10.  0. 10.  4.  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [1. 0. 8. 3. 6.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action -1
Learning step: 4.600521564483643
desired expected reward: 74.60655975341797






Player: 1 
cards in hand: [1. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 3. 6.] 
cards in discard: [ 8. 23.  6.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  1  0  0  1  0  0  0 10
  3  0 11  1  8  8 25  0  3  0 16 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 8. 23.  6.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8. 23.  6.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[50.664837]
 [48.661297]
 [49.1235  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1] -> size -> 35 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: buy - action -1.0
Learning step: 3.9372899532318115
desired expected reward: 71.73285675048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.493103]
 [52.028324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1] -> size -> 35 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: take_action - action -1.0
Learning step: 4.801747798919678
desired expected reward: 55.466583251953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  1.  0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  6.  9.  1.  9.  6.] 
adversary cards in hand: [ 3. 10. 11. 10. 10.] 
adversary cards in discard: [25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  1.  9.  6.] 
adversary cards in hand: [ 3. 10. 11. 10. 10.] 
adversary cards in discard: [25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  1.  9.  6.] 
adversary cards in hand: [ 3. 10. 11. 10. 10.] 
adversary cards in discard: [25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 3. 10. 11. 10. 10.] 
adversary cards in discard: [25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[4.914704 ]
 [2.0410724]
 [3.545774 ]
 [2.0410724]
 [2.0410724]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 10.] 
cards in discard: [25.  3.  3.  0. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: buy - action -1.0
Learning step: 3.687368154525757
desired expected reward: 55.7156982421875



action possibilites: [-1. 11. 10. 10. 15.] 
expected returns: [[42.047592]
 [40.714523]
 [30.606161]
 [30.606161]
 [27.317768]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10. 15.] 
cards in discard: [25.  3.  3.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 144 

action type: take_action - action 10.0
Learning step: 7.959042549133301
desired expected reward: 10.000112533569336



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[14.764959]
 [15.496613]
 [11.663723]
 [11.663723]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10.] 
cards in discard: [25.  3.  3.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 164 

action type: take_action - action 15.0
Learning step: 7.159883975982666
desired expected reward: 34.477638244628906



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[34.36403 ]
 [33.909035]
 [22.630026]
 [33.909035]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 11.] 
cards in discard: [25.  3.  3.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 184 

action type: take_action - action 10.0
Learning step: 9.16169261932373
desired expected reward: 20.825401306152344



action possibilites: [-1. 11. 11. 15.] 
expected returns: [[59.963287]
 [60.36012 ]
 [60.36012 ]
 [55.47895 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 15.] 
cards in discard: [25.  3.  3.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 15. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15] -> size -> 37 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  3.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 204 

action type: take_action - action 10.0
Learning step: 10.412206649780273
desired expected reward: 33.04224395751953



action possibilites: [-1. 11. 15.] 
expected returns: [[24.860287]
 [23.805065]
 [14.711319]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.] 
cards in discard: [25.  3.  3.  0. 11. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 15. 10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0 100   0   0   0   0  -3   0   0   9   0] 
sum of rewards: 230 

action type: gain_card_n - action 4
Learning step: 9.45638370513916
desired expected reward: 60.70096206665039



action possibilites: [-1. 15.] 
expected returns: [[46.09473 ]
 [31.748386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 15. 10. 10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0 120   0   0   0   0  -4   0   0   9   0] 
sum of rewards: 249 

action type: gain_card_n - action 1
Learning step: 12.366406440734863
desired expected reward: 33.21583938598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.358429]
 [45.454334]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 15. 10. 10. 11. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 25. 16.  0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 244 

action type: take_action - action -1.0
Learning step: 10.841096878051758
desired expected reward: 56.93585205078125






Player: 1 
cards in hand: [ 0.  0. 25. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 16.  0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  8.  8.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  8.  8.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.009915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [0. 8. 0. 1. 0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: buy - action -1.0
Learning step: 4.130005836486816
desired expected reward: 49.584346771240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 8.937376 ]
 [10.03359  ]
 [10.025066 ]
 [ 7.714157 ]
 [ 9.410056 ]
 [10.9036665]
 [ 9.303937 ]
 [11.593514 ]
 [ 9.588404 ]
 [ 8.266428 ]
 [ 9.140477 ]
 [ 7.9022503]
 [ 9.322724 ]
 [11.983437 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  9.  6.] 
adversary cards in hand: [0. 8. 0. 1. 0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: take_action - action -1.0
Learning step: 5.992915630340576
desired expected reward: 15.002830505371094



buy possibilites: [-1] 
expected returns: [[39.317635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  8.  6.] 
adversary cards in hand: [0. 8. 0. 1. 0.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0  -5   0   0  50   0] 
sum of rewards: 169 

action type: buy - action 22.0
Learning step: 8.939534187316895
desired expected reward: 16.841787338256836






Player: 1 
cards in hand: [0. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  8.  6.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  9.  0.  8.  6.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 0.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[35.69994 ]
 [28.980549]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  0. 14.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: buy - action -1
Learning step: 5.000715255737305
desired expected reward: 44.31835174560547



action possibilites: [-1] 
expected returns: [[35.999317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 144 

action type: take_action - action 14.0
Learning step: 6.5609564781188965
desired expected reward: 35.54151153564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[33.05474 ]
 [34.72053 ]
 [33.57135 ]
 [33.6623  ]
 [35.645294]
 [34.220722]
 [34.54603 ]
 [31.567116]
 [33.18755 ]
 [36.542496]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 144 

action type: take_action - action -1
Learning step: 6.195287227630615
desired expected reward: 42.194602966308594






Player: 1 
cards in hand: [ 6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  1.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0. 14.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  1.] 
cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0. 14.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
adversary victory points: 9
player victory points: -3 


Player 0 won the game! 



Player 0 bought cards:
Copper: 3 
Silver: 2 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 2 

Remodel: 0 
Workshop: 4 
Chapel: 1 
Witch: 4 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 2 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  0. 10. 25.  0.] 
cards in discard: [25.  3.  3.  0. 11. 11.  1. 10. 15. 10. 10. 11. 11.  3. 15. 22.  3.  0.
  1.  0.  0. 14.  0.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14 25  4 10 11 25 10 10  3  8 10 10  0  6 11
 25 11  3 15  0  0  3 25 15  3 15  1 15 11  1 22] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 21. 29.  8.  0.  9.  2.  1.  5. 10.  5.  8.  0.  8.  6.] 
adversary cards in hand: [ 6. 10.  1.] 
adversary cards in discard: [ 8. 23.  6.  0.  3.  8.  0.  6. 14. 10. 11.  0. 10.  1.  0. 25.  0.  0.
 16.  0.  8.  8. 23.  0.  8.  0.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 8  8  8  6 23  8  6  6 10 22  0  0  0  0  6  0  0  0  1  0  0  0 10  0
 11  1  8  8 25  0  3  0 16 11  1 14 10 23  0] -> size -> 39 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5 500   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 624 

action type: buy - action -1.0
Learning step: 29.37287712097168
desired expected reward: 65.91535949707031



