 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.269218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -120003.3203125
desired expected reward: -120015.421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.922394]
 [24.24258 ]
 [22.384613]
 [10.376569]
 [21.365788]
 [27.38514 ]
 [21.922916]
 [28.965393]
 [15.343858]
 [20.064953]
 [22.664047]
 [20.754803]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.771923065185547



buy possibilites: [-1] 
expected returns: [[33.9998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.965389251708984






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.092747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.99980163574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.830631]
 [26.691456]
 [24.984558]
 [13.839051]
 [29.644268]
 [24.490337]
 [22.783443]
 [24.304558]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.494094848632812



buy possibilites: [-1] 
expected returns: [[21.414352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.644268035888672






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.481327]
 [27.745335]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.414352416992188



action possibilites: [-1] 
expected returns: [[32.46963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.885711669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.130707]
 [35.314075]
 [33.53728 ]
 [21.914215]
 [32.537647]
 [38.41569 ]
 [33.009125]
 [40.12923 ]
 [26.76212 ]
 [31.232323]
 [33.945488]
 [33.151684]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.46963119506836



buy possibilites: [-1] 
expected returns: [[44.130054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.12923049926758






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [8. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  3.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[42.426914]
 [51.907513]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.13005447387695



action possibilites: [-1.] 
expected returns: [[36.10656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.27436447143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.846157]
 [38.841328]
 [36.872555]
 [23.959816]
 [42.409363]
 [36.272896]
 [34.30412 ]
 [36.67323 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.10655975341797



buy possibilites: [-1] 
expected returns: [[30.934185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.409358978271484






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.586388]
 [48.21245 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.934185028076172



action possibilites: [-1] 
expected returns: [[33.500366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.492637634277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.306557]
 [35.33295 ]
 [22.792274]
 [34.7333  ]
 [35.13363 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.5003662109375



buy possibilites: [-1] 
expected returns: [[35.513927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 35.332950592041016






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11  2] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[30.515171]
 [28.146065]
 [36.14123 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [10.  3. 11.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11  2] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.5139274597168



action possibilites: [-1] 
expected returns: [[37.53565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  3. 11.  3.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11  2] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.621639251708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.99966 ]
 [36.604874]
 [22.512203]
 [35.938953]
 [36.62527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  3. 11.  3.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  8  1 11  2] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.535648345947266






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  8.] 
cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  8  1 11  2] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0. 10. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0. 10. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 2. 10.  1.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10.  3. 11.  3.  3.  0.  0. 10. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[32.224537]
 [41.29855 ]
 [41.29855 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  0.] 
cards in discard: [10.  3. 11.  3.  3.  0.  0. 10. 11. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.625267028808594



action possibilites: [-1. 29.] 
expected returns: [[64.905396]
 [71.353775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.013790130615234



action possibilites: [-1.] 
expected returns: [[74.98923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.353759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[66.10789 ]
 [74.13179 ]
 [64.17826 ]
 [72.20215 ]
 [61.31899 ]
 [59.41879 ]
 [71.08059 ]
 [77.61441 ]
 [71.52014 ]
 [84.82534 ]
 [79.727844]
 [64.80162 ]
 [72.38595 ]
 [69.59052 ]
 [64.36206 ]
 [72.82552 ]
 [73.27947 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.98922729492188



buy possibilites: [-1] 
expected returns: [[53.344738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 217.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 84.8253402709961






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  8  1  2] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11. 10.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  8  1  2] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11. 10.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  8  1  2] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11. 10.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 11. 10.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[39.567764]
 [38.655483]
 [47.9837  ]
 [38.655483]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 2. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.3447380065918



action possibilites: [-1] 
expected returns: [[91.066956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 2. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.25830841064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.91551 ]
 [77.118164]
 [89.27777 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 2. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.06695556640625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [8. 2. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 2. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10. 11. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 2. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  1  2  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10. 11. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 2. 1. 0. 0.] 
cards in discard: [15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  1  2  8 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10. 11. 10.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[53.242195]
 [47.866356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10. 11. 10.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  1  2  8 15] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.27778625488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.670784]
 [49.342537]
 [29.175743]
 [48.361126]
 [50.385075]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.  0. 10. 11. 10.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10  8  1  2  8 15] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.38492965698242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  8  1  2  8 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 10  8  1  2  8 15] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0 10  8  1  2  8 15] -> size -> 9 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 0  0  0 10  8  2  8 15] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 0  0  0 10  8  2  8 15] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[70.48437 ]
 [76.59801 ]
 [74.636345]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.38508605957031



action possibilites: [-1. 11. 29.] 
expected returns: [[69.364334]
 [73.69927 ]
 [75.812706]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.30169677734375



action possibilites: [-1. 11.] 
expected returns: [[59.98339]
 [64.31834]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.81270599365234



action possibilites: [-1] 
expected returns: [[54.27784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.17291259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.02919 ]
 [54.83601 ]
 [52.90682 ]
 [40.28476 ]
 [51.811993]
 [58.214306]
 [52.336666]
 [59.96061 ]
 [45.560802]
 [50.407486]
 [53.367615]
 [52.577377]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  8. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.27783966064453



buy possibilites: [-1] 
expected returns: [[101.93068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.96061325073242






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  8.  2.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  2.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  2  8 15 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10.  0. 10. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  2  8 15 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10.  0. 10. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  2  8 15 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 10.  0. 10. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10. 10.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 25.] 
expected returns: [[107.60282 ]
 [104.101685]
 [104.101685]
 [104.101685]
 [126.761505]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10. 25.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8. 10. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 2. 10. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  2  8 15 10] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.93067932128906



action possibilites: [-1] 
expected returns: [[60.86101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  3. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 2. 10. 15.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.45811462402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.527946]
 [49.571857]
 [63.325443]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  3. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 2. 10. 15.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.86101150512695






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 2. 10. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 10. 15.  8.  0.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  2  8 15 10  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 10. 15.  8.  0.] 
cards in discard: [6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  2  8 15 10  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 10. 15.  8.  0.] 
cards in discard: [ 6. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[58.668404]
 [63.047558]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  3. 10.  8.] 
adversary cards in hand: [15.  6.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.325435638427734



action possibilites: [-1] 
expected returns: [[19.935665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.75457763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.567535 ]
 [22.026814 ]
 [19.377342 ]
 [ 5.1138973]
 [26.772694 ]
 [18.519798 ]
 [16.32695  ]
 [20.438072 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.935665130615234



buy possibilites: [-1] 
expected returns: [[32.583485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 25. 10. 10.  0. 10.  3. 10. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [15.  6.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.77267837524414






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [15.  6.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  2  8 15 10  6 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  2  8 15 10  6 15] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  2  8 15 10  6 15] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  7. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[50.323277]
 [58.50562 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  2. 15.  0. 10.] 
adversary cards in discard: [29. 15.  6.  8.  0.] 
adversary owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.5834846496582



action possibilites: [-1. 11.] 
expected returns: [[55.876343]
 [60.061436]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  6. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  2. 15.  0. 10.] 
adversary cards in discard: [29. 15.  6.  8.  0.] 
adversary owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.52127456665039



action possibilites: [-1] 
expected returns: [[44.63538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  6. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8.  2. 15.  0. 10.] 
adversary cards in discard: [29. 15.  6.  8.  0.] 
adversary owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.1406135559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.06263 ]
 [47.868404]
 [45.939217]
 [33.319687]
 [44.844402]
 [51.2467  ]
 [45.369064]
 [53.112   ]
 [38.59455 ]
 [43.44017 ]
 [46.400013]
 [45.60977 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  6. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8.  2. 15.  0. 10.] 
adversary cards in discard: [29. 15.  6.  8.  0.] 
adversary owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.635379791259766



buy possibilites: [-1] 
expected returns: [[52.800167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8.  2. 15.  0. 10.] 
adversary cards in discard: [29. 15.  6.  8.  0.] 
adversary owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.111995697021484






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8.  2. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  2. 15.  0. 10.] 
cards in discard: [29. 15.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  2  8 15 10  6 15 29] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  2. 10.] 
cards in discard: [29. 15.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8  2  8 15 10  6 15 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  2. 10.] 
cards in discard: [29. 15.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8  2  8 15 10  6 15 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  2. 10.] 
cards in discard: [29. 15.  6.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8  2  8 15 10  6 15 29  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 6 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 3.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[40.74033 ]
 [47.308598]
 [36.812366]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  1. 10.  8.] 
adversary cards in hand: [15.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 15 10  6 15 29  0] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.800167083740234



action possibilites: [-1] 
expected returns: [[29.13321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 15 10  6 15 29  0] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.41041564941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.726795]
 [14.091107]
 [29.327969]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [15.  0.  8. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 15 10  6 15 29  0] -> size -> 10 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.133209228515625






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [15.  0.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8. 15.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 15 10  6 15 29  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  2  8 10  6 29  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  2  8 10  6 29  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[44.924526]
 [41.975315]
 [41.975315]
 [52.386997]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  2. 29. 10.  6.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  8  2  8 10  6 29  0] -> size -> 8 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.327957153320312



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[53.785526]
 [49.67329 ]
 [49.67329 ]
 [71.11653 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 25.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  9. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  2. 29. 10.  6.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  8  2  8 10  6 29  0] -> size -> 8 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.48732376098633



action possibilites: [-1] 
expected returns: [[85.604774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  2. 29. 10.  6.] 
adversary cards in discard: [8. 0. 8. 6.] 
adversary owned cards: [ 0  8  2  8 10  6 29  0  6] -> size -> 9 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.11653900146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.794914]
 [88.15082 ]
 [68.73013 ]
 [87.25348 ]
 [88.36568 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  2. 29. 10.  6.] 
adversary cards in discard: [8. 0. 8. 6.] 
adversary owned cards: [ 0  8  2  8 10  6 29  0  6] -> size -> 9 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.60477447509766






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  2. 29. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 29. 10.  6.] 
cards in discard: [8. 0. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 10  6 29  0  6] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 29.  6.  8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  2  8 10  6 29  0  6] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  8  2  8 10  6  0  6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 6.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  8  2  8 10  6  0  6] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  5. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 6.] 
cards in discard: [29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 11. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 0. 10.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[33.38647 ]
 [31.977741]
 [38.172634]
 [31.977741]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29.  2.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.36566162109375



action possibilites: [-1] 
expected returns: [[36.214733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  2.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.70309829711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.129253]
 [35.989246]
 [21.747673]
 [35.291214]
 [36.247944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  3. 10.  0.  3. 29. 25.  0.
 10. 10. 10. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29.  2.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.2147331237793






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [29.  2.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  2.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 10  6  0  6 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  8.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  6.  0.  8.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 3. 10. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.] 
expected returns: [[51.440456]
 [49.217957]
 [52.234814]
 [49.217957]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11
 10 29 10 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.24794387817383



action possibilites: [-1] 
expected returns: [[49.24747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 51.79359817504883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[44.37126 ]
 [52.169132]
 [50.265118]
 [37.174263]
 [55.46392 ]
 [49.729107]
 [49.498528]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  6.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.24747085571289



buy possibilites: [-1] 
expected returns: [[42.495655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.46391677856445






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  2  8 10  6  0  6 29  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [11. 15.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  2  8  6  0  6 29  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [11. 15.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  2  8  6  0  6 29  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [11. 15.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [11. 15.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [10. 29. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10. 11.] 
expected returns: [[56.61648 ]
 [53.309734]
 [65.434105]
 [53.309734]
 [53.309734]
 [62.91482 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 10. 11.] 
cards in discard: [11. 15.  3. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  2. 29.  6.  8.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.49565505981445



action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[33.880108]
 [31.65638 ]
 [31.65638 ]
 [31.65638 ]
 [38.65469 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [11. 15.  3. 10. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  2. 29.  6.  8.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.03367614746094



action possibilites: [-1] 
expected returns: [[16.031895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  2. 29.  6.  8.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.44157791137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.692223]
 [ 9.485515]
 [16.78968 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  2. 29.  6.  8.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.03189468383789






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  2. 29.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 29.  6.  8.] 
cards in discard: [0. 8. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 29. 10.  0. 10.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 29.  6.  8.] 
cards in discard: [0. 8. 8. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [11. 29. 10.  0. 10.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 29.  6.  8.] 
cards in discard: [ 0.  8.  8.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [11. 29. 10.  0. 10.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [11. 29. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[14.500188]
 [17.984821]
 [19.269855]
 [12.833586]
 [12.833586]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  0. 10.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.78968048095703



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[ 0.42405343]
 [ 5.57479   ]
 [-1.2795589 ]
 [-1.2795589 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.561095237731934



action possibilites: [-1] 
expected returns: [[-0.05069542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 7.455868721008301





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.3538902 ]
 [ 0.3679781 ]
 [-7.5713687 ]
 [-0.00952983]
 [ 0.25204444]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 29. 29. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.05069541931152344



buy possibilites: [-1] 
expected returns: [[19.73093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 28. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 0.3679780960083008






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  0.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 28. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3.  0. 29. 25.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  0.  6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 29. 28. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3.  0. 29. 25.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  0.  6.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  3.  0. 29. 25.] 
adversary cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [11.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[ 7.2129755]
 [10.93655  ]
 [12.177121 ]
 [15.780618 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29. 25.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  8. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  6.  8. 29.  2.] 
adversary cards in discard: [ 3. 15.  0.  8.  0.  6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3] -> size -> 11 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.73093032836914



action possibilites: [-1] 
expected returns: [[31.661053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.  3.  3.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  6.  8. 29.  2.] 
adversary cards in discard: [ 3. 15.  0.  8.  0.  6.  6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6] -> size -> 12 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.780617713928223





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.315853]
 [23.402264]
 [31.837582]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 29.  3.  3.] 
cards in discard: [11. 15.  3. 10. 10.  0. 15. 29. 11. 10. 10. 10.  0. 15.  3. 29. 11. 10.
 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  6.  8. 29.  2.] 
adversary cards in discard: [ 3. 15.  0.  8.  0.  6.  6.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6] -> size -> 12 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.661052703857422






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  8. 29.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  8. 29.  2.] 
cards in discard: [ 3. 15.  0.  8.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  8. 29.  2.] 
cards in discard: [ 3. 15.  0.  8.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  7.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  8. 29.  2.] 
cards in discard: [ 3. 15.  0.  8.  0.  6.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15. 10. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [15. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29.] 
expected returns: [[48.442562]
 [48.22369 ]
 [45.3744  ]
 [54.3396  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.83758544921875



action possibilites: [-1. 15. 10.] 
expected returns: [[46.697895]
 [46.39597 ]
 [44.307907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.678466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[42.362034]
 [47.52837 ]
 [46.28842 ]
 [38.065434]
 [49.76723 ]
 [45.840843]
 [46.990883]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  5.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.69790267944336



buy possibilites: [-1] 
expected returns: [[32.09355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.76723098754883






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  6.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11] -> size -> 32 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  6.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11] -> size -> 32 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  6.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11] -> size -> 32 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [11. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[21.645638]
 [25.339214]
 [18.933495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  8.  0. 15.  6.  8.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.09355163574219



action possibilites: [-1] 
expected returns: [[37.129414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  8.  0. 15.  6.  8.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 26.93398666381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.717648]
 [33.224403]
 [21.83189 ]
 [32.596718]
 [34.521847]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0.  3.  6.  8.] 
adversary cards in discard: [ 0.  8.  0. 15.  6.  8.] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.12941360473633






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  6.  8.] 
cards in discard: [ 0.  8.  0. 15.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0.  8.  0. 15.  6.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0.  8.  0. 15.  6.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0.  8.  0. 15.  6.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3.  3. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[57.584446]
 [60.51022 ]
 [54.161854]
 [62.261234]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10. 29.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 15.  8.  6.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.521846771240234



action possibilites: [-1. 11. 10.] 
expected returns: [[93.50432]
 [97.57707]
 [88.76834]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 15.  8.  6.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.722381591796875



action possibilites: [-1] 
expected returns: [[35.35226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 15.  8.  6.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.03109741210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.355186]
 [23.884865]
 [35.365612]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 15.  8.  6.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.35226058959961






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  8.  6.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  6.  2.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  0  6 29  8  0 15  3  6  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29. 10. 15. 15. 10.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 2.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29. 10. 15. 15. 10.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 2.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 29. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29. 10. 15. 15. 10.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 2.] 
cards in discard: [2.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29. 10. 15. 15. 10.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [29. 10. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 15. 10.] 
expected returns: [[25.577415]
 [33.668163]
 [22.349781]
 [25.79353 ]
 [25.79353 ]
 [22.349781]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15. 15. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [ 2. 15.  8.  6.  2.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.36561965942383



action possibilites: [-1. 15. 15. 10. 10.] 
expected returns: [[16.648655]
 [17.441292]
 [17.441292]
 [14.448617]
 [14.448617]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [ 2. 15.  8.  6.  2.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.372596740722656



action possibilites: [-1] 
expected returns: [[23.554306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [ 2. 15.  8.  6.  2.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 17.4412841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.103683]
 [16.483574]
 [23.625885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [ 2. 15.  8.  6.  2.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.554306030273438






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [ 2. 15.  8.  6.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [25. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8.] 
cards in discard: [ 2. 15.  8.  6.  2.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [25. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8.] 
cards in discard: [ 2. 15.  8.  6.  2.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [25. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8.] 
cards in discard: [ 2. 15.  8.  6.  2.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [25. 10.  3. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [25. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[46.963085]
 [55.266117]
 [44.04511 ]
 [50.06331 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3. 11.  0.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 28. 27. 30.  8.  7. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2  0] -> size -> 16 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.625877380371094



action possibilites: [-1] 
expected returns: [[23.254093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 11. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2  0  6] -> size -> 17 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.26612091064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.411003]
 [12.143656]
 [23.447388]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  0. 11. 10.] 
cards in discard: [ 3. 11. 29. 15. 10.  0.  0. 15. 11. 10.  3.  0.  0.  0. 15. 29. 11.  3.
  3. 10. 10. 29. 15. 15. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2  0  6] -> size -> 17 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.254093170166016






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  2  8  6  6 29  8  0 15  3  6  8  0  0  2  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [11. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[44.078526]
 [46.990864]
 [41.688534]
 [48.585953]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6. 29. 15.  2.] 
adversary cards in discard: [6. 0. 8. 3. 8.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.447383880615234



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[11.8957815]
 [14.161117 ]
 [ 9.248027 ]
 [14.161117 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 6.  6. 29. 15.  2.] 
adversary cards in discard: [6. 0. 8. 3. 8.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 41.880165100097656



action possibilites: [-1] 
expected returns: [[10.688369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6. 29. 15.  2.] 
adversary cards in discard: [6. 0. 8. 3. 8.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.312853813171387





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.425227 ]
 [10.389295 ]
 [ 2.0178757]
 [ 9.959249 ]
 [10.704303 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6. 29. 15.  2.] 
adversary cards in discard: [6. 0. 8. 3. 8.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.688368797302246






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 29. 15.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29. 15.  2.] 
cards in discard: [6. 0. 8. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [15.  3.  3.  3.  3.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29. 15.  2.] 
cards in discard: [6. 0. 8. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  4.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [15.  3.  3.  3.  3.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 29. 15.  2.] 
cards in discard: [ 6.  0.  8.  3.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [15.  3.  3.  3.  3.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [15.  3.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[51.75434 ]
 [51.707336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  3.  3.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [0. 2. 0. 6. 8.] 
adversary cards in discard: [ 6.  0.  8.  3.  8. 11.  6.  6. 29. 15.  2.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0 11] -> size -> 17 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.704302787780762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.057877]
 [39.46813 ]
 [50.610287]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  3.  3.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [0. 2. 0. 6. 8.] 
adversary cards in discard: [ 6.  0.  8.  3.  8. 11.  6.  6. 29. 15.  2.] 
adversary owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0 11] -> size -> 17 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.754329681396484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 2. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0. 6. 8.] 
cards in discard: [ 6.  0.  8.  3.  8. 11.  6.  6. 29. 15.  2.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 2  8  6  6 29  8 15  3  6  8  0  0  2  0  6  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [10. 15. 10. 10. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  8.  3.  8. 11.  6.  6. 29. 15.  2.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [10. 15. 10. 10. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  8.  3.  8. 11.  6.  6. 29. 15.  2.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [10. 15. 10. 10. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [10. 15. 10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 10. 15.] 
expected returns: [[9.27222 ]
 [7.316119]
 [9.495297]
 [7.316119]
 [7.316119]
 [9.495297]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 10. 15.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 8. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.61027908325195



action possibilites: [-1] 
expected returns: [[0.7468951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 8. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 9.495299339294434





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.256383 ]
 [-6.2732205]
 [ 0.719059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 15.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 8. 15.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.7468950748443604






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [11. 15. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 29. 11.] 
expected returns: [[-6.414918 ]
 [-3.6460638]
 [-6.789488 ]
 [-8.92782  ]
 [-2.2227952]
 [-3.6460638]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 29. 11.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6.  3.  8. 11.] 
adversary cards in discard: [ 8. 15.  6.  0.] 
adversary owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.7190606594085693



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[3.0739183]
 [4.839351 ]
 [0.3815632]
 [4.839351 ]
 [0.3815632]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6.  3.  8. 11.] 
adversary cards in discard: [ 8. 15.  6.  0.] 
adversary owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.93798303604126



action possibilites: [-1] 
expected returns: [[-0.9503505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  6.  3.  8. 11.] 
adversary cards in discard: [ 8. 15.  6.  0.] 
adversary owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 299 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 5.8857221603393555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-4.770227 ]
 [-8.689537 ]
 [-1.0126238]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  6.  3.  8. 11.] 
adversary cards in discard: [ 8. 15.  6.  0.] 
adversary owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.9503505229949951






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  8. 11.] 
cards in discard: [ 8. 15.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [25. 15.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.] 
cards in discard: [ 8. 15.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [25. 15.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.] 
cards in discard: [ 8. 15.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [25. 15.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [25. 15.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10.] 
expected returns: [[3.3284931e+00]
 [1.0808078e+01]
 [2.1498103e+00]
 [8.3746910e-03]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  3. 10.  0.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  6. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11] -> size -> 12 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.012624979019165



action possibilites: [-1] 
expected returns: [[40.44251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  0.  0. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6] -> size -> 13 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.808077812194824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.10673 ]
 [40.39835 ]
 [29.441628]
 [39.80833 ]
 [41.517822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  0.  0. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6] -> size -> 13 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.442508697509766






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  2. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  2. 29.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10. 25. 15.  3. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3. 2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10. 25. 15.  3. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3. 2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10. 25. 15.  3. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3. 2. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10. 25. 15.  3. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [11. 29.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[22.216137]
 [24.628418]
 [26.110435]
 [26.110435]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29.  0.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11. 15.  3.  3.  3.  3. 15. 10. 10. 10. 15. 15.
 15. 29. 11. 10. 11. 10. 25. 15.  3. 10.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6. 11.  8. 15.  6.] 
adversary cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.51780700683594



action possibilites: [-1.] 
expected returns: [[1.5579252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6. 11.  8. 15.  6.] 
adversary cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.32015609741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-1.340119 ]
 [ 3.137547 ]
 [ 2.0451245]
 [-5.1458664]
 [ 5.259156 ]
 [ 1.6813478]
 [ 2.1404095]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  3.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6. 11.  8. 15.  6.] 
adversary cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.5579252243041992



buy possibilites: [-1] 
expected returns: [[39.87306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 29. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6. 11.  8. 15.  6.] 
adversary cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 259 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 5.2591657638549805






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8. 15.  6.] 
cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0 11  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 15. 10.  3. 10.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 15. 10.  3. 10.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.] 
cards in discard: [ 6.  3.  2.  0. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 15. 10.  3. 10.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [29. 15. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 10.] 
expected returns: [[38.08623 ]
 [44.573227]
 [38.619972]
 [36.535667]
 [36.535667]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10.  3. 10.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.8730583190918



action possibilites: [-1. 15. 10.] 
expected returns: [[28.784584]
 [27.837097]
 [25.318264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.503578186035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.856163]
 [18.077637]
 [28.88432 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.784591674804688






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 10. 10. 10. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [29. 10. 10. 10. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10. 11.] 
expected returns: [[51.2003  ]
 [56.392532]
 [46.218327]
 [46.218327]
 [46.218327]
 [54.163654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10. 11.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 15.] 
adversary cards in discard: [0. 6. 6. 0. 8.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.884323120117188



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[12.413453]
 [ 8.653632]
 [ 8.653632]
 [ 8.653632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 15.] 
adversary cards in discard: [0. 6. 6. 0. 8.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.67818832397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.194688 ]
 [ 2.0056248]
 [12.467603 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0.  2. 15.] 
adversary cards in discard: [0. 6. 6. 0. 8.] 
adversary owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.413439750671387






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  2. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  2. 15.] 
cards in discard: [0. 6. 6. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  0  2  0  6  0  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0. 15. 11.  3.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 2.] 
cards in discard: [0. 6. 6. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  8 15  3  6  8  2  0  6  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0. 15. 11.  3.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2.] 
cards in discard: [0. 6. 6. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  8 15  3  6  8  2  0  6  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 29. 28. 27. 30.  8.  5. 10.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0. 15. 11.  3.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 2.] 
cards in discard: [ 0.  6.  6.  0.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0. 15. 11.  3.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[ 8.400159]
 [ 7.883048]
 [10.370692]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 11.  3.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  8.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.467591285705566



action possibilites: [-1] 
expected returns: [[-12.197358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  8.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 8.546977996826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-13.357394]
 [-13.564489]
 [-11.976182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  3.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  8.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.197358131408691






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  6.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  8. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [10. 15. 10. 15. 11.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [10. 15. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 15. 11.] 
expected returns: [[25.10632 ]
 [21.914593]
 [24.50322 ]
 [21.914593]
 [24.50322 ]
 [28.265617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 15. 11.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  2.  6.] 
adversary cards in discard: [0. 8. 6. 6. 8.] 
adversary owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.976181983947754



action possibilites: [-1] 
expected returns: [[0.27270794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  2.  6.] 
adversary cards in discard: [0. 8. 6. 6. 8.] 
adversary owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 25.498779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.1914375 ]
 [-6.32395   ]
 [-0.41411042]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  2.  6.] 
adversary cards in discard: [0. 8. 6. 6. 8.] 
adversary owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16  0] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.2727079391479492






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0.  2.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  2.  6.] 
cards in discard: [0. 8. 6. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  0  6  0  6  0 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 2. 6.] 
cards in discard: [0. 8. 6. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 6.] 
cards in discard: [0. 8. 6. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 6.] 
cards in discard: [ 0.  8.  6.  6.  8. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15. 15.] 
adversary cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[35.1081  ]
 [35.210102]
 [35.210102]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10
 29 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.4141068458557129



action possibilites: [-1] 
expected returns: [[35.970043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 35.21010208129883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
expected returns: [[30.550278]
 [34.311672]
 [33.488056]
 [27.750725]
 [33.023197]
 [35.954315]
 [33.016544]
 [37.263485]
 [30.205559]
 [35.970043]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  4. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.97004318237305



buy possibilites: [-1] 
expected returns: [[5.4904566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [11. 29. 11. 29.  0.  0.  3. 10. 11. 29. 15.  3. 10. 11. 25. 29. 10. 10.
 10.  1. 11.  3.  0. 15.  3.  1. 11. 10. 15. 10. 15. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.26348114013672






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  0  6  0 16  0 23] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [25.  3. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  6  6 23] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [25.  3. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  6  6 23] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [25.  3. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [25.  3. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [25.  3. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 10.] 
expected returns: [[29.442974]
 [39.196148]
 [29.487976]
 [26.899868]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  5.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [3. 6. 2. 6. 6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0] -> size -> 10 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.490456581115723



action possibilites: [-1] 
expected returns: [[-0.38060093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [3. 6. 2. 6. 6.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.20827865600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-2.8322752 ]
 [-0.86244226]
 [-3.8149939 ]
 [-1.1015666 ]
 [-0.745996  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [3. 6. 2. 6. 6.] 
adversary cards in discard: [0. 8. 6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.3806009292602539






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 6. 2. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 2. 6. 6.] 
cards in discard: [0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 29. 15. 10.  0.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 2. 6. 6.] 
cards in discard: [0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 29. 15. 10.  0.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.] 
expected returns: [[ 9.577341]
 [12.956686]
 [10.162345]
 [ 9.081156]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 15. 10.  0.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  3. 23.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.7459943294525146



action possibilites: [-1. 10.] 
expected returns: [[26.314434]
 [22.701698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  3. 23.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 12.914124488830566





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
expected returns: [[20.95509 ]
 [27.137615]
 [25.66726 ]
 [16.347885]
 [24.803257]
 [29.840202]
 [25.121521]
 [32.045868]
 [20.10305 ]
 [27.084957]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  3. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  3. 23.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.314441680908203



buy possibilites: [-1] 
expected returns: [[34.12249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 6.  3. 23.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 333 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.0458869934082






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 23.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 23.  8. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 11. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 23.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 11. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 11. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 23.  8.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 11. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [10. 11. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11. 11.] 
expected returns: [[ 1.7260704]
 [-0.2826116]
 [ 4.809024 ]
 [ 4.809024 ]
 [ 4.809024 ]
 [ 4.809024 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 11. 11.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 2.] 
adversary cards in discard: [ 0. 15.  6.  3. 23.  8.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.12248992919922



action possibilites: [-1] 
expected returns: [[15.362422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 11.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 2.] 
adversary cards in discard: [ 0. 15.  6.  3. 23.  8.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 2.2076916694641113





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.417935]
 [ 6.251033]
 [15.502004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11. 11.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8. 6. 2.] 
adversary cards in discard: [ 0. 15.  6.  3. 23.  8.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.362421989440918






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 6. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 2.] 
cards in discard: [ 0. 15.  6.  3. 23.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [15. 15.  1.  3. 15.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 2.] 
cards in discard: [ 0. 15.  6.  3. 23.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  2. 10.  9.  0. 10.  0.] 
adversary cards in hand: [15. 15.  1.  3. 15.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 2.] 
cards in discard: [ 0. 15.  6.  3. 23.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [15. 15.  1.  3. 15.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [15. 15.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-2.3225532]
 [-3.5936294]
 [-3.5936294]
 [-3.5936294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  1.  3. 15.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  2.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.501992225646973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-6.362983 ]
 [-3.8945327]
 [-8.793768 ]
 [-4.2626643]
 [-2.2523818]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  1.  3. 15.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8.  2.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -2.3225533962249756



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 8.  2.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  2.  3. 15.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29. 29. 15. 29. 10.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  2.  3. 15.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29. 29. 15. 29. 10.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29. 15. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15. 29. 10.] 
expected returns: [[5.1805935]
 [7.8339577]
 [7.8339577]
 [4.8577256]
 [7.8339577]
 [3.4364638]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 15. 29. 10.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  6.  6. 23.] 
adversary cards in discard: [ 8.  2.  3. 15.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.2523789405822754



action possibilites: [-1. 15. 10. 10.] 
expected returns: [[29.920288]
 [29.955692]
 [27.231712]
 [27.231712]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  6.  6. 23.] 
adversary cards in discard: [ 8.  2.  3. 15.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.393423080444336



action possibilites: [-1] 
expected returns: [[-8.525396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  6.  6. 23.] 
adversary cards in discard: [ 8.  2.  3. 15.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 29.955707550048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.472812 ]
 [-12.3066435]
 [ -8.525401 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  6.  6. 23.] 
adversary cards in discard: [ 8.  2.  3. 15.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.525396347045898






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  6.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  6.  6. 23.] 
cards in discard: [ 8.  2.  3. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 10. 10. 10.  0.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  6.  6. 23.] 
cards in discard: [ 8.  2.  3. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 10. 10. 10.  0.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[17.245998]
 [15.184333]
 [15.184333]
 [15.184333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10.  0.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.525396347045898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.182149]
 [ 9.878522]
 [17.245998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 10.  0.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 29.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.24599838256836



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29.  0.  3. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.  3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29.  0.  3. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.  3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  6.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29.  0.  3. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.  3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [6. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [29.  0.  3. 11. 11.] 
adversary cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.  3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [29.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[4.4170847]
 [8.643693 ]
 [7.202136 ]
 [7.202136 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11. 11.] 
cards in discard: [25.  3. 15. 10.  0. 15.  0.  3. 15. 29. 29. 10.  0.  1.  1. 11. 10. 11.
 11. 11. 15. 15.  1.  3. 15. 29. 29. 29. 15. 10. 10.  3. 10. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 23.  2.  6.] 
adversary cards in discard: [ 6.  0.  8. 29.  8.  0.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.24599838256836



action possibilites: [-1. 15.] 
expected returns: [[-5.0602126]
 [-4.8673224]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [11. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29
 10 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 23.  2.  6.] 
adversary cards in discard: [ 6.  0.  8. 29.  8.  0.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.852499008178711



action possibilites: [-1] 
expected returns: [[-6.63949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29 10
 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 23.  2.  6.] 
adversary cards in discard: [ 6.  0.  8. 29.  8.  0.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -4.8673248291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
expected returns: [[ -9.672479 ]
 [ -5.1973104]
 [ -6.2896204]
 [-12.07117  ]
 [ -6.893174 ]
 [ -3.2684634]
 [ -6.65326  ]
 [ -2.1279984]
 [-10.255136 ]
 [ -6.194354 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29 10
 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  1. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 23.  2.  6.] 
adversary cards in discard: [ 6.  0.  8. 29.  8.  0.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.639490127563477



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 1 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3.] 
cards in discard: [11. 11. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 11 10  3 10 25 10 10 29 10 11 10 29 10
 15 11 15 15  3 11 15 15 15 15 11  1  1 29 29  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 28. 27. 30.  8.  4.  9.  2.  5.  9.  0. 10.  9.  0. 10.  0.] 
adversary cards in hand: [ 3. 15. 23.  2.  6.] 
adversary cards in discard: [ 6.  0.  8. 29.  8.  0.  6.] 
adversary owned cards: [ 8 15  3  6  8  2  6  6 23  0  6  0 29  8] -> size -> 14 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      40       0       0
       0       0     -60       0       0      64       0] 
sum of rewards: 3000279 

action type: buy - action 29.0
Learning step: 120011.25
desired expected reward: 120009.125



