 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.669174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0      -70        0     -300        0        0] 
sum of rewards: -3000615 

action type: buy - action 6.0
Learning step: -120024.4140625
desired expected reward: -120028.875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.895546]
 [111.36026 ]
 [107.763916]
 [ 96.618004]
 [113.29613 ]
 [111.35846 ]
 [107.75879 ]
 [108.86533 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.959716796875



buy possibilites: [-1] 
expected returns: [[108.324356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 113.296142578125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[109.950775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.32435607910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.11264 ]
 [113.39876 ]
 [109.932205]
 [ 99.07818 ]
 [112.11316 ]
 [115.20782 ]
 [113.38826 ]
 [117.10697 ]
 [104.353775]
 [109.92169 ]
 [109.6399  ]
 [110.84934 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.92579650878906



buy possibilites: [-1] 
expected returns: [[112.73036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.10696411132812






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.61232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.73036193847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 96.38933 ]
 [102.29915 ]
 [ 98.407455]
 [ 86.788284]
 [104.35759 ]
 [102.28415 ]
 [ 98.392456]
 [ 99.60866 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.52184295654297



buy possibilites: [-1] 
expected returns: [[104.93648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.35758972167969






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[109.53067]
 [113.80622]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.93647766113281



action possibilites: [-1] 
expected returns: [[122.73477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.1414566040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[120.99196]
 [126.80455]
 [122.97896]
 [111.02777]
 [128.78854]
 [126.80156]
 [122.97596]
 [123.87441]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.73477172851562



buy possibilites: [-1] 
expected returns: [[125.42264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 128.78855895996094






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[105.79387]
 [111.97818]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.42263793945312



action possibilites: [-1.] 
expected returns: [[99.07627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.75393676757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 93.69382 ]
 [ 99.14609 ]
 [ 95.574776]
 [ 84.67765 ]
 [101.017624]
 [ 99.13665 ]
 [ 95.565346]
 [ 96.55442 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  7.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.0762710571289



buy possibilites: [-1] 
expected returns: [[117.48184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.01762390136719






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [11. 29.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [11. 29.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[110.96457 ]
 [109.894424]
 [115.62518 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [11. 29.  0.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.48184204101562



action possibilites: [-1] 
expected returns: [[120.94537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  0.  3.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 120.69061279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[118.701485]
 [124.02286 ]
 [120.534706]
 [109.60341 ]
 [125.84955 ]
 [124.01631 ]
 [120.52818 ]
 [121.46334 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  0.  3.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  6.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.94537353515625



buy possibilites: [-1] 
expected returns: [[131.84738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [11. 29.  0.  3.  3.  0.  3. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 125.84953308105469






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 4. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 98.09527]
 [102.52556]
 [102.52556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  8. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 4. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.84738159179688



action possibilites: [-1] 
expected returns: [[103.89552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 4. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.63336181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.454475]
 [102.145386]
 [ 92.80133 ]
 [105.248215]
 [103.23384 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 4. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.89552307128906



buy possibilites: [-1] 
expected returns: [[118.73988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 4. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 105.24819946289062






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [8. 0. 3. 0. 4. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 0. 3. 0. 4. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 4 8 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 0. 3. 0. 4. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 4 8 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 0. 3. 0. 4. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 10. 11. 11.  3.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29. 10. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[121.875565]
 [127.44823 ]
 [120.49284 ]
 [125.61577 ]
 [125.61577 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 11.  3.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.73988342285156



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[119.09567]
 [116.64713]
 [121.68055]
 [121.68055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3.  3.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 127.81051635742188



action possibilites: [-1] 
expected returns: [[122.54375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.81654357910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.00391]
 [108.63823]
 [122.12367]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.54374694824219






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[114.382416]
 [111.7183  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 4. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.1236572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.82483 ]
 [113.51822 ]
 [110.68403 ]
 [101.53009 ]
 [112.43854 ]
 [115.30981 ]
 [113.450615]
 [116.97857 ]
 [105.9195  ]
 [110.61644 ]
 [110.503944]
 [113.280556]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 4. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.14895629882812



buy possibilites: [-1] 
expected returns: [[119.25825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10.  8. 11.  3. 11.  0.  0. 10. 29. 11. 10. 11.  3.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 4. 0. 3.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 33 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 116.97856140136719






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 0. 3.] 
cards in discard: [0. 0. 0. 4. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0. 3.] 
cards in discard: [0. 0. 0. 4. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0. 3.] 
cards in discard: [0. 0. 0. 4. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11. 29.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[103.5627 ]
 [106.32023]
 [107.90707]
 [106.32023]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.25824737548828



action possibilites: [-1. 11. 11.] 
expected returns: [[106.25663]
 [109.63005]
 [109.63005]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.7242431640625



action possibilites: [-1] 
expected returns: [[106.15344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.16714477539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[103.834   ]
 [105.442535]
 [ 96.629074]
 [108.20978 ]
 [106.85237 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  7. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.1534423828125



buy possibilites: [-1] 
expected returns: [[121.46869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  6. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 108.20976257324219






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  6. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  6. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  0.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[117.37121 ]
 [115.549866]
 [122.81948 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  0.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [4. 0. 8. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.46868896484375



action possibilites: [-1. 10.] 
expected returns: [[135.16676]
 [133.29631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [4. 0. 8. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 122.50344848632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[132.63298]
 [138.18018]
 [134.65529]
 [126.8577 ]
 [123.41662]
 [136.86047]
 [140.1624 ]
 [138.14009]
 [148.07088]
 [142.13945]
 [128.8399 ]
 [133.10747]
 [134.6152 ]
 [127.56029]
 [134.38708]
 [136.45341]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [4. 0. 8. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 135.16676330566406



buy possibilites: [-1] 
expected returns: [[146.95708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [4. 0. 8. 8. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 175 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 148.0708770751953






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [4. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 8. 8. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 8. 8. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 8. 8. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8. 11. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  8. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 11. 10.] 
expected returns: [[151.87366]
 [152.21921]
 [149.87611]
 [152.21921]
 [152.21921]
 [146.99055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [4. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.9570770263672



action possibilites: [-1] 
expected returns: [[128.43929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [4. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 154.89517211914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.93706 ]
 [113.472984]
 [128.81357 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [4. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8 0] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.4392852783203






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [4. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 3 4 8 8 0 0 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10. 11.  8.
 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 8 8 0 0 0 8 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10. 11.  8.
 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 8 8 0 0 0 8 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 10.] 
adversary cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10. 11.  8.
 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[140.21275]
 [137.6215 ]
 [137.6215 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10. 11.  8.
 11. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [0 0 0 3 8 8 0 0 0 8 0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.81356811523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[136.09096]
 [137.7672 ]
 [129.42642]
 [140.16745]
 [140.52472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10. 10.] 
cards in discard: [10.  8. 29. 11.  3. 11.  0.  3. 25. 29.  0. 10.  0.  0.  0. 10. 11.  8.
 11. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [0 0 0 3 8 8 0 0 0 8 0] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 140.52554321289062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 8.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 8 8 0 0 0 8 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 0 0 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 0 0 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 0 0 8 0 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 11. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 11.] 
expected returns: [[114.54672 ]
 [112.7444  ]
 [117.371704]
 [123.80189 ]
 [117.371704]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8. 10. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 0 0 8 0 3] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.52471923828125



action possibilites: [-1] 
expected returns: [[115.921555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 0 0 0 8 0 3 6] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.93185424804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.96852]
 [104.6841 ]
 [116.07399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 0 0 0 8 0 3 6] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.92155456542969






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 0 0 8 0 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 0 0 8 0 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  0  0  8  0  3  6 22] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[115.16417]
 [113.77153]
 [113.77153]
 [116.5872 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  8.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10 11 10  8 10 29 10  8
 25 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  0  0  8  0  3  6 22] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.0739974975586



action possibilites: [-1] 
expected returns: [[118.9496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  0  0  8  0  3  6 22] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 118.59701538085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.43078]
 [104.98619]
 [118.92607]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 8.] 
adversary cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  0  0  8  0  3  6 22] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.94960021972656






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 8.] 
cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  0  0  8  0  3  6 22] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 22.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 29. 10.  3.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[127.26898]
 [133.1282 ]
 [126.38847]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10.  3.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.92605590820312



action possibilites: [-1. 10. 29.] 
expected returns: [[119.24161 ]
 [117.909676]
 [123.997986]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 29.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 133.61508178710938



action possibilites: [-1. 10. 11.] 
expected returns: [[124.798065]
 [122.1084  ]
 [126.6644  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 11.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.99798583984375



action possibilites: [-1] 
expected returns: [[150.59822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.44207763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[146.34418]
 [152.08356]
 [148.48355]
 [137.07124]
 [154.2954 ]
 [152.01602]
 [148.42223]
 [151.20465]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  5.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.5982208251953



buy possibilites: [-1] 
expected returns: [[135.78606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 154.29539489746094






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 22.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0  0  0  8  0  6 22] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  0  8  0  6 22] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  0  8  0  6 22] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  8.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[133.46185]
 [130.54301]
 [133.7486 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 22.  6.  8.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.7860565185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.21754]
 [134.3275 ]
 [131.33322]
 [120.74184]
 [136.22403]
 [134.2585 ]
 [131.26906]
 [134.26112]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  4.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 22.  6.  8.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 132.32481384277344



buy possibilites: [-1] 
expected returns: [[122.036514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [25. 10. 11. 11.  0. 11. 10.  8. 10. 11. 29. 29. 11.  0.  3. 10.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 22.  6.  8.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 136.22401428222656






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 22.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 22.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 22.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[153.78737]
 [151.07735]
 [158.07516]
 [156.22209]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.03651428222656



action possibilites: [-1. 10. 11.] 
expected returns: [[152.8072 ]
 [150.04523]
 [154.66185]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 157.44505310058594



action possibilites: [-1] 
expected returns: [[139.9429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 157.30520629882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[136.75166]
 [138.49577]
 [128.53583]
 [141.59796]
 [139.81438]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  5.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.94290161132812



buy possibilites: [-1] 
expected returns: [[133.43877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.] 
cards in discard: [10.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 22.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 141.59796142578125






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8. 22.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [10. 11. 29. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 29. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [10. 11. 29. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  6.  0.  0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [10. 11. 29. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 11. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 11.  8.] 
expected returns: [[126.01811]
 [124.45713]
 [129.04936]
 [130.71747]
 [129.04936]
 [127.33792]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 11.  8.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  8. 22.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.4387664794922



action possibilites: [-1. 10. 11. 11.  8.] 
expected returns: [[136.17357]
 [133.18977]
 [138.44629]
 [138.44629]
 [136.36426]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8.  0.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  2.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  8. 22.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.75242614746094



action possibilites: [-1] 
expected returns: [[129.30016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  0.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  8. 22.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 141.6508026123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[124.13116 ]
 [126.175095]
 [114.724655]
 [129.2528  ]
 [129.35413 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  0.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3.  8. 22.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.30015563964844






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3.  8. 22.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  8  0  6 22  0  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [11.  0. 10.  8. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  8. 22.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [11.  0. 10.  8. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  8. 22.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [11.  0. 10.  8. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  8. 22.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [11.  0. 10.  8. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 10.] 
expected returns: [[136.27019]
 [137.63203]
 [134.08888]
 [136.21745]
 [134.08888]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  8. 10.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.35414123535156



action possibilites: [-1] 
expected returns: [[164.79399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  0.  9. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 137.76873779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[158.18779]
 [150.17201]
 [165.46117]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  0.  9. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.7939910888672






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  0.  9. 10.] 
adversary cards in hand: [10. 25. 11. 11.  0.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  8. 10. 10.  0.  9. 10.] 
adversary cards in hand: [10. 25. 11. 11.  0.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [10. 25. 11. 11.  0.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 25. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11. 11.] 
expected returns: [[117.23831 ]
 [114.53056 ]
 [123.142044]
 [117.820915]
 [117.820915]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11. 11.  0.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  9. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3.  6.  0. 22.  8.] 
adversary cards in discard: [29.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 165.46116638183594



action possibilites: [-1] 
expected returns: [[126.788956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0. 11.  3.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3.  6.  0. 22.  8.] 
adversary cards in discard: [29.  0.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.14204406738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.66439 ]
 [113.632034]
 [125.42461 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0. 11.  3.] 
cards in discard: [10.  8. 29. 11.  0. 10.  3.  3. 10. 29. 11. 10. 11.  8.  0. 10. 11.  0.
 10.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3.  6.  0. 22.  8.] 
adversary cards in discard: [29.  0.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.78895568847656






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 22.  8.] 
cards in discard: [29.  0.  0.  0.  8.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  8.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  8.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  8.  8. 29.  0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[149.33948]
 [151.4527 ]
 [149.5222 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9. 10.] 
adversary cards in hand: [22.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.42459106445312



action possibilites: [-1] 
expected returns: [[141.36458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [22.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 153.4613494873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[136.95447]
 [138.86253]
 [129.6718 ]
 [141.42784]
 [142.13908]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [22.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.3645782470703






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [22.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 28. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6. 3. 8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[137.98874]
 [140.73909]
 [140.73909]
 [140.73909]
 [135.12999]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.1390838623047



action possibilites: [-1] 
expected returns: [[152.7784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.55384826660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.3523 ]
 [140.24925]
 [154.18008]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  8. 29.  0.] 
adversary cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0  3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.7783966064453






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29.  0.] 
cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0 29  6  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 22.  0.  6.  0.  0.  6.  3.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [11. 25. 10.  0.  3.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 25. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[146.88783]
 [148.00122]
 [156.5637 ]
 [141.66121]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10.  0.  3.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  8. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3  1] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.18006896972656



action possibilites: [-1] 
expected returns: [[141.5502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3. 10. 29.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3  1  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.42774963378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.37259]
 [129.74867]
 [146.9617 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3. 10. 29.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3  1  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.55020141601562






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  6 22  0  0  3  0  6  0  3  1  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [10.  8. 10. 10. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [10.  8. 10. 10. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [10.  8. 10. 10. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [10.  8. 10. 10. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  8. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10. 10.] 
expected returns: [[122.93262 ]
 [119.22499 ]
 [121.827324]
 [119.22499 ]
 [119.22499 ]
 [119.22499 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 10. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [6. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.9617156982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.64945]
 [111.64651]
 [123.20244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10. 10. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [6. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6  0] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 122.9326171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  1  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[121.48349 ]
 [123.844086]
 [123.844086]
 [118.644745]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 8.  0.  6.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.20245361328125



action possibilites: [-1] 
expected returns: [[123.59283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  0.  6.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.00312805175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.78422]
 [110.27742]
 [124.05063]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.] 
cards in discard: [15. 11.  3.  0.  8.  0. 15. 11. 11.  0. 11. 10. 25. 11. 10.  0.  3. 10.
 29. 10.  8. 10. 10. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  0.  6.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.59282684326172






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  6.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6.  0. 22.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 11. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 11. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 11. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3. 0. 6.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 11. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 29.] 
expected returns: [[132.6563 ]
 [134.51826]
 [129.59563]
 [132.53061]
 [136.20467]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.05062866210938



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[142.66695]
 [144.63077]
 [139.87193]
 [144.63077]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 130.3380889892578



action possibilites: [-1] 
expected returns: [[139.23892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [ 8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 147.5571746826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.55522]
 [139.34361]
 [130.14249]
 [142.2009 ]
 [141.57954]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [ 8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  4.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.23892211914062



buy possibilites: [-1] 
expected returns: [[136.99806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.] 
cards in discard: [ 8. 15.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 142.20089721679688






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [29. 11. 10.  0. 11.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [29. 11. 10.  0. 11.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3. 22.  8.  0.  6.  0.  3.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [29. 11. 10.  0. 11.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 11. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11.] 
expected returns: [[96.11716 ]
 [97.592354]
 [96.01261 ]
 [91.35527 ]
 [96.01261 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0. 11.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.99806213378906



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[113.81556]
 [112.83203]
 [108.01613]
 [112.83203]
 [108.01613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 94.28656768798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.760864]
 [ 98.55229 ]
 [113.709625]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.81556701660156






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 22.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0 22  0  0  3  0  6  0  3  6  0  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3. 10. 25.  0.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3. 10. 25.  0.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3. 10. 25.  0.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8.  3. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25.] 
expected returns: [[124.67023 ]
 [123.437546]
 [121.31798 ]
 [130.76105 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 25.  0.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  7. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.70964050292969



action possibilites: [-1] 
expected returns: [[120.78964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0. 11. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.7610321044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.51903]
 [107.75401]
 [121.51484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  0. 11. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 0. 6. 6. 3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.78964233398438






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 3.] 
cards in discard: [8. 0. 0. 6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [11.  3.  0.  8.  3.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[87.88803]
 [87.73635]
 [86.77906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8.  3.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 0. 0. 6. 6. 3.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.51483154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.68194 ]
 [79.6322  ]
 [87.399376]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  8.  3.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 6. 3. 0. 0. 6. 6. 3.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.88803100585938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [8. 0. 0. 6. 3. 0. 0. 6. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [10. 15.  0. 11. 10.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [8. 0. 0. 6. 3. 0. 0. 6. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [10. 15.  0. 11. 10.] 
adversary cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 15.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 10.] 
expected returns: [[60.513847]
 [57.21806 ]
 [57.182934]
 [61.183304]
 [57.21806 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 11. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10. 11.  3.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  6.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.39936828613281



action possibilites: [-1] 
expected returns: [[115.239746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10. 11.  3.  0.  8.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.43406295776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.529785]
 [102.94255 ]
 [114.101036]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0. 10.] 
cards in discard: [ 8. 15.  8. 29. 11.  0. 10. 11.  0. 29. 11. 10. 11. 10. 25.  8.  3. 10.
  0. 11. 10. 11.  3.  0.  8.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.23974609375






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [10. 10. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [10. 10. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [10. 10. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 10. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 15. 10.] 
expected returns: [[132.53723]
 [129.18645]
 [129.18645]
 [129.10666]
 [129.10666]
 [129.18645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [3. 0. 6. 0. 3. 3.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.10101318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.70305]
 [119.22128]
 [131.92711]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [3. 0. 6. 0. 3. 3.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.49342346191406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [3. 0. 6. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [3. 0. 6. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [3. 0. 6. 0. 3. 3. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[95.25163 ]
 [89.558945]
 [89.58692 ]
 [95.89043 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10. 11.] 
cards in discard: [10. 10. 15. 15. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [3. 0. 6. 0. 3. 3. 1. 0. 8. 0. 0. 8.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.9271240234375



action possibilites: [-1] 
expected returns: [[81.82399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [10. 10. 15. 15. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  4.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [3. 0. 6. 0. 3. 3. 1. 0. 8. 0. 0. 8.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.17716979980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[73.315056]
 [76.14535 ]
 [64.247894]
 [79.439766]
 [82.207085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [10. 10. 15. 15. 10. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  4.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [3. 0. 6. 0. 3. 3. 1. 0. 8. 0. 0. 8.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.82398986816406






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [3. 0. 6. 0. 3. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  4.] 
adversary cards in hand: [11. 11.  0.  8.  8.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [3. 0. 6. 0. 3. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  4.] 
adversary cards in hand: [11. 11.  0.  8.  8.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.  8.] 
expected returns: [[104.367386]
 [105.90685 ]
 [105.90685 ]
 [103.63429 ]
 [103.63429 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.  8.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  4.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.20706176757812



action possibilites: [-1] 
expected returns: [[125.74313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 89 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.15422058105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.27023]
 [111.89129]
 [126.51547]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.74313354492188






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 11.  3.  0. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 11.  3.  0. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [ 8. 11.  3.  0. 11.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 11.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[122.54195 ]
 [121.201935]
 [123.10797 ]
 [123.10797 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0. 11.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  3.] 
adversary cards in hand: [0. 1. 8. 0. 6.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.51547241210938



action possibilites: [-1] 
expected returns: [[125.43533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [0. 1. 8. 0. 6.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.67691040039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.54809]
 [113.4136 ]
 [125.71883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [0. 1. 8. 0. 6.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.43533325195312






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 6.] 
cards in discard: [3. 6. 3. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [29. 10. 11.  3. 29.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 6.] 
cards in discard: [3. 6. 3. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [29. 10. 11.  3. 29.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0. 6.] 
cards in discard: [3. 6. 3. 3. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [29. 10. 11.  3. 29.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 10. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 29.] 
expected returns: [[114.95117]
 [116.86109]
 [110.10148]
 [115.13502]
 [116.86109]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  3. 29.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.71882629394531



action possibilites: [-1. 10. 11.] 
expected returns: [[132.56212]
 [126.95354]
 [132.85725]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  2.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 112.99897003173828



action possibilites: [-1] 
expected returns: [[132.89354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 59 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 136.14117431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.2784 ]
 [120.47748]
 [134.00768]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
adversary owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.89353942871094






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 6 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [10.  8. 10. 11. 15.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [10.  8. 10. 11. 15.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [10.  8. 10. 11. 15.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3. 6. 3. 3. 0. 0. 0. 0. 1. 8. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [10.  8. 10. 11. 15.] 
adversary cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10.  8. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11. 15.] 
expected returns: [[89.91193 ]
 [86.44959 ]
 [89.25244 ]
 [86.44959 ]
 [91.25256 ]
 [86.388374]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 11. 15.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  1.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.0076904296875



action possibilites: [-1] 
expected returns: [[145.47182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 15.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.17138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.17033]
 [131.3114 ]
 [145.4718 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10. 15.] 
cards in discard: [10. 10. 15. 15. 10. 15. 11.  0.  0. 15. 10. 15. 11. 11.  0.  8.  8. 15.
 11.  8.  3.  0. 11. 29. 15. 29. 11. 10.  3.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.47181701660156






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [11. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3 0 0 3 6 0 3 0 6 3 3 1 3 0 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  3.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [11. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [11. 15. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 15. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 25.] 
expected returns: [[163.08107]
 [163.22911]
 [157.93341]
 [157.91165]
 [170.32292]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  6. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.] 
adversary owned cards: [ 8  8  0  0  0  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.47181701660156



action possibilites: [-1] 
expected returns: [[134.14716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 8  8  0  0  0  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 170.32290649414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[128.56465]
 [130.84282]
 [122.2859 ]
 [133.28027]
 [136.1191 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 10.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.] 
adversary owned cards: [ 8  8  0  0  0  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.14715576171875






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.  8.] 
expected returns: [[129.27588]
 [125.01767]
 [127.74664]
 [129.9206 ]
 [127.74664]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 11.  8.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
adversary owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 136.11907958984375



action possibilites: [-1] 
expected returns: [[121.10763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
adversary owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 127.86302185058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.44901]
 [107.64928]
 [122.52284]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
adversary owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.10762786865234






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3  0  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 11.  3.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 11.  3.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15. 10. 15. 11.  3.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15. 10. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15. 11.] 
expected returns: [[119.12538]
 [113.27742]
 [113.34662]
 [113.27742]
 [119.15591]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15. 11.  3.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [6. 6. 3. 3. 3.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.52286529541016



action possibilites: [-1] 
expected returns: [[124.08418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15.  3.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [6. 6. 3. 3. 3.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 116.81304931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[118.15792]
 [108.19945]
 [124.3309 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15.  3.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [6. 6. 3. 3. 3.] 
adversary cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.08418273925781






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3. 3.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15.  3. 29. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 3.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15.  3. 29. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 3.] 
cards in discard: [11.  0.  1.  0.  3.  3.  6.  0.  8.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15.  3. 29. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15.  3. 29. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15. 11.] 
expected returns: [[120.99472]
 [115.63257]
 [121.36083]
 [115.63257]
 [119.90812]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29. 15. 11.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.33090209960938



action possibilites: [-1. 15. 15.] 
expected returns: [[116.56025 ]
 [112.247314]
 [112.247314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 117.93170166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.83142]
 [100.77249]
 [116.36123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  6. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.56024932861328






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  0.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  2.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6.] 
cards in discard: [11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[103.70227 ]
 [103.693924]
 [ 99.61011 ]
 [ 99.61011 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [8. 6. 0. 0. 1.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.3612289428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.7472 ]
 [ 99.10568]
 [ 93.7561 ]
 [100.51728]
 [103.11292]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [8. 6. 0. 0. 1.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.70225524902344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8. 6. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 1.] 
cards in discard: [11.  0. 11.  3.  6.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11. 10. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 1.] 
cards in discard: [11.  0. 11.  3.  6.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  3.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11. 10. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 1.] 
cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11. 10. 15. 11.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 8. 11. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 15. 11.] 
expected returns: [[76.90749]
 [75.55337]
 [77.65142]
 [73.10531]
 [73.12064]
 [77.65142]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 15. 11.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.11292266845703



action possibilites: [-1] 
expected returns: [[95.46843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15. 11.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.6616439819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[90.48263]
 [82.53638]
 [95.46844]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15. 11.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 25. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.46842956542969






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 15. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.  1. 11.  8. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 23. 29.  8.  5. 10.  1.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [15. 15. 15. 11.  8.] 
adversary cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.  1. 11.  8. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 15. 15. 11.  8.] 
cards in discard: [25. 11. 15. 10.  0.  0. 15.  1. 11. 10.  0.  8.  8.  1. 11. 15. 10. 15.
  3. 11. 10. 29. 15.  3. 15. 29.  0. 10.  0. 10.  1. 11.  8. 10. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 11 11 11 10  8 10 29 10  8 25 10 10 11
 11 10  8 10 10 15 15 15 15  8 15 15 15 15 15 15  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 23. 29.  8.  5. 10.  0.  2.  9.  7. 10. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  6.  8.  8.  6.  0.  0.  1. 11.] 
adversary owned cards: [ 8  8  0  3  6  0  3  0  6  3  3  1  3  0  0 11  6  0  0 11  0  8 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1.0
Learning step: 119997.1796875
desired expected reward: 120092.6484375



