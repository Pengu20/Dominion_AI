 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.353848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action -1
Learning step: -120000.6875
desired expected reward: -120348.5625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 23.469147]
 [ 33.228313]
 [-43.440567]
 [ 30.127342]
 [ 29.127728]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.038448333740234



buy possibilites: [-1] 
expected returns: [[26.890038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 33.22830581665039






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.445513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.890037536621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 16.511238 ]
 [ 34.466766 ]
 [ 27.190048 ]
 [ -7.248006 ]
 [-60.03275  ]
 [ 38.45436  ]
 [ 36.059227 ]
 [ 23.452972 ]
 [ 49.71218  ]
 [ 43.898895 ]
 [-15.314217 ]
 [ 32.753525 ]
 [ 30.894104 ]
 [  6.0556483]
 [ 20.958374 ]
 [ 21.899609 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.945369720458984



buy possibilites: [-1] 
expected returns: [[21.65644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.7121696472168






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.448402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.65644073486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.196096]
 [ 34.139286]
 [ 25.223837]
 [-47.572426]
 [ 33.278072]
 [ 23.01812 ]
 [ 27.850239]
 [ 20.652756]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.612844467163086



buy possibilites: [-1] 
expected returns: [[17.713644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 34.13927459716797






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 25.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[32.139614]
 [62.616886]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.71364402770996



action possibilites: [-1] 
expected returns: [[15.851265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.49564743041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  5.6188197]
 [ 21.263683 ]
 [ 12.64052  ]
 [-65.30589  ]
 [ 22.870255 ]
 [ 20.164188 ]
 [ 11.445309 ]
 [ 27.871445 ]
 [-21.126572 ]
 [ 14.894236 ]
 [  6.8872485]
 [ 12.636433 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.851264953613281



buy possibilites: [-1] 
expected returns: [[23.224728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.871444702148438






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 7.390798]
 [32.05323 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8.  3.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.224727630615234



action possibilites: [-1] 
expected returns: [[3.6889272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.161697387695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -2.6367235]
 [ 11.234142 ]
 [  1.2534928]
 [-80.283226 ]
 [  9.149473 ]
 [  4.8679185]
 [  6.8569493]
 [  4.497108 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.688927173614502



buy possibilites: [-1] 
expected returns: [[7.8044715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 29.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 11.234146118164062






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8  8  6  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  3.  0. 11.  0.  0.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-22.861963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.804471492767334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-29.000069  ]
 [-10.928174  ]
 [-26.12577   ]
 [-15.465946  ]
 [-39.597496  ]
 [-84.246994  ]
 [ -3.5500603 ]
 [ -8.215767  ]
 [-20.699942  ]
 [ 10.317238  ]
 [  5.9871955 ]
 [-42.204643  ]
 [ -0.47818184]
 [-10.625277  ]
 [-26.26071   ]
 [-10.940662  ]
 [-21.873226  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.423011779785156



buy possibilites: [-1] 
expected returns: [[23.170147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 1. 25.  0.  3.  0.  3. 29.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 177.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 10.317224502563477






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.23414564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.170146942138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-4.6602068e+00]
 [ 1.1474470e+01]
 [ 2.3918757e+00]
 [-7.8456512e+01]
 [ 9.6976852e+00]
 [ 1.4816141e+00]
 [ 4.4169927e+00]
 [ 4.9178600e-02]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.297652244567871



buy possibilites: [-1] 
expected returns: [[-19.501999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 11.474462509155273






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [1. 0. 3. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 8.  0.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [1. 0. 3. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 8.  0.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [1. 0. 3. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 3.9602866]
 [25.43577  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [1. 0. 3. 1. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  8. 10.  9.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14] -> size -> 16 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.501998901367188



action possibilites: [-1] 
expected returns: [[-5.670298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [1. 0. 3. 1. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.783702850341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-11.872403 ]
 [  2.6920228]
 [ -5.6519704]
 [-55.29098  ]
 [  5.7686667]
 [  1.466084 ]
 [ -6.009655 ]
 [  8.39163  ]
 [-35.63754  ]
 [ -3.203706 ]
 [-13.138481 ]
 [ -7.8863583]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [1. 0. 3. 1. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.670298099517822



buy possibilites: [-1] 
expected returns: [[30.878902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [ 1.  0.  3.  1.  3.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 8.391613006591797






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 8.] 
cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 8.] 
cards in discard: [ 8.  0.  3.  0. 14. 11. 10.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  1. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-7.942079]
 [11.375038]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  7. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.878902435302734



action possibilites: [-1] 
expected returns: [[-10.378483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.784013748168945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -28.827408 ]
 [ -10.942372 ]
 [ -25.540697 ]
 [ -52.523502 ]
 [-107.69851  ]
 [   1.1369338]
 [  -6.316978 ]
 [ -14.960634 ]
 [  10.728451 ]
 [   6.854406 ]
 [ -58.34366  ]
 [ -10.932192 ]
 [  -8.791079 ]
 [ -42.461315 ]
 [ -22.514654 ]
 [  -9.394173 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  8.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.378482818603516



buy possibilites: [-1] 
expected returns: [[-8.998564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 10.728424072265625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  8.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 6. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3. 29.  1. 25.] 
adversary cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 1.  3. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[31.338104]
 [46.38306 ]
 [54.12477 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  1. 25.] 
cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0] -> size -> 20 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.998563766479492



action possibilites: [-1] 
expected returns: [[35.22999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  1.  3.  0.] 
cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.70109939575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.499763 ]
 [50.938335 ]
 [45.74955  ]
 [23.651249 ]
 [ 3.6183429]
 [54.267857 ]
 [52.34602  ]
 [42.105396 ]
 [62.706738 ]
 [56.93984  ]
 [16.558144 ]
 [49.3866   ]
 [47.54808  ]
 [31.2728   ]
 [38.69     ]
 [39.28336  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  1.  3.  0.] 
cards in discard: [25. 25.  3.  1.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  7.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.22998809814453



buy possibilites: [-1] 
expected returns: [[-11.792407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  1.  3.  0.] 
cards in discard: [25. 25.  3.  1.  0.  0.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 62.706722259521484






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  3.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  6.  3.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-11.86882  ]
 [  7.971565 ]
 [  1.4302087]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  5. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  6.  3. 14.  0.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6] -> size -> 21 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.792407035827637



action possibilites: [-1] 
expected returns: [[-20.586496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  6.  3. 14.  0.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.68377161026001





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-25.78444 ]
 [-16.297695]
 [-24.485312]
 [-42.147514]
 [-93.93832 ]
 [-13.341441]
 [-16.620548]
 [-22.013298]
 [-10.70586 ]
 [ -8.920435]
 [-46.672043]
 [-16.353476]
 [-17.693033]
 [-38.491947]
 [-20.906858]
 [-18.461124]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  6.  3. 14.  0.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.586496353149414



buy possibilites: [-1] 
expected returns: [[12.620993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  1.  3.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  6.  3. 14.  0.] 
adversary cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. 210.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 257.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -8.92044448852539






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 14.  0.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 25.  3. 25.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 25.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 25.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0.] 
cards in discard: [ 6. 29.  0. 11.  8.  0.  0.  8.  6.  0. 10.  6.  6.  3.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 25.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[13.166027]
 [25.3783  ]
 [31.790989]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  4. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10] -> size -> 23 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 50.36985397338867



action possibilites: [-1] 
expected returns: [[38.539616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6] -> size -> 24 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.18903350830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.585373 ]
 [39.99103  ]
 [-2.9807696]
 [37.052975 ]
 [36.62404  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6] -> size -> 24 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.539615631103516



buy possibilites: [-1] 
expected returns: [[7.318435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 39.991031646728516






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [6. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: -5 





Player: 0 
cards in hand: [1. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.8755975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [6. 1. 6. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.318435192108154





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-7.6658068e+00]
 [ 7.6157575e+00]
 [-1.1245459e+01]
 [-1.2605963e+00]
 [-2.1295458e+01]
 [-4.2856636e+01]
 [ 1.4146471e+01]
 [ 7.9026351e+00]
 [-1.2472153e-02]
 [ 2.3034405e+01]
 [ 1.8658758e+01]
 [-2.9667522e+01]
 [ 6.4702220e+00]
 [ 4.1165147e+00]
 [-1.4846682e+01]
 [-3.3982215e+00]
 [ 1.6846094e+00]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  6.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [6. 1. 6. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.8755974769592285



buy possibilites: [-1] 
expected returns: [[30.499798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  1.  3. 25. 25.  3. 25. 29.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  6.  0.] 
adversary cards in discard: [6. 1. 6. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  300.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 357.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 23.034400939941406






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  6.  0.] 
cards in discard: [6. 1. 6. 0. 6. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  6.  0.] 
cards in discard: [6. 1. 6. 0. 6. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 28. 30.  8.  3. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  6.  0.] 
cards in discard: [6. 1. 6. 0. 6. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  3. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
adversary victory points: 5
player victory points: -5 





Player: 0 
cards in hand: [25. 25.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-12.759909 ]
 [  2.5527244]
 [  2.5527244]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  3. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  6.  6.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0] -> size -> 26 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.499797821044922



action possibilites: [-1] 
expected returns: [[-15.494619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  6.  6.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.491438388824463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-17.80133  ]
 [ -5.8100557]
 [-13.426909 ]
 [-72.97338  ]
 [ -7.366391 ]
 [-13.017844 ]
 [-11.017103 ]
 [-12.189686 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  6.  6.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.494619369506836



buy possibilites: [-1] 
expected returns: [[24.260208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.  3.  3.  0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  6.  6.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -5.810065746307373






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  6.  6.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  6.  6.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
adversary victory points: 5
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
adversary victory points: 5
player victory points: -6 





Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-66.49904 ]
 [-39.116837]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  2. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0] -> size -> 28 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.260208129882812



action possibilites: [-1] 
expected returns: [[36.30041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -39.11679458618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[36.978783  ]
 [51.176537  ]
 [45.65694   ]
 [-0.64506865]
 [54.464817  ]
 [52.46851   ]
 [41.43605   ]
 [56.525303  ]
 [14.638334  ]
 [46.994705  ]
 [36.74491   ]
 [41.85728   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.300411224365234



buy possibilites: [-1] 
expected returns: [[-31.70663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  0. 29.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 473 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 56.52530288696289






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [14.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 10.  0.  0.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  1.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
adversary victory points: 5
player victory points: -7 


action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  0.  8.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 25.  1.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
adversary victory points: 5
player victory points: -7 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6
  1  0  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
adversary victory points: 5
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
adversary victory points: 5
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  1.  6.  0.  6.  0.  0.  0.  8.  3. 11.  6.  0.  6.  0. 10. 29.  0.
  6.  6.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
adversary victory points: 5
player victory points: -7 





Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.797573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -99.6192398071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 18.231705 ]
 [ 31.282246 ]
 [ 22.698742 ]
 [-48.348785 ]
 [ 34.576637 ]
 [ 31.8158   ]
 [ 23.203857 ]
 [ 37.35351  ]
 [ -7.9787445]
 [ 27.897564 ]
 [ 19.932585 ]
 [ 25.375225 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.79757308959961



buy possibilites: [-1] 
expected returns: [[35.53191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 25. 25.  1.  3.  3.  3.  0. 29. 25.  0.  0.  3.  0.  0. 29. 25.  1.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  6.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 483 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.35349655151367






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14.  6.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  0.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  0.  6.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -7 





Player: 0 
cards in hand: [ 1. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-5.50798 ]
 [ 8.645023]
 [ 8.645023]
 [11.640381]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  1. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0] -> size -> 28 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.53190994262695



action possibilites: [-1] 
expected returns: [[33.711838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 11.175054550170898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[32.34375 ]
 [36.829548]
 [38.72257 ]
 [41.64155 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6] -> size -> 29 
adversary victory points: -7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.71183776855469






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  6.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  7.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
adversary victory points: 5
player victory points: -8 





Player: 0 
cards in hand: [ 3.  3. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-10.163029 ]
 [  1.0771818]
 [  7.2335486]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0. 25.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.64154815673828



action possibilites: [-1] 
expected returns: [[-3.1216285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  1. 25.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.233530521392822





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.346777 ]
 [ 5.01277  ]
 [ 0.7215142]
 [ 7.9304824]
 [-1.5583498]
 [ 3.8299356]
 [-0.9223447]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  1. 25.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  9.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.121628522872925



buy possibilites: [-1] 
expected returns: [[53.248196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  1. 25.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 459 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 7.9304728507995605






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  6.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  6.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
adversary victory points: 5
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
adversary victory points: 5
player victory points: -8 





Player: 0 
cards in hand: [ 1.  1.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[18.787567]
 [35.368095]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 25.  0.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.24819564819336



action possibilites: [-1] 
expected returns: [[10.025892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.36811065673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.203316 ]
 [ 29.285488 ]
 [  9.136324 ]
 [ 21.636164 ]
 [ -8.302055 ]
 [ 41.591217 ]
 [ 37.51567  ]
 [ 24.278526 ]
 [ 57.89829  ]
 [ 47.505436 ]
 [-12.9004345]
 [ 29.975262 ]
 [ 32.28765  ]
 [  6.5749516]
 [ 15.633427 ]
 [ 25.746902 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  5.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.02589225769043



buy possibilites: [-1] 
expected returns: [[54.26289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 3. 3.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  6. 10.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  390.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 467.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 57.89828872680664






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  6. 10.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25. 25. 25.  1.
  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  6. 10.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25. 25. 25.  1.
  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
adversary victory points: 5
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[14.916182]
 [31.482906]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [25.  1. 29. 29.  3. 29. 29. 11. 25.  3.  3. 29.  0.  1. 25. 25. 25.  1.
  1.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 0.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.26288986206055



action possibilites: [-1] 
expected returns: [[3.9518723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 0.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.48290252685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-11.40831   ]
 [ -2.3981018 ]
 [ -8.103199  ]
 [  4.477736  ]
 [  0.09901619]
 [ -8.397101  ]
 [  6.4852557 ]
 [-31.930004  ]
 [ -2.8306942 ]
 [ -9.076988  ]
 [  2.7566905 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 25. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 0.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.9518723487854004



buy possibilites: [-1] 
expected returns: [[42.428814]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 25. 11.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 0.] 
adversary cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 533 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 6.485238552093506






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 8. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 1. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 1. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 1. 0.] 
cards in discard: [ 0. 14.  6.  6.  0.  6.  6.  8. 11.  6.  0.  0.  6.  8. 10.  8.  0.  3.
  6.  0.  3.  6.  0.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
adversary victory points: 5
player victory points: -8 





Player: 0 
cards in hand: [29.  1. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[34.479687]
 [45.6777  ]
 [45.6777  ]
 [45.6777  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  0. 29.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.42881393432617



action possibilites: [-1. 29. 29.] 
expected returns: [[-65.51028 ]
 [-48.462475]
 [-48.462475]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.73343276977539



action possibilites: [-1.] 
expected returns: [[53.471813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -59.54201126098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.384075]
 [58.458744]
 [44.04791 ]
 [52.606667]
 [34.5353  ]
 [61.263447]
 [58.506626]
 [50.829308]
 [68.07618 ]
 [65.340454]
 [28.388088]
 [56.273335]
 [54.91584 ]
 [40.06194 ]
 [48.46613 ]
 [53.16453 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.4718132019043



buy possibilites: [-1] 
expected returns: [[48.932755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14.  8.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  390.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 487.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 68.07617950439453






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  8.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  8  8  6  8  6 10 14  6  6 29  0  6  6 10  6  1  0
  6  0  6  0  6  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 25. 25. 25. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
adversary victory points: 5
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 25. 25. 25. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
adversary victory points: 5
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 25. 25. 25. 29.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
adversary victory points: 5
player victory points: -8 





Player: 0 
cards in hand: [ 1. 25. 25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29.] 
expected returns: [[ 9.248608]
 [24.319569]
 [24.319569]
 [24.319569]
 [18.894806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 25. 29.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.93275451660156



action possibilites: [-1] 
expected returns: [[16.187382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 29.  3. 25.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.319589614868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.671173]
 [29.98788 ]
 [24.34815 ]
 [17.050709]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 29.  3. 25.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
adversary victory points: -8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.187381744384766



buy possibilites: [-1] 
expected returns: [[85.10148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 29.  3. 25.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [ 8. 14.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 451 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.987892150878906






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [ 8. 14.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0
  6  0  6  8  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 8. 14.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 8. 14.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 8. 14.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [29.  3.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[54.900166]
 [75.598495]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.10147857666016



action possibilites: [-1.] 
expected returns: [[55.556496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 64.70211791992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[49.476418]
 [63.282917]
 [55.673607]
 [61.00793 ]
 [53.323307]
 [56.05313 ]
 [56.278862]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.556495666503906



buy possibilites: [-1] 
expected returns: [[6.3496165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 25. 11.  1. 29. 25. 29. 29.  0.  1.  0.  3. 25.
  1. 25. 25. 29.  3. 25.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  6.  3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 489 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 63.282894134521484






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  3.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  6.  3.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
adversary victory points: 6
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 3.06074 ]
 [14.102158]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 8. 6. 6. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.349616527557373



action possibilites: [-1.] 
expected returns: [[8.270592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 8. 6. 6. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.07175064086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 0.08055973]
 [13.15683   ]
 [ 4.555407  ]
 [11.6397    ]
 [ 5.6795487 ]
 [ 6.850366  ]
 [ 6.985578  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 8. 6. 6. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.270591735839844



buy possibilites: [-1] 
expected returns: [[28.204723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 8. 6. 6. 3.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
adversary owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 489 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 13.156824111938477






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [1. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6. 6. 3.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11  8  8  6  8  6 10 14  6  6  0  6  6 10  6  1  0  6  0  6  0
  6  8  8  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  1. 29. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [25.  1. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[27.862347]
 [44.77689 ]
 [40.127605]
 [44.77689 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 25.  0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.204723358154297



action possibilites: [-1] 
expected returns: [[42.512188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  0.  1.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.77688980102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.000164]
 [47.97098 ]
 [40.220356]
 [22.550217]
 [50.985527]
 [45.842888]
 [40.142994]
 [57.865025]
 [54.257412]
 [15.331486]
 [43.11408 ]
 [42.245922]
 [26.835415]
 [35.37884 ]
 [43.28055 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 25.  0.  1.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.51218795776367



buy possibilites: [-1] 
expected returns: [[78.34785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 25.  0.  1.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 685 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 57.86502456665039






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  0. 25.  0.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [25. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[56.13246 ]
 [72.326164]
 [70.0437  ]
 [72.326164]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 25.  0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 10.  6.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.34784698486328



action possibilites: [-1] 
expected returns: [[56.066456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0. 29.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 10.  6.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 72.3261489868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[44.99374 ]
 [54.286823]
 [53.72673 ]
 [57.27205 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  0. 29.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  6.  0. 10.  6.] 
adversary cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.06645584106445






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 10.  6.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 11.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 11.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 6.] 
cards in discard: [ 8. 14.  8.  0.  8.  6.  0.  0. 10.  6.  6.  3.  8.  6.  1. 10. 11.  0.
  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 11.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [29. 25.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[ 4.126147]
 [27.715893]
 [34.554035]
 [17.686707]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  1. 11.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.27206039428711



action possibilites: [-1] 
expected returns: [[-13.303295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 11.  3. 25.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.55403137207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-22.19355  ]
 [ -8.17305  ]
 [-11.746454 ]
 [ -2.090069 ]
 [ -3.2449708]
 [-17.806808 ]
 [  5.332192 ]
 [-36.1288   ]
 [ -8.131926 ]
 [-15.594429 ]
 [-12.483852 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1. 11.  3. 25.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.303295135498047



buy possibilites: [-1] 
expected returns: [[47.457043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1. 11.  3. 25.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 563 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 5.332207202911377






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 11.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3. 29. 25. 29.  1.  1. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 11.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3. 29. 25. 29.  1.  1. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
adversary victory points: 6
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[29.977558]
 [42.26145 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  1.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 25. 25.  1. 29. 25.  0.  1.  3. 25. 29.  0.
 25.  0. 29.  3. 29. 25. 29.  1.  1. 11.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  8.  8.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.4570426940918



action possibilites: [-1] 
expected returns: [[34.61266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  8.  8.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 42.26145553588867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.33574  ]
 [43.880703 ]
 [32.208588 ]
 [48.46057  ]
 [43.025208 ]
 [37.089966 ]
 [51.912033 ]
 [ 1.7213078]
 [38.17187  ]
 [22.312664 ]
 [37.152542 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  8.  8.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.6126594543457



buy possibilites: [-1] 
expected returns: [[64.47722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  3. 29. 25.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0. 14.  8.  8.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.] 
adversary owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 553 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 51.91201400756836






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 14.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  8.  8.] 
cards in discard: [ 6.  0. 10. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  8  8  8  6 10 14  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8
  0  0  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 29.  0.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 6.  0. 10. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 29.  0.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 6.  0. 10. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 29.  0.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 29.  0.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [ 3. 25. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[53.612095]
 [68.75273 ]
 [68.75273 ]
 [63.76919 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25. 29.  0.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.47721862792969



action possibilites: [-1] 
expected returns: [[126.92724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  0. 29. 29.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.75269317626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[121.75245]
 [127.30381]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 29.  0. 29. 29.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.92723846435547






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25.  0. 29.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25.  0. 29.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
adversary victory points: 6
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 25.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[77.765205]
 [93.14428 ]
 [93.14428 ]
 [91.8944  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.  1.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 127.30379486083984



action possibilites: [-1] 
expected returns: [[112.33431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  1.  0.  3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.14429473876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.23365 ]
 [119.574745]
 [111.078064]
 [121.813545]
 [116.60763 ]
 [111.89408 ]
 [123.86358 ]
 [ 85.45635 ]
 [112.83175 ]
 [104.472466]
 [114.543846]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  1.  0.  3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.33431243896484



buy possibilites: [-1] 
expected returns: [[111.49556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 29.  1.  0.  3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 543 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.86359405517578






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.  0.  6.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29] -> size -> 37 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.  0.  6.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29] -> size -> 37 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.  0.  6.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 11.  1.  3.  3.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29] -> size -> 37 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [ 1. 11.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[101.94604]
 [106.03656]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  3.  3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  6.  6.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.49555969238281



action possibilites: [-1] 
expected returns: [[43.15139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  6.  6.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 432 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 106.03900146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[36.62203 ]
 [48.142986]
 [41.993576]
 [51.572872]
 [47.432102]
 [40.931973]
 [13.504894]
 [44.40453 ]
 [37.40136 ]
 [45.379574]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 21. 30. 27. 30.  8.  0. 10.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  6.  6.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.151390075683594



buy possibilites: [-1] 
expected returns: [[80.446434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  1.  6.  6.  6.] 
adversary cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 523 

action type: buy - action 16.0
Learning step: 0
desired expected reward: 51.57285690307617






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  1.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  6.  6.  6.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  8.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 6. 0.] 
cards in discard: [ 6.  0. 10. 11.  6.  0.  8.  6.  8.  0.  6.  3.  8.  0.  0.  8. 10.  6.
  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  1. 25.  1.] 
adversary cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [25. 29.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[104.0433  ]
 [117.6363  ]
 [115.452675]
 [117.6363  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 25.  1.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.4464340209961



action possibilites: [-1] 
expected returns: [[130.18118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.63631439208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[124.0671 ]
 [134.54619]
 [127.21458]
 [113.06446]
 [135.1161 ]
 [131.14813]
 [127.41331]
 [138.77591]
 [105.73155]
 [127.97323]
 [128.1772 ]
 [114.81152]
 [122.48429]
 [130.18118]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  2.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.18118286132812



buy possibilites: [-1] 
expected returns: [[73.35138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25.  1. 29.  0.] 
cards in discard: [29. 25.  0.  0.  1.  3. 29. 25. 25.  3. 25. 29.  0. 29. 29. 29. 25. 25.
  0. 29.  1.  0.  3.  1. 16. 11.  1.  1.  3.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -50   0   0 250   0] 
sum of rewards: 635 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 138.77590942382812






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 8.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -8 





Player: 0 
cards in hand: [25. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[46.00411 ]
 [62.428143]
 [62.428143]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 10.  8.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11  0] -> size -> 30 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.35137939453125



action possibilites: [-1] 
expected returns: [[63.59695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 10.  8.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11  0] -> size -> 30 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.42812728881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[54.027393]
 [59.622227]
 [59.33405 ]
 [63.823643]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 10.  8.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8.] 
adversary owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11  0] -> size -> 30 
adversary victory points: -8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.59695053100586






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 10.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  8.  6.] 
cards in discard: [0. 6. 6. 6. 0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  8  6 10  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0
  1 10  0  0 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25. 16. 29.  0.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [0. 6. 6. 6. 0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25. 16. 29.  0.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 6. 6. 6. 0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25. 16. 29.  0.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
adversary victory points: 6
player victory points: -7 





Player: 0 
cards in hand: [29. 25. 16. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 16. 29.] 
expected returns: [[69.993484]
 [80.9702  ]
 [85.62821 ]
 [79.65569 ]
 [80.9702  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 16. 29.  0.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 6. 3. 0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
adversary owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.82365036010742



action possibilites: [-1] 
expected returns: [[75.28983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16. 29.  0.  1.  0.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 6. 3. 0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
adversary owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.6281967163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[67.99192 ]
 [79.73875 ]
 [73.80866 ]
 [82.83795 ]
 [79.969055]
 [72.20295 ]
 [48.515934]
 [75.69713 ]
 [67.064514]
 [76.21911 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16. 29.  0.  1.  0.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 27. 30.  8.  0.  9.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 6. 3. 0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
adversary owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.28983306884766



buy possibilites: [-1] 
expected returns: [[131.38571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16. 29.  0.  1.  0.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29. 16.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 6. 6. 3. 0.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
adversary owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 473 

action type: buy - action 16.0
Learning step: 0
desired expected reward: 82.83792877197266






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [8. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 3. 0.] 
cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8  8  6  6  0  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 25.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
adversary victory points: 6
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 25.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
adversary victory points: 6
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 6. 6. 6. 0. 8. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 25.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
adversary victory points: 6
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 6. 6. 6. 0. 8. 8. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  1.  1. 25.] 
adversary cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
adversary victory points: 6
player victory points: -7 





Player: 0 
cards in hand: [29. 25.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 99.220955]
 [110.158455]
 [114.30967 ]
 [114.30967 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  1. 25.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  0.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6. 0. 8. 6.] 
adversary owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0
  0] -> size -> 25 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.38571166992188



action possibilites: [-1] 
expected returns: [[139.82086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 25.  3.  1.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  0.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6. 0. 8. 6.] 
adversary owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0
  0] -> size -> 25 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 114.30968475341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[134.30663 ]
 [147.21193 ]
 [130.91666 ]
 [140.1785  ]
 [119.824646]
 [150.61423 ]
 [146.5358  ]
 [139.11653 ]
 [157.10753 ]
 [112.79462 ]
 [142.01547 ]
 [142.21774 ]
 [125.67895 ]
 [132.96515 ]
 [142.95882 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1. 25.  3.  1.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 21. 30. 27. 30.  8.  0.  8.  7.  5.  1.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  0.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6. 0. 8. 6.] 
adversary owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0
  0] -> size -> 25 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.82086181640625



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 6 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 2 
Workshop: 1 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  1.  1. 25.  3.  1.] 
cards in discard: [25. 25.  0.  3.  0. 25. 29. 16. 25. 29. 16. 29.  0.  1.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 25  1 29  1 25  1 29 25 25 29  3 25  1
 29 29 11 25 29 25  3  1  1 25 29 29 29  1 16 25 16 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 27. 30.  8.  0.  8.  7.  5.  0.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  0.  6.] 
adversary cards in discard: [0. 6. 6. 6. 0. 8. 8. 6. 0. 8. 6.] 
adversary owned cards: [11  8  8  6  6  6 10  6  0  6  0  6  0  6  8  8  0  0  1 10  0  0 11  0
  0] -> size -> 25 
adversary victory points: -7
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     390       0       0      20       0       0
       0       0     -70       0       0     125       0] 
sum of rewards: 3000460 

action type: buy - action 25.0
Learning step: 120012.1171875
desired expected reward: 120169.2265625



