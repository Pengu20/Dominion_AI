 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.81892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action -1.0
Learning step: -120003.828125
desired expected reward: -120273.15625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.79139 ]
 [ 64.99225 ]
 [ 60.147263]
 [ 21.121422]
 [ 16.463318]
 [ 62.09365 ]
 [ 86.448074]
 [ 69.78253 ]
 [110.22848 ]
 [ 86.460075]
 [ 41.729603]
 [ 55.316566]
 [ 64.862564]
 [ 34.133904]
 [ 62.930458]
 [ 62.595802]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.72972106933594



buy possibilites: [-1] 
expected returns: [[67.843155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 110.22846984863281






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.4609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.84315490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.885063]
 [69.88339 ]
 [29.51099 ]
 [79.78482 ]
 [72.5092  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 68.86410522460938



buy possibilites: [-1] 
expected returns: [[66.492134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 79.7848129272461






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  3.  3.  0.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 60.01172]
 [109.40233]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.49213409423828



action possibilites: [-1] 
expected returns: [[53.565098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.87340545654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.25536 ]
 [63.48889 ]
 [59.19732 ]
 [22.916962]
 [60.956535]
 [82.739456]
 [67.66233 ]
 [82.8244  ]
 [43.53989 ]
 [63.354492]
 [61.7061  ]
 [61.766815]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.56509780883789



buy possibilites: [-1] 
expected returns: [[87.16431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.82438659667969






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.96647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 25.  0.  0.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.164306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 65.36925 ]
 [ 85.03844 ]
 [ 80.46238 ]
 [ 40.168625]
 [104.66326 ]
 [ 89.466606]
 [ 84.89055 ]
 [ 83.32416 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 25.  0.  0.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.38886260986328



buy possibilites: [-1] 
expected returns: [[70.5616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 25.  0.  0.  3.  0.  8.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.66323852539062






Player: 1 
cards in hand: [1. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[51.65984]
 [57.22992]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8 29 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.56159973144531



action possibilites: [-1] 
expected returns: [[45.312668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 66.78205871582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.42109  ]
 [ 3.7763972]
 [46.85795  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.31266784667969






Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[50.271442]
 [92.47421 ]
 [71.17052 ]
 [70.98764 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0. 11.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.857948303222656



action possibilites: [-1] 
expected returns: [[48.563004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.21630096435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.93857 ]
 [51.480698]
 [47.388123]
 [11.409248]
 [49.094563]
 [69.11257 ]
 [55.436058]
 [69.32123 ]
 [32.303387]
 [51.343483]
 [49.81213 ]
 [50.02897 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.56300354003906



buy possibilites: [-1] 
expected returns: [[71.716965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11.  0.  0.] 
cards in discard: [ 8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 69.32121276855469






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 16.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 16.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 16.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 65.32333 ]
 [107.342285]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.71696472167969



action possibilites: [-1] 
expected returns: [[56.26257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.23872375488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[42.22289 ]
 [61.039673]
 [56.60594 ]
 [20.680143]
 [58.457287]
 [78.903946]
 [65.325134]
 [79.10956 ]
 [40.59788 ]
 [60.891396]
 [59.244255]
 [59.503693]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.262569427490234



buy possibilites: [-1] 
expected returns: [[106.37099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.  0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 79.10954284667969






Player: 1 
cards in hand: [ 0.  0.  6. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.  1.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8. 29.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [ 6. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10.  9. 10.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[ 7.223149]
 [20.628025]
 [10.584309]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -10.743637084960938



action possibilites: [-1] 
expected returns: [[73.72911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 21.121612548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.62027]
 [43.26367]
 [78.20655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [29. 25.  0.  0.  3.  0. 29.  0.  0. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.72911071777344






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 22. 14.  0.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 6. 22. 14.  0.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[51.568207]
 [52.394943]
 [67.33983 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.20655822753906



action possibilites: [-1. 10. 11.] 
expected returns: [[61.895935]
 [62.65451 ]
 [77.63674 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  9.  9. 10.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.522064208984375



action possibilites: [-1] 
expected returns: [[62.86355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  8.  9. 10.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.36296844482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[54.319984]
 [68.11663 ]
 [64.778465]
 [36.432495]
 [66.20839 ]
 [82.67816 ]
 [71.32689 ]
 [82.93893 ]
 [53.070892]
 [67.98875 ]
 [66.80398 ]
 [67.268936]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  7.  9. 10.  8.  9. 10.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.863548278808594



buy possibilites: [-1] 
expected returns: [[88.03427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 82.9389419555664






Player: 1 
cards in hand: [16.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 25.  3.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 25.  3.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [ 6. 22. 14.  0.  0.  6.  1.  0.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 25.  3.  8.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[ 78.54433]
 [ 97.77704]
 [117.5675 ]
 [ 83.75044]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3.  8.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  7.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.03427124023438



action possibilites: [-1] 
expected returns: [[114.831055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  8.  0.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.04231262207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.01269 ]
 [122.66629 ]
 [118.543594]
 [ 81.768555]
 [140.46234 ]
 [126.69386 ]
 [122.51527 ]
 [121.45311 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  8.  0.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  6.  9.  9.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.8310546875



buy possibilites: [-1] 
expected returns: [[104.63515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  8.  0.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 140.4623260498047






Player: 1 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 29.] 
expected returns: [[62.09899]
 [76.12448]
 [65.83876]
 [76.3678 ]
 [76.3678 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.63514709472656



action possibilites: [-1. 11.  8. 29.] 
expected returns: [[67.64904 ]
 [81.963554]
 [71.51489 ]
 [82.20543 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.91242980957031



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[100.416985]
 [114.896   ]
 [103.9987  ]
 [100.82089 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  8.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.2054214477539



action possibilites: [-1] 
expected returns: [[99.742065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 118.43742370605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 89.90504 ]
 [104.951096]
 [101.37853 ]
 [ 70.66055 ]
 [102.926476]
 [120.11768 ]
 [108.37975 ]
 [120.4238  ]
 [ 88.582466]
 [104.80687 ]
 [103.57198 ]
 [104.23007 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  6.  9. 10.  7.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.7420654296875



buy possibilites: [-1] 
expected returns: [[86.70001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10.] 
cards in discard: [10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [22.  0.  0.  0.  1.] 
adversary cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.42378234863281






Player: 1 
cards in hand: [22.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  0.  0.  1.] 
cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3. 0. 0.] 
cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 16. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3. 0. 0.] 
cards in discard: [6. 0. 0. 6. 6. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 16. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 29. 30. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3. 0. 0.] 
cards in discard: [6. 0. 0. 6. 6. 0. 3. 2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22. 16. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[150.34755]
 [151.44843]
 [190.33797]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 25.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  6.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.70001220703125



action possibilites: [-1] 
expected returns: [[102.27257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 184.0034942626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 77.045   ]
 [ 92.88118 ]
 [ 89.10966 ]
 [ 56.381577]
 [108.95407 ]
 [ 96.51992 ]
 [ 92.74841 ]
 [ 91.644135]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  8.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.27256774902344



buy possibilites: [-1] 
expected returns: [[77.91968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.95408630371094






Player: 1 
cards in hand: [6. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  0.  6.  6.  0.  3.  2. 22. 16. 14.  0.  0.  0.  1.  3.  0.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[67.21428 ]
 [82.270645]
 [82.0177  ]
 [82.270645]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.919677734375



action possibilites: [-1. 11. 29. 11.] 
expected returns: [[72.92923]
 [88.53209]
 [88.8327 ]
 [88.53209]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.65492248535156



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[77.92032]
 [93.11092]
 [93.11092]
 [93.11092]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.83271026611328



action possibilites: [-1] 
expected returns: [[102.50842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.65217590332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 91.342   ]
 [107.01963 ]
 [103.32342 ]
 [ 71.130005]
 [104.912994]
 [123.10745 ]
 [110.60247 ]
 [123.4037  ]
 [ 89.916504]
 [106.87623 ]
 [105.58021 ]
 [106.151726]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.5084228515625



buy possibilites: [-1] 
expected returns: [[108.3759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  2.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 273 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.40370178222656






Player: 1 
cards in hand: [ 0. 22.  2.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  2.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 29. 10.  8.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 29. 10.  8.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 29. 29. 30. 30.  8.  5.  9.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 29. 10.  8.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10. 29. 10.  8.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8.] 
expected returns: [[113.289345]
 [114.45843 ]
 [131.99634 ]
 [114.45843 ]
 [118.478424]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  8.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  6.  3. 14.  0.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.37590026855469



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[112.70186 ]
 [113.699005]
 [113.699005]
 [117.41585 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  0.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 29 11 29 29 10 10 29 11 10 29 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  6.  3. 14.  0.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.0681610107422



action possibilites: [-1] 
expected returns: [[61.485214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  6.  3. 14.  0.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 134.79347229003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.3097  ]
 [33.05815 ]
 [63.030426]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  6.  3. 14.  0.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.48521423339844






Player: 1 
cards in hand: [ 1.  6.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3. 14.  0.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29. 25.  0.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
adversary victory points: 0
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3. 0.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
adversary victory points: 0
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
adversary victory points: 0
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3. 0.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
adversary victory points: 0
player victory points: -2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[107.237305]
 [123.813126]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  3.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -71.03599548339844



action possibilites: [-1.] 
expected returns: [[96.61234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  3.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 122.39802551269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 80.46453 ]
 [ 95.91962 ]
 [ 92.301605]
 [ 60.500084]
 [ 93.84813 ]
 [112.33485 ]
 [ 99.49657 ]
 [112.615974]
 [ 79.05404 ]
 [ 95.781944]
 [ 94.50386 ]
 [ 94.886314]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  3.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.61234283447266



buy possibilites: [-1] 
expected returns: [[66.2521]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  0. 11. 11. 29.  8. 10. 25. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 16.  6.  3.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.61598205566406






Player: 1 
cards in hand: [ 0.  0. 16.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  6.  3.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6
 16  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
adversary victory points: 0
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
adversary victory points: 0
player victory points: -3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[64.0753  ]
 [78.71448 ]
 [79.016815]
 [64.48339 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.2520980834961



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[77.675735]
 [91.32089 ]
 [78.03731 ]
 [91.64329 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.21025085449219



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[ 87.72063 ]
 [101.43787 ]
 [ 88.139435]
 [101.75154 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 91.64329528808594



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[122.419785]
 [139.5966  ]
 [123.171814]
 [139.5966  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.75154113769531



action possibilites: [-1] 
expected returns: [[110.16058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.56373596191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 97.14875 ]
 [113.87453 ]
 [109.95362 ]
 [ 79.4648  ]
 [ 75.63276 ]
 [111.63171 ]
 [130.9313  ]
 [117.66059 ]
 [150.30434 ]
 [131.24022 ]
 [ 95.65824 ]
 [106.32707 ]
 [113.72729 ]
 [ 89.786385]
 [112.34354 ]
 [112.85714 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  9.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.16058349609375



buy possibilites: [-1] 
expected returns: [[144.93686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [10. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  90   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 150.30433654785156






Player: 1 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [25. 29. 10. 11. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [16. 22.  0.  2.  0.  0.  3.  0.  0.  1. 14.  1.  6.  3.  0. 10.  0. 16.
  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [25. 29. 10. 11. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
adversary victory points: 0
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 29. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11. 10.] 
expected returns: [[107.74063 ]
 [140.66072 ]
 [124.051834]
 [108.601265]
 [123.77516 ]
 [108.601265]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 10. 11. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  5.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [16.  6.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.93685913085938



action possibilites: [-1] 
expected returns: [[59.302307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 10. 29. 29.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [16.  6.  0. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.66073608398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.638428]
 [30.948334]
 [58.694885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 10. 29. 29.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [16.  6.  0. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.30230712890625






Player: 1 
cards in hand: [16.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0. 14.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6 14  0  6  0  6 22  0  6  0  2  6 16
  1 10  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9. 10.  4.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11. 25. 29. 10. 11. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 23.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11. 25. 29. 10. 11. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 23.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11. 25. 29. 10. 11. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[56.958313]
 [72.31121 ]
 [61.18399 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 10. 11. 25. 29. 10. 11. 10. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.69489288330078



action possibilites: [-1.  8. 10.] 
expected returns: [[69.07311]
 [72.70845]
 [69.58644]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 10 29 11 10 29 11 10 29 29 10 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.31121063232422



action possibilites: [-1] 
expected returns: [[55.967888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 69.77322387695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[47.257694]
 [60.22956 ]
 [57.061096]
 [30.93631 ]
 [58.456146]
 [73.712715]
 [63.358047]
 [74.0194  ]
 [46.13685 ]
 [60.091423]
 [59.03203 ]
 [59.784874]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  3.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.96788787841797



buy possibilites: [-1] 
expected returns: [[111.93666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 74.01939392089844






Player: 1 
cards in hand: [0. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  0. 25. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11. 29.] 
expected returns: [[ 75.60191 ]
 [ 91.961914]
 [108.62128 ]
 [ 91.67776 ]
 [ 91.961914]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 11. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 30. 30.  8.  4.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 2.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0] -> size -> 29 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.93666076660156



action possibilites: [-1] 
expected returns: [[61.02883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 29. 11. 10.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 2.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.29104614257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.66194 ]
 [23.926933]
 [52.84043 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 29. 11. 10.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [3. 0. 6. 0. 2.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.028831481933594






Player: 1 
cards in hand: [3. 0. 6. 0. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 2.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 2.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 2.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 29.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
adversary victory points: 0
player victory points: -5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[54.80112]
 [55.55443]
 [70.10455]
 [70.3473 ]
 [70.3473 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.840423583984375



action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[48.615253]
 [49.24311 ]
 [62.4197  ]
 [62.691498]
 [62.691498]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.3472900390625



action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[35.414165]
 [36.081894]
 [48.77826 ]
 [49.005005]
 [36.081894]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 10.] 
cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.691497802734375



action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[46.339424]
 [47.025692]
 [60.7629  ]
 [47.025692]
 [61.01758 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 29.] 
cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.00499725341797



action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[ 76.88778]
 [ 77.51712]
 [ 91.21173]
 [ 77.51712]
 [106.49133]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 25.] 
cards in discard: [29. 29.  8.  0.  0.  0. 25. 29.  0. 11. 29. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 4 
card supply: [23. 28. 29. 30. 30.  8.  3.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.017578125



action possibilites: [-1] 
expected returns: [[97.64133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 29. 30. 30.  8.  2.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.49136352539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 70.60129 ]
 [ 84.58738 ]
 [ 67.31498 ]
 [ 81.294   ]
 [ 55.89616 ]
 [ 52.887012]
 [ 82.71769 ]
 [ 98.58237 ]
 [ 87.776115]
 [114.147125]
 [ 98.87568 ]
 [ 69.33847 ]
 [ 78.299355]
 [ 84.455505]
 [ 64.41652 ]
 [ 83.31748 ]
 [ 83.81395 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 28. 29. 30. 30.  8.  2.  8.  7.  9.  8.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 150   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.64132690429688



buy possibilites: [-1] 
expected returns: [[53.675133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.  0. 29.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  2.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 22.  1.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 307.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 114.1471176147461






Player: 1 
cards in hand: [ 0.  1. 10. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10. 22.  1.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  2.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1. 22. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22.  1. 16.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6 22  0  6  0  2  6 16  1
 10  0  6 23  0  6  0  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  2.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 10. 11. 11.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[75.11033]
 [90.19146]
 [75.79748]
 [89.91457]
 [89.91457]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11. 11.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.675132751464844



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[61.541336]
 [62.169754]
 [75.85559 ]
 [75.85559 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 90.19146728515625



action possibilites: [-1] 
expected returns: [[56.66201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 272 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 79.78035736083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.350204]
 [55.262127]
 [51.98757 ]
 [23.058046]
 [69.22049 ]
 [58.43451 ]
 [55.135967]
 [54.36885 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  7.  9.  7.  2.  9.  9.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.662010192871094



buy possibilites: [-1] 
expected returns: [[44.36284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  6.  9.  7.  2.  9.  9.  3.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 69.22049713134766






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  6.  9.  7.  2.  9.  9.  3.  9. 10.] 
adversary cards in hand: [ 8. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10. 11. 29. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  6.  9.  7.  2.  9.  9.  3.  9. 10.] 
adversary cards in hand: [ 8. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10. 11. 29. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23. 16.  6.  0.  0.  0.  0.  6.  6.  6.  0.  6.  0.  3.  0.  6.  0.
  2.  6.  6. 10. 16.  0.  1.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 8. 25. 29. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10. 11. 29. 11.  0. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29. 29.] 
expected returns: [[ 6.999809]
 [ 8.811422]
 [24.147896]
 [15.288637]
 [15.288637]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 29. 29.  0.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 10. 11. 10.  0. 29. 10. 11. 29. 11.  0. 10.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  1.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10] -> size -> 33 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.36283874511719



action possibilites: [-1] 
expected returns: [[54.746292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6] -> size -> 34 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.147903442382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.13749 ]
 [55.211372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 29.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6] -> size -> 34 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.74629211425781






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 29.  0. 25. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  6.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 29.  0. 25. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  5.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0. 29.  0. 25. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
adversary victory points: 0
player victory points: -8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[39.137714]
 [51.791645]
 [65.18829 ]
 [51.518208]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25. 11.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  5.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 16. 23.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.21137237548828



action possibilites: [-1] 
expected returns: [[100.55072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11. 10.  0.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  5.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 16. 23.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.18830108642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 81.49542 ]
 [ 98.48548 ]
 [ 94.524284]
 [115.33409 ]
 [102.30524 ]
 [ 98.34403 ]
 [ 97.25709 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11. 10.  0.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  5.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 16. 23.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.55072021484375



buy possibilites: [-1] 
expected returns: [[86.0369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11. 10.  0.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [ 0.  1. 10. 16. 23.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.3340835571289






Player: 1 
cards in hand: [ 0.  1. 10. 16. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10. 16. 23.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 


action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10. 16.  1.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  1.  6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 16  6  0  6  0  6  0  6  0  2  6 16  1 10
  0  6 23  0  6  0  6  6 10  6 11] -> size -> 35 
action values: 2 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9. 10.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15] -> size -> 35 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15] -> size -> 35 
action values: 0 
buys: 2 
player value: 4 
card supply: [23. 28. 29. 30. 30.  8.  0.  8.  4.  9.  7.  2.  9.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
adversary victory points: 0
player victory points: -8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[26.252495]
 [40.291073]
 [27.068405]
 [40.487762]
 [40.291073]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.03690338134766



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[11.1404  ]
 [22.616302]
 [11.619085]
 [22.616302]
 [11.619085]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.180809020996094



action possibilites: [-1] 
expected returns: [[6.3935113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.32887077331543





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.6992846]
 [ 6.364947 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.3935112953186035






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  8.] 
adversary cards in hand: [29. 11. 25. 10. 29.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
adversary victory points: 0
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  8.] 
adversary cards in hand: [29. 11. 25. 10. 29.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
adversary victory points: 0
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [29. 11. 25. 10. 29.] 
adversary cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
adversary victory points: 0
player victory points: -8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 11. 25. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 10. 29.] 
expected returns: [[ 7.6875787]
 [15.732946 ]
 [15.420361 ]
 [24.239332 ]
 [ 7.4918084]
 [15.732946 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 25. 10. 29.] 
cards in discard: [25.  8. 29. 29.  0. 29. 29. 11. 25.  0. 29.  0. 11. 10.  0.  0. 15. 29.
 11. 10. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.364939212799072



action possibilites: [-1] 
expected returns: [[78.79557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 29. 25. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.23932647705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[69.16307 ]
 [79.107086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10. 29. 25. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [0. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.79557037353516






Player: 1 
cards in hand: [0. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [10. 10. 11.  0. 11.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
adversary victory points: 0
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [10. 10. 11.  0. 11.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
adversary victory points: 0
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 10. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[48.184418]
 [48.472668]
 [48.472668]
 [59.26986 ]
 [59.26986 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0. 11.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  7.] 
adversary cards in hand: [ 6. 16. 10.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.10708618164062



action possibilites: [-1] 
expected returns: [[53.709717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [ 6. 16. 10.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.94422912597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[41.287178]
 [52.881943]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [ 6. 16. 10.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
adversary victory points: -8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.709716796875






Player: 1 
cards in hand: [ 6. 16. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 10.  6.  0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  6  0  6  0  6  0  6  0  2  6 16  1 10  0
  6 23  0  6  0  6  6 10  6 11 15 16 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  9.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [29. 10.  0. 29.  8.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
adversary victory points: 0
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [29. 10.  0. 29.  8.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [29. 10.  0. 29.  8.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [29. 10.  0. 29.  8.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 10.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.  8.] 
expected returns: [[21.283464]
 [34.895214]
 [21.88084 ]
 [34.895214]
 [24.877602]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 29.  8.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.881961822509766



action possibilites: [-1. 29.  8. 25.] 
expected returns: [[23.678177]
 [36.43521 ]
 [27.076153]
 [49.58001 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 25.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.0008544921875



action possibilites: [-1] 
expected returns: [[20.52937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.58000946044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.947762]
 [19.62896 ]
 [17.104837]
 [18.207712]
 [30.299908]
 [22.046782]
 [30.542885]
 [ 7.981321]
 [19.52265 ]
 [18.658504]
 [19.09557 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  2.  9.  9.  2.  9.  6.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.529369354248047



buy possibilites: [-1] 
expected returns: [[3.9170537]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 373 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.542884826660156






Player: 1 
cards in hand: [0. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [15. 29. 11. 29. 29.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [15. 29. 11. 29. 29.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [ 6. 11.  0.  0.  6.  0.  0. 15. 16. 23. 10. 16.  0.  1.  6. 15.  0.  0.
  0.  0.  0.  0.  0.  6.  6.  6.  8.  0. 16. 10.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [15. 29. 11. 29. 29.] 
adversary cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 29. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11. 29. 29.] 
expected returns: [[22.29957 ]
 [21.362247]
 [30.313046]
 [29.93306 ]
 [30.313046]
 [30.313046]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11. 29. 29.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.917053699493408



action possibilites: [-1. 15. 11. 29. 29.] 
expected returns: [[-6.5112076 ]
 [-7.3299427 ]
 [ 0.81507635]
 [ 1.1557703 ]
 [ 1.1557703 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 29. 29.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.031875610351562



action possibilites: [-1. 15. 11.] 
expected returns: [[-2.429733 ]
 [-3.211742 ]
 [ 5.0297236]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  6.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.687346935272217



action possibilites: [-1] 
expected returns: [[10.76845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0. 29. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 329 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.554497241973877





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 2.542562]
 [10.129129]
 [ 8.261171]
 [17.600077]
 [11.881475]
 [10.013512]
 [10.480574]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0. 29. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  4.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.768449783325195



buy possibilites: [-1] 
expected returns: [[6.0942464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [25. 29. 11. 10. 29. 25. 11. 15. 11. 10. 10.  0. 11. 10. 29. 29. 25.  0.
 29.  8.  0.  0. 29. 29. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [ 3.  6.  6. 10.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 319 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 17.600086212158203






Player: 1 
cards in hand: [ 3.  6.  6. 10.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 10.  2.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [11. 29.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 10.  2.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [11. 29.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 10.  2.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [11. 29.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 29.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[49.777946]
 [64.37965 ]
 [64.66112 ]
 [64.37965 ]
 [50.358868]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [ 0. 11.  0.  0. 15.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.0942463874816895



action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[84.86025]
 [98.97294]
 [98.97294]
 [85.33262]
 [85.33262]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  5.] 
adversary cards in hand: [ 0. 11.  0.  0. 15.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.48561096191406



action possibilites: [-1] 
expected returns: [[72.28436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  0. 15.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 102.29974365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[62.402664]
 [72.083275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.] 
cards in discard: [ 0. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 0. 11.  0.  0. 15.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.28436279296875






Player: 1 
cards in hand: [ 0. 11.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 15.] 
cards in discard: [ 0.  3.  6.  6. 10.  2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6
 23  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [29. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
adversary victory points: 0
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [29. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  3.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [29. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [29. 29. 25.  0.  0.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[47.64334]
 [61.45526]
 [61.45526]
 [76.08288]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0.  0.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 1.  0.  6.  6. 16.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.08325958251953



action possibilites: [-1] 
expected returns: [[32.47292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 29. 29.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 1.  0.  6.  6. 16.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 76.08287048339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[20.396282]
 [29.015072]
 [34.243332]
 [31.221489]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0. 29. 29.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  8.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 1.  0.  6.  6. 16.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.47291946411133



buy possibilites: [-1] 
expected returns: [[32.876114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0. 29. 29.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 1.  0.  6.  6. 16.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 34.243309020996094






Player: 1 
cards in hand: [ 1.  0.  6.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  6. 16.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 0. 15. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  6. 16.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 0. 15. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  6. 16.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 0. 15. 11. 29. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -7 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29. 11.] 
expected returns: [[-2.4049566]
 [-2.9896805]
 [ 7.1003356]
 [ 7.3583503]
 [ 7.1003356]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 29. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 6.  0. 23.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.87611389160156



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[-6.3759074]
 [ 2.1027737]
 [ 2.1027737]
 [ 2.1027737]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  4.] 
adversary cards in hand: [ 6.  0. 23.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.170013189315796



action possibilites: [-1] 
expected returns: [[-6.638166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 6.  0. 23.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 4.2876362800598145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-14.304497 ]
 [ -8.7104645]
 [ -5.170414 ]
 [ -6.7985115]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  7.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 6.  0. 23.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.6381659507751465



buy possibilites: [-1] 
expected returns: [[-8.9929905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 6.  0. 23.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
adversary victory points: -7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -5.170409202575684






Player: 1 
cards in hand: [ 6.  0. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 23.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [10.  8. 29. 11. 25.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 23.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 29. 30. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [10.  8. 29. 11. 25.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 23.  0.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [10.  8. 29. 11. 25.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  8. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 11. 25.] 
expected returns: [[18.118382]
 [17.745407]
 [19.68414 ]
 [26.039236]
 [25.659708]
 [34.496433]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 11. 25.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [16.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.992990493774414



action possibilites: [-1] 
expected returns: [[-5.8140974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 11. 29. 10.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [16.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.496437072753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.082491 ]
 [ -5.5070744]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 29. 11. 29. 10.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [16.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.8140974044799805






Player: 1 
cards in hand: [16.  0. 15. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 15. 16.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23
  0  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 15. 29. 25. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11. 25. 10.  8. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 15. 29. 25. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11. 25. 10.  8. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 15. 29. 25. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11. 25. 10.  8. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 15. 29. 25. 15.] 
adversary cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11. 25. 10.  8. 29. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 29. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 25. 15.] 
expected returns: [[-17.12447  ]
 [-17.929394 ]
 [-10.078346 ]
 [ -2.7552276]
 [-17.929394 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 25. 15.] 
cards in discard: [ 0. 15. 29. 11. 11. 10. 10.  8. 25. 29. 29.  0.  0. 29. 29. 15. 15.  8.
 29. 11.  0. 11. 11. 25. 10.  8. 29. 11. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.507071495056152



action possibilites: [-1] 
expected returns: [[60.86473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 15. 15. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -2.755225419998169





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.22861]
 [60.62204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29. 15. 15. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.86473083496094






Player: 1 
cards in hand: [ 0.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 8. 15.  0. 10.  8.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 8. 15.  0. 10.  8.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  9.  9.  2.  9.  3.] 
adversary cards in hand: [ 8. 15.  0. 10.  8.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 8. 15.  0. 10.  8.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.  8.] 
expected returns: [[34.58732 ]
 [37.41035 ]
 [34.04073 ]
 [34.854332]
 [37.41035 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 10.  8.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 25  8 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10
 11 11 15 15 29 15 11 15  8 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.622039794921875



action possibilites: [-1] 
expected returns: [[71.70759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 50.43804168701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.961792]
 [69.66405 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [0. 0. 8. 0. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.70758819580078






Player: 1 
cards in hand: [0. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [ 0.  3.  6.  6. 10.  2. 11. 15. 11.  0.  0.  1.  1.  0.  6.  6. 16.  3.
  6.  0. 23.  0.  0.  0. 15. 16. 16.  0. 14. 10.  0.  6.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[55.18038]
 [67.27967]
 [67.5532 ]
 [80.8259 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 25.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.6640396118164



action possibilites: [-1] 
expected returns: [[37.013313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 29. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.82588195800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.81105 ]
 [33.889984]
 [38.938522]
 [36.08394 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 29. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  6.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.01331329345703



buy possibilites: [-1] 
expected returns: [[14.504404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 29. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 38.93852233886719






Player: 1 
cards in hand: [6. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 11. 29. 11. 11.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8] -> size -> 34 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [ 0. 11. 29. 11. 11.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8] -> size -> 34 
adversary victory points: 0
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 11.] 
expected returns: [[-13.5312195]
 [ -5.3123136]
 [ -5.010935 ]
 [ -5.3123136]
 [ -5.3123136]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [10. 16.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.504404067993164



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[-1.465812]
 [ 7.856625]
 [ 7.856625]
 [ 7.856625]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  3.] 
adversary cards in hand: [10. 16.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.575632095336914



action possibilites: [-1] 
expected returns: [[8.358261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [10. 16.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.02206039428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[1.0686297]
 [6.31267  ]
 [9.657396 ]
 [8.477695 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  5.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [10. 16.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.358261108398438



buy possibilites: [-1] 
expected returns: [[-0.7977505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [10. 16.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 9.65739631652832






Player: 1 
cards in hand: [10. 16.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0. 16.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [ 8. 29. 29. 10. 29.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
adversary victory points: 0
player victory points: -6 


action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [ 8. 29. 29. 10. 29.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [ 8. 29. 29. 10. 29.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0.  0.] 
cards in discard: [6. 0. 3. 6. 6. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [ 8. 29. 29. 10. 29.] 
adversary cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 10. 29.] 
expected returns: [[16.51741 ]
 [18.135445]
 [24.406221]
 [24.406221]
 [16.146318]
 [24.406221]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 10. 29.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.7977504730224609



action possibilites: [-1. 29. 10. 29. 15.] 
expected returns: [[14.003126]
 [22.146646]
 [13.631731]
 [22.146646]
 [13.072189]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 15.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.264604568481445



action possibilites: [-1. 10. 29. 29.] 
expected returns: [[27.244343]
 [26.904827]
 [35.25122 ]
 [35.25122 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.750041961669922



action possibilites: [-1. 29. 10.] 
expected returns: [[11.31649 ]
 [18.04447 ]
 [10.916279]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.01972198486328



action possibilites: [-1. 11.] 
expected returns: [[22.909166]
 [29.73497 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 4 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  2.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.01692008972168



action possibilites: [-1] 
expected returns: [[16.009811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15. 10. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  1.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.482425689697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.9539523]
 [15.85977  ]
 [13.938761 ]
 [14.833441 ]
 [23.659002 ]
 [17.674194 ]
 [23.987741 ]
 [ 7.281447 ]
 [15.753195 ]
 [15.187258 ]
 [16.009827 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15. 10. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  1.  8.  9.  2.  9.  1.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.009811401367188



buy possibilites: [-1] 
expected returns: [[5.4878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  0. 15. 29. 15. 15. 29.  8. 15. 10.  8. 25.  0.  0. 11. 29. 29. 11.
 25. 15.  8. 29. 11.  0. 11. 11.  8. 15. 10. 10. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  1.] 
adversary cards in hand: [11. 14. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 373 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.98773956298828






Player: 1 
cards in hand: [11. 14. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14. 16.  0.  0.] 
cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  1.] 
adversary cards in hand: [15. 15. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29] -> size -> 38 
adversary victory points: 0
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14. 16.  0.  0.] 
cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  1.] 
adversary cards in hand: [15. 15. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29] -> size -> 38 
adversary victory points: 0
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14. 16.  0.  0.] 
cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  1.] 
adversary cards in hand: [15. 15. 15. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29] -> size -> 38 
adversary victory points: 0
player victory points: -6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 11. 10.] 
expected returns: [[29.802078]
 [29.132599]
 [29.132599]
 [29.132599]
 [39.16012 ]
 [29.828678]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 11. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  1.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.  0. 11. 14. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1  0] -> size -> 46 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.487800121307373



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 5 
Witch: 3 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 15. 15. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 25 29 11 29 29 29 11 10 29 11 10 29 29 10 25 29 25 10 11 11
 15 15 29 15 11 15  8 15  8  8 15  8 15 29 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 29. 30.  8.  0.  7.  2.  4.  7.  0.  8.  9.  2.  9.  0.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  6.  6.  1. 10. 16.  0. 16.  0.  0.  0. 11. 14. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0  6  0  6  0  6  0  2  6 16  1 10  0  6 23  0
  6  0  6  6 10  6 11 15 16 15  8  0  0  0 11  1  3  0 14  1  1  0] -> size -> 46 
adversary victory points: -6
player victory points: 0 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0     -40       0       0      64       0] 
sum of rewards: 3000219 

action type: gain_card_n - action 8
Learning step: 120007.4765625
desired expected reward: 120039.5234375



