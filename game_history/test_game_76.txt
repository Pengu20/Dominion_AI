 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.6298504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       20        0
        0        0        0      -70        0        0        8        0] 
sum of rewards: -3000077 

action type: buy - action 8.0
Learning step: -119996.515625
desired expected reward: -120160.5234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  3.7922473]
 [ 18.26729  ]
 [  6.282972 ]
 [-72.50374  ]
 [ 13.829962 ]
 [  3.8726907]
 [ 11.0980835]
 [  2.2968464]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.60774564743042



buy possibilites: [-1] 
expected returns: [[3.0501523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 18.26728630065918






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.082285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.05015230178833





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 15.349993]
 [ 30.244555]
 [ 18.025883]
 [-62.135937]
 [ 25.734747]
 [ 25.694193]
 [ 15.250797]
 [ 37.79528 ]
 [ 24.46842 ]
 [ 22.847622]
 [ 28.544584]
 [ 13.766134]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.780675888061523



buy possibilites: [-1] 
expected returns: [[-5.8556833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.79528045654297






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-14.253412]
 [  8.836287]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.855683326721191



action possibilites: [-1.] 
expected returns: [[-16.387175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 7.666578769683838





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.829807 ]
 [ -1.2101779]
 [-50.058926 ]
 [-12.998848 ]
 [-48.059006 ]
 [-83.76964  ]
 [ -5.417502 ]
 [ -5.4698777]
 [-16.04977  ]
 [ -0.7813697]
 [  5.990562 ]
 [ -6.623666 ]
 [ -1.329026 ]
 [ -8.258467 ]
 [ -7.1793947]
 [ -2.7700827]
 [-16.697454 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.387174606323242



buy possibilites: [-1] 
expected returns: [[14.654469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 5.990569591522217






Player: 1 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-6.767682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.654468536376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  -5.6157026]
 [  -2.3217096]
 [-100.301    ]
 [  -5.8594766]
 [  -5.37752  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.201418399810791



buy possibilites: [-1] 
expected returns: [[4.511702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -2.321702480316162






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.507399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.511702060699463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 23.112217]
 [ 37.260674]
 [ 25.955118]
 [-55.386284]
 [ 33.716606]
 [ 33.70291 ]
 [ 23.366362]
 [ 43.655285]
 [ 32.684814]
 [ 31.093786]
 [ 36.04673 ]
 [ 23.847002]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.510480880737305



buy possibilites: [-1] 
expected returns: [[-20.009756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.655277252197266






Player: 1 
cards in hand: [29.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 29.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [29.  3.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-8.389357]
 [13.541426]
 [13.541426]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29.  3.  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.009756088256836



action possibilites: [-1. 29.] 
expected returns: [[ 3.2668314]
 [24.502104 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [29.  3.  0.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.13385009765625



action possibilites: [-1.] 
expected returns: [[20.71476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.50210952758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 22.162254]
 [ 36.29437 ]
 [ 24.714918]
 [-10.738637]
 [-54.267403]
 [ 32.249657]
 [ 32.164543]
 [ 22.249487]
 [ 36.652096]
 [ 43.127106]
 [ 31.07865 ]
 [ 36.141254]
 [ 29.546202]
 [ 30.557741]
 [ 34.747833]
 [ 21.597696]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.714759826660156



buy possibilites: [-1] 
expected returns: [[-8.881392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  3.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 8. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 97.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.12710189819336






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 29.  3.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 29.  3.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 8. 29.  3.  0. 29.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-10.719477]
 [  9.834362]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.881391525268555



action possibilites: [-1.] 
expected returns: [[2.2573695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.440664291381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  4.086915]
 [ 18.90059 ]
 [  7.749025]
 [-28.722332]
 [-71.4511  ]
 [ 15.284224]
 [ 15.264198]
 [  3.282844]
 [ 19.405445]
 [ 25.709972]
 [ 14.1985  ]
 [ 19.025967]
 [ 12.366764]
 [ 13.68351 ]
 [ 17.724342]
 [  4.943871]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  3. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.2573695182800293



buy possibilites: [-1] 
expected returns: [[-0.36484528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.7099666595459






Player: 1 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  3. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  3. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  3. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [29.  1.  3. 29. 29.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  1.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-13.95636  ]
 [  5.4462934]
 [  5.4462934]
 [  5.4462934]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 29. 29.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.36484527587890625



action possibilites: [-1. 29. 29.] 
expected returns: [[-2.4052072]
 [18.177626 ]
 [18.177626 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 29.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 5.353220462799072



action possibilites: [-1. 29.] 
expected returns: [[ 5.9235883]
 [27.583944 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  0.  3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.177621841430664



action possibilites: [-1.] 
expected returns: [[7.7953944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.583932876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.0458145]
 [ 25.128712 ]
 [-23.108665 ]
 [ 13.664938 ]
 [-21.662556 ]
 [-65.02292  ]
 [ 21.10357  ]
 [ 21.016815 ]
 [ 10.998928 ]
 [ 25.487444 ]
 [ 31.957193 ]
 [ 19.93404  ]
 [ 24.986292 ]
 [ 18.386871 ]
 [ 19.414747 ]
 [ 23.594923 ]
 [ 10.5117035]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  2. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.795394420623779



buy possibilites: [-1] 
expected returns: [[33.441803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 29.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 117.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.957197189331055






Player: 1 
cards in hand: [ 3.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 29.] 
cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29  8 10 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [22. 29.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [22. 29.  0.  3.  3.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.069733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.441802978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  9.795677]
 [ 24.605125]
 [ 13.396406]
 [-65.33331 ]
 [ 20.929993]
 [ 20.885971]
 [  8.983902]
 [ 31.443567]
 [ 19.820936]
 [ 18.000801]
 [ 23.372988]
 [ 10.522053]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  1. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.984735488891602



buy possibilites: [-1] 
expected returns: [[36.573215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  0.  0.] 
adversary cards in discard: [22. 29.  0.  3.  3.  0.  1.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.443552017211914






Player: 1 
cards in hand: [ 0. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0.  0.] 
cards in discard: [22. 29.  0.  3.  3.  0.  1.  0.  8.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [1. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 0.6007614]
 [21.922132 ]
 [21.922132 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 29.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.57321548461914



action possibilites: [-1.] 
expected returns: [[3.0959353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.925334930419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  5.731293]
 [  8.493137]
 [-78.83123 ]
 [  5.709189]
 [  5.066378]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.095935344696045



buy possibilites: [-1] 
expected returns: [[-8.851803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 8.493124008178711






Player: 1 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29. 29.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29. 29.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 1.  0.  3. 10. 29. 29.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29. 29.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 3.7971568]
 [24.370256 ]
 [24.370256 ]
 [24.370256 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29. 29.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.851802825927734



action possibilites: [-1. 29.] 
expected returns: [[20.598263]
 [39.729267]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.16004753112793



action possibilites: [-1. 29.] 
expected returns: [[34.023994]
 [51.010506]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [29.  0.  0.  3.  0.  0. 29.  3. 29.  3.  3.  3.  0. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.26466369628906



action possibilites: [-1.] 
expected returns: [[23.247913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 32.50213623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.33148  ]
 [ 38.181526 ]
 [ 27.62018  ]
 [ -7.0656137]
 [-48.434853 ]
 [ 34.744534 ]
 [ 34.867138 ]
 [ 24.032309 ]
 [ 38.78844  ]
 [ 33.80145  ]
 [ 38.31217  ]
 [ 32.13669  ]
 [ 33.278008 ]
 [ 37.158527 ]
 [ 24.496801 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9. 10.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.247913360595703



buy possibilites: [-1] 
expected returns: [[27.525152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.78843307495117






Player: 1 
cards in hand: [ 0.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-39.866695]
 [-19.55546 ]
 [-19.55546 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.5251522064209



action possibilites: [-1. 29.] 
expected returns: [[ 3.6865306]
 [24.638006 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.891862869262695



action possibilites: [-1.] 
expected returns: [[21.756493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.871427536010742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 24.387407]
 [ 38.27657 ]
 [ 27.199266]
 [-59.370323]
 [ 34.65503 ]
 [ 34.674465]
 [ 24.547522]
 [ 33.626526]
 [ 32.06631 ]
 [ 37.047318]
 [ 24.476915]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.756492614746094



buy possibilites: [-1] 
expected returns: [[78.124214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 108.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 38.27655029296875






Player: 1 
cards in hand: [ 3.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [10.  0.  0.  0. 22.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [10.  0.  0.  0. 22.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [10.  0.  0.  0. 22.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.70266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  8.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.12421417236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[75.4794   ]
 [89.22594  ]
 [78.65675  ]
 [-0.2899108]
 [85.96757  ]
 [85.88814  ]
 [75.146225 ]
 [84.96065  ]
 [83.32068  ]
 [88.10257  ]
 [76.8627   ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  8.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.21440124511719



buy possibilites: [-1] 
expected returns: [[79.16532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [ 0. 25. 29. 29. 29.  0.  0. 29.  3.  1. 29. 29.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  8.] 
adversary cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 68.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 89.2259521484375






Player: 1 
cards in hand: [ 0.  0. 29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  8.] 
cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  8.] 
cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29.  8.] 
cards in discard: [10.  0.  0.  0. 22.  0.  0.  3.  0.  3. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-19.092657]
 [  2.979875]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.16532135009766



action possibilites: [-1.] 
expected returns: [[-8.321608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.263366222381592





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -7.3533874]
 [ -4.3403707]
 [-77.13995  ]
 [ -7.9146147]
 [ -6.999259 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.32160758972168



buy possibilites: [-1] 
expected returns: [[40.59295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -4.340374946594238






Player: 1 
cards in hand: [ 0.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0. 10. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 29.  0. 29.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-16.355234 ]
 [  5.3930917]
 [  5.3930917]
 [  5.3930917]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 29.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.59294891357422



action possibilites: [-1. 29.] 
expected returns: [[-23.639858]
 [ -4.017709]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.683321714401245



action possibilites: [-1.] 
expected returns: [[14.246542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.379024505615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 15.017103]
 [ 28.193316]
 [ 17.8216  ]
 [-15.001415]
 [-54.58233 ]
 [ 24.7212  ]
 [ 24.566334]
 [ 14.560394]
 [ 28.447416]
 [ 23.644636]
 [ 28.125214]
 [ 22.11233 ]
 [ 23.207396]
 [ 26.85676 ]
 [ 15.597265]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  9.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.246541976928711



buy possibilites: [-1] 
expected returns: [[46.931297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 28.447412490844727






Player: 1 
cards in hand: [ 3.  0.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  1.  0. 25.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0.  3. 10.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  1.  0. 25.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0.  3. 10.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8. 10. 10. 10.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  1.  0. 25.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0.  3. 10.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10.  9.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  1.  0. 25.] 
adversary cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[30.720339]
 [50.387447]
 [44.33531 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0. 25.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8. 10. 10.  9.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.931297302246094



action possibilites: [-1. 25.] 
expected returns: [[-29.188543]
 [-15.666969]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8. 10. 10.  9.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.917457580566406



action possibilites: [-1] 
expected returns: [[50.39871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  9.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -15.666971206665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 46.068428]
 [ 59.771202]
 [ 49.777225]
 [ 13.567448]
 [-26.79853 ]
 [ 56.91155 ]
 [ 56.748   ]
 [ 45.08007 ]
 [ 60.05665 ]
 [ 55.93487 ]
 [ 59.947433]
 [ 54.16937 ]
 [ 55.55073 ]
 [ 58.800495]
 [ 48.851364]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  9.  9.  8.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.39870834350586



buy possibilites: [-1] 
expected returns: [[14.945452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [ 3.  3. 29.  3.  0.  3.  3. 29.  3. 25. 29. 29.  0.  0.  0.  1. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 8. 29.  0. 29.  0.] 
adversary cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 60.05665969848633






Player: 1 
cards in hand: [ 8. 29.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 29.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 29.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 29.  0.] 
cards in discard: [ 0. 14. 29.  0.  0.  1.  0. 11. 22.  3.  0.  3.  0.  3. 10.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-21.786898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.945451736450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -21.896881 ]
 [  -8.081957 ]
 [ -18.862757 ]
 [ -53.14754  ]
 [-101.82076  ]
 [ -11.661161 ]
 [ -11.765467 ]
 [ -22.364971 ]
 [  -7.7376194]
 [ -12.750101 ]
 [  -8.099317 ]
 [ -14.373991 ]
 [ -13.220835 ]
 [  -9.390947 ]
 [ -21.347065 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  7.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -22.33261489868164



buy possibilites: [-1] 
expected returns: [[11.624207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -7.73762845993042






Player: 1 
cards in hand: [29.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  9.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[11.53927 ]
 [29.739595]
 [29.739595]
 [24.019257]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0. 25.] 
cards in discard: [25.  3.  0.  0.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.62420654296875



action possibilites: [-1. 25. 29.] 
expected returns: [[-5.6725073]
 [ 6.785477 ]
 [12.498121 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 29.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.75716781616211



action possibilites: [-1. 25.] 
expected returns: [[16.327871]
 [29.893438]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.528244495391846



action possibilites: [-1] 
expected returns: [[30.721502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6] -> size -> 27 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.893423080444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 30.173925 ]
 [ 43.625755 ]
 [ 33.37909  ]
 [ -1.8697014]
 [-42.788067 ]
 [ 40.438015 ]
 [ 40.437843 ]
 [ 29.814772 ]
 [ 44.095795 ]
 [ 39.488163 ]
 [ 43.750885 ]
 [ 37.863686 ]
 [ 39.028175 ]
 [ 42.60929  ]
 [ 31.196295 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  9.  8.  6.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6] -> size -> 27 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.72150230407715



buy possibilites: [-1] 
expected returns: [[60.2596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  9.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6] -> size -> 27 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 425 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 44.09579086303711






Player: 1 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  9.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  9.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-27.478315]
 [-11.542608]
 [-16.659084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 25.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.25960159301758



action possibilites: [-1. 25.] 
expected returns: [[-26.404806]
 [-15.580463]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11] -> size -> 28 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.98480224609375



action possibilites: [-1] 
expected returns: [[-35.15044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -15.580459594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -35.683647]
 [ -23.409142]
 [ -32.46192 ]
 [-102.25861 ]
 [ -26.531755]
 [ -36.871887]
 [ -28.93249 ]
 [ -34.46688 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -35.15044021606445



buy possibilites: [-1] 
expected returns: [[-17.89101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  3.  0.  0.  1.  0. 29. 29. 25. 29. 29. 25.  3.  0.  1.  3. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -23.409147262573242






Player: 1 
cards in hand: [ 6.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  0. 29.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  1. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[-76.88267]
 [-74.86086]
 [-74.86086]
 [-67.92161]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0.  0. 22.  0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.891010284423828



action possibilites: [-1. 25. 25.] 
expected returns: [[-48.067745]
 [-42.149128]
 [-42.149128]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  3.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0.  0. 22.  0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -73.18409729003906



action possibilites: [-1] 
expected returns: [[6.1349196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  3.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0.  0. 22.  0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -42.149131774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  7.1087117]
 [ 19.988352 ]
 [ 10.5921955]
 [-72.81595  ]
 [ 17.024586 ]
 [  6.1229644]
 [ 14.4813   ]
 [  8.425884 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  3.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0.  0. 22.  0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.1349196434021



buy possibilites: [-1] 
expected returns: [[15.312975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  3.] 
cards in discard: [1. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0.  0. 22.  0.] 
adversary cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 19.988351821899414






Player: 1 
cards in hand: [14.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 22.  0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0.] 
cards in discard: [ 8. 29.  0. 10.  0. 10.  6. 11.  0.  3.  3.  1.  0.  6.  0. 29.  6.  3.
  0.  8.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
adversary victory points: 6
player victory points: -1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-37.406734]
 [-19.181444]
 [-25.105726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -36.38370132446289



action possibilites: [-1. 25.] 
expected returns: [[-33.312366]
 [-19.661627]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  6. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -25.457548141479492



action possibilites: [-1] 
expected returns: [[-9.493595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0. 11.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -19.66162872314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -7.36036   ]
 [  7.1125827 ]
 [ -4.4036336 ]
 [-45.063156  ]
 [-82.67951   ]
 [  3.4984365 ]
 [  3.6472402 ]
 [ -6.810934  ]
 [  7.7827716 ]
 [  2.5274024 ]
 [  7.22296   ]
 [  0.91309404]
 [  1.9761834 ]
 [  6.0314345 ]
 [ -7.249958  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  5.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0. 11.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.493595123291016



buy possibilites: [-1] 
expected returns: [[20.720545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  0. 11.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 495 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.782815456390381






Player: 1 
cards in hand: [14.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  0. 29.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0. 29. 25.  0.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  8.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [ 6. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 29. 25.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[41.14811]
 [56.00215]
 [51.17234]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -191.13775634765625



action possibilites: [-1. 25. 29.] 
expected returns: [[10.01096 ]
 [21.068216]
 [26.217058]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.86299133300781



action possibilites: [-1. 29.] 
expected returns: [[15.97735 ]
 [32.505424]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.759117126464844



action possibilites: [-1.] 
expected returns: [[12.320406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 14.11042594909668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.26383  ]
 [ 23.416624 ]
 [ 13.7229595]
 [-58.81246  ]
 [ 20.390657 ]
 [  9.421589 ]
 [ 17.882402 ]
 [ 12.266567 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25] -> size -> 31 
action values: 1 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.320405960083008



buy possibilites: [-1] 
expected returns: [[-26.907816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  6. 10.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 349 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 23.416627883911133






Player: 1 
cards in hand: [ 0. 10. 29.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  6. 10.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  1.  1. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1. 29. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6. 10. 22.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  1.  1. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6. 10. 22.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  1.  1. 29.  3.] 
adversary cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  1.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-26.173176 ]
 [ -9.3040695]
 [ -9.3040695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 29.  3.] 
cards in discard: [ 1.  1. 29. 25. 25.  0.  3.  0.  3.  3.  0.  3. 25. 29. 25.  0.  0.  1.
  0.  0.  3. 25. 25.  1. 29. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -26.90781593322754



action possibilites: [-1. 29.] 
expected returns: [[-24.187246]
 [ -5.343905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.  1.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.029911041259766



action possibilites: [-1.] 
expected returns: [[-30.143457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.475656509399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -29.871311]
 [ -16.281435]
 [ -64.413956]
 [ -26.651886]
 [ -64.61346 ]
 [ -21.455036]
 [-104.58504 ]
 [ -19.70869 ]
 [ -19.73917 ]
 [ -30.484917]
 [ -15.836365]
 [ -20.732382]
 [ -16.207027]
 [ -22.392357]
 [ -21.211647]
 [ -17.432386]
 [ -29.360067]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  4.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -30.143457412719727



buy possibilites: [-1] 
expected returns: [[10.266233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 337.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -15.836374282836914






Player: 1 
cards in hand: [8. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  1.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 26. 30.  8.  5. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  1.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 26. 30.  8.  5. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  1.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-4.7724576]
 [ 5.7101502]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  0. 25.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 26. 30.  8.  5. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1] -> size -> 34 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.266233444213867



action possibilites: [-1] 
expected returns: [[-37.657013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  0.  0. 29.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 26. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.710136890411377





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -44.294113]
 [ -28.399515]
 [ -83.97511 ]
 [ -39.866074]
 [ -86.21598 ]
 [-118.14271 ]
 [ -30.729177]
 [ -32.695774]
 [ -47.30753 ]
 [ -30.296886]
 [ -32.533108]
 [ -28.92661 ]
 [ -34.69908 ]
 [ -32.342045]
 [ -30.761059]
 [ -38.30746 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  0.  0. 29.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 22. 30. 26. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.657012939453125



buy possibilites: [-1] 
expected returns: [[-44.23793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3.  0.  0. 29.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 21. 30. 26. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 268.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -28.3995361328125






Player: 1 
cards in hand: [0. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 26. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  0. 29. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 21. 30. 26. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  0. 29. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 25. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  0. 29. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 9.071445]
 [19.47595 ]
 [24.237757]
 [19.47595 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29. 25.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 25. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -44.23793029785156



action possibilites: [-1. 25.] 
expected returns: [[13.167744]
 [26.80697 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 25. 30.  8.  4. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3] -> size -> 36 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.075849533081055



action possibilites: [-1] 
expected returns: [[-17.791801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.806983947753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-20.013443 ]
 [ -7.2482586]
 [-16.734943 ]
 [-90.217415 ]
 [-10.145411 ]
 [-10.250793 ]
 [-20.810644 ]
 [-11.081898 ]
 [-12.707916 ]
 [ -8.226034 ]
 [-18.297926 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 21. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.79180145263672



buy possibilites: [-1] 
expected returns: [[18.074003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 288.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -7.248256683349609






Player: 1 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 20. 30. 25. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 14.  0. 11.  0. 29. 10.  0. 29.  6. 10. 22.  1.  8.  0.  6.  0.
  0.  6.  3.  0.  6.  3.  0.  6.  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 24. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-32.270416]
 [-21.10095 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 25.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  3. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.074003219604492



action possibilites: [-1] 
expected returns: [[-38.85611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29. 29.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 11.  0.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 39 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -21.100950241088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-40.76588]
 [-88.64997]
 [-39.16359]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 29. 29.] 
cards in discard: [ 3. 25. 25. 29. 29.  1.  1.  1.  1. 25.  1.  1.  3.  0.  0. 29. 25.  1.
 29. 25.  0.  0.  0. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  1. 11.  0.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 39 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -38.856109619140625






Player: 1 
cards in hand: [ 3.  1. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  0.  8.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29 29 29  8 10 22  0  3 10  0  0 14 11  6
  0  8  6 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25.  0.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-54.474583]
 [-47.93947 ]
 [-40.448196]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -39.1635856628418



action possibilites: [-1. 25. 29.] 
expected returns: [[-50.579018]
 [-44.547787]
 [-37.270332]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -46.230472564697266



action possibilites: [-1.] 
expected returns: [[-28.239838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -42.538333892822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -36.86223 ]
 [ -19.077263]
 [ -32.01966 ]
 [ -80.095985]
 [-122.49147 ]
 [ -22.158863]
 [ -24.156717]
 [ -40.632526]
 [ -21.003695]
 [ -24.178526]
 [ -19.644379]
 [ -26.582413]
 [ -24.070644]
 [ -21.743425]
 [ -27.603329]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 20. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -28.239837646484375



buy possibilites: [-1] 
expected returns: [[-8.070648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 19. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   40.    0.    0.    0.    0.  -10.
   0.    0.   13.5   0. ] 
sum of rewards: 308.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -19.07727813720703






Player: 1 
cards in hand: [6. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6. 8. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  3. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6. 8. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 19. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  3. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 19. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  3. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-11.239344 ]
 [ -1.3616302]
 [ -1.3616302]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3. 25.  3.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 24. 30.  8.  2. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0] -> size -> 37 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.070648193359375



action possibilites: [-1] 
expected returns: [[-64.4896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.  3. 29.  1.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -1.3616399765014648





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -75.94183 ]
 [ -59.28563 ]
 [ -71.43281 ]
 [-124.37833 ]
 [ -62.561073]
 [ -64.885284]
 [ -79.45343 ]
 [ -64.63387 ]
 [ -66.922874]
 [ -62.42382 ]
 [ -62.370365]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25.  3. 29.  1.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 19. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -64.4896011352539



buy possibilites: [-1] 
expected returns: [[-116.79838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25.  3. 29.  1.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [11.  3.  0.  0.  3.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.  -20.
   0.    0.   13.5   0. ] 
sum of rewards: 278.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -59.2856559753418






Player: 1 
cards in hand: [11.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  0.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  0.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 18. 30. 24. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  0.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [6. 8. 3. 0. 6. 0. 0. 0. 3. 6. 0. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1.  3.  0. 29.  0.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-1.6965232]
 [14.181009 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 29.  0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  6. 29.  6.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -116.79837799072266



action possibilites: [-1.] 
expected returns: [[-1.1740367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  6. 29.  6.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.826833724975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -4.546995 ]
 [  8.839058 ]
 [ -1.2324781]
 [-80.28166  ]
 [  5.7334456]
 [  5.6947017]
 [ -5.119213 ]
 [  4.779487 ]
 [  3.1300364]
 [  7.8329244]
 [ -3.2112646]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 18. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  6. 29.  6.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.1740367412567139



buy possibilites: [-1] 
expected returns: [[-3.2753487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 17. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11.  6. 29.  6.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: 268.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 8.839059829711914






Player: 1 
cards in hand: [ 0. 11.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 29.  6.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 17. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1.  3.  1. 25.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 17. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1.  3.  1. 25.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1.  3.  1. 25.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 16. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [25.  1.  3.  1. 25.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25.  1.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-77.5388 ]
 [-74.19639]
 [-74.19639]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  1. 25.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  1. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.275348663330078



action possibilites: [-1] 
expected returns: [[-33.569016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1. 25. 29.  0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -74.19638061523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-36.346996]
 [-23.349478]
 [-32.686687]
 [-63.949593]
 [-26.242846]
 [-26.385548]
 [-37.739796]
 [-23.038864]
 [-27.21534 ]
 [-23.174257]
 [-28.951134]
 [-27.60879 ]
 [-24.319628]
 [-34.319218]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  1. 25. 29.  0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  3.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -33.56901550292969



buy possibilites: [-1] 
expected returns: [[-36.156403]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  1. 25. 29.  0.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -40   0   0 250   0] 
sum of rewards: 495 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -23.03885841369629






Player: 1 
cards in hand: [ 6. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  1. 29. 29.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  1. 29. 29.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 25.  1. 29. 29.] 
adversary cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-123.08227]
 [-127.61278]
 [-120.89008]
 [-120.89008]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1. 29. 29.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  6.  6.  6. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -36.156402587890625



action possibilites: [-1.] 
expected returns: [[-63.62893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  6.  6.  6. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -124.74683380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-65.47318 ]
 [-53.55831 ]
 [-62.51175 ]
 [-88.1023  ]
 [-56.821026]
 [-56.95216 ]
 [-66.351654]
 [-53.173832]
 [-57.638287]
 [-53.604668]
 [-59.063095]
 [-57.962837]
 [-54.91388 ]
 [-63.62893 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0. 25. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  2.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  6.  6.  6. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -63.628929138183594



buy possibilites: [-1] 
expected returns: [[-28.953827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [ 1. 25.  1. 29. 29.  0.  0.  0.  1. 25.  1.  3. 25.  3. 29.  1.  1.  1.
 29.  3.  0.  0.  0. 25. 25.  1.  3.  1. 25. 29.  0. 25. 29. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [14.  6.  6.  6. 10.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0 250   0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -53.1738395690918






Player: 1 
cards in hand: [14.  6.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  6. 10.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  6. 10.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  6. 10.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 1. 29. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-103.76649 ]
 [-104.89976 ]
 [-104.89976 ]
 [-110.544426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  1.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0. 14.  6.  6.  6.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -28.953826904296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-128.1299 ]
 [-120.7607 ]
 [-134.65242]
 [-105.5113 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  1.] 
adversary cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0. 14.  6.  6.  6.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0] -> size -> 43 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -103.76649475097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  1.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0. 14.  6.  6.  6.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  3.  1.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0. 14.  6.  6.  6.
 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 16. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  3.  1.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  0.  0.  3.  6.  0.  3. 11.  3.  0.  0.  3.  0.
  1. 29. 11.  6.  6.  0.  6.  0. 22. 29.  6.  0.  0.  0. 14.  6.  6.  6.
 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-19.65845 ]
 [ -8.905307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  1.] 
cards in discard: [ 1. 29. 29. 25.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -105.51131439208984



action possibilites: [-1] 
expected returns: [[-59.63392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1.  0. 25.] 
cards in discard: [ 1. 29. 29. 25.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.905311584472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -70.05884 ]
 [ -53.774635]
 [ -65.53717 ]
 [-107.50957 ]
 [ -56.630093]
 [ -58.82129 ]
 [ -74.38503 ]
 [ -55.99283 ]
 [ -58.672485]
 [ -54.474747]
 [ -60.927002]
 [ -58.4705  ]
 [ -56.569324]
 [ -57.373276]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1.  0. 25.] 
cards in discard: [ 1. 29. 29. 25.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 15. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -59.63391876220703



buy possibilites: [-1] 
expected returns: [[-70.17014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1.  0. 25.] 
cards in discard: [ 1. 29. 29. 25.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 6.  6. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  300.    0.    0.   20.    0.    0.    0.    0.  -60.
   0.    0.   13.5   0. ] 
sum of rewards: 268.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -53.774658203125






Player: 1 
cards in hand: [ 6.  6. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [8. 3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [8. 3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  8.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [8. 3. 8.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 25.  1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 25.] 
expected returns: [[38.556786]
 [52.500896]
 [47.939346]
 [47.939346]
 [47.939346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1. 25. 25.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -70.1701431274414



action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-8.771425 ]
 [ 1.2001958]
 [ 1.2001958]
 [ 1.2001958]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.6536865234375



action possibilites: [-1] 
expected returns: [[-3.6540637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.2001900672912598





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-1.0061068e+01]
 [ 2.4072523e+00]
 [-6.4671693e+00]
 [-1.0980129e-02]
 [-1.0964656e-01]
 [-1.1011871e+01]
 [-8.2828879e-01]
 [-2.4748034e+00]
 [ 1.6500735e+00]
 [-7.1028376e+00]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  1.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 14. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.6540637016296387



buy possibilites: [-1] 
expected returns: [[-35.160023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  1.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [6. 6. 0. 1. 6.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  300.    0.    0.   40.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: 278.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 2.4072489738464355






Player: 1 
cards in hand: [6. 6. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 1. 6.] 
cards in discard: [ 8.  3.  8. 29.  6.  6.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [ 3. 25.  1.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
adversary victory points: 6
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-53.301804]
 [-44.0477  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  3.  1.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -35.1600227355957



action possibilites: [-1] 
expected returns: [[-32.077026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  1. 25.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -44.0477409362793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-34.012566]
 [-20.977589]
 [-30.2819  ]
 [-61.65773 ]
 [-23.845827]
 [-23.986816]
 [-35.46165 ]
 [-20.660536]
 [-24.814667]
 [-20.786104]
 [-26.55429 ]
 [-25.204508]
 [-21.927364]
 [-31.885921]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3.  1. 25.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  1.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -32.0770263671875



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 13 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1.  3.  1. 25.  0.] 
cards in discard: [ 1. 29. 29. 25.  3.  1. 25.  0.  0.  3.  1.  0. 25. 25.  1.  1. 29. 25.
 25. 25.  1.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3 29 29 29 29 29  3 25  1  1  3
 25 25 25 25  1  1 25  1 25  1  1  1  1  1 25 25  1  1 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 23. 30.  8.  0. 10.  7.  7.  0.  0.  9. 10.  8.  9. 10.] 
adversary cards in hand: [29.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  3.  8. 29.  6.  6.  0.  6.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 29 29  8 10 22  0  3 10  0  0 14  6  0  8  6
 11  6  6  0  6 11  1  6  3  6  3  6  0  6  0  3  1  6  0  1  8] -> size -> 45 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     300       0       0      20       0       0
       0       0     -80       0       0     125       0] 
sum of rewards: 3000360 

action type: buy - action 25.0
Learning step: 120015.2265625
desired expected reward: 119994.5625



