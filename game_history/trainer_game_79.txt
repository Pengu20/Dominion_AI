 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[341.5341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   9 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 624 

action type: buy - action -1.0
Learning step: 29.37287712097168
desired expected reward: 65.91535949707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[315.60043]
 [330.10263]
 [323.23404]
 [287.9412 ]
 [337.124  ]
 [324.84882]
 [320.7556 ]
 [341.0863 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.956891059875488
desired expected reward: 334.8664245605469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.04102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.172863960266113
desired expected reward: 331.91351318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.40732]
 [337.35144]
 [330.23157]
 [284.71255]
 [326.81152]
 [346.23904]
 [330.34457]
 [332.11075]
 [301.8325 ]
 [326.67917]
 [320.10846]
 [352.0383 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.32951831817627
desired expected reward: 344.4018249511719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.59464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 8.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.029263496398926
desired expected reward: 342.009033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[316.33356]
 [329.5813 ]
 [323.15762]
 [289.7596 ]
 [336.75296]
 [325.18948]
 [321.2883 ]
 [340.93173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [ 8.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.762603759765625
desired expected reward: 331.244140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 8.  3.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 8.  3.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [ 8.  3.  0. 29.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.66678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.082056999206543
desired expected reward: 331.84967041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[327.11194]
 [345.23602]
 [337.5371 ]
 [291.937  ]
 [334.55487]
 [353.8337 ]
 [338.34882]
 [340.01248]
 [309.05762]
 [333.98117]
 [327.31598]
 [358.86908]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.350032806396484
desired expected reward: 348.0735168457031



buy possibilites: [-1] 
expected returns: [[295.73157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -9.920098304748535
desired expected reward: 324.0610656738281






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  8 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.8831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.251411437988281
desired expected reward: 288.48016357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[312.8104 ]
 [326.61765]
 [319.90228]
 [284.94296]
 [318.5183 ]
 [332.84357]
 [321.89194]
 [323.14932]
 [298.34137]
 [317.6169 ]
 [312.5007 ]
 [336.2273 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.801722526550293
desired expected reward: 329.5390319824219



buy possibilites: [-1] 
expected returns: [[270.0103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -8.049803733825684
desired expected reward: 304.4508972167969






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  8. 16.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  8. 16.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  8. 16.  0.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[306.28644]
 [286.73886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.8724589347839355
desired expected reward: 263.1378479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[276.83432]
 [293.3793 ]
 [284.72464]
 [248.40137]
 [299.68625]
 [287.79794]
 [281.66983]
 [301.12772]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.882463455200195
desired expected reward: 296.9648742675781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 16.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [15.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[270.92102]
 [247.0309 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.751663208007812
desired expected reward: 291.37603759765625



action possibilites: [-1] 
expected returns: [[247.24098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 15.0
Learning step: -6.381056785583496
desired expected reward: 240.49850463867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[223.80504]
 [240.05994]
 [232.07056]
 [191.33276]
 [230.48254]
 [245.87791]
 [234.47691]
 [235.60912]
 [206.04887]
 [228.64018]
 [222.47168]
 [247.0877 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -6.699399471282959
desired expected reward: 240.5415802001953



buy possibilites: [-1] 
expected returns: [[272.03198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 12.5 

action type: buy - action 1.0
Learning step: -4.537637233734131
desired expected reward: 221.12950134277344






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[220.40921]
 [202.39487]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.410613059997559
desired expected reward: 262.6213684082031



action possibilites: [-1.] 
expected returns: [[274.95798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 9 

action type: take_action - action 10.0
Learning step: -3.4134628772735596
desired expected reward: 197.5868682861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[251.71829]
 [265.2952 ]
 [258.6775 ]
 [224.71715]
 [257.2626 ]
 [270.34488]
 [260.54547]
 [261.36563]
 [236.98982]
 [255.86446]
 [250.6357 ]
 [271.66296]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.490201473236084
desired expected reward: 267.4677734375



buy possibilites: [-1] 
expected returns: [[291.5698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 12.5 

action type: buy - action 10.0
Learning step: -5.607901096343994
desired expected reward: 250.25653076171875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 14.  0.  0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1  8 16  0  8 14  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3. 29.  0.  8.  0.  3. 16.  8.  3.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[221.685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 29. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.69890022277832
desired expected reward: 280.8708801269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[204.17226]
 [217.25131]
 [210.98416]
 [179.80661]
 [209.55078]
 [222.57068]
 [212.47684]
 [213.31125]
 [190.78285]
 [208.04065]
 [203.02689]
 [225.04681]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 29. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -7.3682451248168945
desired expected reward: 213.9468536376953



buy possibilites: [-1] 
expected returns: [[248.04536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 29. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -17.5 

action type: buy - action 10.0
Learning step: -5.6960129737854
desired expected reward: 202.3446502685547






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 29. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 14.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3. 10.  0. 15.] 
adversary cards in discard: [10.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.] 
adversary cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[245.71223]
 [227.2884 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: discard_down_to_3_cards - action 0
Learning step: -3.002333879470825
desired expected reward: 140.59616088867188



action possibilites: [-1.] 
expected returns: [[250.9121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -5.5268988609313965
desired expected reward: 216.9215087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[222.65776]
 [231.37231]
 [195.46216]
 [232.03203]
 [248.58978]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  3.  3.  1.  0.  0. 10. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.406297206878662
desired expected reward: 243.50579833984375






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 1. 14.  0.  8. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 1. 14.  0.  8. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[226.27698]
 [206.674  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -8.522209167480469
desired expected reward: 240.06756591796875



action possibilites: [-1.] 
expected returns: [[242.5637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -5.0808634757995605
desired expected reward: 204.6900634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[214.75148]
 [227.83119]
 [221.58981]
 [190.65479]
 [220.07642]
 [233.56783]
 [223.39297]
 [224.42804]
 [201.24025]
 [219.38464]
 [214.36629]
 [235.54778]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.189439296722412
desired expected reward: 235.374267578125






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [ 1. 14.  0.  8. 29.  3.  3.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 10. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[235.89626]
 [219.8358 ]
 [214.93921]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  3.  0.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -8.282058715820312
desired expected reward: 227.26573181152344



action possibilites: [-1. 15.] 
expected returns: [[267.25064]
 [236.71762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  1.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -10 

action type: take_action - action 10.0
Learning step: -5.302028179168701
desired expected reward: 206.21221923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[234.41585]
 [253.38766]
 [243.7553 ]
 [199.20189]
 [260.68884]
 [246.55711]
 [239.78932]
 [262.27792]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  0.  1.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.371350288391113
desired expected reward: 258.8793029785156



buy possibilites: [-1] 
expected returns: [[289.07156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  0.  1.] 
cards in discard: [10.  3.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -19.605985641479492
desired expected reward: 179.5959014892578






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [10.  6. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[240.4258 ]
 [227.28748]
 [227.28748]
 [227.28748]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  3.  0.  0.] 
adversary cards in discard: [ 3.  3. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -11.899011611938477
desired expected reward: 277.17254638671875



action possibilites: [-1. 10. 10.] 
expected returns: [[221.81444]
 [204.14436]
 [204.14436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  3.  0.  0.] 
adversary cards in discard: [ 3.  3. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -32 

action type: take_action - action 10.0
Learning step: -8.046191215515137
desired expected reward: 216.9987335205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[198.68571]
 [206.45543]
 [165.8768 ]
 [210.21678]
 [220.99   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  3.  0.  0.] 
adversary cards in discard: [ 3.  3. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.09069538116455
desired expected reward: 213.72372436523438






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  0.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  6. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  6. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  6. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  6. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[237.36272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [10.  6. 10. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [ 3.  3. 14.  0. 16.  0.  8. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -8.383650779724121
desired expected reward: 212.60633850097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[216.86243]
 [222.62825]
 [192.33022]
 [225.1441 ]
 [235.29495]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [10.  6. 10. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [ 3.  3. 14.  0. 16.  0.  8. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -9.433042526245117
desired expected reward: 226.82688903808594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.  8. 29.  1.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.  8. 29.  1.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [ 3.  3. 14.  0. 16.  0.  8. 29.  1.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [10.  1. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[261.6858 ]
 [246.72845]
 [242.51476]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -8.722172737121582
desired expected reward: 226.57278442382812



action possibilites: [-1] 
expected returns: [[164.25339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action 15.0
Learning step: -10.04599666595459
desired expected reward: 231.78794860839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[149.3992 ]
 [159.73985]
 [143.30714]
 [154.16371]
 [136.48636]
 [128.92502]
 [153.61772]
 [163.4933 ]
 [156.40544]
 [172.16457]
 [157.05809]
 [138.32011]
 [144.51903]
 [152.39355]
 [133.90965]
 [148.4648 ]
 [164.66943]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -6.330124855041504
desired expected reward: 157.9232635498047



buy possibilites: [-1] 
expected returns: [[178.01488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -25.0 

action type: buy - action 29.0
Learning step: -5.097570896148682
desired expected reward: 151.96054077148438






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [29. 15. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[123.35454]
 [109.76252]
 [109.76252]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [29. 15. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8. 16.  0.  0.] 
adversary cards in discard: [0. 3. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -8.985067367553711
desired expected reward: 169.02981567382812



action possibilites: [-1. 10.] 
expected returns: [[152.86617]
 [139.49489]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [29. 15. 10.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8. 16.  0.  0.] 
adversary cards in discard: [0. 3. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action 10.0
Learning step: -3.6531174182891846
desired expected reward: 103.10172271728516



action possibilites: [-1.] 
expected returns: [[210.4112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 15. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8. 16.  0.  0.] 
adversary cards in discard: [0. 3. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: -2.8404927253723145
desired expected reward: 136.65438842773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[190.76816]
 [204.62106]
 [197.24976]
 [163.2631 ]
 [196.353  ]
 [209.6739 ]
 [200.34985]
 [201.00002]
 [175.48387]
 [194.9119 ]
 [189.50348]
 [210.15228]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 15. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8. 16.  0.  0.] 
adversary cards in discard: [0. 3. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.688514709472656
desired expected reward: 203.72268676757812



buy possibilites: [-1] 
expected returns: [[122.57058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 15. 10.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8. 16.  0.  0.] 
adversary cards in discard: [0. 3. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.0992560386657715
desired expected reward: 179.04261779785156






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14.  8. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 16.  0.  0.] 
cards in discard: [0. 3. 0. 8. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 16.  0.  0.] 
cards in discard: [0. 3. 0. 8. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 16.  0.  0.] 
cards in discard: [0. 3. 0. 8. 3. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [10.  0.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[143.77544]
 [135.4367 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -6.1380534172058105
desired expected reward: 116.43252563476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[132.92714]
 [116.40598]
 [143.25763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 25. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -7.244237422943115
desired expected reward: 135.21844482421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [10.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 25. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [10.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [10.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [ 3.  0. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[144.54979]
 [133.5749 ]
 [129.07472]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 15.] 
cards in discard: [10.  0.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -7.735931396484375
desired expected reward: 135.52169799804688



action possibilites: [-1] 
expected returns: [[136.44553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10.  0.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 15.0
Learning step: -5.962947845458984
desired expected reward: 121.69650268554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[122.19723 ]
 [134.0912  ]
 [127.791756]
 [ 99.32949 ]
 [126.966805]
 [137.82289 ]
 [130.14319 ]
 [130.52313 ]
 [109.210365]
 [125.225334]
 [120.64921 ]
 [138.29918 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10.  0.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -6.566201686859131
desired expected reward: 129.8793182373047



buy possibilites: [-1] 
expected returns: [[122.17935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [10.  0.  6.  3.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -21 

action type: buy - action 15.0
Learning step: -4.333425521850586
desired expected reward: 116.31578826904297






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 1.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 16  0  8 14  3  8  3  1  3  3  8  0  0
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [10.  0.  6.  3.  3. 15. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [10.  0.  6.  3.  3. 15. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0.  8.  3.  3.  3. 14.  8. 16.  0.  0.  3.  3.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 29.  1.  0.  0.] 
adversary cards in discard: [10.  0.  6.  3.  3. 15. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [ 8. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[85.61161]
 [77.89478]
 [78.34696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  1.  0.  0.] 
cards in discard: [10.  0.  6.  3.  3. 15. 15.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -7.978636264801025
desired expected reward: 114.20071411132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[71.142815]
 [79.853584]
 [76.18839 ]
 [54.968132]
 [74.623634]
 [83.17275 ]
 [76.34964 ]
 [76.77864 ]
 [62.928486]
 [73.9311  ]
 [70.6735  ]
 [84.28202 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  1.  0.  0.] 
cards in discard: [10.  0.  6.  3.  3. 15. 15.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -6.045660495758057
desired expected reward: 76.48775482177734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 15.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 24. 30.  8.  9.  9. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [ 0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[133.84592]
 [123.1941 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 16.  3.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16] -> size -> 24 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: discard_down_to_3_cards - action 9
Learning step: -7.475151062011719
desired expected reward: 127.00313568115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.580925]
 [106.58236 ]
 [132.72137 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  3. 16.  3.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16] -> size -> 24 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.488698482513428
desired expected reward: 124.9025650024414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 16.  3.] 
cards in discard: [16. 14.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  6. 10. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [29.  0.  6. 10. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [29.  0.  6. 10. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [29.  0.  6. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
expected returns: [[75.86834 ]
 [66.8568  ]
 [64.50882 ]
 [61.398685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6. 10. 15.] 
cards in discard: [ 8. 15.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -8.266769409179688
desired expected reward: 124.45458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.867023]
 [46.510532]
 [73.52665 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6. 10. 15.] 
cards in discard: [ 8. 15.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -5.373255252838135
desired expected reward: 67.92552185058594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  1.  3.  3.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 29.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  1.  3.  3.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 29.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 10.  1.  3.  3.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 29.  0.  6. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 0. 10.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[73.68936]
 [64.87792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3.  3.] 
cards in discard: [ 8. 15.  0.  3. 10. 29.  0.  6. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -5.306618690490723
desired expected reward: 68.22003936767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.43454 ]
 [67.72217 ]
 [64.363945]
 [42.421013]
 [70.35854 ]
 [64.6273  ]
 [62.202282]
 [70.57787 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  3.  3.] 
cards in discard: [ 8. 15.  0.  3. 10. 29.  0.  6. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.  0.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -5.2106194496154785
desired expected reward: 65.29474639892578



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.  0.  0.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.  0.  0.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [16. 14.  0.  3.  0. 29. 15. 16.  3.  3.  3. 10.  0.  0.  0.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 0. 15.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29.] 
expected returns: [[113.17737]
 [100.59851]
 [105.66415]
 [105.98175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10  0] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -3.901324987411499
desired expected reward: 59.906307220458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.96242 ]
 [111.67392 ]
 [ 93.1419  ]
 [111.143456]
 [118.96538 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 24. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10  0] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -6.285637855529785
desired expected reward: 106.64009094238281



buy possibilites: [-1] 
expected returns: [[83.87376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 29.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10  0] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -44 

action type: buy - action 3.0
Learning step: -5.8965373039245605
desired expected reward: 105.77738952636719






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 16  0  8 14  3  8  3  3  3  8  0  0  3  3 16 15
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  6. 10. 15.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  6. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[125.88915]
 [112.31481]
 [106.96678]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10. 15.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 14. 29.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -2.7001264095306396
desired expected reward: 81.17362976074219



action possibilites: [-1] 
expected returns: [[95.21884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 14. 29.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action 15.0
Learning step: -3.156888008117676
desired expected reward: 100.829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[82.47616]
 [65.23618]
 [93.89953]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  9.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 14. 29.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -2.957789182662964
desired expected reward: 92.26105499267578



buy possibilites: [-1] 
expected returns: [[72.4906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 14. 29.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action 6.0
Learning step: -17.280771255493164
desired expected reward: 47.955406188964844






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14. 29.] 
cards in discard: [0. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 10.  1.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.  6. 15.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 14. 29.] 
cards in discard: [0. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 10.  1.] 
adversary cards in discard: [ 3.  0. 15.  8. 29.  0.  6. 15.  3.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[91.03623]
 [81.59283]
 [81.59283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  1.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.  6. 15.  3.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -3.398303985595703
desired expected reward: 69.09230041503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.29484 ]
 [84.460075]
 [81.50853 ]
 [63.15883 ]
 [87.35127 ]
 [81.50013 ]
 [79.66243 ]
 [88.521706]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 10.  1.] 
cards in discard: [ 3.  0. 15.  8. 29.  0.  6. 15.  3.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -4.17397403717041
desired expected reward: 83.60260772705078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0  8 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [1. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [1. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[91.217354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -4.554524898529053
desired expected reward: 83.96720886230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[81.09177 ]
 [89.04861 ]
 [84.01579 ]
 [65.97563 ]
 [84.42403 ]
 [91.02814 ]
 [86.879654]
 [87.247025]
 [72.68778 ]
 [83.03665 ]
 [79.85869 ]
 [91.03919 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -4.719638347625732
desired expected reward: 85.12757873535156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 16.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  3. 10.  3.] 
adversary cards in discard: [1. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 16.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  5. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  3. 10.  3.] 
adversary cards in discard: [1. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 16.  0.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 29.  3. 10.  3.] 
adversary cards in discard: [1. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 29.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[111.35064]
 [102.27426]
 [ 97.50586]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3. 10.  3.] 
cards in discard: [1. 0. 3. 6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -4.393042087554932
desired expected reward: 86.64614868164062



action possibilites: [-1. 29. 15.] 
expected returns: [[96.135056]
 [84.628784]
 [78.62629 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [1. 0. 3. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -3.869516134262085
desired expected reward: 90.7475814819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 85.669365]
 [ 70.147285]
 [103.36906 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [1. 0. 3. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6] -> size -> 18 
action values: 2 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  8.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -3.8971831798553467
desired expected reward: 92.23787689208984



buy possibilites: [-1] 
expected returns: [[44.063316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [1. 0. 3. 6. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  3. 10.] 
adversary cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
adversary owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -334 

action type: buy - action 6.0
Learning step: -19.215940475463867
desired expected reward: 50.93134307861328






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 10.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0.  8.  0.  3.  3. 14. 29.  3. 16.  0.  0.  0.  8.  3.  0. 15. 16.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 10.  0.  3. 15.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 8. 10.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
expected returns: [[42.290756]
 [38.52061 ]
 [36.070633]
 [33.803505]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3. 15.] 
cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15  1 10 10  6 29  8 15  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -4.051048278808594
desired expected reward: 40.01226806640625



action possibilites: [-1] 
expected returns: [[90.66233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.056800603866577
desired expected reward: 34.877254486083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.943794]
 [67.76013 ]
 [94.678406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 1.  0.  3.  6.  0.  6. 10.  6. 29.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -4.8497138023376465
desired expected reward: 85.81261444091797






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15 10  0  0  3  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[47.430325]
 [40.142033]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 16.  3.] 
adversary cards in discard: [8. 3. 8.] 
adversary owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -7.019176006317139
desired expected reward: 87.65922546386719



action possibilites: [-1.] 
expected returns: [[85.889015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 16.  3.] 
adversary cards in discard: [8. 3. 8.] 
adversary owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: -2.2165188789367676
desired expected reward: 35.76390838623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[70.75986 ]
 [74.700745]
 [55.074333]
 [75.84158 ]
 [83.64349 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  4. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 16.  3.] 
adversary cards in discard: [8. 3. 8.] 
adversary owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.84503698348999
desired expected reward: 81.04397583007812



buy possibilites: [-1] 
expected returns: [[78.54494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 16.  3.] 
adversary cards in discard: [8. 3. 8.] 
adversary owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 8.0
Learning step: -3.8748185634613037
desired expected reward: 71.9667739868164






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 16.  3.] 
cards in discard: [8. 3. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [8. 3. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.] 
cards in discard: [8. 3. 8. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.] 
cards in discard: [8. 3. 8. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 29.  1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[55.361637]
 [49.723427]
 [46.897213]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0. 10.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.5573859214782715
desired expected reward: 72.987548828125



action possibilites: [-1. 10.] 
expected returns: [[84.79981]
 [68.77194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: -2.3400774002075195
desired expected reward: 45.107418060302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[67.647316]
 [81.77191 ]
 [74.903015]
 [44.0783  ]
 [72.97727 ]
 [88.013725]
 [75.34755 ]
 [75.9212  ]
 [54.53588 ]
 [72.02126 ]
 [66.97812 ]
 [89.66629 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.2497758865356445
desired expected reward: 80.550048828125



buy possibilites: [-1] 
expected returns: [[115.60871]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  3.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -4.031170845031738
desired expected reward: 63.61616134643555






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 10.  8.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0. 29.  3.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 10.  8.] 
adversary cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0. 29.  3.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 19 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 15.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[-5.324433 ]
 [-4.934128 ]
 [-4.54253  ]
 [-3.2936046]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10.  8.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0. 29.  3.  1.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -8.61666202545166
desired expected reward: 106.99205017089844



action possibilites: [-1] 
expected returns: [[5.7389426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0. 29.  3.  1.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 15.0
Learning step: -1.3935226202011108
desired expected reward: -5.940548419952393





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 2.2332258 ]
 [ 4.9007416 ]
 [ 3.8712683 ]
 [-0.63168573]
 [ 6.246409  ]
 [ 3.5617437 ]
 [ 2.989699  ]
 [ 6.2818522 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.] 
cards in discard: [ 8. 10.  0.  6.  6.  0.  6.  0. 29.  3.  1.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -1.9363893270492554
desired expected reward: 3.802553176879883






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  1.  6. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 8.  3.  8.  6.  0. 16.  3. 29.  3.  3.  0.  0. 16.  3. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[68.04226 ]
 [60.547844]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 7
Learning step: -2.542524576187134
desired expected reward: 21.6961669921875



action possibilites: [-1. 10.] 
expected returns: [[68.81241 ]
 [63.034294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -2.9618375301361084
desired expected reward: 51.334197998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.03289 ]
 [69.92997 ]
 [66.540695]
 [51.86476 ]
 [71.5042  ]
 [68.01928 ]
 [65.297966]
 [71.26851 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 22. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.667210340499878
desired expected reward: 65.14518737792969



buy possibilites: [-1] 
expected returns: [[94.65821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -22.0 

action type: buy - action 3.0
Learning step: -2.2972257137298584
desired expected reward: 64.24347686767578






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.157608]
 [35.13483 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14.  0. 16.  3.] 
adversary cards in discard: [15.  3.  0.  8.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -5.905844211578369
desired expected reward: 88.75236511230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.520452]
 [16.686193]
 [47.9237  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 21. 30.  8.  6.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14.  0. 16.  3.] 
adversary cards in discard: [15.  3.  0.  8.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -3.819676160812378
desired expected reward: 45.15788650512695



buy possibilites: [-1] 
expected returns: [[77.9554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 3.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 14.  0. 16.  3.] 
adversary cards in discard: [15.  3.  0.  8.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -16.830312728881836
desired expected reward: -0.1441326141357422






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 16.  3.] 
cards in discard: [15.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  3. 29.  8. 15.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.] 
cards in discard: [15.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.] 
cards in discard: [15.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.] 
cards in discard: [15.  3.  0.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.] 
adversary cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[2.9763522]
 [0.4520321]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [16. 29.  0.  3.  3.] 
adversary cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 9
Learning step: -3.585644483566284
desired expected reward: 14.031432151794434



action possibilites: [-1] 
expected returns: [[41.97159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [16. 29.  0.  3.  3.] 
adversary cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 15.0
Learning step: -0.8253927230834961
desired expected reward: -0.43032312393188477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.964626]
 [21.017178]
 [41.408405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 6.  0.  3. 10.  1.  0. 10.  6.  8.  3.  6.  0.  3. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [16. 29.  0.  3.  3.] 
adversary cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -3.05719256401062
desired expected reward: 38.91439437866211






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [16. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.  3.  3.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  3.  3.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  3.  3.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[70.95941]
 [63.5692 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 8.  3.  3. 22.  0.] 
adversary cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.3119163513183594
desired expected reward: 38.096466064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.595245]
 [62.216972]
 [49.21489 ]
 [62.907227]
 [68.703705]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 8.  3.  3. 22.  0.] 
adversary cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.801652431488037
desired expected reward: 64.5832290649414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 22.  0.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0. 0. 8.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0. 0. 8.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 21. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0. 0. 8.] 
cards in discard: [15.  3.  0.  8. 10. 14.  0.  0. 16.  3.  0. 16. 29.  0.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [6. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[58.649017]
 [54.50157 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [ 3.  6.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -5.443619728088379
desired expected reward: 63.26008605957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.4719  ]
 [38.18839 ]
 [59.417343]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [ 3.  6.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.914622783660889
desired expected reward: 51.96040725708008



buy possibilites: [-1] 
expected returns: [[38.469852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 3. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0  3] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: -6.408024787902832
desired expected reward: 44.06389236450195






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  3  8  0  0  3  3 16 15  0  0  3  8  0  6  0 22 10
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [6. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[44.719303]
 [38.373318]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 3.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1 10 10  6 29  8 15  3  6  6  8  0  3  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -4.247612953186035
desired expected reward: 34.22224044799805



action possibilites: [-1] 
expected returns: [[68.96376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.961290121078491
desired expected reward: 31.298200607299805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.461975]
 [45.868233]
 [68.128204]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  5.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -4.892680644989014
desired expected reward: 64.07108306884766



buy possibilites: [-1] 
expected returns: [[76.68316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -18.918041229248047
desired expected reward: 26.950183868408203






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1. 15. 10. 10. 29.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 1. 15. 10. 10. 29.] 
adversary cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 15. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 29.] 
expected returns: [[40.32912 ]
 [26.728899]
 [30.686205]
 [30.686205]
 [34.13296 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10. 10. 29.] 
cards in discard: [ 3.  6.  0.  0. 10.  0.  6.  6.  8.  3.  0.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 22.  0. 29.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -7.427084445953369
desired expected reward: 69.25607299804688



action possibilites: [-1. 15. 10. 29.  8.] 
expected returns: [[16.738684]
 [14.633238]
 [15.31909 ]
 [16.315367]
 [16.336418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 22.  0. 29.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -4.458953857421875
desired expected reward: 24.979570388793945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.774385]
 [14.533209]
 [ 9.186923]
 [15.338467]
 [15.739544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 22.  0. 29.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 0. 0.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.8645570278167725
desired expected reward: 12.874116897583008






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 22.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  0. 29.] 
cards in discard: [8. 0. 0. 3. 8. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0. 29.] 
cards in discard: [8. 0. 0. 3. 8. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  0. 29.] 
cards in discard: [8. 0. 0. 3. 8. 3. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [10.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.583334]
 [18.779535]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [10.  1. 15. 10. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14. 16. 16. 15.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.667136192321777
desired expected reward: 11.072402000427246



action possibilites: [-1.] 
expected returns: [[19.46685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [10.  1. 15. 10. 29.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14. 16. 16. 15.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -3.8130784034729004
desired expected reward: 14.208572387695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.28494 ]
 [18.29173 ]
 [11.204461]
 [18.745193]
 [20.240126]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [10.  1. 15. 10. 29.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14. 16. 16. 15.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.9163568019866943
desired expected reward: 15.550493240356445



buy possibilites: [-1] 
expected returns: [[46.09221]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [10.  1. 15. 10. 29.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [14. 16. 16. 15.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29.] 
adversary owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -97.0 

action type: buy - action 0.0
Learning step: -4.677172660827637
desired expected reward: 12.607768058776855






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [14. 16. 16. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 16. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16. 16. 15.  3.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  5.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16. 15.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16. 15.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16. 15.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 2.2267907 ]
 [-0.12758589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  8.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0. 16. 14.
 16. 15.] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -6.122972011566162
desired expected reward: 39.96923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.13307834]
 [ 4.7164774 ]
 [ 2.485439  ]
 [-6.3852386 ]
 [ 6.08364   ]
 [ 2.5559175 ]
 [ 0.8022704 ]
 [ 5.1417503 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 20. 30.  8.  4.  8. 10.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  8.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0. 16. 14.
 16. 15.] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.8899459838867188
desired expected reward: -1.6631619930267334



buy possibilites: [-1] 
expected returns: [[25.096258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [10.  1. 15. 10. 29.  8.  0. 10.  0.  0.  6.  3.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  4.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  8.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0. 16. 14.
 16. 15.] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 11.0
Learning step: -2.6895158290863037
desired expected reward: 3.394115686416626






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0. 16. 14.
 16. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  4.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  0.  0.  1.  0.  0. 22.  0. 29. 10.  0. 16. 14.
 16. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 20. 30.  8.  4.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11] -> size -> 21 
adversary victory points: -2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-7.6530867]
 [-8.204673 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  4.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.299747467041016
desired expected reward: 19.796510696411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.992895 ]
 [ -4.7655497]
 [-10.070118 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 20. 30.  8.  4.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.5916221141815186
desired expected reward: -11.900395393371582



buy possibilites: [-1] 
expected returns: [[10.825132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  6.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -388.0 

action type: buy - action 6.0
Learning step: -18.815908432006836
desired expected reward: -25.626462936401367






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 14  8  3  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3  1
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6. 10.  0. 10.  3.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[12.098038]
 [ 8.243497]
 [ 8.243497]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 10.  3.] 
cards in discard: [ 6.  6. 11.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 29.  0. 22.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -4.215335845947266
desired expected reward: 6.609796524047852



action possibilites: [-1. 10.] 
expected returns: [[ 2.9848948]
 [-2.5962105]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 29.  0. 22.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -57 

action type: take_action - action 10.0
Learning step: -3.2226035594940186
desired expected reward: 4.697279930114746



action possibilites: [-1.] 
expected returns: [[-9.309252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 29.  0. 22.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -1.9296478033065796
desired expected reward: -4.525854110717773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-8.266487 ]
 [-7.915371 ]
 [-8.163663 ]
 [-9.922285 ]
 [-7.681431 ]
 [-8.218017 ]
 [-8.418928 ]
 [-7.9911184]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  9.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 29.  0. 22.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -1.6174194812774658
desired expected reward: -10.926671028137207



buy possibilites: [-1] 
expected returns: [[21.210556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 29.  0. 22.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: -20 

action type: buy - action 11.0
Learning step: -0.1386909782886505
desired expected reward: -7.8201212882995605






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [10.  3. 29.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0. 22.] 
cards in discard: [0. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  0.  0.  8. 29.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  0. 22.] 
cards in discard: [0. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  0.  0.  8. 29.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  0. 22.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  0.  0.  8. 29.] 
adversary cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[13.250838]
 [12.430602]
 [10.314338]
 [10.445879]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 29.] 
cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -4.688114166259766
desired expected reward: 16.522441864013672



action possibilites: [-1.  8. 29.] 
expected returns: [[22.461594]
 [20.33147 ]
 [20.344006]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29.  3.] 
cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  1 10 10 29  8 15  3  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action 10.0
Learning step: -3.0383529663085938
desired expected reward: 9.392252922058105



action possibilites: [-1.] 
expected returns: [[4.826231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: trash_cards_n_from_hand - action 7
Learning step: -3.1839816570281982
desired expected reward: 13.667450904846191





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.318778 ]
 [-4.6122355]
 [ 4.538917 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  6. 11.  0.  6.  6. 11. 10. 10.  6.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -2.6676571369171143
desired expected reward: 2.158573865890503






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
adversary victory points: -4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  8. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[ 3.583045 ]
 [ 0.7346561]
 [ 2.3060765]
 [-0.5734463]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 15.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -4.654491424560547
desired expected reward: -0.115570068359375



action possibilites: [-1.  8. 15.] 
expected returns: [[ 2.159472 ]
 [-3.8403425]
 [-4.8475533]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  1.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 10  1 10 10  8 15  6  6  8  0  3  6  0  6  0 11  6 11] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 10.0
Learning step: -3.446584701538086
desired expected reward: -3.903203248977661



action possibilites: [-1. 15.] 
expected returns: [[28.874275]
 [22.890438]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.236393690109253
desired expected reward: -2.4536614418029785



action possibilites: [-1] 
expected returns: [[-6.520133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action 15.0
Learning step: -2.09661865234375
desired expected reward: 20.7938232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-10.190387 ]
 [ -7.2946715]
 [ -9.1149235]
 [-17.35611  ]
 [ -6.510433 ]
 [ -8.025116 ]
 [ -9.586141 ]
 [ -7.9644876]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -0.7674522995948792
desired expected reward: -7.287585258483887



buy possibilites: [-1] 
expected returns: [[2.9527164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8. 15.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 15.  0.  8. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
adversary owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.  60. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -48.0 

action type: buy - action 0.0
Learning step: -1.8240444660186768
desired expected reward: -12.014433860778809






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10. 15.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  3.  8.] 
adversary cards in discard: [ 0. 10.  8. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-7.463993]
 [-8.20476 ]
 [-9.585334]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  3.  8.] 
cards in discard: [ 0. 10.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [16.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0. 15. 10.  8. 14.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -4.260369300842285
desired expected reward: -1.3076529502868652



action possibilites: [-1.  8. 11.] 
expected returns: [[6.1178093]
 [4.428514 ]
 [5.875248 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  8. 11.] 
cards in discard: [ 0. 10.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [16.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0. 15. 10.  8. 14.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action 10.0
Learning step: -2.2997989654541016
desired expected reward: -11.752812385559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.3554535]
 [3.7061553]
 [7.7828264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  8. 11.] 
cards in discard: [ 0. 10.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [16.  3. 16.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0. 15. 10.  8. 14.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -3.064781904220581
desired expected reward: 3.05302357673645






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [16.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16.  0.  0.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0. 15. 10.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 16.  0.  0.] 
cards in discard: [ 0.  8.  0.  0. 10.  3. 29.  0. 22.  0.  3.  3.  0.  0. 15. 10.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6.  0. 10.  6.] 
adversary cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[11.257804]
 [10.992468]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  6.] 
cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.021914482116699
desired expected reward: 3.760909080505371



action possibilites: [-1. 11.] 
expected returns: [[7.695548 ]
 [6.9947357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  6. 11.] 
cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action 10.0
Learning step: -3.303284168243408
desired expected reward: 8.115470886230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 2.578639 ]
 [ 4.017898 ]
 [-0.6918199]
 [ 3.7131605]
 [ 7.3030834]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  6. 11.] 
cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 20. 30.  8.  3.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -3.1819257736206055
desired expected reward: 4.513622283935547



buy possibilites: [-1] 
expected returns: [[-10.978394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  6. 11.] 
cards in discard: [ 0. 10.  8. 15. 10.  0.  6.  3.  8. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 20. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 14. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -369.0 

action type: buy - action 6.0
Learning step: -18.66242218017578
desired expected reward: -19.354244232177734






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14. 10.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1.  8. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 20. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 19. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-1.3299998]
 [-4.4859524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 19. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 15. 29. 22. 16.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.466973781585693
desired expected reward: -15.445367813110352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-2.979225  ]
 [-1.8269455 ]
 [-5.088101  ]
 [-1.8608208 ]
 [-0.40780902]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 19. 30.  8.  2.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 15. 29. 22. 16.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -4.88541316986084
desired expected reward: -6.995834827423096



buy possibilites: [-1] 
expected returns: [[-10.126438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 15. 29. 22. 16.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -20.473440170288086
desired expected reward: -25.561542510986328






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3. 15. 29. 22. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 22. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29. 22. 16.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 10. 11. 15.] 
adversary cards in discard: [ 6.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29. 22. 16.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 10. 11. 15.] 
adversary cards in discard: [ 6.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29. 22. 16.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 10. 11. 15.] 
adversary cards in discard: [ 6.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[8.243359 ]
 [3.262745 ]
 [7.3149014]
 [2.072527 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 15.] 
cards in discard: [ 6.  6.  0. 10.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -4.880929470062256
desired expected reward: -15.007368087768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 2.5241094]
 [ 4.436255 ]
 [-1.3306404]
 [ 4.3402014]
 [ 8.697101 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11. 15.] 
cards in discard: [ 6.  6.  0. 10.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16.  0.  3.  3.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.7330732345581055
desired expected reward: 1.2849750518798828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  3.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  6. 10.  0. 11.] 
adversary cards in discard: [ 6.  6.  0. 10.  6.  0.  0.  0. 10. 11. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  3.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  6. 10.  0. 11.] 
adversary cards in discard: [ 6.  6.  0. 10.  6.  0.  0.  0. 10. 11. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
adversary victory points: -5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  6. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-3.4271832]
 [-5.3202686]
 [-4.1796803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  0. 11.] 
cards in discard: [ 6.  6.  0. 10.  6.  0.  0.  0. 10. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -6.022225379943848
desired expected reward: 2.674868583679199





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.3984804]
 [-7.7757006]
 [-3.1848316]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0. 11.] 
cards in discard: [ 6.  6.  0. 10.  6.  0.  0.  0. 10. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 19. 30.  8.  1.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.44960355758667
desired expected reward: -8.706798553466797



buy possibilites: [-1] 
expected returns: [[-13.289635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0. 11.] 
cards in discard: [ 6.  6.  0. 10.  6.  0.  0.  0. 10. 11. 15.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -421.0 

action type: buy - action 6.0
Learning step: -20.81251335144043
desired expected reward: -31.5426025390625






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.  0. 16.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  6.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6  6] -> size -> 21 
adversary victory points: -6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 3. 10.  0.  8. 14.  8.  0.  0.  3. 15. 29. 22. 16.  0. 16.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  6.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6  6] -> size -> 21 
adversary victory points: -6
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  6.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[-14.867651]
 [-14.60111 ]
 [-14.362812]
 [-14.362812]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  8.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  6  8  0  3  6  0  6  0 11  6 11  0  6  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -121 

action type: buy - action -1
Learning step: -5.708343029022217
desired expected reward: -18.99797821044922



action possibilites: [-1] 
expected returns: [[-14.196762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: trash_cards_n_from_hand - action 6
Learning step: -4.335028171539307
desired expected reward: -14.023008346557617





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.908882]
 [-14.55966 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.064242839813232
desired expected reward: -18.261005401611328






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  6.  0.] 
adversary cards in discard: [8. 6. 8.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  6.  0.] 
adversary cards in discard: [8. 6. 8.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  6.  0.] 
adversary cards in discard: [8. 6. 8.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  3. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  6.  0.] 
adversary cards in discard: [8. 6. 8.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  6.  0.] 
adversary cards in discard: [8. 6. 8.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-13.642767]
 [-11.40728 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  0.] 
cards in discard: [8. 6. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 22. 10. 16.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -5.046212673187256
desired expected reward: -19.60587501525879



action possibilites: [-1.] 
expected returns: [[-14.98612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [8. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 22. 10. 16.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action 10.0
Learning step: -4.266823768615723
desired expected reward: -15.674103736877441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-17.308609]
 [-14.717779]
 [-16.723188]
 [-16.70505 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [8. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 22. 10. 16.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1.0
Learning step: -4.107659816741943
desired expected reward: -19.093780517578125



buy possibilites: [-1] 
expected returns: [[-9.483457]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [8. 6. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0. 22. 10. 16.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -120.0 

action type: buy - action 0.0
Learning step: -5.347947120666504
desired expected reward: -22.65656280517578






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 22. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22. 10. 16.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 22 10  0  3 10  0  0  0
  3  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  6. 10.  3.  0.] 
adversary cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6. 10.  3.  0.] 
adversary cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6. 10.  3.  0.] 
adversary cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [10.  6. 10.  3.  0.] 
adversary cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [10.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-8.890291]
 [-8.722235]
 [-8.722235]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  3.  0.] 
cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.2252373695373535
desired expected reward: -14.708694458007812



action possibilites: [-1. 10.] 
expected returns: [[-14.289219]
 [-11.568403]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  0.] 
cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -89 

action type: take_action - action 10.0
Learning step: -4.291003704071045
desired expected reward: -13.103471755981445



action possibilites: [-1.] 
expected returns: [[-20.385271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   40    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -69 

action type: take_action - action 10.0
Learning step: -3.330249071121216
desired expected reward: -14.898642539978027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-18.691141]
 [-21.008575]
 [-18.892979]
 [-20.9836  ]
 [-20.564102]
 [-18.616816]
 [-19.979094]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -2.918478488922119
desired expected reward: -23.303749084472656



buy possibilites: [-1] 
expected returns: [[-13.309769]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 8.  6.  8.  0. 10.  0.  6.  6.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [15.  3.  3.  0.  0.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
adversary owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   40.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -4.364913463592529
desired expected reward: -23.056049346923828






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.  0.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  0  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3
  0  8 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  6.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  6.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  8.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  6.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [ 6.  6.  6. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 6.  6.  6. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[8.542118 ]
 [8.800774 ]
 [3.1111288]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 11. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  4.  9.  6.] 
adversary cards in hand: [ 8.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
adversary owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -4.659738063812256
desired expected reward: -17.969507217407227



action possibilites: [-1] 
expected returns: [[-12.062281]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 15.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
adversary owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -81 

action type: gain_card_n - action 8
Learning step: -4.495587348937988
desired expected reward: -1.0118670463562012





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.937502]
 [-12.287806]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 15.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
adversary owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.186299800872803
desired expected reward: -16.248580932617188



buy possibilites: [-1] 
expected returns: [[-12.516798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 15.] 
cards in discard: [10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  0. 14.  8.] 
adversary cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
adversary owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: buy - action 0.0
Learning step: -5.584752559661865
desired expected reward: -19.52226448059082






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14.  8.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  8  8  3  3 16 15  0  0  3  8  0  0 10  0  3 10  0  0  0  3  0
  8 15  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8. 10. 29.  0.  0.  3.  0. 15.  0. 16.  0.  0. 10. 11. 15.  3.  3.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8. 10.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[-14.608868]
 [-12.027555]
 [-13.383722]
 [-12.027555]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 10.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.158660411834717
desired expected reward: -17.675458908081055



action possibilites: [-1.  8. 10.] 
expected returns: [[-31.416288]
 [-28.434647]
 [-27.91798 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -89 

action type: take_action - action 10.0
Learning step: -4.502590179443359
desired expected reward: -16.433712005615234



action possibilites: [-1.  8.] 
expected returns: [[-12.324417]
 [-10.651913]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 6.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  6  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -70 

action type: take_action - action 10.0
Learning step: -2.3568849563598633
desired expected reward: -30.274879455566406



action possibilites: [-1.] 
expected returns: [[-16.153425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.7363871335983276
desired expected reward: -13.277688980102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-17.890448]
 [-17.529554]
 [-16.641748]
 [-16.777645]
 [-18.203884]
 [-17.20563 ]
 [-16.474293]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  7.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -1.5251072645187378
desired expected reward: -17.678531646728516



buy possibilites: [-1] 
expected returns: [[-13.372911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  60   0   0   0   0   0   0   0  18   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: -0.5120083093643188
desired expected reward: -17.28965187072754






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
adversary victory points: -4
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.44721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -5.016417026519775
desired expected reward: -18.389328002929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-11.093819]
 [-12.055595]
 [-10.77496 ]
 [-11.48465 ]
 [-12.045376]
 [-10.597847]
 [-10.350695]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  2. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.173858165740967
desired expected reward: -15.621068954467773



buy possibilites: [-1] 
expected returns: [[-10.87237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  0. 11.  6.  6.  6. 15. 11. 10. 10.  8.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  1. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -107.0 

action type: buy - action 8.0
Learning step: -4.992359638214111
desired expected reward: -17.03773307800293






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  1. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  1. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  1. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  8.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
adversary victory points: -4
player victory points: 6 





Player: 0 
cards in hand: [ 0.  8.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-17.076103]
 [-16.005625]
 [-14.207365]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10 10 10  8 15  8  0  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 10.  8. 15.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -5.2523627281188965
desired expected reward: -16.124732971191406



action possibilites: [-1] 
expected returns: [[-23.683317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 10.  8. 15.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: trash_cards_n_from_hand - action 6
Learning step: -4.425528049468994
desired expected reward: -14.342262268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-27.340918]
 [-24.867104]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 10.  8. 15.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action -1
Learning step: -3.844744920730591
desired expected reward: -27.52806282043457






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 15.  3.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 8. 10.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8. 15.  3.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 8. 10.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
adversary victory points: -4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ -9.968953]
 [-13.389238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 8. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15. 29.  3.  0. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1.0
Learning step: -4.529063701629639
desired expected reward: -29.396167755126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.587286]
 [-12.633287]
 [-11.042125]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 8. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15. 29.  3.  0. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1.0
Learning step: -5.053863048553467
desired expected reward: -18.378076553344727



buy possibilites: [-1] 
expected returns: [[-3.9122574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 8. 10.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15. 29.  3.  0. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
adversary owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -139.0 

action type: buy - action 0.0
Learning step: -6.35866117477417
desired expected reward: -19.94595718383789






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [15. 29.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  0. 16.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  0  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0
 11  0  3  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15.  6.  3.  8.  6.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 16.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15.  6.  3.  8.  6.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 16.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  3.  9.  6.] 
adversary cards in hand: [15.  6.  3.  8.  6.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 16.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15.  6.  3.  8.  6.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
adversary victory points: -4
player victory points: 6 





Player: 0 
cards in hand: [15.  6.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-33.63327 ]
 [-29.193478]
 [-31.272724]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  8.  6.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: buy - action -1
Learning step: -5.945324420928955
desired expected reward: -9.857582092285156



action possibilites: [-1] 
expected returns: [[-37.00843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action 15.0
Learning step: -3.8230156898498535
desired expected reward: -33.01649475097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-32.34928 ]
 [-36.724873]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -89 

action type: take_action - action -1
Learning step: -3.36175274848938
desired expected reward: -40.370182037353516



buy possibilites: [-1] 
expected returns: [[-20.316935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 6.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
adversary owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -100    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action 0.0
Learning step: -4.789667129516602
desired expected reward: -37.138946533203125






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3 16 15  3  8  0  0 10  0  3 10  0  0  0  3  0  8 15  0 11
  0  3  8 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3.  3. 16.  8. 10. 11.  0.  0.  0.  0.  8. 10.  8. 15.  3.
 10. 15. 29.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-17.953552]
 [-17.836157]
 [-17.836157]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.336080551147461
desired expected reward: -24.65301513671875



action possibilites: [-1. 10.  8.] 
expected returns: [[-11.828669]
 [ -9.143948]
 [-10.758355]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 10  8 15  8  3  0  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action 10.0
Learning step: -3.2864081859588623
desired expected reward: -21.122568130493164



action possibilites: [-1. 10.] 
expected returns: [[-16.636091]
 [-13.732647]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.8283472061157227
desired expected reward: -11.89649772644043



action possibilites: [-1. 11.] 
expected returns: [[-11.676234]
 [-12.768649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action 10.0
Learning step: -1.534650206565857
desired expected reward: -15.267298698425293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-10.953991]
 [-11.127121]
 [-12.479342]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -1.6215327978134155
desired expected reward: -13.297773361206055



buy possibilites: [-1] 
expected returns: [[-12.433399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8. 10.  6.  0.  0.  0. 11.  6.  6.  0. 15.  6.  3.  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [15. 16.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -90.   0.   0.  60. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -69.0 

action type: buy - action 0.0
Learning step: -3.1820521354675293
desired expected reward: -14.136041641235352






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [15. 16.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3 16 15  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-17.455217]
 [-16.905834]
 [-15.506128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.686330318450928
desired expected reward: -17.11972999572754



action possibilites: [-1.  8.] 
expected returns: [[-16.066013]
 [-13.784739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action 10.0
Learning step: -3.4611403942108154
desired expected reward: -19.79928207397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ -9.915575]
 [-10.592531]
 [-16.052647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1.0
Learning step: -3.405426025390625
desired expected reward: -19.471439361572266






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 11.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  3 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10. 10.  6.  6.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10. 10.  6.  6.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [11. 10. 10.  6.  6.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-13.412973]
 [-12.634445]
 [-10.894828]
 [-10.894828]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  6.  6.] 
cards in discard: [10.  6.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16. 10.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -3.9121429920196533
desired expected reward: -19.96478843688965



action possibilites: [-1] 
expected returns: [[-17.892681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.  6.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16. 10.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: gain_card_n - action 0
Learning step: -4.806560516357422
desired expected reward: -15.727052688598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.8070755]
 [-18.568329 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.  6.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16. 10.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -2.903365135192871
desired expected reward: -20.79604721069336



buy possibilites: [-1] 
expected returns: [[-19.83168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.  6.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 16. 10.  3.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action 0.0
Learning step: -4.7058587074279785
desired expected reward: -18.512939453125






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  3.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 18. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 17. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-13.190706]
 [-11.813568]
 [-12.879841]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  6  0  6 11  0  6  6  6  0  0 10  0 11  8  0  0  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 17. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.236996173858643
desired expected reward: -24.068675994873047



action possibilites: [-1] 
expected returns: [[-13.222696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 17. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.6267402172088623
desired expected reward: -16.04214096069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-13.541641]
 [-13.882854]
 [-13.336313]
 [-13.65036 ]
 [-13.341774]
 [-13.34079 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 17. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -3.5917446613311768
desired expected reward: -16.814441680908203



buy possibilites: [-1] 
expected returns: [[-12.9768505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3. 15.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -66.0 

action type: buy - action 3.0
Learning step: -2.925163745880127
desired expected reward: -16.261476516723633






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [10.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.  8.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10. 15.  0.  6.  0.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.  8.  0.] 
cards in discard: [ 0.  8.  3.  0.  8.  0.  3. 11.  3. 10.  3. 10. 29.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10. 15.  0.  6.  0.] 
adversary cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.] 
adversary owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 15.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-18.39242 ]
 [-17.304813]
 [-17.138918]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  6.  0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  6  0  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -4.144204139709473
desired expected reward: -17.121055603027344



action possibilites: [-1] 
expected returns: [[-10.241543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action 15.0
Learning step: -2.773488998413086
desired expected reward: -19.912403106689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-10.460536]
 [ -8.880323]
 [-10.34246 ]
 [ -9.862502]
 [ -8.838921]
 [ -9.193756]
 [-13.174559]
 [-10.430819]
 [-11.278702]
 [-10.225792]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  6.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1
Learning step: -3.109226942062378
desired expected reward: -13.350769996643066



buy possibilites: [-1] 
expected returns: [[24.082973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [10.  6.  0.  8.  0.  6.  0.  0. 11. 10. 10.  6.  6.  3.  8.  0.  0.  0.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  5.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.    0.   -3.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -63.5 

action type: buy - action 11.0
Learning step: -2.1325840950012207
desired expected reward: -10.971515655517578






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  5.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3 11] -> size -> 26 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  5.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3 11] -> size -> 26 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3 11] -> size -> 26 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [0. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-18.252949]
 [-17.0442  ]
 [-17.0442  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  3  6  6  0  6  6  6  0  0 10  0 11  8  0  0  0  0  0
  3 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -5.989149570465088
desired expected reward: 18.09382438659668



action possibilites: [-1] 
expected returns: [[-20.642353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.4711196422576904
desired expected reward: -22.337783813476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.206707]
 [-21.627522]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -3.339703321456909
desired expected reward: -23.9820556640625






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 11.  0.] 
cards in discard: [11. 10.  0.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6. 10.  0. 11.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 11.  0.] 
cards in discard: [11. 10.  0.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6. 10.  0. 11.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 11.  0.] 
cards in discard: [11. 10.  0.  0.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 6. 10.  0. 11.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [ 6. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-12.090877]
 [-12.064506]
 [-13.06141 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 11.  0.] 
cards in discard: [8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.  0.  3.  3. 29. 11.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11  0] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1.0
Learning step: -4.1583251953125
desired expected reward: -25.785846710205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-12.983866 ]
 [-13.3998575]
 [-13.071879 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 11.  0.] 
cards in discard: [8. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.  0.  3.  3. 29. 11.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11  0] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -4.605580806732178
desired expected reward: -17.3893985748291



Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 10.  0. 11.  0.] 
cards in discard: [8. 8. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 10 10  8 15  8  6  6  6  6  6  0 10  0 11  8  0  0  0  0  0  3 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 16. 30.  8.  0.  8.  4.  0. 10.  8.  9. 10.  2.  9.  6.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  0.  0.  8.  0.  0.  3.  3. 29. 11.  0.] 
adversary owned cards: [29  8 16  3  8 10  0  3 10  0  0  0  3  0  8 15  0 11  0  3  8 10  0  0
  3 11  0] -> size -> 27 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4  -90    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -629 

action type: buy - action 0.0
Learning step: -30.800806045532227
desired expected reward: -43.78467559814453



