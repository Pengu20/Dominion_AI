 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.81376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0     -230        0     -300        0        0] 
sum of rewards: -3000635 

action type: buy - action 6.0
Learning step: -120026.9453125
desired expected reward: -119988.0859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[110.48727 ]
 [112.87213 ]
 [111.6978  ]
 [107.69874 ]
 [115.38706 ]
 [114.134315]
 [112.94343 ]
 [113.5679  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.49793243408203



buy possibilites: [-1] 
expected returns: [[114.319244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.38706970214844






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[115.778404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.31924438476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[112.98173 ]
 [115.398544]
 [114.21537 ]
 [110.12657 ]
 [116.256966]
 [117.88249 ]
 [116.65039 ]
 [120.63405 ]
 [113.74826 ]
 [115.467445]
 [116.16415 ]
 [116.107574]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.13455963134766



buy possibilites: [-1] 
expected returns: [[108.7023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.6340560913086






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[103.45541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.70230102539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.183846]
 [102.55826 ]
 [101.39491 ]
 [ 97.33256 ]
 [103.4088  ]
 [105.060425]
 [103.80766 ]
 [107.84374 ]
 [100.935   ]
 [102.627266]
 [103.31053 ]
 [103.25021 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.50672149658203



buy possibilites: [-1] 
expected returns: [[134.89386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.84375762939453






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[132.80052]
 [137.44772]
 [134.61737]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.89385986328125



action possibilites: [-1. 11.] 
expected returns: [[133.47821]
 [135.29333]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.56918334960938



action possibilites: [-1] 
expected returns: [[141.23112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.32705688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[137.47316]
 [139.92905]
 [138.7269 ]
 [134.52289]
 [140.80191]
 [142.47574]
 [141.20247]
 [145.38791]
 [138.25221]
 [140.0003 ]
 [140.70808]
 [140.65063]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.2311248779297



buy possibilites: [-1] 
expected returns: [[138.08966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 145.38790893554688






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.04282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.08966064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[112.4039  ]
 [114.60948 ]
 [113.52721 ]
 [109.95767 ]
 [116.87968 ]
 [115.75597 ]
 [114.673706]
 [115.23881 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.14118957519531



buy possibilites: [-1] 
expected returns: [[123.194916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 116.87968444824219






Player: 1 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11.  0. 29.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[155.87097]
 [160.37033]
 [157.62827]
 [160.37033]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.19491577148438



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[127.36414]
 [128.90826]
 [131.36337]
 [131.36337]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 29.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 160.97683715820312



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[144.04253]
 [145.65466]
 [148.12628]
 [143.47388]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 10.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.36337280273438



action possibilites: [-1. 11. 10.] 
expected returns: [[146.80081]
 [148.66031]
 [146.12166]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.12628173828125



action possibilites: [-1] 
expected returns: [[147.56836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 149.94320678710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[146.24182]
 [148.52913]
 [145.12074]
 [147.40804]
 [144.61469]
 [143.49358]
 [149.34201]
 [150.88124]
 [149.71506]
 [155.09709]
 [153.47212]
 [146.96678]
 [148.88107]
 [148.59393]
 [146.59378]
 [149.25409]
 [149.20126]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.568359375



buy possibilites: [-1] 
expected returns: [[150.50746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 10. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 155.09707641601562






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  3.  3. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[135.48273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.50746154785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[133.82518]
 [134.8973 ]
 [131.2884 ]
 [137.02524]
 [136.53   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 136.34814453125



buy possibilites: [-1] 
expected returns: [[134.35042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 137.02523803710938






Player: 1 
cards in hand: [ 0.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[129.81567]
 [134.28659]
 [131.55574]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 11.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.3504180908203



action possibilites: [-1. 11. 25.] 
expected returns: [[135.9513 ]
 [137.77936]
 [142.35085]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 25.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 134.2341766357422



action possibilites: [-1] 
expected returns: [[137.62271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29. 29.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.35086059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[134.4087 ]
 [137.05928]
 [135.75926]
 [131.22751]
 [138.00635]
 [139.786  ]
 [138.43697]
 [142.78786]
 [135.24484]
 [137.13724]
 [137.89543]
 [137.8164 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29. 29.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.62271118164062



buy possibilites: [-1] 
expected returns: [[159.27075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 29. 29.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 142.787841796875






Player: 1 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  3. 14.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  3. 14.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[161.88892]
 [161.35019]
 [163.46399]
 [161.35019]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.270751953125



action possibilites: [-1] 
expected returns: [[148.67769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 162.95806884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.0652 ]
 [148.1645 ]
 [144.46559]
 [150.34595]
 [149.83923]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  8.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.6776885986328



buy possibilites: [-1] 
expected returns: [[134.89517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 29. 29. 25.  0.  0.  0. 11. 29. 29. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 150.345947265625






Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[138.66742]
 [138.1642 ]
 [142.46466]
 [143.9071 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.89517211914062



action possibilites: [-1] 
expected returns: [[115.00082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.91268920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.83329]
 [112.32096]
 [117.50342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.00081634521484






Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  8  0  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[151.34969]
 [150.81578]
 [152.85503]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.50343322753906



action possibilites: [-1] 
expected returns: [[116.592964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 152.4402313232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.70309 ]
 [112.003944]
 [117.56868 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.59296417236328






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  8.  8. 29.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  8.  8. 29.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3. 10.  0.  6.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  8.  8. 29.] 
adversary cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 29.] 
expected returns: [[149.29555]
 [153.69975]
 [149.85384]
 [149.85384]
 [153.69975]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  8. 29.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.56867980957031



action possibilites: [-1.  8.  8. 29. 11.] 
expected returns: [[144.20447]
 [144.7126 ]
 [144.7126 ]
 [148.20078]
 [145.7914 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 29. 11.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 153.39212036132812



action possibilites: [-1.  8.  8. 11.] 
expected returns: [[158.0162 ]
 [158.51875]
 [158.51875]
 [159.61494]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11.  0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.20079040527344



action possibilites: [-1] 
expected returns: [[153.92894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.67996215820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[151.55968]
 [153.82803]
 [152.71402]
 [148.82922]
 [154.63676]
 [156.1606 ]
 [155.00626]
 [158.7348 ]
 [152.2758 ]
 [153.89223]
 [154.54416]
 [154.48108]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.92893981933594



buy possibilites: [-1] 
expected returns: [[155.85524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [25. 10.  0.  3. 29. 29. 10. 10. 11. 10.  3.  3.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 158.7347869873047






Player: 1 
cards in hand: [ 3.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[144.9019 ]
 [148.86343]
 [146.47162]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 155.85523986816406



action possibilites: [-1. 11.  8.] 
expected returns: [[143.20985]
 [144.73618]
 [143.68918]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.3110809326172



action possibilites: [-1] 
expected returns: [[142.3469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 145.78250122070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.76215]
 [141.86751]
 [140.83426]
 [137.22539]
 [142.62079]
 [144.03432]
 [142.9622 ]
 [146.42268]
 [140.42545]
 [141.92897]
 [142.5308 ]
 [142.46695]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.34689331054688



buy possibilites: [-1] 
expected returns: [[144.09938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 146.42269897460938






Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [ 3.  6.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 14  3  8  0  0  6  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  6.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  6.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  6.  0.  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[136.47717]
 [140.61078]
 [135.9231 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.09938049316406



action possibilites: [-1. 10. 10.] 
expected returns: [[152.46352]
 [151.80476]
 [151.80476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 139.79457092285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[149.92392]
 [152.46323]
 [151.21747]
 [146.86792]
 [153.36871]
 [155.07547]
 [153.78192]
 [157.9558 ]
 [150.72594]
 [152.53615]
 [153.26526]
 [153.19492]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  4.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 152.46353149414062



buy possibilites: [-1] 
expected returns: [[159.03696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 157.95579528808594






Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  6.  0.  0. 14.  0.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 10.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[169.26929]
 [169.76733]
 [173.28351]
 [168.71783]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.03695678710938



action possibilites: [-1.  8. 10. 29.] 
expected returns: [[161.51494]
 [162.01515]
 [160.96146]
 [165.54042]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 173.1761474609375



action possibilites: [-1.  8. 10. 25.] 
expected returns: [[171.84113]
 [172.32219]
 [171.33812]
 [177.04886]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3. 25.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 165.5404052734375



action possibilites: [-1] 
expected returns: [[163.21916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  7. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.04885864257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[160.47408]
 [162.72966]
 [161.62494]
 [157.76541]
 [165.04938]
 [163.8985 ]
 [162.79378]
 [163.39653]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  3.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  7. 10.  8.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.2191619873047



buy possibilites: [-1] 
expected returns: [[172.15308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  3.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  8. 29. 29.  0.  0.  0. 10. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 165.0493621826172






Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29. 10. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 29. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 10.] 
expected returns: [[144.23549]
 [148.1218 ]
 [148.1218 ]
 [143.6996 ]
 [143.6996 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [6. 0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 172.153076171875



action possibilites: [-1. 29. 10. 10. 25.] 
expected returns: [[144.28894]
 [148.27963]
 [143.73679]
 [143.73679]
 [149.79718]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  3. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  7. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [6. 0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 146.56204223632812



action possibilites: [-1] 
expected returns: [[132.83675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  6. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [6. 0. 3. 3. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 149.79718017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[131.50098]
 [129.02238]
 [134.16628]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  6. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [6. 0. 3. 3. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.8367462158203






Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [6. 0. 3. 3. 3. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  8.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [6. 0. 3. 3. 3. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  8.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [6. 0. 3. 3. 3. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 28. 30.  8.  6. 10.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  8.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6.  0.  3.  3.  3.  0.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  8.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[128.98204]
 [133.27217]
 [128.39714]
 [129.51892]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  8.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.16629028320312



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[122.81725 ]
 [122.325966]
 [123.306114]
 [126.5812  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8. 29.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 132.90597534179688



action possibilites: [-1. 10.  8.] 
expected returns: [[145.43044]
 [144.9325 ]
 [145.90955]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.  0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 29 11 10 25  8 29 10  8 10 10
 29 10 29 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.58119201660156



action possibilites: [-1] 
expected returns: [[116.90842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 147.42523193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[116.20951 ]
 [117.88019 ]
 [117.05958 ]
 [114.192696]
 [119.66018 ]
 [118.76566 ]
 [117.930176]
 [118.34762 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  7.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.90841674804688



buy possibilites: [-1] 
expected returns: [[135.09436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 119.66017150878906






Player: 1 
cards in hand: [ 0.  6.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0. 11.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  3.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[164.51529]
 [166.13182]
 [166.13182]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 797   0] 
sum of rewards: 822 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 218.71377563476562



action possibilites: [-1] 
expected returns: [[127.41347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 167.18702697753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.59444]
 [122.123  ]
 [127.20502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.41346740722656






Player: 1 
cards in hand: [ 3. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [29. 14.  0.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [29. 14.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [29. 14.  0.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [29. 14.  0.  6.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 10.] 
adversary cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[123.95447]
 [124.4023 ]
 [123.50717]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 10.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 29 29 29 11 10 25  8 29 10  8 10 10 29 10 29
 29 11 11 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  0.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 127.20501708984375



action possibilites: [-1] 
expected returns: [[123.75128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  0.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 127.08016967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.62457]
 [119.31959]
 [124.10108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 25. 29. 10. 10.  3. 29. 29. 11. 29. 29.  8.  0.  0. 10. 10. 11.  0.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  6.  3. 16.  0.] 
adversary cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.75128173828125






Player: 1 
cards in hand: [ 0.  6.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 16.  0.] 
cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 16.  0.] 
cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 16.  0.] 
cards in discard: [29. 14.  0.  6.  0.  3.  0. 10.  3.  0.  0.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 29.] 
expected returns: [[131.9429 ]
 [132.4655 ]
 [131.32872]
 [133.6489 ]
 [136.27927]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.10106658935547



action possibilites: [-1.  8. 10. 11. 25.] 
expected returns: [[139.47083]
 [139.99406]
 [138.88712]
 [141.14502]
 [145.31595]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 28. 30.  8.  6.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 134.50848388671875



action possibilites: [-1] 
expected returns: [[144.49341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.3159637451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[141.18607]
 [142.3101 ]
 [138.54262]
 [144.54034]
 [144.0228 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  7.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.493408203125



buy possibilites: [-1] 
expected returns: [[113.03371]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 11.  0. 29. 10.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 144.54034423828125






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 10.] 
expected returns: [[102.7094  ]
 [106.514656]
 [106.514656]
 [104.22242 ]
 [102.21893 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 10.  0.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.03370666503906



action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[104.62225]
 [108.52202]
 [106.18178]
 [104.12017]
 [108.52202]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0. 29.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.56304931640625



action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[ 97.95674]
 [ 99.62721]
 [ 97.37238]
 [102.18659]
 [ 99.62721]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.52201843261719



action possibilites: [-1. 11. 10. 11.  8.] 
expected returns: [[95.093796]
 [96.73472 ]
 [94.517555]
 [96.73472 ]
 [95.60582 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  8.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.18659973144531



action possibilites: [-1] 
expected returns: [[148.18193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  8.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.82299041748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[146.02188]
 [148.12558]
 [147.09143]
 [143.48564]
 [148.8786 ]
 [150.28949]
 [149.21994]
 [152.67825]
 [146.68369]
 [148.18579]
 [148.78738]
 [148.72005]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  8.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  2.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.1819305419922



buy possibilites: [-1] 
expected returns: [[155.20564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  8.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [6. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 152.67825317382812






Player: 1 
cards in hand: [ 0.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [6. 0. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  6.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [29. 29. 10. 11.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0. 8. 0. 0. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [29. 29. 10. 11.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0. 8. 0. 0. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [29. 29. 10. 11.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0. 8. 0. 0. 0. 8. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [29. 29. 10. 11.  0.] 
adversary cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 29. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 11.] 
expected returns: [[144.82422]
 [148.61496]
 [148.61496]
 [144.31918]
 [146.33136]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10. 11.  0.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 155.2056427001953



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[145.45857]
 [149.38928]
 [144.9258 ]
 [147.0165 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0.  0.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.61495971679688



action possibilites: [-1. 10. 11.] 
expected returns: [[140.14955]
 [139.58725]
 [141.78096]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  3.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 149.3892822265625



action possibilites: [-1] 
expected returns: [[171.34305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.8573760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[167.62245]
 [169.8269 ]
 [168.74542]
 [164.96707]
 [170.61406]
 [172.09276]
 [170.9711 ]
 [174.59195]
 [168.31778]
 [170.52138]
 [170.45732]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  1.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.34304809570312



buy possibilites: [-1] 
expected returns: [[184.92294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [ 8. 29. 25.  8. 10. 11.  0. 29. 10. 10. 29. 29. 29. 29. 11. 10.  0. 11.
  8. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 10. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 174.59194946289062






Player: 1 
cards in hand: [ 0.  6.  6. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10. 14.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 14.  6.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29. 29.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [29. 29. 29.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[154.55983]
 [158.63313]
 [158.63313]
 [158.63313]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.] 
cards in discard: [10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 915   0] 
sum of rewards: 970 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 220.74154663085938



action possibilites: [-1. 11.] 
expected returns: [[117.9955 ]
 [119.61156]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [10.  0. 29. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 152.99725341796875



action possibilites: [-1] 
expected returns: [[137.10239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  0. 29. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 159 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 118.55424499511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.34726]
 [131.86887]
 [137.16153]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0. 29. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.10238647460938






Player: 1 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  5.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6.  0.  8.  0.  0.  0.  8.  0. 16.  0.  3.  0. 10. 14.  0.  6.  6.  6.
  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  4.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 25. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10. 29.] 
expected returns: [[126.54529 ]
 [130.79079 ]
 [132.40433 ]
 [125.962944]
 [130.79079 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 10. 29.  0.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  5.  9.  6.  4.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8] -> size -> 25 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.16152954101562



action possibilites: [-1] 
expected returns: [[131.43585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  0. 11.  0.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  4.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8  6] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.40432739257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[129.27982 ]
 [130.4569  ]
 [126.496025]
 [132.79726 ]
 [132.25099 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 29.  0. 11.  0.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  4.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8  6] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.43585205078125



buy possibilites: [-1] 
expected returns: [[153.35368]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 29.  0. 11.  0.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8  6] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 132.79725646972656






Player: 1 
cards in hand: [ 0.  8. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0. 29.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 14  3  8  0  0  6  0  0  0  3  6  0  6 16 29  0  0  6  0  8  0
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[158.07025]
 [158.54596]
 [162.06247]
 [157.49756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.3536834716797



action possibilites: [-1. 10.] 
expected returns: [[120.726105]
 [120.204865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 157.4374237060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.177345]
 [119.24033 ]
 [115.65247 ]
 [121.354   ]
 [120.84976 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  3.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 120.72608947753906



buy possibilites: [-1] 
expected returns: [[128.11493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 121.35400390625






Player: 1 
cards in hand: [16.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  0.] 
cards in discard: [6. 0. 8. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  8. 10. 29. 29.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8  8] -> size -> 33 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.  0.] 
cards in discard: [6. 0. 8. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  8. 10. 29. 29.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8  8] -> size -> 33 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 29. 29.] 
expected returns: [[122.00806 ]
 [122.465866]
 [122.465866]
 [121.513   ]
 [125.656815]
 [125.656815]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 29. 29.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.11492919921875



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[131.1637 ]
 [131.67464]
 [131.67464]
 [130.70346]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29 10  8 10 10 29 10 29 29 11 11
 10  8 10 29 10 29 15  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 121.45588684082031



action possibilites: [-1] 
expected returns: [[128.9458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 131.21954345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[125.737495]
 [123.327576]
 [128.26431 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.94580078125






Player: 1 
cards in hand: [3. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 28. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11.  0. 11. 10.] 
adversary cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10.] 
expected returns: [[149.56616]
 [153.783  ]
 [151.21574]
 [151.21574]
 [148.95207]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 11. 10.] 
cards in discard: [10.  0. 29. 29. 15. 29. 11.  8. 25. 29. 10. 29.  0. 11.  0.  8. 10.  8.
 29.  3.  0. 10. 29. 10. 29.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.26429748535156



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[147.20876]
 [148.73672]
 [148.73672]
 [152.49835]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.] 
cards in discard: [ 0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  4.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 148.8892822265625



action possibilites: [-1] 
expected returns: [[122.61197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 11.] 
cards in discard: [ 0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.4983673095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.43367 ]
 [118.006355]
 [123.011894]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 29. 11.] 
cards in discard: [ 0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.61196899414062






Player: 1 
cards in hand: [0. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  8.  8. 29.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 0.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  8.  8. 29.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
adversary victory points: 1
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 29.] 
expected returns: [[114.33152]
 [118.0331 ]
 [114.80612]
 [114.80612]
 [118.0331 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8. 29.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.  0.
  6.  6.  6.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.01190185546875



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[109.158646]
 [109.67949 ]
 [109.67949 ]
 [109.67949 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25  8 29  8 10 10 29 10 29 29 11 11 10
  8 10 29 10 29 15  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.  0.
  6.  6.  6.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.791259765625



action possibilites: [-1] 
expected returns: [[110.50924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.  0.
  6.  6.  6.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 107.78057861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[107.92023]
 [105.3992 ]
 [110.60719]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.  0.
  6.  6.  6.  0.] 
adversary owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.50923919677734






Player: 1 
cards in hand: [ 0.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  0. 16.  3.  0.  3.  0.  3.  3.  8.  0.  0.  6.  6.  0.
  6.  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  3  8  0  0  6  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6
  0  3  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[139.9385 ]
 [139.39403]
 [141.5401 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.60719299316406



action possibilites: [-1] 
expected returns: [[154.28453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 140.44834899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.21619]
 [153.31859]
 [149.61739]
 [155.49985]
 [155.0102 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  2.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.28453063964844



buy possibilites: [-1] 
expected returns: [[158.73024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 155.49984741210938






Player: 1 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [10.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [10.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10. 15.  0. 10.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15  8] -> size -> 32 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10. 10. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 10.] 
expected returns: [[153.37259]
 [152.84395]
 [152.84395]
 [153.4202 ]
 [152.84395]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  0. 10.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10
 29 10 29 15  8  8 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.73023986816406



action possibilites: [-1] 
expected returns: [[132.77454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 153.42019653320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[130.41234]
 [132.8351 ]
 [131.64536]
 [127.49448]
 [135.32741]
 [134.0944 ]
 [133.52925]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  6.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.7745361328125



buy possibilites: [-1] 
expected returns: [[173.51886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [8. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 135.32742309570312






Player: 1 
cards in hand: [8. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 0.] 
cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  8. 29. 29. 29.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6. 0. 0.] 
cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  8. 29. 29. 29.] 
adversary cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
adversary victory points: 1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10.  8. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 29. 29.] 
expected returns: [[124.75472]
 [124.20439]
 [125.28721]
 [128.908  ]
 [128.908  ]
 [128.908  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29. 29.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.51885986328125



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[146.11133]
 [145.4558 ]
 [146.69745]
 [150.85847]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.13935852050781



action possibilites: [-1.  8.] 
expected returns: [[172.49478]
 [173.12173]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10. 29. 29. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 145.38287353515625



action possibilites: [-1] 
expected returns: [[183.38354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10. 29. 29. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 173.12173461914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.28197]
 [181.42273]
 [177.5714 ]
 [183.6947 ]
 [183.14117]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10. 29. 29. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  1.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 183.383544921875



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 7 
Witch: 1 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [] 
cards in discard: [ 0. 10. 29. 25. 11. 11. 29. 11.  0. 29. 29.  8. 15.  8. 11. 10.  0.  3.
  0. 11. 15. 10. 10. 10. 29. 29. 10.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 29 29 11 25 29 10 10 29 10 29 29 11 11 10  8 10 29
 10 29 15  8  8 15  8 11  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 27. 30.  8.  3.  9.  5.  0.  9.  0.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 3. 8.] 
adversary cards in discard: [10.  8.  0.  0.  0.  3.  0.  0.  6.  6.  8.  3.  6.  0.  0.] 
adversary owned cards: [ 3 10  3  8  0  0  0  0  0  3  6  0  6 16  0  0  6  0  8  0  8  6  0  3
  6  0] -> size -> 26 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      60       0       0
       0       0       0       0       0       8       0] 
sum of rewards: 3000123 

action type: buy - action 8.0
Learning step: 119997.5703125
desired expected reward: 120181.265625



