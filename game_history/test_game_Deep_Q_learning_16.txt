 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.34315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0       0       0       0
       0       0     -30       0       0       0       0] 
sum of rewards: 3000055 

action type: buy - action 0.0
Learning step: 120002.25
desired expected reward: 120001.0703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.837011]
 [21.559408]
 [20.675764]
 [15.233939]
 [23.214851]
 [19.376099]
 [18.49245 ]
 [19.700901]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.731422424316406



buy possibilites: [-1] 
expected returns: [[18.834936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 23.214845657348633






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.528246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.834936141967773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.910759]
 [17.222204]
 [16.722424]
 [13.913486]
 [16.104603]
 [18.404072]
 [16.004536]
 [19.924822]
 [14.994177]
 [15.614607]
 [17.51579 ]
 [16.979252]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.320152282714844



buy possibilites: [-1] 
expected returns: [[20.804592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 19.924821853637695






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.207575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.80459213256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.926367]
 [23.544392]
 [22.922882]
 [18.35487 ]
 [21.96449 ]
 [24.86593 ]
 [21.869413]
 [26.556015]
 [20.278372]
 [21.24791 ]
 [23.89639 ]
 [23.366173]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.580656051635742



buy possibilites: [-1] 
expected returns: [[27.200071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.556013107299805






Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.17475 ]
 [27.177217]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.200071334838867



action possibilites: [-1] 
expected returns: [[41.059383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.47223472595215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[35.760124]
 [40.35559 ]
 [39.53119 ]
 [33.903435]
 [42.01889 ]
 [38.247833]
 [37.423435]
 [39.29135 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.059383392333984



buy possibilites: [-1] 
expected returns: [[44.867695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.018898010253906






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3. 11.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[31.352846]
 [35.06653 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.86769485473633



action possibilites: [-1.] 
expected returns: [[19.906607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.56680679321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.29164 ]
 [21.90966 ]
 [21.288158]
 [17.322102]
 [16.720142]
 [20.329763]
 [23.231203]
 [20.23469 ]
 [25.89083 ]
 [24.921286]
 [18.643642]
 [22.356739]
 [19.613182]
 [18.73872 ]
 [22.261663]
 [21.731447]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.906606674194336



buy possibilites: [-1] 
expected returns: [[30.403166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.890830993652344






Player: 1 
cards in hand: [ 1.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0.] 
cards in discard: [15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[48.250866]
 [45.592804]
 [50.657207]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 11.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.403165817260742



action possibilites: [-1] 
expected returns: [[38.879807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.76416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.94713 ]
 [38.84344 ]
 [34.309116]
 [37.834553]
 [38.40936 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.87980651855469



buy possibilites: [-1] 
expected returns: [[41.015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 29.  0.  0.  0.  3.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 38.84344482421875






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3. 11.  1.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3. 11.  1.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [25.  3. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[33.75654 ]
 [41.16858 ]
 [37.36319 ]
 [39.677692]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.01499938964844



action possibilites: [-1] 
expected returns: [[46.16898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.675682067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.805485]
 [48.9853  ]
 [42.688267]
 [47.589573]
 [49.402588]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.16897964477539






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[42.17896]
 [41.35373]
 [51.46988]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.402587890625



action possibilites: [-1. 10. 10.] 
expected returns: [[51.430496]
 [50.48252 ]
 [50.48252 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.430076599121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.0469  ]
 [56.423676]
 [55.004017]
 [45.55254 ]
 [52.727745]
 [59.02192 ]
 [53.0648  ]
 [62.002544]
 [49.52526 ]
 [51.645138]
 [56.902042]
 [52.59312 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.43048858642578



buy possibilites: [-1] 
expected returns: [[109.33548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 10.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.002540588378906






Player: 1 
cards in hand: [15.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [25.  3. 11. 29.  0. 11.  0. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [25.  3. 11. 29.  0. 11.  0. 29. 29.  0.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[175.19965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 11.  3.  3.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.33547973632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[171.19003]
 [179.09325]
 [166.69067]
 [176.61728]
 [176.34058]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0. 29. 29.  0.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 11.  3.  3.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 175.98101806640625



buy possibilites: [-1] 
expected returns: [[197.29242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [25.  3. 11. 29.  0. 11.  0. 29. 29.  0.  0.  0. 10. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 11.  3.  3.] 
adversary cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 179.09329223632812






Player: 1 
cards in hand: [ 3.  1. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  3.  3.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7. 10.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7. 10.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 6. 29.  0.  0.  0.  0.  0. 15.  3.  0.  3.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[45.933475]
 [51.225304]
 [49.989666]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 197.29241943359375



action possibilites: [-1] 
expected returns: [[68.15211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15. 29.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.46604537963867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.769073]
 [68.04823 ]
 [61.45112 ]
 [66.619125]
 [67.80177 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15. 29.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.15210723876953



buy possibilites: [-1] 
expected returns: [[57.68634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  3. 11.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15. 29.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 68.04822540283203






Player: 1 
cards in hand: [15. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 29.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[72.47313]
 [82.47304]
 [82.47304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.  0.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.68634033203125



action possibilites: [-1. 29. 11.] 
expected returns: [[57.646954]
 [66.91494 ]
 [64.24614 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 11.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.3335189819336



action possibilites: [-1. 11.] 
expected returns: [[71.86611]
 [76.51533]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.9149398803711



action possibilites: [-1] 
expected returns: [[42.149956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.45858001708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[40.59069 ]
 [47.69667 ]
 [46.256687]
 [38.699448]
 [37.599255]
 [43.886574]
 [50.352062]
 [44.354954]
 [55.741745]
 [53.461594]
 [41.05407 ]
 [47.751823]
 [42.994843]
 [40.62955 ]
 [48.22021 ]
 [43.472145]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  9.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.14995574951172



buy possibilites: [-1] 
expected returns: [[65.54242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 1. 3.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 55.74173355102539






Player: 1 
cards in hand: [0. 3. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 3.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[15.517874 ]
 [13.2544365]
 [13.2544365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.  0.  3.  6.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.54241943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.134928]
 [14.169826]
 [11.220558]
 [13.475937]
 [15.376896]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [ 3. 25.  3.  0.  0. 29.  3. 11. 10. 25. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.  0.  3.  6.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.517866134643555



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.  0.  3.  6.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.  0.  3.  6.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3. 29. 29. 11. 15.  3.  0.  0.  1.  0.  3.  6.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[38.94039]
 [41.19131]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.37687873840332



action possibilites: [-1] 
expected returns: [[35.230354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.604591369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.485575]
 [35.736008]
 [34.97725 ]
 [29.58498 ]
 [37.273216]
 [33.78154 ]
 [33.022785]
 [34.871437]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  7.  9.  8.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.23035430908203



buy possibilites: [-1] 
expected returns: [[55.65647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.273223876953125






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 29.  3. 29.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[66.06899 ]
 [75.150276]
 [75.150276]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 29.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.656471252441406



action possibilites: [-1. 29.] 
expected returns: [[44.69536]
 [50.86511]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.0693130493164



action possibilites: [-1.] 
expected returns: [[48.77083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.865081787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.792877]
 [52.044437]
 [50.965416]
 [44.340893]
 [54.018986]
 [49.538803]
 [48.546654]
 [49.184746]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  6.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.77082824707031



buy possibilites: [-1] 
expected returns: [[42.318886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 6.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.01896286010742






Player: 1 
cards in hand: [0. 3. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [10.  0.  3.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11] -> size -> 26 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [10.  0.  3.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  9.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11] -> size -> 26 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11] -> size -> 26 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[72.670006]
 [69.89006 ]
 [69.89006 ]
 [76.3325  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10. 11.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15. 29.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.318885803222656



action possibilites: [-1] 
expected returns: [[90.33084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 15. 29.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.46820831298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[83.133415]
 [79.52569 ]
 [88.5803  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 15. 29.  0.  3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.33084106445312






Player: 1 
cards in hand: [ 3. 15. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29.  0.  3.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3. 10. 11.  0.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29.  0.  3.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3. 10. 11.  0.
 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
adversary victory points: 6
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[16.34949  ]
 [18.98112  ]
 [18.243795 ]
 [14.2007675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 10.  0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3. 11. 29. 29.  3.  3.  3.  0.  3. 10. 11.  0.
 10.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  8. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8] -> size -> 25 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.58028411865234



action possibilites: [-1] 
expected returns: [[69.60467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 10. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 24. 30.  8.  7. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6] -> size -> 26 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.981122970581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.1132 ]
 [66.37957]
 [59.68226]
 [64.94935]
 [65.71964]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 10. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 24. 30.  8.  7. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6] -> size -> 26 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.60466766357422



buy possibilites: [-1] 
expected returns: [[77.282875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 10. 25.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0. 29.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6] -> size -> 26 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 66.37957763671875






Player: 1 
cards in hand: [ 6.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0. 29.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  8.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  7.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  7.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 29.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.  0.  3.  1.  3.  6.  3. 15. 29.  0.  3.  6.
  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[90.35025]
 [88.40548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.28287506103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.61992]
 [80.76401]
 [89.7096 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.3502426147461



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 6. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  1 15  3  0  6 29 29  8  6  3  1 10
  8  6  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[175.41576]
 [184.79907]
 [189.34277]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 10.  8.  0. 15.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.70960235595703



action possibilites: [-1. 11.] 
expected returns: [[201.70186]
 [209.94858]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 10.  8.  0. 15.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 189.34275817871094



action possibilites: [-1] 
expected returns: [[85.51711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  8.  0. 15.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 211.96556091308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[81.38335 ]
 [89.995186]
 [88.23524 ]
 [77.71451 ]
 [85.44333 ]
 [93.37383 ]
 [85.883896]
 [97.0991  ]
 [82.159515]
 [84.37568 ]
 [90.77756 ]
 [86.22447 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  8.  0. 15.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.5171127319336



buy possibilites: [-1] 
expected returns: [[4.767438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  8.  0. 15.] 
adversary cards in discard: [0. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.09906768798828






Player: 1 
cards in hand: [29. 10.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8.  0. 15.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29] -> size -> 30 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  8.  0. 15.] 
cards in discard: [0. 8. 6. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29] -> size -> 30 
adversary victory points: 7
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[60.007225]
 [58.057076]
 [62.720955]
 [61.229076]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 11.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 11.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.767437934875488



action possibilites: [-1. 10. 11.] 
expected returns: [[ 98.07603 ]
 [ 95.53874 ]
 [100.013725]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 11.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.720947265625



action possibilites: [-1] 
expected returns: [[44.16059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 11.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.794189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.449986]
 [43.532986]
 [40.37585 ]
 [42.800446]
 [43.98267 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0. 10. 25.  3.  3.  0. 10.  3. 10. 29. 29. 11.  3.
  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 29.  8. 11.  3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.16059112548828






Player: 1 
cards in hand: [ 1. 29.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  8. 11.  3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[14.518675]
 [13.196104]
 [16.382963]
 [16.382963]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.982666015625



action possibilites: [-1] 
expected returns: [[16.814457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 16.616456985473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.73414  ]
 [12.6449795]
 [16.227379 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.814456939697266






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
adversary victory points: 7
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[22.85604 ]
 [25.330606]
 [25.330606]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  0.] 
cards in discard: [10. 11.  3.  0. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.227378845214844



action possibilites: [-1. 29. 29.] 
expected returns: [[17.301481]
 [21.88067 ]
 [21.88067 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 29.] 
cards in discard: [10. 11.  3.  0. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.330596923828125



action possibilites: [-1. 29. 10.] 
expected returns: [[35.67272 ]
 [38.605976]
 [33.750603]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.88067054748535



action possibilites: [-1. 10.] 
expected returns: [[26.158857]
 [24.68591 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10. 11.  3.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.60597610473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.39649 ]
 [26.193369]
 [21.954947]
 [25.509253]
 [21.706545]
 [21.291977]
 [24.431816]
 [27.559708]
 [24.446938]
 [30.279156]
 [29.231886]
 [22.715546]
 [26.497316]
 [23.762823]
 [22.801641]
 [26.51243 ]
 [25.272501]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10. 11.  3.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.15886878967285



buy possibilites: [-1] 
expected returns: [[55.408043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 267.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 30.279157638549805






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3. 10.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 23. 30.  8.  7. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3. 10.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  6. 29. 10.  8.  0. 15.  8.  1. 29.  3.  0.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 22. 30.  8.  7. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3. 10.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[60.472996]
 [68.76983 ]
 [58.084793]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 22. 30.  8.  7. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.408042907714844



action possibilites: [-1] 
expected returns: [[77.84407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.  3.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.76981353759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[76.01613]
 [81.30735]
 [73.10817]
 [79.60971]
 [80.38676]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.  3.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 22. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.84407043457031



buy possibilites: [-1] 
expected returns: [[70.7687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.  3.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 81.3073501586914






Player: 1 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8
  0  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  3.  3. 11.  3.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  3.  3. 11.  3.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  3.  3. 11.  3.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  3.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[27.109228]
 [31.612764]
 [29.603798]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 11.  3.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3.  1.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.7686996459961



action possibilites: [-1. 11. 10.] 
expected returns: [[48.111595]
 [50.484745]
 [45.817863]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3.  1.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.61277198791504



action possibilites: [-1] 
expected returns: [[96.89736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3.  1.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.343605041503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[92.95121]
 [88.96824]
 [97.13696]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3.  1.] 
adversary cards in discard: [6. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.8973617553711






Player: 1 
cards in hand: [29.  8. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  3.  1.] 
cards in discard: [6. 8. 6. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 10.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3. 10. 29. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 29.  3.  1.] 
cards in discard: [6. 8. 6. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [25. 10. 11. 10. 10.] 
adversary cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3. 10. 29. 11.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
adversary victory points: 8
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25. 10. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 10. 10.] 
expected returns: [[58.35005 ]
 [68.068245]
 [55.915894]
 [63.067726]
 [55.915894]
 [55.915894]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 10. 10.] 
cards in discard: [10. 11.  3.  0. 10. 11. 25. 29. 29. 29.  0.  0.  0. 10.  0.  3. 25.  0.
  0.  3. 10.  3.  3. 10. 29. 11.  3.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  6. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6] -> size -> 26 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.13697052001953



action possibilites: [-1] 
expected returns: [[18.561852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6  6] -> size -> 27 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 68.06824493408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.317585]
 [15.388184]
 [18.360579]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6  6] -> size -> 27 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.561851501464844






Player: 1 
cards in hand: [ 0.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0.  0.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3 15  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0
  3  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  0.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  0.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  0.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
adversary victory points: 8
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[33.372093]
 [38.475536]
 [35.99353 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0.  0.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  5. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.360584259033203



action possibilites: [-1] 
expected returns: [[46.824287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.  3.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  4. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.47553253173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[45.518555]
 [52.59687 ]
 [51.285973]
 [42.42093 ]
 [55.192528]
 [49.425095]
 [49.96401 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.  3.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 21. 30.  8.  4. 10.  5.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.82428741455078



buy possibilites: [-1] 
expected returns: [[58.180607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.  3.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  4. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.19252014160156






Player: 1 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 21. 30.  8.  4. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 25.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 21. 30.  8.  4. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 25.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 21. 30.  8.  4. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 25.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[36.115494]
 [33.64875 ]
 [48.708023]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 25.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  4. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0. 10.  3.  0.
  0.  8.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.180606842041016



action possibilites: [-1] 
expected returns: [[50.803818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  3. 29.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0. 10.  3.  0.
  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.7080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.619423]
 [44.49091 ]
 [52.006977]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  3. 29.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0. 10.  3.  0.
  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.80381774902344






Player: 1 
cards in hand: [3. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0. 10.  3.  0.
  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [ 6.  8.  6.  0.  6. 29.  8. 29.  3.  1.  6.  8.  0.  6.  0. 10.  3.  0.
  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29. 10. 10. 11.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 29. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10. 11.] 
expected returns: [[30.784246]
 [30.260115]
 [34.19591 ]
 [30.260115]
 [30.260115]
 [32.709095]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 10. 11.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.0069694519043



action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[87.299904]
 [85.70484 ]
 [85.70484 ]
 [85.70484 ]
 [92.91824 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.60270118713379



action possibilites: [-1] 
expected returns: [[81.56737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.26982116699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.98737 ]
 [75.838234]
 [81.7452  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.56736755371094






Player: 1 
cards in hand: [3. 3. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 10.  3. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 10.  3. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0. 10.  3. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[77.505165]
 [83.10275 ]
 [76.20908 ]
 [76.20908 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3. 10.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.7452163696289



action possibilites: [-1] 
expected returns: [[121.98823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 379 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.4084243774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.20314]
 [113.25519]
 [121.98821]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [25. 10. 11. 10. 10.  3.  0. 11. 25.  0. 11.  0.  0.  3.  3. 25. 10.  3.
  0.  3.  3. 29.  3. 15. 29. 11. 10. 10. 10. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.98822784423828






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 6. 3. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[13.006218]
 [11.191086]
 [14.896651]
 [14.896651]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  3.  6.  0.] 
adversary cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.98822784423828



action possibilites: [-1. 10. 29.] 
expected returns: [[17.00458 ]
 [15.359245]
 [18.599936]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29.] 
cards in discard: [29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  3.  6.  0.] 
adversary cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.752981185913086



action possibilites: [-1. 10.] 
expected returns: [[38.717934]
 [37.072605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [29. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  3.  6.  0.] 
adversary cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.48094940185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[35.669907]
 [37.461502]
 [37.181118]
 [34.94477 ]
 [38.155594]
 [36.620174]
 [37.98513 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [29. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  4.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  3.  6.  0.] 
adversary cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.71793746948242



buy possibilites: [-1] 
expected returns: [[83.63715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [29. 29. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [10.  6.  3.  6.  0.] 
adversary cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 409 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.15559005737305






Player: 1 
cards in hand: [10.  6.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  6.  0.] 
cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11] -> size -> 39 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  6.  0.] 
cards in discard: [8. 6. 3. 1. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11] -> size -> 39 
adversary victory points: 8
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[78.63921]
 [81.70826]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  3.  6.  8. 29.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.63715362548828



action possibilites: [-1] 
expected returns: [[83.694664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  3.  6.  8. 29.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 389 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.63297271728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.57355]
 [86.63504]
 [80.21886]
 [85.33314]
 [85.17585]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 21. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  3.  6.  8. 29.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.69466400146484



buy possibilites: [-1] 
expected returns: [[99.95461]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  3.  6.  8. 29.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 361 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 86.6350326538086






Player: 1 
cards in hand: [ 6.  3.  6.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  8. 29.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10. 10. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 6.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10. 10. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 6.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [10.  0. 10. 10. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[116.75098 ]
 [115.121124]
 [115.121124]
 [115.121124]
 [115.121124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 10.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8.  1.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6. 29.  3.  6.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.9546127319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.740425]
 [111.36724 ]
 [119.11506 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10. 10.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29.  8.  1.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6. 29.  3.  6.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.75096130371094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  1.  0.  0.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6. 29.  3.  6.  8.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  0.  0.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  1.  0.  0.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6. 29.  3.  6.  8.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 20. 30.  8.  3. 10.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  0.  0.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  1.  0.  0.] 
cards in discard: [ 8.  6.  3.  1.  8.  0.  0.  0. 10.  6.  3.  6.  0.  6. 29.  3.  6.  8.
  6. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  0.  0.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
adversary victory points: 9
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[76.759285]
 [81.187485]
 [79.50776 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  0.  0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.11505126953125



action possibilites: [-1] 
expected returns: [[39.779278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 399 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.31319427490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.691765]
 [40.639816]
 [34.526695]
 [39.34528 ]
 [40.13511 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 20. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
adversary victory points: -4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.77927780151367



buy possibilites: [-1] 
expected returns: [[44.85743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 371 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 40.63979721069336






Player: 1 
cards in hand: [0. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3] -> size -> 43 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3] -> size -> 43 
adversary victory points: 10
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3] -> size -> 43 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[84.127205]
 [82.25767 ]
 [89.578514]
 [89.578514]
 [82.25767 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 11. 10.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [0. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.85742950439453



action possibilites: [-1] 
expected returns: [[47.471127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [0. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.95490264892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.513176]
 [39.232544]
 [47.47113 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [0. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.471126556396484






Player: 1 
cards in hand: [ 0.  8.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  6. 10.] 
cards in discard: [0. 0. 0. 6. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  3. 25. 11.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 3.] 
cards in discard: [0. 0. 0. 6. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  3. 25. 11.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 3.] 
cards in discard: [0. 0. 0. 6. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0.  3. 25. 11.] 
adversary cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15.  0.  3. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11.] 
expected returns: [[ 98.93026 ]
 [103.23942 ]
 [112.865135]
 [105.934616]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 25. 11.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0] -> size -> 27 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.471126556396484



action possibilites: [-1] 
expected returns: [[47.120575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 11. 10.  3.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.8651351928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.032288]
 [42.254463]
 [47.12059 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 11. 10.  3.] 
cards in discard: [29. 29. 11. 29. 29.  3. 10.  0. 15.  3. 11.  0.  3.  3.  0. 10.  0. 10.
 10. 10. 15.  3. 11.  3. 15.  0.  0. 15. 11. 10.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6] -> size -> 28 
adversary victory points: -4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.120574951171875






Player: 1 
cards in hand: [ 0.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -5 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  8.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  6.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  8.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[17.494198]
 [15.679068]
 [20.029413]
 [20.029413]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 25. 25.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  2.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 16.  8.  1.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8] -> size -> 29 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.120574951171875



action possibilites: [-1] 
expected returns: [[19.115747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 16.  8.  1.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6] -> size -> 30 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.0294132232666





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.05779 ]
 [20.154175]
 [16.904776]
 [19.40422 ]
 [20.157454]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 6. 16.  8.  1.  1.] 
adversary cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.  6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6] -> size -> 30 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.115747451782227






Player: 1 
cards in hand: [ 6. 16.  8.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  8.  1.  1.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 11.  3.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  8.  1.  1.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 11.  3.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  8.  1.  1.] 
cards in discard: [ 0.  0.  0.  6.  3.  6. 10.  0.  8.  3.  6.  3.  6.  0.  8. 29.  0.  0.
 29.  8.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 11.  3.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
adversary victory points: 10
player victory points: -6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[16.942171]
 [21.793577]
 [19.810091]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3.  3.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.15745735168457



action possibilites: [-1. 11.] 
expected returns: [[77.00155]
 [80.54037]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  4.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.136430740356445



action possibilites: [-1] 
expected returns: [[42.495064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  480    0    0   40    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 479 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.4524154663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[38.65827 ]
 [43.582146]
 [42.670116]
 [36.405964]
 [45.366207]
 [41.354362]
 [41.82739 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  3.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.49506378173828



buy possibilites: [-1] 
expected returns: [[123.615486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  480    0    0   40    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: 459 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.3662109375






Player: 1 
cards in hand: [6. 6. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10. 15.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11] -> size -> 46 
adversary victory points: 10
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10. 15.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11] -> size -> 46 
adversary victory points: 10
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 10. 15.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11] -> size -> 46 
adversary victory points: 10
player victory points: -6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 15. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 15.] 
expected returns: [[11.004663]
 [12.541203]
 [12.104868]
 [11.259236]
 [12.104868]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 15.  0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  3.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.61548614501953



action possibilites: [-1] 
expected returns: [[65.75828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15.  0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -120    0    0
   64    0] 
sum of rewards: 439 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.81676959991455





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.524105]
 [59.576855]
 [66.32576 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15.  0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
adversary victory points: -6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.7582778930664






Player: 1 
cards in hand: [0. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [0. 6. 6. 8. 6. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10.  3. 10. 29. 10.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
adversary victory points: 10
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [0. 6. 6. 8. 6. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 19. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10.  3. 10. 29. 10.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
adversary victory points: 10
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [0. 6. 6. 8. 6. 6. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10.  3. 10. 29. 10.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  3. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[12.481482]
 [12.086418]
 [12.086418]
 [15.035955]
 [12.086418]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 29. 10.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0. 10.  1.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6. 3. 0. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.32574462890625



action possibilites: [-1. 10. 10.] 
expected returns: [[9.697907]
 [8.566068]
 [8.566068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0. 10.  1.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6. 3. 0. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.482789039611816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.776886 ]
 [6.7944975]
 [9.697907 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [29.  1.  0. 10.  1.] 
adversary cards in discard: [0. 6. 6. 8. 6. 6. 3. 0. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.697898864746094






Player: 1 
cards in hand: [29.  1.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 10.  1.] 
cards in discard: [0. 6. 6. 8. 6. 6. 3. 0. 6. 0. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11.  3. 10. 15. 29.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0. 10.  1.] 
cards in discard: [0. 6. 6. 8. 6. 6. 3. 0. 6. 0. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11.  3. 10. 15. 29.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
adversary victory points: 10
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 29.] 
expected returns: [[3.8828323]
 [5.4917097]
 [2.9440825]
 [4.770706 ]
 [6.806811 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 15. 29.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.697898864746094



action possibilites: [-1. 11. 10. 15. 11.] 
expected returns: [[22.99852 ]
 [24.988634]
 [21.55348 ]
 [24.047476]
 [24.988634]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 11.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.607316017150879



action possibilites: [-1] 
expected returns: [[57.146217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0   40    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: 419 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.60621452331543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.190342]
 [51.46382 ]
 [57.146214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 11.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 8. 3. 8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 485 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.146217346191406






Player: 1 
cards in hand: [0. 3. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 11. 10.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
adversary victory points: 10
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 11. 10.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
adversary victory points: 10
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 8.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 11. 10.  3.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
adversary victory points: 10
player victory points: -5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[-1.5647798]
 [-1.0157833]
 [-1.4654887]
 [-1.5647798]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10.  3.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6. 29.  8.  1.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.146217346191406



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[35.143307]
 [38.19963 ]
 [34.02505 ]
 [34.02505 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  6. 29.  8.  1.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 465 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.563991665840149



action possibilites: [-1] 
expected returns: [[105.58276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  6. 29.  8.  1.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  450    0    0   40    0    0    0    0 -140    0    0
   64    0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.04979705810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.91155 ]
 [106.81552 ]
 [ 99.142944]
 [105.23857 ]
 [105.58276 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 18. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  6. 29.  8.  1.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
adversary victory points: -5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 450   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 485 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.582763671875



buy possibilites: [-1] 
expected returns: [[108.46158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 6.  6. 29.  8.  1.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
adversary victory points: -5
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  480    0    0   40    0    0    0    0 -150    0    0
   16    0] 
sum of rewards: 381 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 106.81551361083984






Player: 1 
cards in hand: [ 6.  6. 29.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  8.  1.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  6 29 29  8  6  3  1 10  8  6  8  8  0  3  6  6  6  0  6
  1 16  0  6  8  6  1  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3] -> size -> 50 
adversary victory points: 11
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3] -> size -> 50 
adversary victory points: 11
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3] -> size -> 50 
adversary victory points: 11
player victory points: -3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[4.1462307]
 [5.3757963]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 16.  6.  0.  8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.] 
adversary owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.46157836914062



action possibilites: [-1] 
expected returns: [[-1.1399022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 16.  6.  0.  8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.] 
adversary owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 302 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 5.054890155792236





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.0123432]
 [-1.5647798]
 [-1.1398857]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 16.  6.  0.  8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.] 
adversary owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.1399022340774536



buy possibilites: [-1] 
expected returns: [[-1.5647798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [25.  0.  3. 10. 25. 25.  0.  3. 15. 11. 29. 11.  0.  3.  0. 15. 11. 15.
 10. 15.  0. 10. 29.  3. 10. 10.  3.  3. 15. 29. 11. 10. 15. 11.  3. 15.
  3. 29. 11.  0. 10. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3  1  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [ 0. 16.  6.  0.  8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.] 
adversary owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
adversary victory points: -3
player victory points: 11 

Reward from previous game state: 
[  -5.    0.    0.  420.    0.    0.   20.    0.    0.    0.    0. -170.
    0.    0.    0.    0.] 
sum of rewards: 265.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -1.01235830783844






Player: 1 
cards in hand: [ 0. 16.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  0.  8.] 
cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0
  6  8  6  1  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 17. 30.  8.  1.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [10.  3. 15. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3  1  0] -> size -> 52 
adversary victory points: 11
player victory points: -3 


Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 0 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 3 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  3. 15. 15. 10.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 25 10  3 29  3  3 10 25 10
 11 11 10  3 10 29 10 10 25  3 10 11 15 15 11 15  3 15  3 15 15 11 15 15
 15  3  1  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 17. 30.  8.  0.  9.  2.  5.  7.  4. 10. 10.  0. 10.  0.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 0.  6.  6.  8.  6.  6.  3.  0.  6.  0.  6.  0. 29.  1.  0. 10.  1.  0.
  0.  3.  8.  3.  8.  8. 29.  6.] 
adversary owned cards: [ 0  0  3  0 29 29  8  3 10  8  6  8  8  0  3  6  6  6  0  6  1 16  0  6
  8  6  1  0  3  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 11 

Reward from previous game state: 
[     -5 3000000       0     450       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000445 

action type: buy - action -1
Learning step: 120017.859375
desired expected reward: 120016.296875



