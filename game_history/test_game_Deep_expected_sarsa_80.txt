 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.667336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0     -50       0    -300       0       0] 
sum of rewards: 2999755 

action type: buy - action 6.0
Learning step: 119996.1875
desired expected reward: 119846.53125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.748165]
 [83.94353 ]
 [67.044266]
 [14.616837]
 [75.841064]
 [85.53498 ]
 [74.22002 ]
 [97.92047 ]
 [32.739567]
 [57.335182]
 [60.626305]
 [71.10201 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.0652847290039



buy possibilites: [-1] 
expected returns: [[70.38245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.92045593261719






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.392365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.3824462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 72.50132 ]
 [ 99.819855]
 [ 83.30139 ]
 [ 33.63222 ]
 [101.45713 ]
 [ 90.20182 ]
 [ 74.02099 ]
 [ 87.19769 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.118896484375



buy possibilites: [-1] 
expected returns: [[80.1609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.45712280273438






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[62.557472]
 [91.00325 ]
 [77.95705 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.16089630126953



action possibilites: [-1. 11.] 
expected returns: [[67.17682 ]
 [81.053986]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.79061126708984



action possibilites: [-1] 
expected returns: [[58.98458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 92.31707000732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 42.25218   ]
 [ 70.836914  ]
 [ 53.687016  ]
 [ 17.29859   ]
 [  0.96174383]
 [ 62.61692   ]
 [ 72.45648   ]
 [ 60.974876  ]
 [110.01795   ]
 [ 84.73677   ]
 [ 18.893564  ]
 [ 48.81737   ]
 [ 43.847168  ]
 [ 20.514738  ]
 [ 47.175316  ]
 [ 57.858788  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.984580993652344



buy possibilites: [-1] 
expected returns: [[69.290764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 110.01795196533203






Player: 1 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[49.925247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.29076385498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.74905   ]
 [65.336716  ]
 [48.626713  ]
 [ 0.82908535]
 [66.90419   ]
 [55.71509   ]
 [39.221413  ]
 [52.556046  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.86054992675781



buy possibilites: [-1] 
expected returns: [[65.19233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.90419006347656






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 3 8 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [25.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[28.737123]
 [83.80571 ]
 [44.161697]
 [57.1218  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0 11] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.19232940673828



action possibilites: [-1] 
expected returns: [[27.074549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0 11  6] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.38433074951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 13.563423]
 [ 24.030811]
 [-24.49232 ]
 [ 30.952662]
 [ 28.28877 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0 11  6] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.074548721313477



buy possibilites: [-1] 
expected returns: [[51.623856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  3.  3.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  0 11  6] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 30.95265769958496






Player: 1 
cards in hand: [3. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  0 11  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[32.886765]
 [21.614464]
 [44.57259 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.62385559082031



action possibilites: [-1] 
expected returns: [[16.279497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.51465606689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  7.0180497]
 [ 29.890589 ]
 [ 16.016867 ]
 [-26.137415 ]
 [ 31.293768 ]
 [ 21.727537 ]
 [  8.293596 ]
 [ 19.30469  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.279497146606445



buy possibilites: [-1] 
expected returns: [[-0.44815922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 11. 29.  3.  3.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.293764114379883






Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [6. 0. 8. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 0. 8. 3. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 0. 8. 3. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6. 0. 8. 3. 0. 3. 1. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.01853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.44815921783447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  1.7816682]
 [ 28.211718 ]
 [ 12.356831 ]
 [-36.600796 ]
 [ 29.708048 ]
 [ 19.07249  ]
 [  3.2686229]
 [ 16.173946 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.37183952331543



buy possibilites: [-1] 
expected returns: [[36.584007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.708070755004883






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0 11  6  0  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25.  0. 11.  8.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11. 25.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.  8.] 
expected returns: [[34.08048 ]
 [46.588566]
 [80.6357  ]
 [46.588566]
 [36.333412]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 11.  8.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.584007263183594



action possibilites: [-1] 
expected returns: [[43.421722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  8.  0. 10.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.95065307617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.917988 ]
 [43.335266 ]
 [ 5.9974313]
 [49.30468  ]
 [46.816593 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  8.  0. 10.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.421722412109375



buy possibilites: [-1] 
expected returns: [[50.967224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  8.  0. 10.] 
cards in discard: [11.  0.  3.  3.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  1.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 49.30467224121094






Player: 1 
cards in hand: [ 6. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  0.  3.] 
cards in discard: [3. 8. 0. 0. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 3.] 
cards in discard: [3. 8. 0. 0. 0. 6. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3.] 
cards in discard: [3. 8. 0. 0. 0. 6. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3.] 
cards in discard: [3. 8. 0. 0. 0. 6. 1. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[18.210936]
 [31.148138]
 [ 5.563644]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  0.] 
cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.96722412109375



action possibilites: [-1] 
expected returns: [[-2.1390219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.41534423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-13.023166  ]
 [ -3.34814   ]
 [-48.341415  ]
 [  3.4690967 ]
 [  0.54185677]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  7.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.139021873474121



buy possibilites: [-1] 
expected returns: [[-6.86784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11.  0.  3.  3.  0.  0.  8. 25. 11.  0. 11.  8.  0. 10. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  6.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 1. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 3.469094753265381






Player: 1 
cards in hand: [1. 1. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  6.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  6.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 3. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[ 0.29635382]
 [ 2.6131272 ]
 [22.037012  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.867839813232422



action possibilites: [-1.  8.] 
expected returns: [[11.596012]
 [13.537762]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.49668312072754



action possibilites: [-1] 
expected returns: [[4.812096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 16.591567993164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -5.3523297]
 [ 18.412615 ]
 [  4.203134 ]
 [-36.615173 ]
 [ 11.582066 ]
 [ 19.788738 ]
 [ 10.233271 ]
 [ 29.983458 ]
 [-23.89178  ]
 [ -3.976201 ]
 [ -1.1604075]
 [  7.900124 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.812096118927002



buy possibilites: [-1] 
expected returns: [[26.141893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.98346519470215






Player: 1 
cards in hand: [0. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [8. 1. 1. 1. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [8. 1. 1. 1. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [8. 1. 1. 1. 3. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[57.141106]
 [47.153343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  8.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.14189338684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.800568]
 [66.71105 ]
 [54.812668]
 [17.359093]
 [67.875435]
 [59.863342]
 [47.964943]
 [57.95273 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [29. 29.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  5.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  8.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 53.35304260253906



buy possibilites: [-1] 
expected returns: [[75.33915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [29. 29.  8.  0.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  8.] 
adversary cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 67.87541961669922






Player: 1 
cards in hand: [ 1.  0.  6. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 11.  8.] 
cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 11.  8.] 
cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 11.  8.] 
cards in discard: [8. 1. 1. 1. 3. 0. 3. 0. 3. 0. 3. 6. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  8.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.  8.] 
expected returns: [[23.554314]
 [35.779907]
 [11.542133]
 [11.542133]
 [25.907133]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10.  8.] 
cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.33914947509766



action possibilites: [-1] 
expected returns: [[21.493544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.46583557128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  6.1392922]
 [-27.205698 ]
 [ 21.16371  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.49354362487793






Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8. 25.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8. 25.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3. 11.  8. 25.] 
adversary cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 25.] 
expected returns: [[21.558598]
 [32.05259 ]
 [32.05259 ]
 [23.61102 ]
 [62.760963]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  8. 25.] 
cards in discard: [29. 29.  8.  0.  0.  0. 11.  0.  0.  0. 10.  3. 10. 11. 10.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  8. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.163724899291992



action possibilites: [-1] 
expected returns: [[9.000452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.760986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  1.1331186]
 [-25.233778 ]
 [ 11.475637 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.000452041625977






Player: 1 
cards in hand: [3. 3. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[28.887766]
 [47.354477]
 [18.96557 ]
 [30.838404]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10.  8.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.475654602050781



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[38.587914]
 [28.433058]
 [40.507126]
 [57.31504 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8. 29.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.42969512939453



action possibilites: [-1. 10.  8. 10.] 
expected returns: [[58.15773 ]
 [47.709427]
 [60.137596]
 [47.709427]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8. 10.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 10 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.31504440307617



action possibilites: [-1] 
expected returns: [[80.856064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 66.78842163085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 75.45324 ]
 [ 94.38972 ]
 [ 82.91342 ]
 [ 48.122234]
 [ 88.847786]
 [ 95.5234  ]
 [ 87.75419 ]
 [103.80819 ]
 [ 60.2529  ]
 [ 76.538795]
 [ 78.74223 ]
 [ 85.949005]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.85606384277344



buy possibilites: [-1] 
expected returns: [[79.61691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 1.] 
adversary cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.8082275390625






Player: 1 
cards in hand: [6. 0. 6. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29] -> size -> 24 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29] -> size -> 24 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 1.] 
cards in discard: [29.  3.  0.  1.  3.  0.  6.  0.  8.  3.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29] -> size -> 24 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[24.332747]
 [36.498787]
 [12.39856 ]
 [26.719011]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  8.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.61691284179688



action possibilites: [-1] 
expected returns: [[21.059776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.356468200683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.722036]
 [18.732798]
 [-9.301668]
 [22.509176]
 [21.168238]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  5.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.059776306152344



buy possibilites: [-1] 
expected returns: [[3.33077]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 22.509183883666992






Player: 1 
cards in hand: [ 1.  1.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  1. 11.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 7 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[48.902916]
 [58.925713]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 1.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.3307700157165527



action possibilites: [-1] 
expected returns: [[21.282013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 1.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.11515045166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.419998]
 [ 31.125605]
 [ 18.746834]
 [-20.265247]
 [ 32.329227]
 [ 24.002396]
 [ 11.623615]
 [ 21.960022]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  4.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 1.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.282012939453125



buy possibilites: [-1] 
expected returns: [[-9.942891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11.  3. 11.  8. 10. 11. 29. 29. 29.  8.  0.  0. 10. 10.  8. 11.  0.
  0. 10.  8. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6. 8. 1.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.] 
adversary owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 32.3292121887207






Player: 1 
cards in hand: [8. 0. 6. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 1.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  8. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  8. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11. 10.] 
expected returns: [[33.721928]
 [24.308777]
 [35.451256]
 [24.308777]
 [42.963215]
 [24.308777]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [1. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.942891120910645



action possibilites: [-1] 
expected returns: [[26.548124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 10.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [1. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.68893051147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.22074 ]
 [-7.587868]
 [29.409712]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10. 10.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [1. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.548124313354492






Player: 1 
cards in hand: [1. 3. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 6. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 6. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 6. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.83869 ]
 [50.997585]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [10. 11. 10.  8. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.40972328186035



action possibilites: [-1] 
expected returns: [[29.257898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.85106658935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 17.31702 ]
 [ 36.44984 ]
 [ 25.016382]
 [-10.273834]
 [ 37.572033]
 [ 29.871267]
 [ 18.43779 ]
 [ 28.026941]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  3.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.257898330688477



buy possibilites: [-1] 
expected returns: [[27.585352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.57204055786133






Player: 1 
cards in hand: [ 6. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  3.  3.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  1.  1.  0.  1. 11.  0.  8.  6.  8.  1. 29.  1.  3.  1.  6.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 5.230003]
 [22.809542]
 [-4.08702 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.585351943969727



action possibilites: [-1. 10. 11.] 
expected returns: [[14.634422 ]
 [ 5.6523643]
 [23.75371  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 11.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.8095645904541



action possibilites: [-1] 
expected returns: [[1.8254275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.71834945678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ -5.784346  ]
 [  9.217447  ]
 [  0.08021116]
 [-27.285524  ]
 [ 10.147909  ]
 [  3.8035665 ]
 [  2.436481  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  2.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.825427532196045



buy possibilites: [-1] 
expected returns: [[7.9140363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 10.147912979125977






Player: 1 
cards in hand: [ 0.  8. 29.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  1.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 29. 11. 25.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 29. 11. 25.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 29. 11. 25.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 3.] 
cards in discard: [0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29.  8. 29. 11. 25.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29.  8. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11. 25.] 
expected returns: [[ 7.985148]
 [24.281635]
 [ 9.768808]
 [24.281635]
 [16.784683]
 [40.124508]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29. 11. 25.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  7. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.914036273956299



action possibilites: [-1] 
expected returns: [[-5.5593543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29. 11.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.124473571777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-13.516846]
 [-31.894762]
 [ -5.452415]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 29. 11.  0. 10.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.559354305267334






Player: 1 
cards in hand: [ 6.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  8.  0. 11.  8.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 22. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  8.  0. 11.  8.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [11.  8.  0. 11.  8.] 
adversary cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.  8.] 
expected returns: [[-13.11479 ]
 [ -8.022099]
 [-12.238544]
 [ -8.022099]
 [-12.238544]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.  8.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 29.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.452420711517334



action possibilites: [-1] 
expected returns: [[-13.642237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  8.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 29.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 169 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -1.7986140251159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-22.263199]
 [-41.58755 ]
 [-14.644526]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  8.] 
cards in discard: [10. 11. 10.  8. 10. 10. 10. 11. 11.  0.  3.  0.  0. 10. 11. 29. 11.  3.
  0.  0. 10. 25. 29.  8. 29. 11.  0. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  6. 29.  1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.642236709594727






Player: 1 
cards in hand: [ 1.  0.  6. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 29.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 29.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  1.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6. 29.  1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  0.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-5.6912947]
 [-4.464857 ]
 [ 1.7530484]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  6. 10.  0.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 3. 8. 1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.644533157348633



action possibilites: [-1] 
expected returns: [[-1.9476905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 3. 8. 1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 0.8239994049072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-10.428399  ]
 [ -3.885475  ]
 [-32.692635  ]
 [  0.21897411]
 [ -1.2010984 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  4.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 3. 8. 1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.947690486907959



buy possibilites: [-1] 
expected returns: [[17.588552]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [1. 8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 3. 8. 1.] 
adversary cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
adversary owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 0.21896696090698242






Player: 1 
cards in hand: [0. 1. 3. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 8. 1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11  6  0  1  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1
  1  6  1 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10. 15. 10. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10. 15. 10. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1  8] -> size -> 36 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 0.  1. 29.  8.  1.  6.  3.  6.  1.  6.  0. 11.  0.  1. 11.  1.  0.  6.
 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10. 15. 10. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1  8] -> size -> 36 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 15. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15. 10. 10.] 
expected returns: [[ 5.551088 ]
 [ 6.9249873]
 [-2.5544465]
 [-0.6431174]
 [-2.5544465]
 [-2.5544465]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15. 10. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 10 11 11  8 10  8 29 11 10 29
 10  8 10 11 10 10 11 10 11 15  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 1. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.588552474975586



action possibilites: [-1] 
expected returns: [[-0.01189375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 1. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 11.866262435913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-12.164297 ]
 [-37.81144  ]
 [ -1.4843407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 1. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.011893749237060547






Player: 1 
cards in hand: [6. 1. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0.  0. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  5. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0.  0. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 0. 3.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0.  0. 10.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-11.421293 ]
 [-19.703733 ]
 [ -2.3756104]
 [-19.703733 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  6. 10.  0.  3.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  6.  1.  1.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.4843387603759766



action possibilites: [-1] 
expected returns: [[-7.7737637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  3.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  6.  1.  1.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -3.4068870544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-17.025679]
 [-10.149738]
 [-40.15399 ]
 [ -5.824172]
 [ -7.397766]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  3.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  6.  1.  1.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.773763656616211



buy possibilites: [-1] 
expected returns: [[21.969034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 29.  6.  1.  1.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -5.824151515960693






Player: 1 
cards in hand: [ 1. 29.  6.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6.  1.  1.] 
cards in discard: [29.  6.  1.  1.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 11. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 6.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 11. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 19. 30. 28. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 11. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 19. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 11. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 11.] 
expected returns: [[-12.751768]
 [ -3.613298]
 [ -3.613298]
 [ -3.613298]
 [ -3.613298]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 11. 11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.96903419494629



action possibilites: [-1] 
expected returns: [[-9.291373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -4.692258358001709





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-19.238436]
 [-41.80729 ]
 [-10.157663]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 6. 1. 0.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.291373252868652






Player: 1 
cards in hand: [3. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  8. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  8. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 0.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 29.  8. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 29.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8. 10. 11.] 
expected returns: [[-22.142355]
 [-27.89787 ]
 [-10.165922]
 [-21.141405]
 [-27.89787 ]
 [-16.432808]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8. 10. 11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -10.157659530639648



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[-18.494835]
 [-25.938093]
 [-10.931744]
 [ -4.485689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.19993019104004



action possibilites: [-1. 11.] 
expected returns: [[-4.519606]
 [ 4.205771]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.80134105682373



action possibilites: [-1] 
expected returns: [[-24.403627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 3.203458309173584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-33.467316]
 [-27.276026]
 [-54.65386 ]
 [-23.48694 ]
 [-24.951807]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  2.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.403627395629883



buy possibilites: [-1] 
expected returns: [[-21.86222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 1. 1. 8.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
adversary owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -23.486940383911133






Player: 1 
cards in hand: [0. 8. 1. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 1. 8.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 11  6  0  1  3  6  1  1  8  3  1 29  6  0  1  0  0 29  1  1  6
  1 11 29  3 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  0. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  0. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  0. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25. 29.  0. 10. 11.] 
adversary cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25. 29.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11.] 
expected returns: [[-22.617014 ]
 [ -0.9185538]
 [-11.507092 ]
 [-28.70517  ]
 [-16.67688  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 10. 11.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  6. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.862220764160156



action possibilites: [-1] 
expected returns: [[-23.03483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11.  8.  3.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.9185566902160645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-29.96141 ]
 [-48.488934]
 [-23.034838]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10. 11.  8.  3.] 
cards in discard: [ 1.  8. 11.  0.  8.  3.  0.  8. 15. 10. 10.  1.  8. 11. 10.  0.  0. 10.
  1. 11.  0. 11. 11. 11. 10.  8. 10.  0.  1.  8. 29. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 17. 30. 27. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -23.03483009338379






Player: 1 
cards in hand: [ 0.  0. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 11.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 27. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 11.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 17. 30. 27. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 11.] 
cards in discard: [29.  6.  1.  1.  0.  3.  6.  1.  3. 29.  1.  1.  6. 14.  3.  0.  6.  1.
  0.  0.  8.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[-23.637596]
 [-17.402725]
 [-11.745719]
 [-17.402725]
 [-31.654692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 29.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -23.03483009338379



action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-13.956053 ]
 [ -6.4927793]
 [ -6.4927793]
 [-12.455132 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.] 
cards in discard: [ 0. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 29.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -18.198741912841797



action possibilites: [-1] 
expected returns: [[4.6168504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.] 
cards in discard: [ 0. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 29.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -7.383034706115723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.414994]
 [-25.424067]
 [  5.115972]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.] 
cards in discard: [ 0. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1.  0. 29.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.61685037612915






Player: 1 
cards in hand: [ 1.  0. 29.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  6. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  0. 10. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.] 
cards in discard: [0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  0. 10. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [ 0.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 10.  0. 10. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 0.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 10.  0. 10. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 0.  6. 15.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 10.  0. 10. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-11.23682  ]
 [-18.24392  ]
 [-18.24392  ]
 [ -3.8592877]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 10. 11.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3.  1. 11.  6.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.115986347198486



action possibilites: [-1] 
expected returns: [[-15.429432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 10.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3.  1. 11.  6.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -4.745372772216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-23.110891]
 [ -9.146257]
 [-17.485151]
 [-45.76032 ]
 [-13.944288]
 [-15.239103]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 10.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 15. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3.  1. 11.  6.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.429431915283203



buy possibilites: [-1] 
expected returns: [[-2.6666217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 10.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3.  1. 11.  6.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -9.146262168884277






Player: 1 
cards in hand: [29.  3.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 11.  6.] 
cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15.  0. 25.  8.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.] 
cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15.  0. 25.  8.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 25.  8.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 25.  8.] 
adversary cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 15.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 25.  8.] 
expected returns: [[ 0.38042212]
 [13.355253  ]
 [-4.9858074 ]
 [26.997683  ]
 [ 1.6316371 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0. 25.  8.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 26. 30.  8.  5. 10.  0.  1.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 1.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15. 29. 11.  3.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.666621685028076



action possibilites: [-1] 
expected returns: [[-65.747086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0.  8.  0.  8.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 26. 30.  8.  4. 10.  0.  1.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 1.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15. 29. 11.  3.  6.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.9976749420166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-75.04398 ]
 [-66.78295 ]
 [-98.70814 ]
 [-61.463142]
 [-63.642986]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  0.  8.  0.  8.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 14. 30. 26. 30.  8.  4. 10.  0.  1.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 1.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15. 29. 11.  3.  6.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -65.74708557128906



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 8 
Witch: 1 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 15.  0.  8.  0.  8.] 
cards in discard: [ 0. 10.  1. 29. 11. 11.  8.  1.  1. 11.  1. 10.  0. 10.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 25 11  8 11 11  8 10  8 29 11 10 29 10
  8 10 11 10 10 11 10 11 15  1  8  1  8  1  1  8  1  1  1  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 26. 30.  8.  4. 10.  0.  0.  9.  4.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 1.] 
adversary cards in discard: [ 0.  6. 15.  0. 29. 11.  1.  6.  1. 14. 15. 29. 11.  3.  6.  6.] 
adversary owned cards: [ 0 11  6  0  3  6  1  8  3  1 29  6  0  1  0  0 29  1  1  6  1 11 29  3
 14  0  6  3 15  0 15  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0     -90       0       0       8       0] 
sum of rewards: 3000023 

action type: buy - action 8.0
Learning step: 120003.375
desired expected reward: 119941.9140625



