 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.072855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.439399719238281
desired expected reward: -5.792742729187012





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.17169 ]
 [20.489937]
 [19.068357]
 [14.980381]
 [21.988886]
 [21.079632]
 [19.654362]
 [20.280893]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.461978912353516



buy possibilites: [-1] 
expected returns: [[20.929653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.98888397216797






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.466858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.92965316772461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.09846 ]
 [23.432978]
 [22.007711]
 [17.856514]
 [21.83551 ]
 [24.951485]
 [24.02334 ]
 [25.304333]
 [20.780725]
 [22.597403]
 [23.115246]
 [23.223936]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.70461654663086



buy possibilites: [-1] 
expected returns: [[25.572983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.304332733154297






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.520643]
 [25.204994]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.572982788085938



action possibilites: [-1] 
expected returns: [[23.478378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 26.434040069580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.446877]
 [23.781393]
 [22.35613 ]
 [18.244896]
 [25.280342]
 [24.371086]
 [22.94582 ]
 [23.572351]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.478378295898438



buy possibilites: [-1] 
expected returns: [[24.717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 25.28034210205078






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.438416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.716999053955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.772625]
 [26.144276]
 [24.69415 ]
 [20.598515]
 [27.669285]
 [26.744198]
 [25.294077]
 [25.93153 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.502620697021484



buy possibilites: [-1] 
expected returns: [[25.932877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.66928482055664






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  3.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[22.18945 ]
 [21.606647]
 [23.831926]
 [24.169998]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.932876586914062



action possibilites: [-1. 10. 11.] 
expected returns: [[28.374067]
 [27.71708 ]
 [30.188091]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.369178771972656



action possibilites: [-1] 
expected returns: [[27.506886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.69530487060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.589796]
 [27.985544]
 [26.522888]
 [22.327919]
 [26.346104]
 [29.52926 ]
 [28.590677]
 [29.891165]
 [25.26376 ]
 [27.128023]
 [27.659506]
 [27.770967]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.506885528564453



buy possibilites: [-1] 
expected returns: [[33.377937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.89116668701172






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[33.434025]
 [35.20399 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.37793731689453



action possibilites: [-1] 
expected returns: [[30.85736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.71384048461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.94749 ]
 [25.782906]
 [31.032007]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.85736083984375






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [22.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[26.95134 ]
 [28.734802]
 [28.734802]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.032007217407227



action possibilites: [-1] 
expected returns: [[27.828585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.319568634033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.973568]
 [28.327545]
 [26.89037 ]
 [22.704683]
 [29.838896]
 [28.922089]
 [27.484917]
 [28.116632]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.828584671020508



buy possibilites: [-1] 
expected returns: [[26.527748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.83889389038086






Player: 1 
cards in hand: [ 0.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[29.64014 ]
 [31.695843]
 [29.01895 ]
 [31.695843]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  3. 29.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.527748107910156



action possibilites: [-1. 10. 29.] 
expected returns: [[32.107403]
 [31.502632]
 [34.09015 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.79430389404297



action possibilites: [-1. 10. 11.] 
expected returns: [[36.47134 ]
 [35.839005]
 [38.195625]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 11.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.09014892578125



action possibilites: [-1] 
expected returns: [[40.266396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.62934875488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.31867 ]
 [40.751183]
 [39.26612 ]
 [34.99151 ]
 [39.0866  ]
 [42.313087]
 [41.365643]
 [42.673138]
 [37.987625]
 [39.880577]
 [40.42014 ]
 [40.533314]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  6. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.266395568847656



buy possibilites: [-1] 
expected returns: [[40.94379]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 22.  0.] 
adversary cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 32  0] 
sum of rewards: 87 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.67313766479492






Player: 1 
cards in hand: [ 0.  0.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 22.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 22.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 22.  0.] 
cards in discard: [29. 29.  0.  0.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[37.181046]
 [36.530464]
 [36.530464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.943790435791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.13782 ]
 [36.08208 ]
 [31.77112 ]
 [38.17457 ]
 [37.345016]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.19002151489258



buy possibilites: [-1] 
expected returns: [[36.010246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0. 10. 29. 29. 29. 11.  0. 10.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 38.17456817626953






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10. 11. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10. 11. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [10. 11. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10. 11. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[30.566935]
 [29.934889]
 [32.29039 ]
 [32.29039 ]
 [32.29039 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.01024627685547



action possibilites: [-1] 
expected returns: [[33.361015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.771217346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.055069]
 [27.617952]
 [33.35649 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 29.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.36101531982422






Player: 1 
cards in hand: [ 3. 29.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 29.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 29. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29. 22.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 29. 22.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 29. 22.] 
cards in discard: [11.  0.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[24.875103]
 [24.288206]
 [24.288206]
 [24.288206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.35649108886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.134642]
 [23.984241]
 [20.169632]
 [25.897724]
 [25.12376 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  9. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.93012809753418



buy possibilites: [-1] 
expected returns: [[34.084232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  8. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 25.897720336914062






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  8. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  8. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  0.  0.  3. 29.  3.  3.  0. 29. 22.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.311909]
 [32.14911 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.084232330322266



action possibilites: [-1. 29.] 
expected returns: [[36.86377]
 [38.95182]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.18098449707031



action possibilites: [-1. 10.] 
expected returns: [[38.144463]
 [37.49711 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.951820373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[36.026093]
 [38.438744]
 [36.965805]
 [34.219055]
 [32.878372]
 [36.787712]
 [39.987873]
 [39.048153]
 [42.222427]
 [40.344917]
 [35.697716]
 [35.849922]
 [37.57522 ]
 [33.571472]
 [38.110363]
 [38.222572]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.14446258544922



buy possibilites: [-1] 
expected returns: [[36.617966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 42.2224235534668






Player: 1 
cards in hand: [3. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25] -> size -> 26 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25] -> size -> 26 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[37.041058]
 [37.787384]
 [38.95977 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [3. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.61796569824219



action possibilites: [-1.  8. 11.] 
expected returns: [[36.440994]
 [37.214012]
 [38.093887]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 11.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [3. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.95977020263672



action possibilites: [-1] 
expected returns: [[40.00072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [3. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.47322082519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.698658]
 [40.17799 ]
 [38.66432 ]
 [34.371883]
 [41.76992 ]
 [40.804256]
 [39.29059 ]
 [39.955906]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [3. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.0007209777832



buy possibilites: [-1] 
expected returns: [[34.865356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [10. 11. 10. 11. 11.  3.  8. 10.  0.  0. 10. 10. 25. 29. 29.  0.  0.  0.
  3. 10. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [3. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.769920349121094






Player: 1 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [3. 0. 3. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [3. 0. 3. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [3. 0. 3. 8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [ 3.  0.  3.  8.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[33.8301  ]
 [33.19776 ]
 [34.636482]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10
  8 25 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.8653564453125



action possibilites: [-1] 
expected returns: [[22.049995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 36.848663330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.358582]
 [17.54869 ]
 [22.293245]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.04999542236328






Player: 1 
cards in hand: [ 3.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  0.  3.  8.  3. 15. 29.  0.  3.  0.  0. 22.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8.] 
expected returns: [[36.064392]
 [35.403996]
 [38.22946 ]
 [35.403996]
 [36.906597]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  8.  3.] 
cards in discard: [ 8. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.293245315551758



action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[38.37732 ]
 [37.731937]
 [37.731937]
 [39.200325]
 [40.493076]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3. 29.] 
cards in discard: [ 8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.30666732788086



action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[42.23701 ]
 [41.618008]
 [41.618008]
 [43.026447]
 [43.924946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3. 11.] 
cards in discard: [ 8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  3.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.49307632446289



action possibilites: [-1] 
expected returns: [[46.60497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [ 8. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.33362579345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.467796]
 [45.430542]
 [41.03517 ]
 [47.564022]
 [46.71824 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [ 8. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.6049690246582



buy possibilites: [-1] 
expected returns: [[45.47959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [ 8. 10. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  8  0] 
sum of rewards: 63 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 47.56401824951172






Player: 1 
cards in hand: [29. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  9. 10.  4.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8.  9. 10.  4.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.] 
cards in discard: [ 6. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  9. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [11. 25. 10. 10. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11. 25. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 10. 10.] 
expected returns: [[32.42862 ]
 [34.04905 ]
 [36.100548]
 [31.834446]
 [31.834446]
 [31.834446]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 10. 10.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  9. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [22. 29. 15.  3.  3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.479591369628906



action possibilites: [-1] 
expected returns: [[32.644367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10. 29.  3.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [22. 29. 15.  3.  3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.100547790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.766926]
 [27.792877]
 [32.7523  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10. 10. 29.  3.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [22. 29. 15.  3.  3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.64436721801758






Player: 1 
cards in hand: [22. 29. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 29. 15.  3.  3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 11. 11.  0. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 29. 15.  3.  3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 11. 11.  0. 10.] 
adversary cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[30.057436]
 [31.584644]
 [31.584644]
 [29.502407]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 10.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  2.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.75230407714844



action possibilites: [-1] 
expected returns: [[30.274437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.875404357910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.414082]
 [29.231693]
 [25.498941]
 [31.043493]
 [30.325212]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.
 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  6.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.274436950683594



buy possibilites: [-1] 
expected returns: [[29.80052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [ 8. 10. 10.  8. 29. 29. 11. 10. 10.  8.  3. 25. 11. 10. 10. 10. 29.  3.
 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 31.04349136352539






Player: 1 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[29.89328 ]
 [31.562061]
 [31.562061]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.800519943237305



action possibilites: [-1] 
expected returns: [[28.7339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.951053619384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[27.10354 ]
 [29.329718]
 [27.95985 ]
 [24.050459]
 [30.82155 ]
 [29.916613]
 [29.122044]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  3.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.73390007019043



buy possibilites: [-1] 
expected returns: [[39.8024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.821548461914062






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11. 29.  0.  0.  0.  6. 22. 29. 15.  3.  3.  0.  8.  0.  0.  3.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [ 8. 11. 10. 10. 29.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10. 29.] 
expected returns: [[29.09194 ]
 [29.897148]
 [30.813705]
 [28.461224]
 [28.461224]
 [31.164053]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 10. 29.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.802398681640625



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[39.836494]
 [41.538136]
 [39.212204]
 [39.212204]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.302743911743164



action possibilites: [-1] 
expected returns: [[35.141796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.970252990722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.004368]
 [33.93601 ]
 [29.731558]
 [36.00047 ]
 [35.182   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  5.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.14179611206055



buy possibilites: [-1] 
expected returns: [[35.59992]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  4.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.00046920776367






Player: 1 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  4.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [25. 11. 11. 10. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  4.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [25. 11. 11. 10. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [25. 11. 11. 10. 10.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25. 11. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 10. 10.] 
expected returns: [[33.901825]
 [37.661106]
 [35.561012]
 [35.561012]
 [33.293423]
 [33.293423]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11. 10. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  8. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.599918365478516



action possibilites: [-1] 
expected returns: [[25.852562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10. 10. 29.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.661102294921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.869247]
 [21.107775]
 [25.770317]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10. 10. 10. 29.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.852561950683594






Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [8. 0. 0. 6. 0. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5. 10. 10.  0.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
expected returns: [[37.27339 ]
 [38.035393]
 [36.67584 ]
 [38.035393]
 [38.035393]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8.  3.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 10 11 11 10 29 10 10 11 10 29  8 10  8 25 10
 11 10  8 10  8 10 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  3. 22.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.77031707763672



action possibilites: [-1] 
expected returns: [[25.746895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  3. 22.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 40.323394775390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.899696]
 [21.060635]
 [25.843645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  3. 22.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.74689483642578






Player: 1 
cards in hand: [11.  3. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 22.  0.  3.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 29. 10. 10.  0.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 22.  0.  3.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 29. 10. 10.  0.] 
adversary cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[39.11396 ]
 [41.043797]
 [38.5336  ]
 [38.5336  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 10.  0.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 29. 15.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.843645095825195



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[36.617355]
 [36.015705]
 [36.015705]
 [36.015705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 29. 15.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.3077392578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.500916]
 [35.374214]
 [31.41573 ]
 [37.312046]
 [36.542175]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  3.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 29. 15.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.61735534667969



buy possibilites: [-1] 
expected returns: [[31.395258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.] 
cards in discard: [10. 11. 11. 11.  0.  0.  0.  8. 15.  8. 29. 11. 10. 10.  0. 25. 11. 11.
 10. 10. 10. 29.  8.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 29. 15.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.31204605102539






Player: 1 
cards in hand: [ 0. 29. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  8.  3.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  8.  3.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  7. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  8.  3.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  7. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11. 10. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25. 10.] 
expected returns: [[20.460957]
 [19.908869]
 [21.974886]
 [19.908869]
 [23.910118]
 [19.908869]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 25. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  7. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.3952579498291



action possibilites: [-1] 
expected returns: [[27.961754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.910118103027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.311443]
 [23.381245]
 [28.232372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0.  6.  3. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.961753845214844






Player: 1 
cards in hand: [ 0.  0.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 10.  8.  3. 29.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 10.  8.  3. 29.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 11.] 
cards in discard: [ 8.  0.  0.  6.  0.  3.  6. 14.  0.  0.  0. 29.  0. 11.  3. 22.  0.  3.
  0.  0. 29. 15.  8.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 10.  8.  3. 29.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 10.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[30.073917]
 [29.484264]
 [29.484264]
 [30.82579 ]
 [32.0068  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3. 29.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 22.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.232372283935547



action possibilites: [-1. 10. 10.  8.  8.] 
expected returns: [[36.35493 ]
 [35.791252]
 [35.791252]
 [37.073635]
 [37.073635]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  8.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 10 29 10 10 11 10 29 10  8 25 10 11 10  8
 10  8 10 11 15  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 22.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.27084732055664



action possibilites: [-1] 
expected returns: [[34.475655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 22.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 36.42694091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.616913]
 [29.654154]
 [34.590027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 22.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.47565460205078






Player: 1 
cards in hand: [ 6. 22.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.  8.] 
expected returns: [[30.69376 ]
 [31.472233]
 [31.472233]
 [30.093075]
 [31.472233]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.  0.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29 11 11 29 10 10 11 10 29 10  8 25 10 11 10  8 10
  8 10 11 15  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.59002685546875



action possibilites: [-1] 
expected returns: [[24.94932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 33.67866516113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.245066]
 [20.551311]
 [25.036564]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  8.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.94931983947754






Player: 1 
cards in hand: [ 0. 14.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  8.  0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6 14  0  6  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  2.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  1.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [10. 11.  0. 15.  0.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[27.259579]
 [26.722555]
 [28.825819]
 [27.166409]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  1.  9.  5.  9. 10.  0.  9.  8.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.036563873291016



action possibilites: [-1] 
expected returns: [[26.046103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  1.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.182613372802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.379257]
 [25.17434 ]
 [21.544441]
 [26.936174]
 [26.237637]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  1.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.04610252380371



buy possibilites: [-1] 
expected returns: [[28.196419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  0.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 26.936176300048828






Player: 1 
cards in hand: [11.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6
  0  0  8  6  0  6  3  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 25. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 11. 29. 10.] 
adversary cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[23.151798]
 [22.62981 ]
 [24.584703]
 [24.876097]
 [22.62981 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29. 10.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0. 11.  6. 29.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.19641876220703



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[24.480635]
 [23.952602]
 [23.952602]
 [26.211632]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0. 11.  6. 29.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 23.817787170410156



action possibilites: [-1. 10.] 
expected returns: [[24.503899]
 [24.002625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.  0. 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0. 11.  6. 29.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.65697479248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[22.850307]
 [23.55837 ]
 [20.337261]
 [24.531525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 10. 11. 10. 10. 11.  0.  3. 29.  8. 10.  8.  8.  8. 15.  8. 11. 10.
  0. 15.  0.  0. 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 1 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0. 11.  6. 29.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.50389862060547






Player: 1 
cards in hand: [ 6.  0. 11.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  6. 29.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 15. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  6. 29.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [10.  0. 15. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  0. 15. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 11.] 
expected returns: [[24.966894]
 [24.410164]
 [24.868956]
 [26.543585]
 [26.543585]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 11. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.531524658203125



action possibilites: [-1] 
expected returns: [[24.48832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 11.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 25.698091506958008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.853004]
 [20.101145]
 [24.703106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15. 11.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0. 29.  3.  3.  3.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.488319396972656






Player: 1 
cards in hand: [ 0. 29.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  3.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 11. 10.  8.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 11. 10.  8.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 11. 10.  8.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 11. 10.  8.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.  8.] 
expected returns: [[33.59192]
 [34.27109]
 [35.04419]
 [33.05932]
 [34.27109]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 10.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  6.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.703105926513672



action possibilites: [-1] 
expected returns: [[34.205154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 34.27109146118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.425682]
 [29.51698 ]
 [34.363106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.20515441894531






Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0. 29.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [25. 10. 29. 11. 11.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 0.  6. 22.  3.  0.  3.  8.  8.  0.  0.  0.  3.  8. 11.  0.  0.  6.  0.
 11.  6. 29.  0. 15.  0. 29.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [25. 10. 29. 11. 11.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 10. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 11. 11.] 
expected returns: [[29.037683]
 [32.40241 ]
 [28.49384 ]
 [30.82305 ]
 [30.522564]
 [30.522564]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29. 11. 11.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  6. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.36310958862305



action possibilites: [-1] 
expected returns: [[27.497967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 11. 11.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.402408599853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.850983]
 [23.14421 ]
 [27.6255  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11. 11. 11.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.497966766357422






Player: 1 
cards in hand: [11.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0
  0  8  6  0  6  3  0  8  3  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  0. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  0. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  0. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [6. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10.  0. 10. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 29.] 
expected returns: [[27.636671]
 [28.361546]
 [27.081076]
 [27.081076]
 [29.508844]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 10. 29.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [22.  0.  3.  0.  3.] 
adversary cards in discard: [ 6.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.625499725341797



action possibilites: [-1. 10. 10.] 
expected returns: [[28.39121 ]
 [27.831648]
 [27.831648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [22.  0.  3.  0.  3.] 
adversary cards in discard: [ 6.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.822460174560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[26.626877]
 [27.439083]
 [23.890327]
 [28.525364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [22.  0.  3.  0.  3.] 
adversary cards in discard: [ 6.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.39120864868164






Player: 1 
cards in hand: [22.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.  0.  3.] 
cards in discard: [ 6.  0.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0.  8. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0. 8. 3.] 
cards in discard: [ 6.  0.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0.  8. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 8. 3.] 
cards in discard: [ 6.  0.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 10.  0.  8. 29.] 
adversary cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[33.09909 ]
 [32.588066]
 [33.750923]
 [34.822975]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8. 29.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.52536392211914



action possibilites: [-1. 10.  8.] 
expected returns: [[35.129066]
 [34.591534]
 [35.81454 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 10 11 10 29 10 25 10 11 10  8 10  8 10 11
 15  8  8 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 35.764915466308594



action possibilites: [-1] 
expected returns: [[30.339039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 35.236106872558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[28.436497]
 [29.22416 ]
 [25.773537]
 [30.28147 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 11. 10.  0. 15. 11. 15. 11.  0.  8. 10.  8. 25. 10. 29. 11. 11. 11.
  8.  8. 10. 29.  0. 10. 10.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  0.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.339038848876953






Player: 1 
cards in hand: [ 0.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6
  0  6  3  0  8  3  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [15. 11.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [15. 11.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 30. 30. 24. 30.  8.  5. 10.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [15. 11.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [15. 11.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15. 11.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.  8.  8. 29.] 
expected returns: [[22.99267 ]
 [22.89558 ]
 [24.522964]
 [23.708431]
 [23.708431]
 [24.832397]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  6. 29.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.281471252441406



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[25.521542]
 [26.198742]
 [26.198742]
 [24.99949 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 10 29 10 25 10 11 10  8 10  8 10 11 15
  8  8 15  8 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  6. 29.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.180259704589844



action possibilites: [-1] 
expected returns: [[19.840576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  6. 29.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 25.58906364440918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.377558]
 [15.911238]
 [20.102072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  6. 29.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.840576171875






Player: 1 
cards in hand: [ 6.  6. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  3.  0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 10. 11. 15.] 
adversary cards in discard: [15. 11. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 10. 11. 15.] 
adversary cards in discard: [15. 11. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 10. 11. 15.] 
adversary cards in discard: [15. 11. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [11. 15. 10. 11. 15.] 
adversary cards in discard: [15. 11. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11. 15. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 11. 15.] 
expected returns: [[25.260418]
 [26.79827 ]
 [25.163582]
 [24.702143]
 [26.79827 ]
 [25.163582]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 11. 15.] 
cards in discard: [15. 11. 29.  8.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 11.  6.  6.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.10207176208496



action possibilites: [-1] 
expected returns: [[25.335548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 15.] 
cards in discard: [15. 11. 29.  8.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 8. 11.  6.  6.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 25.972518920898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.617075]
 [20.947792]
 [25.38442 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11. 15.] 
cards in discard: [15. 11. 29.  8.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 8. 11.  6.  6.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.335548400878906






Player: 1 
cards in hand: [ 8. 11.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  6.  0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0.  8. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0.  8. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0.  8. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 11.] 
expected returns: [[29.268719]
 [29.96932 ]
 [29.96932 ]
 [28.722027]
 [30.77227 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10. 11.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  4.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1. 11.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.38442039489746



action possibilites: [-1] 
expected returns: [[21.600647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1. 11.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 29.969318389892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.085205]
 [17.728313]
 [21.69614 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8. 10.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1. 11.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.60064697265625






Player: 1 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 6.  0.  8. 11. 22.  0.  3.  0.  3.  0.  8.  3. 16. 15.  3.  0.  0.  6.
  3.  3. 29.  6.  0.  3.  1. 11.  8.  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 23. 30.  8.  5.  9.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[28.528786]
 [30.334755]
 [30.334755]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1.  8.  3.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.69614028930664



action possibilites: [-1. 15.] 
expected returns: [[33.976776]
 [33.88127 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1.  8.  3.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.71083641052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[32.024532]
 [32.824516]
 [29.22229 ]
 [33.894417]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [ 1.  8.  3.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.976776123046875






Player: 1 
cards in hand: [ 1.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [10.  8.  0. 10. 11.] 
adversary cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11.] 
expected returns: [[30.783627]
 [30.221828]
 [31.5072  ]
 [30.221828]
 [32.333435]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10. 11.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  3.] 
adversary cards in hand: [16.  6. 15.  0.  0.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.8944206237793



action possibilites: [-1] 
expected returns: [[27.562656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [16.  6. 15.  0.  0.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 31.5072021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.92844 ]
 [23.454414]
 [27.588737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 10.] 
cards in discard: [15. 11. 29.  8.  8. 15. 11. 15. 10. 11. 15. 15. 11.  8.  0.  8. 10.  0.
 29. 29.  0.  3. 15. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [16.  6. 15.  0.  0.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.56265640258789






Player: 1 
cards in hand: [16.  6. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 15.  0.  0.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0
  6  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  2.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [10.  8. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  8. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 10. 25.] 
expected returns: [[27.573   ]
 [27.012623]
 [28.287624]
 [29.10974 ]
 [27.012623]
 [31.079151]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 10. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  5.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11] -> size -> 37 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.58873748779297



action possibilites: [-1] 
expected returns: [[30.904102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.079151153564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.22792 ]
 [26.408937]
 [31.091858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11. 10.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.904102325439453






Player: 1 
cards in hand: [8. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 15. 11.  3. 29.] 
adversary cards in discard: [25. 10.  8. 11. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 15. 11.  3. 29.] 
adversary cards in discard: [25. 10.  8. 11. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[30.028334]
 [29.932627]
 [31.542128]
 [31.850155]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3. 29.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  6.  8.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.09185791015625



action possibilites: [-1. 15. 11. 11.] 
expected returns: [[30.392359]
 [30.298601]
 [31.881927]
 [31.881927]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  6.  8.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.212692260742188



action possibilites: [-1] 
expected returns: [[33.489708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 6.  6.  8.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 31.082477569580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.684801]
 [28.861595]
 [33.57685 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 6.  6.  8.  0. 11.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.489707946777344






Player: 1 
cards in hand: [ 6.  6.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 15.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  8.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 15.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  8.  0. 11.] 
cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [11. 15.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 15.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.  8.] 
expected returns: [[34.250168]
 [35.77945 ]
 [34.15511 ]
 [34.964527]
 [34.964527]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8.  0.  8.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15. 29. 11. 15. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  1.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.  0.  6.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6  0] -> size -> 39 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.57685089111328



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 7 
Witch: 1 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  8.  0.  8.] 
cards in discard: [25. 10.  8. 11. 10.  0. 15.  0.  3. 15. 29. 11. 15. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 11 29 11 29 10 25 10 11 10  8 10  8 10 11 15  8
  8 15  8 15 15 15 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 30.  8.  4.  8.  1.  0.  9.  5.  9. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 3.  3. 16. 29.  0.  0.  0.  1.  1.  8.  3.  0. 11. 11. 15. 16.  6.  0.
  6.  8.  0.  3.  3.  6.  0.  6.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0 29 22  0 29  3 11  3  8 15  3  6 11  6  0  0  8  6  0  6
  3  0  8  3  0  6  0 16  3  1 16  1 11  6  0] -> size -> 39 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -469 

action type: gain_card_n - action 8
Learning step: -15.118935585021973
desired expected reward: 19.845592498779297



