 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[360.41623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -3  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -548 

action type: buy - action -1
Learning step: -54.7374382019043
desired expected reward: -55.363040924072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[347.9262 ]
 [359.31958]
 [365.3689 ]
 [347.68478]
 [347.67776]
 [367.89465]
 [350.57065]
 [354.6155 ]
 [350.66553]
 [356.32004]
 [361.77536]
 [360.38803]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 361.9034729003906



buy possibilites: [-1] 
expected returns: [[328.44046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 367.89459228515625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.30212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 328.4404602050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[353.18936]
 [364.58273]
 [370.63205]
 [352.9479 ]
 [373.1578 ]
 [355.83383]
 [361.58316]
 [365.65118]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 368.1708984375



buy possibilites: [-1] 
expected returns: [[301.42242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 373.15777587890625






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[277.5295]
 [285.0361]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 301.42242431640625



action possibilites: [-1] 
expected returns: [[269.19904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -293 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 278.6820983886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.73376]
 [271.1271 ]
 [277.17642]
 [259.49228]
 [279.70215]
 [262.3782 ]
 [268.12756]
 [272.1956 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0
desired expected reward: 269.19903564453125



buy possibilites: [-1] 
expected returns: [[260.02628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 25 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 279.7021484375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[218.79686]
 [226.30345]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [ 6. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0
desired expected reward: 260.0262756347656



action possibilites: [-1] 
expected returns: [[235.81654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11.  0.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 226.0252227783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[223.9493 ]
 [241.39194]
 [223.70786]
 [226.59373]
 [236.4111 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11.  0.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0
desired expected reward: 235.81654357910156



buy possibilites: [-1] 
expected returns: [[250.20131]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6. 11. 11.  0.  0.  3.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 15 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 241.39195251464844






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3] -> size -> 16 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[250.50441]
 [258.01102]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0
desired expected reward: 250.20130920410156



action possibilites: [-1] 
expected returns: [[248.4159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 257.3146057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[236.97926]
 [254.42192]
 [236.73781]
 [239.62367]
 [249.44109]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0
desired expected reward: 248.4158935546875



buy possibilites: [-1] 
expected returns: [[243.46126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 15 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 254.4219207763672






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3] -> size -> 18 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 6. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[246.01503]
 [253.52165]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  0.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: 0
desired expected reward: 243.4612579345703



action possibilites: [-1] 
expected returns: [[246.27489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -314 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 253.6851348876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[230.85669]
 [248.29938]
 [230.61525]
 [233.50114]
 [243.31851]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: 0
desired expected reward: 246.27488708496094



buy possibilites: [-1] 
expected returns: [[240.66757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 248.2993621826172






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[272.92593]
 [280.43253]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  6. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: 0
desired expected reward: 240.66757202148438



action possibilites: [-1] 
expected returns: [[261.43185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -314 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 276.22119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[251.15617]
 [268.59885]
 [250.91472]
 [253.80061]
 [263.618  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: 0
desired expected reward: 261.4318542480469



buy possibilites: [-1] 
expected returns: [[254.96861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3. 11.  3.  6.  0.  0.  6.  3. 11.  6.  3.  0.  0.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 268.5988464355469






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10  8  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[220.67807]
 [228.18466]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  5. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0
desired expected reward: 254.96861267089844



action possibilites: [-1] 
expected returns: [[243.71678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 228.1593017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[231.62094]
 [243.0143 ]
 [249.06361]
 [231.37949]
 [251.58937]
 [234.26538]
 [240.01474]
 [244.08278]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0
desired expected reward: 243.71678161621094



buy possibilites: [-1] 
expected returns: [[226.81192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 251.58937072753906






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  6.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[183.83293]
 [191.33954]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  3.  3.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  4. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: 0
desired expected reward: 226.81192016601562



action possibilites: [-1] 
expected returns: [[181.50694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -315 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 188.4137420654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[170.96037]
 [170.71893]
 [183.42221]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 181.50694274902344






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [8. 0. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 25. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [8. 0. 0. 0. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[196.1626 ]
 [203.66917]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 183.4221954345703



action possibilites: [-1] 
expected returns: [[207.2314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -336 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 199.66075134277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[196.3588 ]
 [213.80147]
 [196.11734]
 [199.00323]
 [208.82063]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: 0
desired expected reward: 207.2313995361328



buy possibilites: [-1] 
expected returns: [[195.54652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 213.80148315429688






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[161.17435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: 0
desired expected reward: 195.54652404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.8094 ]
 [166.50917]
 [149.58073]
 [152.37305]
 [161.86568]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 23. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 161.17434692382812



buy possibilites: [-1] 
expected returns: [[168.12398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 6. 11. 11.  6.  0.  0.  0.  6. 11.  3.  6.  3.  3.  6.  3. 11.  3.  3.
  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 166.5091552734375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 22. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3] -> size -> 28 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[194.34413]
 [201.85072]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  2. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: 0
desired expected reward: 168.1239776611328



action possibilites: [-1] 
expected returns: [[186.6132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -325 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 198.9249267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[176.48857]
 [176.25508]
 [188.72441]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 186.6132049560547






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  0.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[169.59724]
 [176.84975]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 22. 30.  8.  1. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 188.7244110107422



action possibilites: [-1] 
expected returns: [[176.56511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 22. 30.  8.  0. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -336 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 173.32814025878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[165.8586 ]
 [182.85648]
 [168.45888]
 [178.09444]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 22. 30.  8.  0. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: 0
desired expected reward: 176.5651092529297



buy possibilites: [-1] 
expected returns: [[169.10936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 182.85647583007812






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 10.  0.  8.  0.  0.  0.  0.  0.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[158.83354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.10935974121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[146.20677]
 [158.6686 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 158.8335418701172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  6.  0.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 6. 11.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[142.07375]
 [149.32625]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  6.  0.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  0. 10.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.66859436035156



action possibilites: [-1] 
expected returns: [[208.0807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 146.83580017089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[198.5956 ]
 [215.59349]
 [201.19589]
 [210.83144]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 21. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 208.08070373535156



buy possibilites: [-1] 
expected returns: [[214.36766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 215.5934600830078






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3] -> size -> 33 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 20. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3] -> size -> 33 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 20. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3] -> size -> 33 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[151.92903]
 [158.59732]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.  3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  9.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: 0
desired expected reward: 214.36766052246094



action possibilites: [-1] 
expected returns: [[203.03645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 2 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 156.22024536132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[190.42067]
 [202.65651]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 6. 11.  0.  3.  3.  3.  6.  3. 11.  0.  6.  0.  3.  3.  6.  0.  6.  3.
 16.  3. 11.  6.  0.  6.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: 0
desired expected reward: 203.0364532470703






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 16.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 16.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 16.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 16.  3.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11. 16.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[177.11752]
 [184.37001]
 [164.64198]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.  6.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  8.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 202.65650939941406



action possibilites: [-1] 
expected returns: [[165.96245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  6.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 22 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 181.1785125732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[154.36311]
 [166.41643]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  6.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.9624481201172






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 1.  0.  3.  8.  0.  0. 10.  0.  0.  0.  0.  3. 10.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[117.79188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.4164276123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[106.04485 ]
 [116.77863 ]
 [122.49259 ]
 [124.90603 ]
 [108.533165]
 [113.967804]
 [117.872185]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  6.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.79187774658203



buy possibilites: [-1] 
expected returns: [[95.68154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0  -1   0   0  18   0] 
sum of rewards: 3 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 124.90602111816406






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [1. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11] -> size -> 36 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 20. 30.  8.  0.  7.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11] -> size -> 36 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 6 
card supply: [24. 28. 30. 20. 30.  8.  0.  7.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11.  6.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11] -> size -> 36 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 6. 11.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[110.62742 ]
 [117.147766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  6.  3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 20. 30.  8.  0.  7.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [0. 1. 0. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.6815414428711



action possibilites: [-1] 
expected returns: [[121.96584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [0. 1. 0. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: 20 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 114.89463806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[111.11477]
 [122.85335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [0. 1. 0. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.9658432006836






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [0. 1. 0. 8. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [0. 1. 0. 8. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [0. 1. 0. 8. 0. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.098816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.85334777832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[103.477684]
 [115.644165]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.09881591796875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  0.] 
cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [ 0.  1.  0.  8.  0.  1.  0.  0. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.91832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 23 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.64414978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[109.196556]
 [123.93547 ]
 [111.51665 ]
 [120.075775]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 20. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 23 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.91831970214844



buy possibilites: [-1] 
expected returns: [[104.7973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 2 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 123.93547821044922






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  8  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 16.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 16.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 16.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3. 16.  6.  3.] 
adversary cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  3. 16.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[ 95.77995 ]
 [102.192505]
 [ 84.90602 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 16.  6.  3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  6.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.79730224609375



action possibilites: [-1] 
expected returns: [[92.66083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  5.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 29 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 99.89691925048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.30968]
 [92.66084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  3.] 
cards in discard: [16. 11. 16.  3.  6.  6. 11.  0.  0.  3.  0.  3. 16. 11.  6.  6.  6.  3.
  6.  0.  6.  3.  3.  3.  0.  6.  6.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  5.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.66082763671875






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  5.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16] -> size -> 39 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 19. 30.  8.  0.  5.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16] -> size -> 39 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[153.24786]
 [160.2953 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  5.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.66082763671875



action possibilites: [-1] 
expected returns: [[141.85107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 19. 30.  8.  0.  4.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0 -5  0  0 16  0] 
sum of rewards: 28 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 157.8623504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[131.04933]
 [146.43066]
 [133.4605 ]
 [142.34802]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 19. 30.  8.  0.  4.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.85107421875



buy possibilites: [-1] 
expected returns: [[134.62947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  4.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 30 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 146.4306640625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  4.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 18. 30.  8.  0.  4.  5.  7. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 18. 30.  8.  0.  4.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 98.2217 ]
 [105.09712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  6.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  4.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.6294708251953



action possibilites: [-1] 
expected returns: [[132.28877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 37 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 102.67160034179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[121.198265]
 [133.17627 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.2887725830078






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 0.  8.  0.  3.  0.  0. 10.  8.  0.  8.  0.  0.  0. 10.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [16.  3.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[164.58037]
 [152.37077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  6.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.17626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[153.49474]
 [165.47273]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  6.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 164.5803680419922



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 16.  3.  3.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  5.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 16.  3.  3.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11. 16.  3.  3.  6.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 16.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[155.65593]
 [162.25967]
 [143.9308 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.  3.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  3.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 165.4727325439453



action possibilites: [-1] 
expected returns: [[150.55122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0 -8  0  0 16  0] 
sum of rewards: 36 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 159.8973388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[139.70937]
 [151.39626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  6.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.5512237548828






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [11.  0.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  4.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[131.93434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.39625549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[121.76254]
 [136.18347]
 [124.06395]
 [132.51802]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 18. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11 11] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 131.93434143066406



buy possibilites: [-1] 
expected returns: [[119.87673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11 11] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0 -9  0  0  8  0] 
sum of rewards: 18 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 136.18348693847656






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  8.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 11. 16.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 11. 16.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 11. 16.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3] -> size -> 44 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3.  6.  3. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[83.4086  ]
 [88.92195 ]
 [73.587715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 11. 16.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  2.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.8767318725586



action possibilites: [-1] 
expected returns: [[45.78996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 16.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  20   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 45 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 86.82131958007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.00329]
 [45.78996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 16.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.78995895385742






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  3.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 16.  0. 11.  0.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 16.  0. 11.  0.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 8.] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0 10  3  0  0  8  3  0 10  0  8  1 10  1  0  0 10  0  8 10 11 11] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 16.  0. 11.  0.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 16.  0. 11.  0.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0.  0. 10.  0. 11. 10.  0.  0.  0.  3.  0.  8. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
action values: 2 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16. 16.  0. 11.  0.] 
adversary cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [16. 16.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
expected returns: [[89.31694 ]
 [78.202515]
 [78.202515]
 [95.48938 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0. 11.  0.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  1.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.78995895385742



action possibilites: [-1] 
expected returns: [[65.31599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.  0.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  0.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  30   0   0  20   0   0   0   0 -11   0   0  16   0] 
sum of rewards: 54 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 93.194580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[55.20092 ]
 [68.95149 ]
 [57.335274]
 [65.315994]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  0.  0.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 17. 30.  8.  0.  0.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.31598663330078



buy possibilites: [-1] 
expected returns: [[77.1422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  0.  0.] 
cards in discard: [16.  3. 11.  0.  3.  3.  0. 16. 11.  3.  3.  6.  6. 16.  3.  3.  6.  6.
 16. 11. 16.  3.  3.  6.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  3. 16.
 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  40   0   0  20   0   0   0   0 -12   0   0   8   0] 
sum of rewards: 56 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 68.95149230957031






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [16.  6.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[128.57442 ]
 [116.738625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.14219665527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[117.29189]
 [128.90286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 128.5744171142578



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3.  6.  0. 11.] 
adversary cards in discard: [16.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [14. 11.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3.  6.  0. 11.] 
adversary cards in discard: [16.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [14. 11.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3.  6.  0. 11.] 
adversary cards in discard: [16.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14. 11.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 16. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3.  6.  0. 11.] 
adversary cards in discard: [16.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14. 11.  0.  0.  0.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  3.  6.  0. 11.] 
adversary cards in discard: [16.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 6.  3.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 94.19194]
 [101.22017]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  0. 11.] 
cards in discard: [16.  6.  6.  6.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  3.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.90284729003906



action possibilites: [-1] 
expected returns: [[70.583336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0.] 
cards in discard: [16.  6.  6.  6.  0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  30   0   0  20   0   0   0   0 -13   0   0   9   0] 
sum of rewards: 46 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 98.76043701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.35097]
 [71.6822 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0.] 
cards in discard: [16.  6.  6.  6.  0. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10. 10.  0. 10.] 
adversary cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.58333587646484






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0. 10.] 
cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 16.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1. 11. 10. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10. 10.] 
cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 16.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 10. 10.] 
cards in discard: [14. 11.  0.  0.  0.  1.  3. 10.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  3. 16.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[111.72052]
 [100.30127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 16.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 71.68218994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[100.32266]
 [111.53511]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  3. 16.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14.  1.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.72052001953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [14.  1.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[92.11831 ]
 [80.849365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  3.] 
adversary cards in discard: [14.  1.  8.  0.  8.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[   -5     0     5    30     0     0     0     0     0     0     0   -13
     0 -3000   248     0] 
sum of rewards: -2735 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: 93.68643188476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[81.24208]
 [92.31825]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8. 10. 11.  3.] 
adversary cards in discard: [14.  1.  8.  0.  8.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.11830139160156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  3.] 
cards in discard: [14.  1.  8.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  6. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [14.  1.  8.  0.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [14.  1.  8.  0.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 16. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3. 16. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 16.] 
expected returns: [[68.32085]
 [58.55807]
 [73.6485 ]
 [58.55807]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 11. 16.  3.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  2.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.31824493408203



action possibilites: [-1] 
expected returns: [[46.352287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  3.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  30   0   0  20   0   0   0   0 -14   0   0   9   0] 
sum of rewards: 45 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 71.59963989257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.511414]
 [46.352287]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 16.  3.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.35228729248047






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 10.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 4 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.  1.  8.  0.  8.  8. 11.  0.  8. 10.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [16.  6. 11. 16.  3.] 
adversary cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [16.  6. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 16.] 
expected returns: [[33.042793]
 [26.75972 ]
 [36.602844]
 [26.75972 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 11. 16.  3.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  1.  5. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8 15] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.35228729248047



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 12 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [16.  6. 16.  3.] 
cards in discard: [16.  6.  6.  6.  0. 11. 11.  6.  3.  6.  0.  0.  6.  3.  3. 16.  3.  0.
  3. 16.  6. 11. 11.  3. 16. 16.  3. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11  6  3  6  3  6  3  6  3  6 11
  6  6  3  3  6  6  3 16  3 16 16 11 16  3 16 16  3 16 16  3 16 16  3 11
 11 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 15. 30.  8.  0.  0.  0.  5. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3  0 10  0  8 10  1  0  0 10  0  8 10 11 11 14  3  8 15] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5 500   5  30   0   0  20   0   0   0   0 -15   0   0   9   0] 
sum of rewards: 544 

action type: gain_card_n - action 3
Learning step: 50.88169860839844
desired expected reward: 86.06471252441406



