 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.722084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000068 

action type: buy - action 11.0
Learning step: -300010.25
desired expected reward: -299975.75





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 42.513905]
 [ 76.22758 ]
 [ 58.050716]
 [ 20.662956]
 [ 66.827034]
 [ 80.83305 ]
 [ 63.158466]
 [117.265045]
 [ 35.424114]
 [ 46.51294 ]
 [ 66.91987 ]
 [ 39.376312]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.10722351074219



buy possibilites: [-1] 
expected returns: [[17.871143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.26504516601562






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.860455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.871143341064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.651768]
 [64.51958 ]
 [49.406387]
 [15.794602]
 [69.54112 ]
 [53.619137]
 [38.96056 ]
 [33.685833]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.21940612792969



buy possibilites: [-1] 
expected returns: [[11.929995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 69.54113006591797






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.575414]
 [39.187855]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.929994583129883



action possibilites: [-1.] 
expected returns: [[35.503727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.72602462768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 38.125942]
 [ 65.57324 ]
 [ 49.71937 ]
 [ 30.962532]
 [ 20.14788 ]
 [ 58.391735]
 [ 68.73266 ]
 [ 54.60105 ]
 [113.05075 ]
 [ 99.89228 ]
 [ 32.67784 ]
 [ 61.332653]
 [ 40.92853 ]
 [ 34.91829 ]
 [ 57.54196 ]
 [ 34.975105]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.503726959228516



buy possibilites: [-1] 
expected returns: [[16.534393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 113.0507583618164






Player: 1 
cards in hand: [3. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.72253 ]
 [47.855064]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.534393310546875



action possibilites: [-1] 
expected returns: [[8.345706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.86795425415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.247599  ]
 [18.369156  ]
 [-0.42975116]
 [20.13396   ]
 [11.266701  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.34570598602295



buy possibilites: [-1] 
expected returns: [[7.8433676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 20.133960723876953






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 8. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 8. 0. 0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 7.9600306]
 [29.246769 ]
 [11.55878  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.843367576599121



action possibilites: [-1] 
expected returns: [[2.058496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.34428024291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 4.530093 ]
 [12.78301  ]
 [-4.175959 ]
 [15.814757 ]
 [ 5.4782066]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.0584959983825684



buy possibilites: [-1] 
expected returns: [[5.932849]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 15.814759254455566






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-30.186558]
 [ 22.652527]
 [ 15.732194]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 29.] 
cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.932848930358887



action possibilites: [-1] 
expected returns: [[7.718211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.6257905960083





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.572476 ]
 [22.342041 ]
 [16.011799 ]
 [-2.2688608]
 [17.962128 ]
 [25.749073 ]
 [17.616833 ]
 [39.67405  ]
 [ 5.8564177]
 [11.424313 ]
 [19.46093  ]
 [ 8.885318 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11. 10.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.7182111740112305



buy possibilites: [-1] 
expected returns: [[37.769566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.  0.] 
cards in discard: [10.  8. 11. 10.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [0. 8. 0. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.67405700683594






Player: 1 
cards in hand: [3. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [0. 8. 0. 3. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [0. 8. 0. 3. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.497211]
 [38.58249 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25 10  8 10  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.76956558227539



action possibilites: [-1] 
expected returns: [[14.471633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 49.48347091674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.779362]
 [ 6.244253]
 [16.871746]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.471632957458496



buy possibilites: [-1] 
expected returns: [[8.913474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 18.779369354248047






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 3 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 10.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 10.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 10.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 10.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.488197]
 [51.443844]
 [25.683014]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 10.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.913474082946777



action possibilites: [-1] 
expected returns: [[15.437844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 59.91506576538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.209644 ]
 [33.98805  ]
 [ 5.3465853]
 [37.99211  ]
 [18.878075 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  6.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.437844276428223



buy possibilites: [-1] 
expected returns: [[15.141171]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 0.  8.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.99211502075195






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  8. 10. 29.] 
adversary cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  8. 10. 29.] 
adversary cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  8. 10. 29.] 
adversary cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [25.  0.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10. 29.] 
expected returns: [[-41.211082 ]
 [  7.2443514]
 [-23.09882  ]
 [-34.53083  ]
 [  2.1069689]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8. 10. 29.] 
cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.1411714553833



action possibilites: [-1] 
expected returns: [[14.975017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 29.  0.  0.] 
cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.936395168304443





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.109315]
 [29.746895]
 [21.337406]
 [ 6.436528]
 [31.866997]
 [23.985237]
 [17.017136]
 [15.045833]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 29.  0.  0.] 
cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  9.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.975016593933105



buy possibilites: [-1] 
expected returns: [[35.566853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 29.  0.  0.] 
cards in discard: [ 0.  8.  0. 10.  8. 11.  0.  3. 10.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.866985321044922






Player: 1 
cards in hand: [3. 0. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 29.] 
expected returns: [[25.44587 ]
 [39.243595]
 [49.31634 ]
 [39.243595]
 [66.88803 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 8.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.56685256958008



action possibilites: [-1.  8. 11.  8.] 
expected returns: [[27.704872]
 [39.434986]
 [50.69549 ]
 [39.434986]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 8.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 64.27528381347656



action possibilites: [-1] 
expected returns: [[62.552128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 8.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.40323257446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.265076]
 [88.534904]
 [78.90269 ]
 [55.526592]
 [90.78861 ]
 [81.60658 ]
 [72.587105]
 [67.583206]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  8.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 8.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.552127838134766



buy possibilites: [-1] 
expected returns: [[26.977093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [6. 3. 0. 3. 6. 8.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 90.78861236572266






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6. 3. 0. 3. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6. 3. 0. 3. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6. 3. 0. 3. 6. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 4.86695 ]
 [ 8.112781]
 [ 8.112781]
 [36.582874]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10. 29.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.977092742919922



action possibilites: [-1. 10. 10.] 
expected returns: [[27.413567]
 [29.683258]
 [29.683258]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.215797424316406



action possibilites: [-1. 10.  8.] 
expected returns: [[21.000725]
 [22.166557]
 [29.676273]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25 10  8 10  8 29  0 10  8 11 10 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 29.683258056640625



action possibilites: [-1.] 
expected returns: [[29.710812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 34.41939926147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[43.373558]
 [64.52864 ]
 [52.532253]
 [23.908737]
 [58.7032  ]
 [67.2678  ]
 [56.01495 ]
 [88.60927 ]
 [37.33034 ]
 [44.95634 ]
 [58.441277]
 [39.547363]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.710811614990234



buy possibilites: [-1] 
expected returns: [[49.28037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 88.6092758178711






Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29. 29. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29. 29. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29. 29. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29. 29. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[ 0.8511219]
 [29.214657 ]
 [12.923169 ]
 [ 1.6784682]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11. 10.  0.] 
cards in discard: [10. 11. 29. 11.  0.  8.  8.  0. 29. 29. 10.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8. 10.  7.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.28036880493164



action possibilites: [-1] 
expected returns: [[53.138477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7. 10.  7.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.665611267089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.53691 ]
 [63.65707 ]
 [38.003582]
 [67.35196 ]
 [49.735588]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  7. 10.  7.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.13847732543945



buy possibilites: [-1] 
expected returns: [[-1.9304085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.  8.  0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 67.35198211669922






Player: 1 
cards in hand: [0. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [8. 8. 3. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [8. 8. 3. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [8. 8. 3. 0. 0. 6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 10. 29.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 29.] 
expected returns: [[14.061357]
 [20.974792]
 [20.974792]
 [15.450753]
 [38.93647 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10. 29.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.9304084777832031



action possibilites: [-1.  8.  8. 10. 11.] 
expected returns: [[31.920006]
 [44.628407]
 [44.628407]
 [36.631977]
 [53.363873]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10. 11.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.956886291503906



action possibilites: [-1] 
expected returns: [[23.374813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.00602340698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.931652]
 [35.71117 ]
 [16.385406]
 [37.920864]
 [25.964016]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  3.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.374813079833984



buy possibilites: [-1] 
expected returns: [[29.776344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 10.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.92085266113281






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 29.  0.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 29.  0.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0. 6. 3. 0. 3. 0. 6. 8. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 29.  0.] 
adversary cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[-18.23914 ]
 [ -9.9496  ]
 [ -5.764779]
 [ -5.764779]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.776344299316406



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[-8.277986]
 [12.380792]
 [26.103558]
 [-5.264265]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 10.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -5.764779090881348



action possibilites: [-1. 11. 10.] 
expected returns: [[18.454193]
 [37.513954]
 [18.30524 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.103553771972656



action possibilites: [-1] 
expected returns: [[104.71409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.72989273071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 93.04565 ]
 [113.147804]
 [105.5727  ]
 [ 85.65583 ]
 [ 77.355316]
 [105.63017 ]
 [119.32875 ]
 [107.06763 ]
 [146.35939 ]
 [135.65306 ]
 [ 90.45723 ]
 [109.28834 ]
 [ 99.35739 ]
 [ 89.23093 ]
 [110.57563 ]
 [105.24266 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  9.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.7140884399414



buy possibilites: [-1] 
expected returns: [[72.347374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 25.  3. 11. 10.  0.  8.  0. 10.  8. 29. 11.  0.  8.  8. 10. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 146.35939025878906






Player: 1 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[ 5.5274878]
 [47.981586 ]
 [41.71957  ]
 [17.739216 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3] -> size -> 20 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.34737396240234



action possibilites: [-1] 
expected returns: [[38.609467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.16305923461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.346912]
 [56.50295 ]
 [46.480885]
 [32.37915 ]
 [58.38631 ]
 [49.160877]
 [41.695293]
 [36.46727 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  7.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.609466552734375



buy possibilites: [-1] 
expected returns: [[13.049029]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0. 29.  0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.386287689208984






Player: 1 
cards in hand: [3. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [3. 6. 0. 3. 0. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 10.  0.  8.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 0.] 
cards in discard: [3. 6. 0. 3. 0. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 11. 10.  0.  8.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[13.140019]
 [13.36539 ]
 [27.359299]
 [13.36539 ]
 [19.73846 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.  8.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.049029350280762



action possibilites: [-1] 
expected returns: [[7.0052347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.23335647583008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.2585382]
 [-19.434305 ]
 [  9.455171 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  8.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.005234718322754






Player: 1 
cards in hand: [8. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0. 11.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0. 11.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [3. 6. 0. 3. 0. 6. 6. 3. 3. 8. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0. 11.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[ 2.2221851]
 [24.170315 ]
 [15.763732 ]
 [24.170315 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0. 11.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.455183029174805



action possibilites: [-1] 
expected returns: [[56.865795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.27153396606445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.022854]
 [61.03873 ]
 [32.91669 ]
 [62.359165]
 [55.08977 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  2.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.86579513549805



buy possibilites: [-1] 
expected returns: [[24.821098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [8. 6. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 62.35916519165039






Player: 1 
cards in hand: [8. 6. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 0 6 3 0 6 0 8 6 3 1 3 6 3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 29.  8.  0.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 0 3 0 6 0 8 6 3 1 3 6 3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 29.  8.  0.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 0 3 0 6 0 8 6 3 1 3 6 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10. 10. 29.  8.  0.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10. 10. 29.  8.  0.] 
adversary cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.  8.] 
expected returns: [[-13.240207 ]
 [-12.5435095]
 [-12.5435095]
 [ -1.3927364]
 [-10.714136 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  8.  0.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.82109832763672



action possibilites: [-1. 10. 10.  8. 10.] 
expected returns: [[36.158363]
 [39.799088]
 [39.799088]
 [49.05325 ]
 [39.799088]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  0. 10.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8 10  8 29  0 10  8 11 10 11 29  8 10  8
 10 25 11 10 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -1.3927595615386963



action possibilites: [-1] 
expected returns: [[21.105995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 54.04452896118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.78374 ]
 [25.410786]
 [ 8.316969]
 [25.494488]
 [24.89162 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  1.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.105995178222656



buy possibilites: [-1] 
expected returns: [[73.66616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 25.  0. 29.  8.  0. 29.  0. 10. 11. 10. 10.  0.  8. 10.  8. 11.  0.
  8.  0. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 25.494464874267578






Player: 1 
cards in hand: [3. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [10.  8.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  8  3  0  3  0  6  0  8  6  3  1  3  6  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10.  8.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  8.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  8.  1.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.] 
expected returns: [[38.248634]
 [41.01865 ]
 [47.2217  ]
 [71.88186 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  6. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.6661605834961



action possibilites: [-1] 
expected returns: [[30.609333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 72.10211181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[22.032818]
 [30.780277]
 [10.553966]
 [22.130062]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.609333038330078



buy possibilites: [-1] 
expected returns: [[28.5055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.  0. 10.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 3.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 30.78026580810547






Player: 1 
cards in hand: [3. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 11. 11.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3] -> size -> 31 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.  8.] 
expected returns: [[-24.122345 ]
 [-13.053184 ]
 [ -1.6664637]
 [ -1.6664637]
 [-13.053184 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  8.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.50550079345703



action possibilites: [-1] 
expected returns: [[-32.050007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 10.720438003540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-35.056015]
 [-41.952164]
 [-32.49776 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 3. 8. 6. 0.] 
adversary cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -32.05000686645508






Player: 1 
cards in hand: [0. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 0.] 
cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10.  8.  1.  0.  0.  0.  8.  3.  0.  6.  3.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  8.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[50.05865]
 [60.60687]
 [64.78359]
 [52.61729]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  8.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [8. 1. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -32.49775314331055



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[67.66832]
 [79.13605]
 [67.85827]
 [67.85827]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  8.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [8. 1. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.1730842590332



action possibilites: [-1] 
expected returns: [[62.469967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [8. 1. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 83.22246551513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[49.89615 ]
 [60.901676]
 [40.603436]
 [64.24236 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [8. 1. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.469966888427734






Player: 1 
cards in hand: [8. 1. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 6. 3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 10. 29.] 
expected returns: [[-23.381794]
 [-10.40727 ]
 [-18.831652]
 [-18.831652]
 [-18.831652]
 [ 30.108776]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10. 29.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.24236297607422



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[61.719357]
 [62.70168 ]
 [62.70168 ]
 [62.70168 ]
 [85.49992 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 29.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.3002967834472656



action possibilites: [-1. 10. 10.] 
expected returns: [[139.48798]
 [128.67813]
 [128.67813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.50006103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[111.91178 ]
 [140.70702 ]
 [135.793   ]
 [ 90.097305]
 [156.65714 ]
 [129.3999  ]
 [139.68405 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  6.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 139.4879608154297



buy possibilites: [-1] 
expected returns: [[138.61023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 8.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 156.65711975097656






Player: 1 
cards in hand: [6. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 8.] 
cards in discard: [1. 8. 1. 0. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 8.] 
cards in discard: [1. 8. 1. 0. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 8.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 25.  0.] 
adversary cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 25.] 
expected returns: [[105.8199  ]
 [119.843414]
 [139.39313 ]
 [106.79304 ]
 [163.61203 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 25.  0.] 
cards in discard: [ 3. 25. 10.  0.  8.  3.  0. 10. 15. 11.  8. 11.  8.  0.  0. 15. 29. 11.
  0.  8.  8.  8. 10. 11. 29. 29. 10. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  5. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 8. 0. 3.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.6102294921875



action possibilites: [-1] 
expected returns: [[10.301475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 8. 0. 3.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 163.61199951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 3.4003859 ]
 [ 9.129104  ]
 [-0.99227667]
 [12.879184  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [6. 3. 8. 0. 3.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.301474571228027






Player: 1 
cards in hand: [6. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 3.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [10.  8. 15. 10.  8.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 3.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [10.  8. 15. 10.  8.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 3.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [10.  8. 15. 10.  8.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  8. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15. 10.  8.] 
expected returns: [[11.828429 ]
 [ 1.592123 ]
 [ 2.9231148]
 [ 7.3665648]
 [ 1.592123 ]
 [ 2.9231148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 10.  8.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0. 6. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.87918758392334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.775234]
 [-18.264122]
 [ 10.902224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 10.  8.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0. 6. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.828422546386719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0. 6. 3. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [11.  0.  8. 29. 15.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0. 6. 3. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 24. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [11.  0.  8. 29. 15.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [1. 8. 1. 0. 6. 3. 0. 6. 3. 0. 0. 8. 6. 0. 6. 3. 8. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [11.  0.  8. 29. 15.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  0.  8. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 15.] 
expected returns: [[48.97108 ]
 [61.997234]
 [47.57635 ]
 [64.633385]
 [52.613922]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29. 15.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.902228355407715



action possibilites: [-1.  8. 15.] 
expected returns: [[75.26666 ]
 [76.588425]
 [79.33616 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10
 25 11 10 10  8  8  3 15 15 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.37248611450195



action possibilites: [-1] 
expected returns: [[-21.852463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 79.3361587524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-28.548332 ]
 [-11.461116 ]
 [-20.208408 ]
 [-33.532177 ]
 [-15.6955595]
 [-10.584671 ]
 [ 23.249817 ]
 [-29.49273  ]
 [-25.13625  ]
 [-16.443    ]
 [-23.125027 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  7. 10. 10.  1. 10.  8.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.852462768554688



buy possibilites: [-1] 
expected returns: [[53.81055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  8.] 
adversary cards in hand: [1. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.249832153320312






Player: 1 
cards in hand: [1. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  8.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  8.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 6.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [10. 29. 10.  0.  0.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[36.949062]
 [36.14066 ]
 [54.85118 ]
 [36.14066 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  0.  0.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.810550689697266



action possibilites: [-1. 10. 10.] 
expected returns: [[106.07189]
 [ 97.75142]
 [ 97.75142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.998966217041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 83.83927 ]
 [108.22757 ]
 [103.276184]
 [ 65.23853 ]
 [121.76136 ]
 [ 97.22616 ]
 [105.52095 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  5.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 106.0718994140625



buy possibilites: [-1] 
expected returns: [[113.29583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 121.76139068603516






Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [15.  1.  0.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11] -> size -> 35 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [15.  1.  0.  8.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 23. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11] -> size -> 35 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 11. 10.  8.  3.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11] -> size -> 35 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.  8.] 
expected returns: [[63.301975]
 [59.58592 ]
 [82.17909 ]
 [54.178036]
 [59.58592 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  8.  3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.29582977294922



action possibilites: [-1] 
expected returns: [[50.92993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.68133544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.051117]
 [13.818166]
 [49.37157 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.929931640625






Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  0. 25.  0.  8.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0. 15. 11.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [11.  0. 25.  0.  8.] 
adversary cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0. 15. 11.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[17.795452]
 [27.479702]
 [57.590233]
 [ 9.334609]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  0.  8.] 
cards in discard: [25.  8. 11. 10.  0.  0. 29. 10.  8. 15. 10.  8. 11. 29. 29. 15.  8.  3.
 11. 11. 29. 10. 10.  0.  0. 15. 11.  8. 10.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  4. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.37156677246094



action possibilites: [-1] 
expected returns: [[40.460575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.59025192260742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[37.857376]
 [51.093914]
 [20.844036]
 [39.45328 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.460575103759766



buy possibilites: [-1] 
expected returns: [[119.006355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  8. 10. 11.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 51.09389114379883






Player: 1 
cards in hand: [6. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  8. 25.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  8. 25.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 25.] 
expected returns: [[32.663063]
 [60.27303 ]
 [28.07032 ]
 [35.506367]
 [70.46836 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8. 25.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  3. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 10.  6.  8.  3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.00635528564453



action possibilites: [-1] 
expected returns: [[-6.5745482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8. 11. 11.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 10.  6.  8.  3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.4683609008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.99673 ]
 [-7.682555]
 [-8.717161]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  8. 11. 11.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 10.  6.  8.  3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.574548244476318



buy possibilites: [-1] 
expected returns: [[1.5717716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  8. 11. 11.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [ 1. 10.  6.  8.  3.] 
adversary cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 16.99673843383789






Player: 1 
cards in hand: [ 1. 10.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  6.  8.  3.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  6  3  1  3  6  3 10  0  6  1  0  6  0
  3 15  3  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [15.  8.  0.  8. 10.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [15.  8.  0.  8. 10.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  1.  0.  8.  0.  6.  3.  0.  3.  0.  0.  8.  3.  0.  0.  3.  6.  6.
  6.  3.  3.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [15.  8.  0.  8. 10.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15.  8.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 10.] 
expected returns: [[56.05371 ]
 [58.15289 ]
 [54.842728]
 [54.842728]
 [49.14332 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  8. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25
 11 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.5717716217041016



action possibilites: [-1] 
expected returns: [[135.1779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 58.152896881103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[123.68648]
 [145.97949]
 [139.66905]
 [106.87275]
 [153.42847]
 [132.7495 ]
 [134.89783]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  4.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.1779022216797



buy possibilites: [-1] 
expected returns: [[137.40688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 153.42843627929688






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [10. 11. 15.  3. 10.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11] -> size -> 38 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [10. 11. 15.  3. 10.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11] -> size -> 38 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 11. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 10.] 
expected returns: [[83.15918 ]
 [63.905254]
 [97.70136 ]
 [79.88069 ]
 [63.905254]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  3. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.40687561035156



action possibilites: [-1] 
expected returns: [[50.229248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.69856262207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.193443]
 [11.077979]
 [50.11113 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3. 10.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.229248046875






Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 29.  8.  8. 29.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 21. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 29.  8.  8. 29.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 29.  8.  8. 29.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 29.] 
expected returns: [[51.862343]
 [58.24793 ]
 [44.91364 ]
 [44.91364 ]
 [58.24793 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  8. 29.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.111080169677734



action possibilites: [-1.  8.  8.] 
expected returns: [[57.81518 ]
 [51.884754]
 [51.884754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.09413528442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[32.17317 ]
 [53.396633]
 [17.026917]
 [58.006428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 3.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.81516647338867






Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 10. 15.  8. 29.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29. 29.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 10. 15.  8. 29.] 
adversary cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29. 29.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 15.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 29.] 
expected returns: [[17.88277 ]
 [ 9.88403 ]
 [14.564273]
 [11.615423]
 [25.714352]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  8. 29.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29. 29.  0.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.006412506103516



action possibilites: [-1. 10. 15.  8.] 
expected returns: [[18.306015]
 [10.201761]
 [17.738285]
 [12.445134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  8.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29. 29.  0.  8.  8.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.857802391052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 3.8717008]
 [13.7673025]
 [-3.7133403]
 [18.306015 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  8.] 
cards in discard: [ 3. 25. 11.  0.  0.  8. 10. 11.  0. 25.  0. 29. 10.  8. 11. 11. 11. 15.
  8.  8. 10. 15. 11. 10. 15.  3. 10. 29. 29.  0.  8.  8.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [ 3. 15.  0.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.305992126464844






Player: 1 
cards in hand: [ 3. 15.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  1.  8.] 
cards in discard: [0. 3. 0. 0. 3. 3. 3. 0. 0. 3. 3. 3. 0. 3. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 29. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.  8.] 
expected returns: [[35.79756 ]
 [74.09784 ]
 [74.09784 ]
 [38.246204]
 [45.43384 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.305992126464844



action possibilites: [-1. 29.  8.] 
expected returns: [[ 71.86788]
 [103.98841]
 [ 75.12972]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  0.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.10792541503906



action possibilites: [-1. 11.] 
expected returns: [[53.56564]
 [80.83712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [10.  8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  5.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.11925506591797



action possibilites: [-1] 
expected returns: [[76.501175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10.  8. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.06916046142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[64.84567 ]
 [83.49088 ]
 [78.99164 ]
 [53.0643  ]
 [93.12292 ]
 [74.310814]
 [76.56052 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  8. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  3.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.50117492675781



buy possibilites: [-1] 
expected returns: [[16.152393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  8. 15. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 93.12293243408203






Player: 1 
cards in hand: [6. 6. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 8.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 8.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 8.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3.  0.  0.  3.  3.  3.  0.  3.  0.  6.  0.  3.
 15.  0.  1.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15. 15. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10. 11. 15.] 
expected returns: [[ 57.912773]
 [ 85.961494]
 [ 85.961494]
 [ 64.80912 ]
 [100.00945 ]
 [ 85.961494]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 11. 15.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  4.] 
adversary cards in hand: [3. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.152393341064453



action possibilites: [-1] 
expected returns: [[47.82195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 15.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [3. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: -21 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 105.86782836914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.17464 ]
 [19.106201]
 [45.624153]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10. 15.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [3. 3. 8. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.82194900512695






Player: 1 
cards in hand: [3. 3. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [25. 11. 10.  8.  8.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [25. 11. 10.  8.  8.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.  8.  8.] 
expected returns: [[ 76.400406]
 [112.722404]
 [ 93.2392  ]
 [ 72.00574 ]
 [ 78.67179 ]
 [ 78.67179 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  8.  8.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  2. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [3. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.6241455078125



action possibilites: [-1] 
expected returns: [[57.921146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  8. 25.  0.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [3. 3. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.72240447998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.513325]
 [31.791573]
 [59.738186]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.  8. 25.  0.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [3. 3. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.921146392822266






Player: 1 
cards in hand: [ 0.  6. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  8.  6.] 
cards in discard: [3. 3. 8. 3. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  8.  6.] 
cards in discard: [3. 3. 8. 3. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 11.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.  8.] 
expected returns: [[17.061737 ]
 [25.791176 ]
 [25.791176 ]
 [ 7.4887056]
 [ 7.4887056]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  8.  0.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.73819351196289



action possibilites: [-1] 
expected returns: [[13.52547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.753971099853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 5.936434]
 [-3.005683]
 [12.027396]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  8.  0.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.525469779968262






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [10. 11.  8.  3.  3.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [10. 11.  8.  3.  3.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [10. 11.  8.  3.  3.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 11.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[64.314415]
 [55.998516]
 [70.13729 ]
 [57.211582]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3.  3.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  2.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.027410507202148



action possibilites: [-1] 
expected returns: [[30.627327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  3.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.10347747802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.584708]
 [ 9.504485]
 [30.627316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  3.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.62732696533203






Player: 1 
cards in hand: [0. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [10. 10.  0. 15.  8.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [10. 10.  0. 15.  8.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.  8.] 
expected returns: [[33.09214 ]
 [20.13078 ]
 [20.13078 ]
 [30.076565]
 [22.868675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15.  8.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.  0.
  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.62732696533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 4.4270287]
 [-9.985594 ]
 [33.092144 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 15.  8.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.  0.
  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.092140197753906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.  0.
  3.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [29.  0.  0. 29. 11.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.  0.
  3.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 20. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [29.  0.  0. 29. 11.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  3.  6.  6.  0.  6. 15.  8.  6.  1.  0.  3.  0.  0.  0.  0.
  3.  3.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [29.  0.  0. 29. 11.] 
adversary cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[34.965183]
 [37.26922 ]
 [37.26922 ]
 [40.001957]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29. 11.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  1.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1  3] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.092140197753906



action possibilites: [-1] 
expected returns: [[-0.1621077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1  3] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: -51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.80508041381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-12.571619  ]
 [ -4.3875523 ]
 [-19.709686  ]
 [ -0.16211557]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 29.] 
cards in discard: [10.  8. 15. 11. 29. 29. 11.  3.  0. 15. 11. 15. 15. 10. 15. 25. 11. 10.
  8.  8. 25.  0. 15. 11. 11.  8.  8.  0. 15. 11. 10.  8.  3.  3. 10. 10.
  0. 15.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1  3] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.1621077060699463






Player: 1 
cards in hand: [0. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  1  0  6  0  3 15  3
  6  6  3  0  0  6  1  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [29. 15. 10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [29. 15. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.  8. 15.] 
expected returns: [[72.82714]
 [95.80967]
 [78.74696]
 [68.26181]
 [73.86467]
 [78.74696]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10.  8. 15.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.1621077060699463



action possibilites: [-1. 10. 15.] 
expected returns: [[59.45927 ]
 [55.744404]
 [65.00272 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.] 
cards in discard: [15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11
 10 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.38375854492188



action possibilites: [-1] 
expected returns: [[3.6869388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 65.0027084350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. -1.] 
expected returns: [[10.345474 ]
 [22.401958 ]
 [18.14798  ]
 [ 2.5992684]
 [18.3172   ]
 [24.66195  ]
 [30.564556 ]
 [ 8.921422 ]
 [13.6102495]
 [ 4.9574976]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  6. 10. 10.  1. 10.  0.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.686938762664795



buy possibilites: [-1] 
expected returns: [[-19.240067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  8. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [3. 8. 3. 3. 6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -100    0    0
  128    0] 
sum of rewards: 33 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.56454849243164






Player: 1 
cards in hand: [3. 8. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 11.  8. 15. 10.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29] -> size -> 45 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 11.  8. 15. 10.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29] -> size -> 45 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 6.] 
cards in discard: [8. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 11.  8. 15. 10.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29] -> size -> 45 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 11.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 15. 10.] 
expected returns: [[19.71767 ]
 [42.15671 ]
 [42.15671 ]
 [31.173996]
 [33.800774]
 [25.746914]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 15. 10.] 
cards in discard: [15.  8. 29. 29. 15. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  6.  0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3  0] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.240066528320312



action possibilites: [-1] 
expected returns: [[-6.767825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15. 10.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  6.  0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3  0] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -98 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 35.752410888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.375271]
 [-14.96898 ]
 [ -7.046288]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15. 10.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [ 3. 15.  0.  6.  0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
adversary owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3  0] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.767825126647949






Player: 1 
cards in hand: [ 3. 15.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  6.  0.] 
cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  0  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3
  0  0  6  1  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [15.  0.  0. 11. 29.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [15.  0.  0. 11. 29.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [8. 0. 0. 3. 8. 3. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [15.  0.  0. 11. 29.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [8. 0. 0. 3. 8. 3. 3. 6. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [15.  0.  0. 11. 29.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[47.534153]
 [48.840244]
 [56.320354]
 [59.417423]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 11. 29.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.0462846755981445



action possibilites: [-1. 11.] 
expected returns: [[34.15239]
 [48.74966]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.33049774169922



action possibilites: [-1] 
expected returns: [[23.481594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 37.17245864868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ -4.5885973]
 [ 16.308758 ]
 [ 13.44638  ]
 [-17.159191 ]
 [ 31.380234 ]
 [  9.587142 ]
 [ 20.465935 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 19. 30.  8.  1. 10.  2.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.48159408569336



buy possibilites: [-1] 
expected returns: [[39.156372]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 19. 30.  8.  1. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 6. 6. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: -71 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.380218505859375






Player: 1 
cards in hand: [0. 3. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 19. 30.  8.  1. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 10. 15. 29. 25.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11. 29. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 19. 30.  8.  1. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 10. 15. 29. 25.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11. 29. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 8.] 
cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 19. 30.  8.  1. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [11. 10. 15. 29. 25.] 
adversary cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11. 29. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [11. 10. 15. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 29. 25.] 
expected returns: [[ -6.79614  ]
 [  0.7523236]
 [-15.459885 ]
 [-10.031761 ]
 [  1.6397696]
 [ 13.659551 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 29. 25.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11. 29. 11.
  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 30.  8.  1. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.  0.  0.  3.  6.  6.
  8.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1  0] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.1563720703125



Game is draw!



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 7 
Witch: 2 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 10. 15. 29.  8. 10.] 
cards in discard: [15.  8. 29. 29. 15. 10.  1. 11. 11.  8. 15. 10. 15.  8.  1. 11. 29. 11.
  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 29 11 25  8  8 29  0 10  8 11 10 11 29  8 10  8 10 25 11 10
 10  8  8  3 15 15 11 29 11 15  3  0 11 15 15 11 15 15 15 15 29  1  1 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 19. 30.  8.  0. 10.  1.  0.  8.  5. 10. 10.  1. 10.  0.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  3.  3.  6.  1. 15.  3.  6.  0.  0.  0.  3.  6.  6.
  8.  6.] 
adversary owned cards: [ 3  8  8  3  3  0  0  8  3  3  6  3  0  6  0  6  0  3 15  3  6  6  3  0
  0  6  1  3  0  1  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: -2.865957260131836
desired expected reward: 10.793614387512207



