 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.44104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000015 

action type: buy - action 0.0
Learning step: -119994.609375
desired expected reward: -120144.4609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 84.24726 ]
 [104.231476]
 [ 95.37054 ]
 [ 63.56949 ]
 [112.35148 ]
 [103.83926 ]
 [ 95.57377 ]
 [ 95.54928 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.5860595703125



buy possibilites: [-1] 
expected returns: [[88.37264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.35147857666016






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.28379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.37264251708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 86.19372 ]
 [102.92991 ]
 [ 94.86762 ]
 [ 66.49293 ]
 [101.04351 ]
 [110.724556]
 [102.35999 ]
 [117.694824]
 [ 78.850105]
 [ 94.16199 ]
 [ 94.79659 ]
 [ 94.85321 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.34529113769531



buy possibilites: [-1] 
expected returns: [[81.03302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.69481658935547






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[71.41436]
 [92.24281]
 [86.87667]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.03302001953125



action possibilites: [-1. 11.] 
expected returns: [[ 88.487915]
 [104.049   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 93.6156005859375



action possibilites: [-1] 
expected returns: [[101.06024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 115.48532104492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.89576 ]
 [116.86975 ]
 [110.28633 ]
 [ 81.88737 ]
 [118.6245  ]
 [115.34783 ]
 [108.719765]
 [101.61742 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.06024169921875



buy possibilites: [-1] 
expected returns: [[94.39884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.62451934814453






Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.574394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.39884185791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 98.60168 ]
 [106.87623 ]
 [100.08253 ]
 [ 72.994545]
 [ 62.134995]
 [106.98991 ]
 [109.54988 ]
 [105.11846 ]
 [130.39897 ]
 [115.69103 ]
 [ 86.904305]
 [ 96.96709 ]
 [ 98.32475 ]
 [ 88.75524 ]
 [ 95.53869 ]
 [ 92.51192 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.95336151123047



buy possibilites: [-1] 
expected returns: [[99.65893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  3.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 130.3990020751953






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  0. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  0. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  0. 11.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[106.96882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.65892791748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[104.59697 ]
 [112.89553 ]
 [ 83.042046]
 [119.08892 ]
 [107.03163 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.2767333984375



buy possibilites: [-1] 
expected returns: [[109.22025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 119.08893585205078






Player: 1 
cards in hand: [ 3.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 25.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 25.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 29. 25.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 25.] 
expected returns: [[ 96.92688 ]
 [ 89.853745]
 [111.41153 ]
 [117.84577 ]
 [133.18872 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 25.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.22025299072266



action possibilites: [-1] 
expected returns: [[78.57766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29.  0.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.80850219726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.72915 ]
 [92.61431 ]
 [85.27434 ]
 [39.52258 ]
 [97.409805]
 [92.64137 ]
 [85.36491 ]
 [83.46207 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 29.  0.  0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.5776596069336



buy possibilites: [-1] 
expected returns: [[118.673805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 29.  0.  0.] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.40975952148438






Player: 1 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 25. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 25. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 25. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 25. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[ 76.45272]
 [ 93.8321 ]
 [109.94792]
 [ 93.8321 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  6.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.6738052368164



action possibilites: [-1] 
expected returns: [[65.87772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.6116943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[62.26557 ]
 [78.644936]
 [71.573944]
 [42.759197]
 [87.149345]
 [78.72251 ]
 [71.42701 ]
 [71.47529 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  6.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.87772369384766



buy possibilites: [-1] 
expected returns: [[77.896385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  0.  8.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.14934539794922






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 29.] 
adversary cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[107.4897 ]
 [111.1701 ]
 [130.26068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 29.] 
cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.8963851928711



action possibilites: [-1. 10.] 
expected returns: [[87.45536 ]
 [84.671455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 129.2181854248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 78.33256 ]
 [ 97.541336]
 [ 87.369705]
 [ 56.421158]
 [107.30654 ]
 [ 97.30735 ]
 [ 86.87254 ]
 [ 90.05233 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [11. 25. 11. 11.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  5.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.45536041259766



buy possibilites: [-1] 
expected returns: [[130.79678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [11. 25. 11. 11.  0.  0.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 107.30655670166016






Player: 1 
cards in hand: [10. 11.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.  3.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  3.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 80.39722]
 [102.23075]
 [ 97.73972]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.79678344726562



action possibilites: [-1. 11. 11.] 
expected returns: [[ 93.79908 ]
 [110.490654]
 [110.490654]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.84285736083984



action possibilites: [-1] 
expected returns: [[95.39333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.38299560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 71.72827 ]
 [100.19238 ]
 [ 92.57432 ]
 [ 40.73337 ]
 [112.6919  ]
 [100.70356 ]
 [ 93.922806]
 [ 97.53936 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  4.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.3933334350586



buy possibilites: [-1] 
expected returns: [[120.41273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.6919174194336






Player: 1 
cards in hand: [ 0.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6. 16.  0.  0.  0.  0.  0. 10. 11.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0. 25.  0. 10.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[ 83.81882 ]
 [ 98.79821 ]
 [115.591415]
 [ 90.02714 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  0. 10.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.41272735595703



action possibilites: [-1] 
expected returns: [[116.492714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.  3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 113.23790740966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[116.87944 ]
 [126.55416 ]
 [119.6603  ]
 [ 96.81106 ]
 [131.90831 ]
 [125.159676]
 [118.2658  ]
 [114.85946 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.  0.  3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  7.  9.  3.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.49271392822266



buy possibilites: [-1] 
expected returns: [[123.92837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.  0.  3.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 131.90830993652344






Player: 1 
cards in hand: [ 0. 11.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.  3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.  3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  6.  3.] 
cards in discard: [6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  8.  0.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11 11] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[72.54534 ]
 [88.187065]
 [88.187065]
 [89.43674 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  8.  0.] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25  8 11 11 11 10 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.9283676147461



action possibilites: [-1] 
expected returns: [[117.71032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 93.79320526123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.74019]
 [ 88.09294]
 [119.26368]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11. 29. 11.  3.  0.  0. 11. 11. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.71031951904297






Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[61.039986]
 [61.14013 ]
 [75.66478 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.2636489868164



action possibilites: [-1] 
expected returns: [[60.019432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 80.74886322021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.364483]
 [21.098145]
 [61.560623]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.019432067871094






Player: 1 
cards in hand: [ 3.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  0.  0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  3.  6.  3.  0.  3.  0.  3. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 11.  8.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[59.879776]
 [81.641396]
 [76.26377 ]
 [67.86408 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  8.] 
cards in discard: [10. 11.  0.  3. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.56062316894531



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[77.11791 ]
 [93.25623 ]
 [80.76159 ]
 [70.304794]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8. 10.] 
cards in discard: [10. 11.  0.  3. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.23712158203125



action possibilites: [-1] 
expected returns: [[48.04995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 102.82465362548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.94338 ]
 [63.447014]
 [56.023304]
 [24.29922 ]
 [67.09794 ]
 [61.931557]
 [54.896828]
 [50.437305]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  2.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.049949645996094



buy possibilites: [-1] 
expected returns: [[84.1395]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 67.09790802001953






Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 97.325386]
 [106.17181 ]
 [132.99884 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 25.  0.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  1.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.1395034790039



action possibilites: [-1] 
expected returns: [[55.053097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11. 11.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  1.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.99880981445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[65.30347 ]
 [65.90034 ]
 [53.10678 ]
 [70.30154 ]
 [58.619324]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 11. 11.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  1.  9.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.053096771240234



buy possibilites: [-1] 
expected returns: [[74.749535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 11. 11.] 
cards in discard: [10. 11.  0.  3. 10.  3. 10. 11. 29. 11.  0.  0.  8. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 70.30155181884766






Player: 1 
cards in hand: [16.  0.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 10.] 
expected returns: [[45.04291 ]
 [58.399208]
 [46.12835 ]
 [46.12835 ]
 [38.514366]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.7495346069336



action possibilites: [-1] 
expected returns: [[57.227325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.62910461425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.072077 ]
 [ 4.7746844]
 [58.17328  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.227325439453125






Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 25. 29.  0. 10.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  1.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 25. 29.  0. 10.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 25. 29.  0. 10.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[20.386364]
 [58.06964 ]
 [41.24504 ]
 [16.287607]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  0. 10.] 
cards in discard: [10. 11.  8.  8.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  6.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.173255920410156



action possibilites: [-1] 
expected returns: [[37.190376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10. 11. 10.] 
cards in discard: [10. 11.  8.  8.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.17732238769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.319023]
 [32.55573 ]
 [38.24987 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0. 10. 11. 10.] 
cards in discard: [10. 11.  8.  8.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.19037628173828



buy possibilites: [-1] 
expected returns: [[67.50672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0. 10. 11. 10.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  3.  0.  3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 44.31904220581055






Player: 1 
cards in hand: [ 6. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  3.] 
cards in discard: [14. 10.  0.  0.  0.  0. 11.  6.  3. 16.  0.  6.  0.  3. 11.  0.  6.  0.
  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0] -> size -> 24 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[39.593544]
 [49.498955]
 [49.498955]
 [49.498955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 11.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.50672149658203



action possibilites: [-1] 
expected returns: [[79.933846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.9976806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.14705 ]
 [61.936836]
 [81.00967 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.93384552001953






Player: 1 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[38.348946]
 [40.335136]
 [49.65451 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.00968170166016



action possibilites: [-1] 
expected returns: [[82.15652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  6.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.661746978759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[61.185028]
 [74.95191 ]
 [41.463943]
 [82.67266 ]
 [85.86886 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11.  8.  8.  0. 10.  0. 25.  3. 29.  0. 10. 11. 10. 15. 11.  0.  3.
 11. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  6.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.1565170288086






Player: 1 
cards in hand: [ 0.  6.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  0. 10.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15] -> size -> 26 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[41.940445]
 [44.752373]
 [38.088554]
 [50.91271 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 85.86884307861328



action possibilites: [-1] 
expected returns: [[43.23932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 14.  6.  0.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.7251091003418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.547277 ]
 [38.33176  ]
 [ 2.8388982]
 [44.901314 ]
 [45.076553 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 14.  6.  0.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.23931884765625






Player: 1 
cards in hand: [ 3. 14.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  3. 11.  3.  8.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  3.  8.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  3.  8.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  3.  8.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[23.885717]
 [33.76516 ]
 [23.65518 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 10. 16.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 68.8016357421875



action possibilites: [-1] 
expected returns: [[47.26058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0. 10. 16.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.8125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 29.826975]
 [-21.659258]
 [ 47.946518]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0. 10. 16.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.26057815551758






Player: 1 
cards in hand: [ 0.  0. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 16.  0.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 10  0  6 10  6 16  3  6  0  0  3  0 14
  6  3 11  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 10. 10. 15. 11.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 10. 10. 15. 11.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 10. 10. 15. 11.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 10. 10. 15. 11.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 10. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15. 11.] 
expected returns: [[90.12514]
 [98.24216]
 [85.46243]
 [85.46243]
 [84.87912]
 [98.24216]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 15. 11.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  6.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.94654846191406



action possibilites: [-1] 
expected returns: [[78.27508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15. 11.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  6. 11.  6.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 105.22957611083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.50604 ]
 [55.419903]
 [78.556595]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15. 11.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  6. 11.  6.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.27507781982422






Player: 1 
cards in hand: [ 0.  6. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  6.  3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10. 25.  0. 29.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.  3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10. 25.  0. 29.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.  3.] 
cards in discard: [10.  0.  0.  3.  3.  3.  0.  6.  6.  0. 11.  0. 14.  3.  6.  0.  3.  4.
  0. 16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10. 25.  0. 29.  3.] 
adversary cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 25.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
expected returns: [[68.704185]
 [62.02414 ]
 [93.94196 ]
 [83.470055]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0. 29.  3.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 29.  8.  5.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.55660247802734



action possibilites: [-1] 
expected returns: [[81.22499]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 11. 15.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.94196319580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[90.53681]
 [78.6361 ]
 [82.48257]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3. 11. 15.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.22499084472656



buy possibilites: [-1] 
expected returns: [[53.23646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3. 11. 15.] 
cards in discard: [15. 11.  8.  0. 10.  0. 11.  3. 15. 11.  3.  8. 15. 11. 10. 10. 15. 11.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 90.53680419921875






Player: 1 
cards in hand: [ 6.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  3.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 26. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [6. 0. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[36.05009]
 [47.1972 ]
 [34.06605]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.2364616394043



action possibilites: [-1] 
expected returns: [[37.3369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.411888122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[17.892004 ]
 [44.05745  ]
 [38.895756 ]
 [-2.0317125]
 [46.21409  ]
 [41.19413  ]
 [41.232983 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  8.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.33689880371094



buy possibilites: [-1] 
expected returns: [[50.553642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [15.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   4.   0.] 
sum of rewards: -41.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 46.214107513427734






Player: 1 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 11. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 25. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 11. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 15. 15. 11. 11.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8] -> size -> 32 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 11.] 
expected returns: [[30.296034]
 [31.98461 ]
 [31.98461 ]
 [42.861107]
 [42.861107]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 11. 11.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  4.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.55364227294922



action possibilites: [-1] 
expected returns: [[63.012444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 11.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.80252456665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.189568]
 [47.46856 ]
 [63.55165 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15. 11.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.01244354248047






Player: 1 
cards in hand: [0. 3. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 15. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 15. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 15. 11. 10. 10.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 10.] 
expected returns: [[19.981243]
 [20.451256]
 [31.263346]
 [20.954794]
 [20.954794]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11. 10. 10.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  3.] 
adversary cards in hand: [14.  6.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.55162811279297



action possibilites: [-1] 
expected returns: [[63.383133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 10.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [14.  6.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.57109069824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.47593 ]
 [34.613075]
 [64.252   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10. 10.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [14.  6.  0.  3.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.38313293457031






Player: 1 
cards in hand: [14.  6.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  3.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  3.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  7.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  3.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [10.  0. 15.  0.  8.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[69.69653]
 [67.1364 ]
 [66.19495]
 [71.29153]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  0.  8.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10 25  8 11 11 11 10 11 11 10 10 11  8 10  0
 15 15 15 15 15  0 15  8 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [ 3.  0. 16.  0. 10.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.2519760131836



action possibilites: [-1] 
expected returns: [[28.590899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [ 3.  0. 16.  0. 10.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 78.53914642333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.293856 ]
 [-5.4148583]
 [27.52854  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [ 3.  0. 16.  0. 10.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.590898513793945






Player: 1 
cards in hand: [ 3.  0. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0. 10.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [11. 29.  0.  8. 15.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0. 10.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [11. 29.  0.  8. 15.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0. 10.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [11. 29.  0.  8. 15.] 
adversary cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 15.] 
expected returns: [[63.007896]
 [73.586754]
 [75.338135]
 [74.00497 ]
 [67.4596  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  8. 15.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.528573989868164



action possibilites: [-1. 11.  8. 15.] 
expected returns: [[36.868603]
 [50.598427]
 [48.44913 ]
 [42.355347]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  0.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  2.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.8110122680664



action possibilites: [-1] 
expected returns: [[32.863964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.761863708496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.99312  ]
 [26.998663 ]
 [-3.6611884]
 [33.045288 ]
 [34.84653  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.] 
cards in discard: [15.  8. 11.  0.  0. 10.  0. 15. 11.  3. 15. 15. 11. 15. 11.  3. 15. 10.
 10.  8.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.86396408081055






Player: 1 
cards in hand: [11.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 11. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 11. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  0.  0.] 
cards in discard: [ 6.  0.  3. 11.  6.  0.  0.  3.  3.  0.  6.  6.  3.  0.  0.  0.  3.  4.
  0.  3.  8. 14.  6.  0.  3.  0.  0.  3.  0. 16.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 11. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 10. 11. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 25.] 
expected returns: [[44.719467]
 [47.364212]
 [48.99603 ]
 [53.473896]
 [64.1399  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 25.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  4.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  6. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.84651184082031



action possibilites: [-1] 
expected returns: [[10.898191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  6. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.13990020751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -10.558303]
 [-100.6201  ]
 [  11.623814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  6. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.898191452026367






Player: 1 
cards in hand: [ 3.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  0. 15. 10.  0.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 0.  0. 15. 10.  0.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-39.13772]
 [-40.54912]
 [-37.99202]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.  0.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.623836517333984



action possibilites: [-1. 15.] 
expected returns: [[-0.58289146]
 [-2.2966824 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -37.99202346801758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-13.30028   ]
 [  4.4522824 ]
 [ -0.84949636]
 [-26.48254   ]
 [  4.6251073 ]
 [ -0.66099215]
 [  3.2340732 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  6.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.582862377166748



buy possibilites: [-1] 
expected returns: [[10.528618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  3.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   4.   0.] 
sum of rewards: -41.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 4.625123500823975






Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 29.  3. 11.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 29.  3. 11.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [15. 10. 29.  3. 11.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 10. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 29. 11.] 
expected returns: [[ 7.730429 ]
 [ 5.536555 ]
 [ 2.5464053]
 [20.896425 ]
 [17.178175 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.  3. 11.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  0. 14.  6.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.528617858886719



action possibilites: [-1. 15. 10. 11. 11.] 
expected returns: [[50.95996 ]
 [54.7666  ]
 [57.59233 ]
 [59.716255]
 [59.716255]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11. 11.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  1.] 
adversary cards in hand: [ 3.  0. 14.  6.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 8.288957595825195



action possibilites: [-1] 
expected returns: [[74.46574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [ 3.  0. 14.  6.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.9205093383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.629692]
 [38.53824 ]
 [75.443245]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [ 3.  0. 14.  6.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.46573638916016






Player: 1 
cards in hand: [ 3.  0. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  6.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [ 8. 15.  0.  0. 15.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  5.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [ 8. 15.  0.  0. 15.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [ 8. 15.  0.  0. 15.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15.] 
expected returns: [[15.858307]
 [27.282957]
 [19.783419]
 [19.783419]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0. 15.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15
 15 15  0 15  8 15 15 15  8 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.4432373046875



action possibilites: [-1] 
expected returns: [[59.972137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 4
Learning step: 0
desired expected reward: 32.61509323120117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.147133]
 [64.14036 ]
 [59.96328 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  3.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.972137451171875



buy possibilites: [-1] 
expected returns: [[41.03656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: 0
desired expected reward: 64.14034271240234






Player: 1 
cards in hand: [8. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [11. 15. 15.  8. 10.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6] -> size -> 33 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [11. 15. 15.  8. 10.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6] -> size -> 33 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [11. 15. 15.  8. 10.] 
adversary cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6] -> size -> 33 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 15. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.  8. 10.] 
expected returns: [[39.345444]
 [48.259068]
 [39.04847 ]
 [39.04847 ]
 [44.12381 ]
 [38.412945]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15.  8. 10.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  3. 10.  0.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.03656005859375



action possibilites: [-1] 
expected returns: [[60.311974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  8. 10.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  2. 10.  0.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 44.12380599975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.957375]
 [39.12213 ]
 [61.132782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  8. 10.] 
cards in discard: [25. 15. 10. 11.  3.  8. 11.  8. 10.  0.  0. 15.  0.  3.  3. 15. 29. 11.
 15. 10. 11.  6.  8.  0. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  2. 10.  0.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.311973571777344






Player: 1 
cards in hand: [10. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  0.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 11. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 11. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 6. 11. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  1. 10.  0.] 
adversary cards in hand: [ 6. 11. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 11. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[-13.954016]
 [ -8.393115]
 [-22.219475]
 [ -8.393115]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  1. 10.  0.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3. 10. 10. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0 10] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.13275909423828



Player 1 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 0 
Workshop: 8 
Chapel: 4 
Witch: 1 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 15.  0. 11.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 29 25  8 11 11 11 10 11 11 10 10 11  8 10  0 15 15 15
  0 15  8 15 15 15  8 15  6 10 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 29.  8.  2.  9.  0.  4.  9.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  6. 11.  0.  0.  0.  3.  0.  3.  0.  6.  8.  3.  0. 14.  6.  0.
  0.  8.  3.  0.  6.  3. 10. 10. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  0  6 10  6 16  3  6  0  0  3  0 14  6
  3 11  6  0  4  0  0  6  0  3  3  0  8  0  0  6  0  8  0 10] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -3000048 

action type: gain_card_n - action 8
Learning step: -120001.1171875
desired expected reward: -120021.21875



