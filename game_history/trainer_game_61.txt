 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[326.47903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -512 

action type: buy - action -1.0
Learning step: -29.706607818603516
desired expected reward: 52.425533294677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[306.2644 ]
 [317.27444]
 [313.55035]
 [285.72858]
 [311.2175 ]
 [324.40378]
 [314.5714 ]
 [317.90488]
 [296.57773]
 [311.69943]
 [309.15918]
 [330.93912]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.431839942932129
desired expected reward: 320.9485168457031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[365.175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.431488037109375
desired expected reward: 322.5075988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[333.39264]
 [347.24902]
 [342.6647 ]
 [307.6353 ]
 [355.8974 ]
 [343.64108]
 [340.01248]
 [363.20074]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.472426414489746
desired expected reward: 354.659423828125



buy possibilites: [-1] 
expected returns: [[332.54385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -9.080214500427246
desired expected reward: 338.1688232421875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.68027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.612611770629883
desired expected reward: 322.9312438964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[304.69843]
 [313.17157]
 [300.08734]
 [309.71216]
 [294.42416]
 [288.62552]
 [308.37073]
 [318.37686]
 [311.1128 ]
 [325.88004]
 [313.80115]
 [296.92087]
 [302.83615]
 [308.35397]
 [293.24997]
 [306.47833]
 [323.4077 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.83038330078125
desired expected reward: 307.37322998046875



buy possibilites: [-1] 
expected returns: [[297.81857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -8.23469352722168
desired expected reward: 301.4775390625






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [ 0.  0.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.3224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 0. 1. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.014092445373535
desired expected reward: 290.8044738769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[301.06967]
 [310.11456]
 [278.14236]
 [310.11148]
 [330.127  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 0. 1. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.950576782226562
desired expected reward: 321.13104248046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.2044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -9.251867294311523
desired expected reward: 320.8751525878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[272.86624]
 [281.87057]
 [277.98682]
 [256.18887]
 [276.80215]
 [286.64957]
 [279.77322]
 [282.22208]
 [264.43033]
 [276.44223]
 [274.2002 ]
 [290.40863]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.321135520935059
desired expected reward: 294.1003723144531



buy possibilites: [-1] 
expected returns: [[310.54834]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 16.0
Learning step: -4.802770137786865
desired expected reward: 271.9993896484375






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 0.  3.  0.  0. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0. 15.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0. 15.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0. 15.  3. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 1. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.6493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.799149513244629
desired expected reward: 302.7491760253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[323.21082]
 [336.64883]
 [332.5419 ]
 [298.24347]
 [329.44565]
 [345.33206]
 [333.1055 ]
 [336.99872]
 [311.11682]
 [329.94473]
 [326.42096]
 [352.7253 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.707894325256348
desired expected reward: 335.992919921875



buy possibilites: [-1] 
expected returns: [[346.74033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: -8.225439071655273
desired expected reward: 324.31646728515625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[341.11108]
 [319.73093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 15.  3.  0.  3.] 
adversary cards in discard: [ 6. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -8.814998626708984
desired expected reward: 337.9253234863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[308.80365]
 [316.054  ]
 [288.70184]
 [316.7658 ]
 [333.41205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 15.  3.  0.  3.] 
adversary cards in discard: [ 6. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -8.37559700012207
desired expected reward: 323.6355895996094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11. 15.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  0.  3.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[299.05676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0.  3. 16.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -8.977523803710938
desired expected reward: 324.43450927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[280.14398]
 [293.1611 ]
 [287.8802 ]
 [264.06894]
 [255.40976]
 [285.9065 ]
 [300.18567]
 [290.06693]
 [311.41107]
 [293.38684]
 [267.5984 ]
 [276.8317 ]
 [285.56567]
 [262.2486 ]
 [282.1615 ]
 [305.54138]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0.  3. 16.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -7.235969066619873
desired expected reward: 290.234130859375



buy possibilites: [-1] 
expected returns: [[325.18384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 0.  3. 16.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  0.  3.  0.] 
adversary cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 70 

action type: buy - action 25.0
Learning step: -4.753914833068848
desired expected reward: 306.6571044921875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  3.  0.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 6. 29. 11.  0.  0.  0.  0.  8. 15. 11.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [25.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[313.5296 ]
 [315.48758]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -8.089813232421875
desired expected reward: 317.0940246582031



action possibilites: [-1] 
expected returns: [[219.12088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action 25.0
Learning step: -9.03087329864502
desired expected reward: 310.19097900390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[209.78658]
 [218.19978]
 [187.91026]
 [218.68318]
 [235.6945 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -3.942786455154419
desired expected reward: 215.1781005859375



buy possibilites: [-1] 
expected returns: [[253.99731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0.  3. 16.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11. 11.  0. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 59 

action type: buy - action 3.0
Learning step: -2.2450501918792725
desired expected reward: 215.95472717285156






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [11. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  7.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [ 6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  6.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [ 6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  6.  9.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [ 6. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[251.78027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -4.9862565994262695
desired expected reward: 249.0110626220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[230.96492]
 [239.54807]
 [237.03137]
 [212.47383]
 [234.91322]
 [245.47318]
 [237.30302]
 [239.96194]
 [222.8244 ]
 [235.48195]
 [233.38261]
 [250.75655]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -5.104709625244141
desired expected reward: 246.6112518310547



buy possibilites: [-1] 
expected returns: [[178.65195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3. 25.  3.  3.  0.  0.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  0.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: -6.978578090667725
desired expected reward: 223.98635864257812






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  3.  0.] 
cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[206.24313]
 [207.32822]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -2.7337987422943115
desired expected reward: 175.91815185546875



action possibilites: [-1] 
expected returns: [[255.58145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 54 

action type: take_action - action 25.0
Learning step: -1.8939026594161987
desired expected reward: 204.9958038330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[235.68338]
 [246.94826]
 [230.74344]
 [243.43753]
 [222.66771]
 [216.31409]
 [240.77647]
 [254.69482]
 [243.84535]
 [263.8052 ]
 [247.31047]
 [225.83728]
 [234.24356]
 [241.29701]
 [221.7648 ]
 [238.43765]
 [261.7048 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  9.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1
Learning step: -4.620596408843994
desired expected reward: 250.9608612060547



buy possibilites: [-1] 
expected returns: [[224.68958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 1.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5.   0.   6.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 63.5 

action type: buy - action 25.0
Learning step: -4.959744453430176
desired expected reward: 258.8454284667969






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  6.] 
cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25] -> size -> 18 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  6.] 
cards in discard: [ 6. 11.  8. 11. 11.  0. 11.  0.  3.  0.  8. 29.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25] -> size -> 18 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[175.6712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -5.338078498840332
desired expected reward: 219.35150146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[155.1619 ]
 [161.50615]
 [138.295  ]
 [161.98734]
 [177.25804]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -2.630460739135742
desired expected reward: 165.81103515625



buy possibilites: [-1] 
expected returns: [[197.27362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: -2.769437789916992
desired expected reward: 152.39244079589844






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [29.  6.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3. 15.  0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[238.80754]
 [222.10864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  8.  3.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -2.6274147033691406
desired expected reward: 194.64620971679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.3045 ]
 [225.06885]
 [198.22702]
 [226.35243]
 [238.63521]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  7.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  8.  3.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -4.569082736968994
desired expected reward: 230.55894470214844



buy possibilites: [-1] 
expected returns: [[269.64206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [25. 25.  3.  0.  0.  0.  0.  1.  0.  0.  3.  0.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  8.  3.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -270.0 

action type: buy - action 6.0
Learning step: -17.344404220581055
desired expected reward: 180.88259887695312






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  8.  3.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  3.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  3.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[158.462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -8.401928901672363
desired expected reward: 261.2401428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[137.047  ]
 [145.85701]
 [142.95401]
 [120.3282 ]
 [151.79276]
 [143.6886 ]
 [141.50458]
 [156.91415]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -3.1183106899261475
desired expected reward: 156.0005340576172



buy possibilites: [-1] 
expected returns: [[153.69014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 48 

action type: buy - action 10.0
Learning step: -1.2172008752822876
desired expected reward: 140.28738403320312






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10] -> size -> 21 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  6.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10] -> size -> 21 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10] -> size -> 21 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[209.7077 ]
 [188.17596]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [10.  3.  0.  3.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -1.7394676208496094
desired expected reward: 151.95066833496094



action possibilites: [-1] 
expected returns: [[255.31021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 65 

action type: gain_card_n - action 1
Learning step: 1.7248947620391846
desired expected reward: 147.11659240722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[241.11705]
 [249.00659]
 [222.24925]
 [248.50008]
 [266.80145]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  6.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1
Learning step: -3.9973487854003906
desired expected reward: 251.3128662109375



buy possibilites: [-1] 
expected returns: [[217.05312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -250.0 

action type: buy - action 6.0
Learning step: -18.728769302368164
desired expected reward: 203.52047729492188






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  6.  6.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  8.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  6.] 
cards in discard: [ 0. 29.  6.  3. 15.  0.  1.  0. 11.  0. 11.  8.  3. 11.  3.  0.  0. 15.
  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[131.37918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -6.396624565124512
desired expected reward: 210.656494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[101.83956 ]
 [112.50678 ]
 [109.279396]
 [ 82.71016 ]
 [120.42464 ]
 [109.320045]
 [106.97935 ]
 [127.710396]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 11.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -2.448164701461792
desired expected reward: 128.93101501464844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [11. 11.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  3.  3.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[140.9968 ]
 [141.42508]
 [141.42508]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0. 25.] 
cards in discard: [10.  3.  0.  3.  1.  3.  3.  6. 16.  3.  0.  0.  3.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  5.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  6.  6.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1.0
Learning step: -1.3833976984024048
desired expected reward: 119.8875961303711



action possibilites: [-1] 
expected returns: [[77.93773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  6.  6.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 51 

action type: take_action - action 25.0
Learning step: -2.76765513420105
desired expected reward: 138.6574249267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.00086 ]
 [66.78478 ]
 [65.326996]
 [50.56657 ]
 [71.55153 ]
 [65.18858 ]
 [64.212685]
 [76.06292 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 24. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  6.  6.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: 0.16750220954418182
desired expected reward: 78.10523223876953



buy possibilites: [-1] 
expected returns: [[101.0798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25. 10.  0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [29.  3.  6.  6.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 40.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 63.0 

action type: buy - action 3.0
Learning step: 2.1579456329345703
desired expected reward: 67.48493957519531






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [29.  3.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  6.  0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  6.  0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[109.17968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -0.04744720458984375
desired expected reward: 101.03235626220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 87.84053 ]
 [ 95.98583 ]
 [ 94.68355 ]
 [ 77.4269  ]
 [ 70.413795]
 [ 91.62599 ]
 [102.99715 ]
 [ 93.398735]
 [108.59034 ]
 [ 96.31434 ]
 [ 81.70829 ]
 [ 88.17289 ]
 [ 92.88911 ]
 [ 78.898   ]
 [ 90.8921  ]
 [109.89771 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 15.  8.  0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -0.6846233606338501
desired expected reward: 108.49505615234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8.  0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0
  1  0 11  8  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [3. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[159.1214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 1.1353458166122437
desired expected reward: 111.0330581665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.22864 ]
 [124.054276]
 [161.74092 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: -1.5312271118164062
desired expected reward: 157.59017944335938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  6.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  7.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  6.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  3.  6.] 
adversary cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[124.99426]
 [112.71722]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.  6.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0  6 10  3  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: -2.3069024085998535
desired expected reward: 159.43402099609375



action possibilites: [-1] 
expected returns: [[91.93713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 107 

action type: gain_card_n - action 1
Learning step: 4.100988864898682
desired expected reward: 70.45291900634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.70374 ]
 [63.014412]
 [91.086205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3. 25.  0.  3.  0. 25. 10.  0.  0.  0.  1.  3.  0.  3.  3.  3.  6.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6  8] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 103 

action type: take_action - action -1
Learning step: 2.408555746078491
desired expected reward: 94.34568786621094






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 15.  6.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0
 11  8  0  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  5.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6.] 
cards in discard: [ 0. 11. 11.  8.  3.  3.  6. 29.  3.  6.  6.  0.  8. 15.  0.  8.  0.  1.
  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [6. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[107.63948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  6. 11. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 83 

action type: buy - action -1.0
Learning step: 1.910838007926941
desired expected reward: 92.99703979492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 90.498955]
 [ 99.47845 ]
 [ 96.71015 ]
 [ 74.73678 ]
 [105.835976]
 [ 97.12495 ]
 [ 95.04501 ]
 [111.629166]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  6. 11. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 83 

action type: take_action - action -1.0
Learning step: 1.3126477003097534
desired expected reward: 104.2081298828125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11. 11. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  4.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  3. 16.] 
adversary cards in discard: [6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11. 11.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  3. 16.] 
adversary cards in discard: [6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11. 11.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  3. 16.] 
adversary cards in discard: [6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11. 11.] 
cards in discard: [6. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  3. 16.] 
adversary cards in discard: [6. 1. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[107.24016]
 [ 93.79092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 16.] 
cards in discard: [6. 1. 0. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 15. 11. 11.  3.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1.0
Learning step: 1.3913662433624268
desired expected reward: 113.02055358886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.97398]
 [ 80.79195]
 [107.31297]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 16.] 
cards in discard: [6. 1. 0. 3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 15. 11. 11.  3.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: take_action - action -1.0
Learning step: 1.455457329750061
desired expected reward: 109.80967712402344



buy possibilites: [-1] 
expected returns: [[73.47116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  3. 16.] 
cards in discard: [6. 1. 0. 3. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11. 15. 11. 11.  3.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 63.0 

action type: buy - action 0.0
Learning step: 0.2544017732143402
desired expected reward: 91.2283935546875






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11. 15. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 11.  3.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  3.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  3.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  3.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.69083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1
Learning step: 3.4669854640960693
desired expected reward: 76.93814849853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.91006 ]
 [ 96.61854 ]
 [ 95.01151 ]
 [ 77.167175]
 [101.525536]
 [ 94.74373 ]
 [ 93.69067 ]
 [105.97877 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: take_action - action -1.0
Learning step: 1.343953013420105
desired expected reward: 112.03478240966797



buy possibilites: [-1] 
expected returns: [[135.56682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 63.0 

action type: buy - action 0.0
Learning step: 1.704749345779419
desired expected reward: 91.61482238769531






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [25. 10.  0. 25.  3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [25. 10.  0. 25.  3.] 
adversary cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 10.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[143.05302]
 [144.3227 ]
 [127.81862]
 [144.3227 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 25.  3.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.  0.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1
Learning step: 1.0593986511230469
desired expected reward: 136.626220703125



action possibilites: [-1. 25. 25.] 
expected returns: [[110.513565]
 [112.08282 ]
 [112.08282 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  3.  0.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  3.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 114 

action type: take_action - action 10.0
Learning step: 1.8239258527755737
desired expected reward: 129.64254760742188



action possibilites: [-1. 25.] 
expected returns: [[135.08992]
 [137.69463]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.  3.] 
cards in discard: [ 6.  1.  0.  3.  3.  0.  0.  3.  3.  3. 16.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  2.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0  6] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 40  0  0  0  0  0  0  0  0  1] 
sum of rewards: 134 

action type: take_action - action 25.0
Learning step: 4.176541805267334
desired expected reward: 116.2593765258789



action possibilites: [-1] 
expected returns: [[141.03688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0  6  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 153 

action type: take_action - action 25.0
Learning step: 3.9385972023010254
desired expected reward: 141.63323974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[121.973755]
 [130.74034 ]
 [129.72578 ]
 [111.5841  ]
 [139.19968 ]
 [127.93965 ]
 [127.93988 ]
 [148.02696 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  4.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0  6  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 153 

action type: take_action - action -1
Learning step: 3.6824822425842285
desired expected reward: 144.7193603515625



buy possibilites: [-1] 
expected returns: [[78.04922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 6. 3.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 25. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0  6  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 60  0  0  0  0  0  0  0 18  0] 
sum of rewards: 171 

action type: buy - action 11.0
Learning step: 3.346123456954956
desired expected reward: 142.54580688476562






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15 11 11  0 15  3  6 29  8 11  6 11  8  3  6  0  1  0 11
  8  0  6  8 11  6  0  0  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -3 





Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.31616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 15.  1.  3.  0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1
Learning step: 4.432152271270752
desired expected reward: 82.48136901855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.68801]
 [108.3071 ]
 [ 83.37487]
 [107.2636 ]
 [124.26174]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 15.  1.  3.  0.] 
adversary cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: take_action - action -1.0
Learning step: 2.2191054821014404
desired expected reward: 121.53527069091797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  1.  3.  0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  0. 16.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  1.  3.  0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  0. 16.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  1.  3.  0.] 
cards in discard: [ 6.  0. 11.  6.  6. 11. 11.  0. 15. 11. 11. 11.  3.  6.  3.  3.  0.  0.
  6.  6.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 21. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  0. 16.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: -2 





Player: 0 
cards in hand: [ 0.  1.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[100.32157]
 [ 92.01463]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 16.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: buy - action -1.0
Learning step: 1.1385109424591064
desired expected reward: 125.40026092529297



action possibilites: [-1] 
expected returns: [[30.936903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 138 

action type: gain_card_n - action 1
Learning step: 4.6912713050842285
desired expected reward: 62.787445068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.808891]
 [23.901577]
 [22.486355]
 [10.517322]
 [27.532011]
 [22.268465]
 [21.224657]
 [30.950193]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 20. 30.  8.  1.  9.  3.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 134 

action type: take_action - action -1
Learning step: 5.732472896575928
desired expected reward: 36.669376373291016



buy possibilites: [-1] 
expected returns: [[76.2804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 110   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 152 

action type: buy - action 11.0
Learning step: 7.939708232879639
desired expected reward: 35.47171401977539






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 20. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.
 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 20. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.
 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.
 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.55912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.
 16.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  6.  6. 15.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3  3] -> size -> 33 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1
Learning step: 2.838560104370117
desired expected reward: 79.11896514892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.890137]
 [63.951424]
 [62.889282]
 [55.141125]
 [65.74904 ]
 [63.161926]
 [62.29177 ]
 [66.42307 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11. 10. 25. 25.  0.  3.  0.  0.  3.  6.  3.  3.  0.  3.  0.  3.  3. 11.
 16.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3.  6.  6. 15.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.] 
adversary owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3  3] -> size -> 33 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 3.4148457050323486
desired expected reward: 67.97396850585938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  6. 15.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6
  8 11  6  0  0  6  6  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  6.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  1.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [16.  1.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[38.484756]
 [32.494396]
 [33.079147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11. 11.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8] -> size -> 33 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 2.6938693523406982
desired expected reward: 69.116943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.527948]
 [33.730133]
 [33.397984]
 [27.851171]
 [36.14004 ]
 [33.007565]
 [33.053524]
 [38.83717 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 19. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11. 11.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8] -> size -> 33 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 4.0773444175720215
desired expected reward: 42.562103271484375



buy possibilites: [-1] 
expected returns: [[38.954094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0. 10.  3.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 11. 11.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8] -> size -> 33 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 122 

action type: buy - action 1.0
Learning step: 5.2899603843688965
desired expected reward: 39.02009201049805






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8. 11. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  3. 11.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 19. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 11.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 11.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 11.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [3. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.697405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0] -> size -> 35 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1
Learning step: 3.465487003326416
desired expected reward: 42.41958236694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.395868]
 [16.660551]
 [32.065247]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0] -> size -> 35 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 3.724640369415283
desired expected reward: 35.42204666137695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.189293]
 [36.917946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 15.  3.  6.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 3.979086399078369
desired expected reward: 36.04433059692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.146517]
 [36.167408]
 [34.846474]
 [23.902279]
 [39.418015]
 [34.74188 ]
 [33.76543 ]
 [43.685932]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 15.  3.  6.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29] -> size -> 36 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 3.5532233715057373
desired expected reward: 43.742523193359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 15.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  3.  6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 25. 25.  3.  3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 25. 25.  3.  3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 25. 25.  3.  3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 6. 25. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[58.62665]
 [61.22545]
 [61.22545]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 25.  3.  3.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  1.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10] -> size -> 37 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 3.881671905517578
desired expected reward: 47.56760787963867



action possibilites: [-1] 
expected returns: [[93.6347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  3.  3.  0. 11.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 4.795508861541748
desired expected reward: 66.02094268798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.944984]
 [94.88531 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  3.  3.  0. 11.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 114 

action type: take_action - action -1
Learning step: 3.0062367916107178
desired expected reward: 96.64093017578125






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0. 25.  6.
 25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0. 25.  6.
 25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8.  8. 29.  8. 15.  3.  6.  6.  3.  0. 11.  8. 11.  3. 11.
 29. 11.  0.  0. 11.  1. 10. 11.  0. 15.  3.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0. 25.  6.
 25.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[169.28935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0. 25.  6.
 25.  3.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 4.26474666595459
desired expected reward: 99.1500244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[156.98422]
 [162.82336]
 [160.96466]
 [167.00287]
 [161.09964]
 [159.82762]
 [170.9155 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1. 16.  1.  0. 10.  3.  3.  3.  3.  0.  3.  0.  3. 11.  0.  0. 25.  6.
 25.  3.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [11. 11.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 0.12848739326000214
desired expected reward: 176.29721069335938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.21411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 15.  3.] 
adversary cards in discard: [11. 11.  0.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: -2.373455762863159
desired expected reward: 168.54200744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[36.19509 ]
 [39.282967]
 [38.37167 ]
 [32.417282]
 [37.559807]
 [41.74966 ]
 [38.499622]
 [44.076008]
 [39.771503]
 [33.652294]
 [35.970184]
 [37.926514]
 [32.18338 ]
 [37.420185]
 [44.519054]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 15.  3.] 
adversary cards in discard: [11. 11.  0.  6.  6.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 3.9532876014709473
desired expected reward: 47.16740036010742



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 15.  3.] 
cards in discard: [11. 11.  0.  6.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  1.] 
adversary cards in discard: [3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 15.  3.] 
cards in discard: [11. 11.  0.  6.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  1.] 
adversary cards in discard: [3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
adversary victory points: 9
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[93.69832]
 [93.17701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  1.] 
cards in discard: [3. 0. 0. 1. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 5.078768253326416
desired expected reward: 49.597808837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[85.52776 ]
 [89.51245 ]
 [87.585075]
 [87.096565]
 [91.70591 ]
 [88.75341 ]
 [89.84498 ]
 [84.32459 ]
 [87.13278 ]
 [86.30405 ]
 [93.0824  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3.  1.] 
cards in discard: [3. 0. 0. 1. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 2.5448529720306396
desired expected reward: 96.24317932128906



buy possibilites: [-1] 
expected returns: [[18.772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3.  1.] 
cards in discard: [3. 0. 0. 1. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5.   0.   9. 100.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 74.0 

action type: buy - action 0.0
Learning step: -0.15401802957057953
desired expected reward: 85.37374877929688






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.508045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  6.  8. 29.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 40 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1
Learning step: 4.925331115722656
desired expected reward: 23.697330474853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[16.721014]
 [19.826153]
 [18.713001]
 [30.703503]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  3.  6.  8. 29.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 40 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 4.292022228240967
desired expected reward: 33.80006790161133



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  8. 29.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3  6 29 11  6 11  8  3  6  0  1  0 11  8  0  6  8
 11  6  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25. 11. 16.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25. 11. 16.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25. 11. 16.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [25. 11. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 16.] 
expected returns: [[81.56463]
 [84.13221]
 [77.64838]
 [68.07832]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 16.  3.  3.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10.  0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 4.973726749420166
desired expected reward: 35.67723846435547



action possibilites: [-1] 
expected returns: [[75.38198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3.  3. 11. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10.  0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 114 

action type: take_action - action 25.0
Learning step: 3.1894824504852295
desired expected reward: 87.32172393798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[63.37691 ]
 [76.084175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  3.  3. 11. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 10.  0.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 114 

action type: take_action - action -1
Learning step: 3.5576863288879395
desired expected reward: 78.93966674804688






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10.  0.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6. 25. 11.
 16.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 11.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6. 25. 11.
 16.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  0. 11.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6. 25. 11.
 16.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[95.451256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6. 25. 11.
 16.  3.  3. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  6.  6. 11. 15.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 3.043444871902466
desired expected reward: 79.12760925292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[85.47127]
 [95.50649]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  0.  1.  0.  0.  0.  0. 25.  3.  1.  0.  3.  3.  0.  6. 25. 11.
 16.  3.  3. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  6.  6. 11. 15.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 2.0091207027435303
desired expected reward: 97.46037292480469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [11.  6.  6. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6. 11. 15.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  6. 11. 15.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[24.695393]
 [23.40692 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 29. 11.  1.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 0.47169265151023865
desired expected reward: 95.9781723022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[20.658941]
 [21.860136]
 [21.936811]
 [23.758226]
 [21.597994]
 [21.962393]
 [25.604944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 29. 11.  1.] 
adversary cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.] 
adversary owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 3.999519109725952
desired expected reward: 28.694917678833008



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29. 11.  1.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11 11  0 15  3 11  6 11  8  3  6  0  1  0 11  8  0  6  8 11  6
  0  0  6  6  3  3  8  3  0 29 10  6  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [11. 11.  0.  6.  6.  3.  0.  6. 15.  3. 10.  0.  0.  3.  0.  0.  8.  3.
  3. 10.  8.  6.  0.  0. 11. 11.  6.  6. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0.  1.] 
adversary cards in discard: [ 0.  0. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [10.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.0313  ]
 [21.463745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  1.] 
cards in discard: [ 0.  0. 25.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0] -> size -> 36 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 4.4590630531311035
desired expected reward: 30.064008712768555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[21.220984]
 [21.8113  ]
 [22.088863]
 [22.955088]
 [21.641703]
 [22.064297]
 [24.407068]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  1.] 
cards in discard: [ 0.  0. 25.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0] -> size -> 36 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 4.378161430358887
desired expected reward: 31.237041473388672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [11.  0.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  2.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25.  6.  3.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25.  6.  3.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25.  6.  3.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [11.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [25.  6.  3.  3.  3.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [25.  6.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[70.4167  ]
 [69.277245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  3.  3.  3.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 5.556390285491943
desired expected reward: 29.963462829589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[56.473885]
 [71.11129 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  3.  3.  3.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 3.1811330318450928
desired expected reward: 73.59783935546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [11.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 10.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  5.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[43.640926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 2.6263558864593506
desired expected reward: 73.73765563964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[37.349846]
 [40.28291 ]
 [39.59605 ]
 [38.720074]
 [42.40959 ]
 [39.45265 ]
 [40.36164 ]
 [34.86062 ]
 [38.99716 ]
 [38.250343]
 [44.723717]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 30. 18. 30.  8.  0.  9.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 3.95487904548645
desired expected reward: 47.59580612182617



buy possibilites: [-1] 
expected returns: [[32.839172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 136 

action type: buy - action 16.0
Learning step: 5.602878093719482
desired expected reward: 44.32295227050781






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  8.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  4.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1.  3.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [ 1.  3.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.321325]
 [19.949339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3.  3. 11.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  8.  3. 11.  6.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1
Learning step: 4.0285820960998535
desired expected reward: 36.86775588989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.988302]
 [19.65506 ]
 [20.135622]
 [24.228304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3.  3. 11.] 
cards in discard: [ 0.  0. 25.  3.  0. 10.  3.  3.  0.  1. 25.  6.  3.  3.  3. 16.  0.  3.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  8.  3. 11.  6.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: take_action - action -1.0
Learning step: 4.629153728485107
desired expected reward: 25.950471878051758



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [11.  8.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 11.  6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  1.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 16.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 16.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 16.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 16.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [ 3. 16.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[37.989407]
 [23.560423]
 [32.049236]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0
 11  3 11  1  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15. 15.  0.  8.  6.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 43 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 4.752397060394287
desired expected reward: 28.980688095092773



action possibilites: [-1] 
expected returns: [[54.83578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15. 15.  0.  8.  6.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 43 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 94 

action type: gain_card_n - action 0
Learning step: 5.2742109298706055
desired expected reward: 18.466096878051758





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[48.67305]
 [58.54083]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [15. 15.  0.  8.  6.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
adversary owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 43 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: take_action - action -1
Learning step: 4.709289073944092
desired expected reward: 59.54507064819336






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [15. 15.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  8.  6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 11 11  0 15  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0
  6  6  3  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.39305 ]
 [26.762512]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.  1.] 
cards in discard: [ 0. 16.  3. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  8.  3.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
adversary owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 104 

action type: buy - action -1.0
Learning step: 2.885078191757202
desired expected reward: 61.42592239379883



action possibilites: [-1] 
expected returns: [[54.307896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  8.  3.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
adversary owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 6.133801460266113
desired expected reward: 32.89632797241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.362743]
 [49.721462]
 [48.38864 ]
 [46.85951 ]
 [48.211792]
 [49.878593]
 [39.767593]
 [47.297024]
 [45.951054]
 [57.81669 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  8.  3.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
adversary owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 124 

action type: take_action - action -1
Learning step: 4.651646614074707
desired expected reward: 58.95954132080078



buy possibilites: [-1] 
expected returns: [[51.641342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  8.  3.  0. 10.] 
adversary cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
adversary owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   9 100   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 156 

action type: buy - action 15.0
Learning step: 6.4434027671813965
desired expected reward: 56.81394577026367






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3.  0. 10.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11 11  3 11  6 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3
  3  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  0. 11.  0.  6.  3.  8.  8. 10. 11.  0.  6.  0.  0. 16.  8. 11.  0.
  0.  3. 11. 11.  0. 11.  8.  3. 11.  6.  0.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 25.  0.  3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[34.253647]
 [30.541227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  0.  3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1
Learning step: 2.8637757301330566
desired expected reward: 54.50511932373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.357561]
 [24.6342  ]
 [23.907942]
 [36.100533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 25.  0.  3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 3.674327850341797
desired expected reward: 37.927978515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [10. 11.  3.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [10. 11.  3.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 6.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [10. 11.  3.  3.  1.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [10. 11.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-12.5663595]
 [-12.743646 ]
 [-13.506491 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.  1.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [0. 3. 6. 3. 3. 6.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0] -> size -> 41 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: buy - action -1.0
Learning step: 2.60724139213562
desired expected reward: 38.707767486572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-12.55229 ]
 [-12.472892]
 [-13.03678 ]
 [-11.542017]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  1.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [0. 3. 6. 3. 3. 6.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0] -> size -> 41 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[-5  0  9 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 94 

action type: take_action - action -1.0
Learning step: 5.057116508483887
desired expected reward: -7.509243965148926



buy possibilites: [-1] 
expected returns: [[27.281397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  1.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [16. 11.  0.  0. 11.] 
adversary cards in discard: [0. 3. 6. 3. 3. 6.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0] -> size -> 41 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5.   0.   9.  90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 64.0 

action type: buy - action 0.0
Learning step: 4.441445827484131
desired expected reward: -8.110843658447266






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [16. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0. 11.] 
cards in discard: [0. 3. 6. 3. 3. 6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [0. 3. 6. 3. 3. 6. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [0. 3. 6. 3. 3. 6. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 18. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [0. 3. 6. 3. 3. 6. 0. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.463425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-5  0  9 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: buy - action -1
Learning step: 4.218857288360596
desired expected reward: 31.500253677368164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[51.661297]
 [55.062157]
 [53.91657 ]
 [54.27475 ]
 [53.324993]
 [58.453148]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-5  0  9 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: take_action - action -1.0
Learning step: 2.388385772705078
desired expected reward: 63.851810455322266



buy possibilites: [-1] 
expected returns: [[0.17430115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  3. 11.  0. 15. 25.  0.  3.  3.  1.  0.  3.  6.  0. 25.  0.  3.
  0. 10. 11.  3.  3.  1. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-5  0  9 80  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 102 

action type: buy - action 10.0
Learning step: 2.4376726150512695
desired expected reward: 55.762657165527344






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0 10] -> size -> 33 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [15. 11.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0 10] -> size -> 33 
adversary victory points: 9
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 11.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16.] 
expected returns: [[40.12544 ]
 [27.788427]
 [36.41916 ]
 [29.357634]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11
  3 11  1  0 16  0 15  0 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 17. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-5  0  9 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 84 

action type: buy - action -1
Learning step: 5.004322052001953
desired expected reward: 5.178623199462891



action possibilites: [-1] 
expected returns: [[27.83577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 119 

action type: gain_card_n - action 1
Learning step: 6.960859775543213
desired expected reward: -0.7302393913269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.628016]
 [30.90037 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 4.9846696853637695
desired expected reward: 32.820438385009766






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [16.  0.  3. 25. 11.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [16.  0.  3. 25. 11.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
adversary victory points: 10
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  0.  3. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 11.] 
expected returns: [[-3.1304102]
 [-2.5535312]
 [-1.0219749]
 [-1.8942118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3. 25. 11.] 
cards in discard: [ 3. 16. 15. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: buy - action -1.0
Learning step: 3.1668763160705566
desired expected reward: 34.06725311279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.3949347]
 [-6.109585 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 25. 11.] 
cards in discard: [ 3. 16. 15. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 4.780348300933838
desired expected reward: 1.6499285697937012



buy possibilites: [-1] 
expected returns: [[31.264757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3. 25. 11.] 
cards in discard: [ 3. 16. 15. 11.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
adversary owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5.   0.  10.  90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 65.0 

action type: buy - action 0.0
Learning step: 3.937548875808716
desired expected reward: 4.255707740783691






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  6.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 11  3 11 11  8  3  6  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3
  8  3  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  3.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  3.  6.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[4.1002903]
 [0.6093614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  6.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8. 11.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 2.7556378841400146
desired expected reward: 34.02039337158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.2745667]
 [ 4.766468 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  6.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8. 11.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 4.105072498321533
desired expected reward: 8.205366134643555



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8. 11.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  8. 11.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [3. 1. 0. 1. 0.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.5158854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 1. 0.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8.  0.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.] 
adversary owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 4.113283634185791
desired expected reward: 8.879762649536133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.74684167]
 [ 2.7170856 ]
 [ 0.4622929 ]
 [ 2.7575958 ]
 [-0.77247286]
 [ 1.7668259 ]
 [ 2.217646  ]
 [ 5.992648  ]
 [ 2.7989247 ]
 [-0.08564401]
 [ 0.8889291 ]
 [ 2.3126895 ]
 [-0.5796261 ]
 [ 1.7138097 ]
 [ 6.193449  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1. 0.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 11.  8.  8.  0.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.] 
adversary owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 4.106610298156738
desired expected reward: 8.622495651245117



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  8.  0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 11 11  8  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3
  0 10  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[47.610054]
 [41.306858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 10.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10.  6.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.  8. 11.  0.] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: buy - action -1.0
Learning step: 5.469336986541748
desired expected reward: 11.662784576416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.72171]
 [46.68456]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 10.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 10.  6.] 
adversary cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.  8. 11.  0.] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 3.3665688037872314
desired expected reward: 50.97660446166992



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 10.  6.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.  8. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 10.  6.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.  8. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 10.  6.] 
cards in discard: [ 0.  3.  6.  3.  3.  6.  0.  3. 11. 16.  0.  0. 11.  0.  6.  0.  0. 10.
 11.  0.  3.  8.  3.  8.  8.  0.  0.  0.  8. 11.  8. 11.  8. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-12.210898]
 [-11.974983]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: buy - action -1.0
Learning step: 2.1447560787200928
desired expected reward: 48.82929611206055



action possibilites: [-1] 
expected returns: [[22.857985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 3.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 6.863053798675537
desired expected reward: -5.11193323135376





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.122947]
 [15.611226]
 [15.466565]
 [14.134782]
 [14.704562]
 [16.037777]
 [11.367215]
 [14.8184  ]
 [14.170272]
 [23.642052]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 3.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-5  0 10 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 5.027404308319092
desired expected reward: 27.88538932800293



buy possibilites: [-1] 
expected returns: [[25.171946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 3.] 
cards in discard: [ 3. 16. 15. 11.  3.  0. 16.  0.  3. 25. 11.  0.  3. 10.  3.  6.  3.  1.
  0.  1.  0.  3.  3.  3.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5.   0.  10.  90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 85.0 

action type: buy - action 0.0
Learning step: 4.160222053527832
desired expected reward: 17.283164978027344






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0  0 11  8  0  6  8 11  6  0  0  6  6  3  3  8  3  0 10
  6  0 10  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[48.963436]
 [42.49387 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 11. 16.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 4.049749374389648
desired expected reward: 29.221694946289062



action possibilites: [-1.] 
expected returns: [[21.972794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 11. 16.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 3.619694471359253
desired expected reward: 46.113563537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.596223]
 [22.629278]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 11. 16.  6.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 4.613414287567139
desired expected reward: 26.58620834350586






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 11. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 16.  6.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 16.  6.] 
cards in discard: [8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 16.  6.] 
cards in discard: [8. 0. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
adversary victory points: 10
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[35.23631 ]
 [32.495735]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [10.  3.  3.  3.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 3.8929977416992188
desired expected reward: 26.522274017333984



action possibilites: [-1] 
expected returns: [[33.079365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 113 

action type: gain_card_n - action 7
Learning step: 5.015929698944092
desired expected reward: 32.58304977416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[20.956478]
 [23.366919]
 [22.199036]
 [30.86046 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  2.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 4.203125953674316
desired expected reward: 37.28248977661133



buy possibilites: [-1] 
expected returns: [[18.621065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0 20  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 4.8590216636657715
desired expected reward: 27.05806541442871






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 16.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 16.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 25.  0. 16.  0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[38.813007]
 [37.38077 ]
 [28.155897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 16.  0.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0. 10.  3.  8.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 4.138259410858154
desired expected reward: 22.75932502746582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[25.092104]
 [31.175379]
 [29.649603]
 [29.503275]
 [28.407063]
 [36.98747 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 16.  0.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0. 10.  3.  8.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 3.049787998199463
desired expected reward: 41.86280059814453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [11.  0. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3.  8.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3.  8.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3.  8.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
adversary victory points: 10
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.697004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 2.8213088512420654
desired expected reward: 39.808780670166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.650573]
 [14.867205]
 [14.127699]
 [13.792511]
 [14.460209]
 [14.753986]
 [ 9.916018]
 [13.779547]
 [12.996771]
 [16.551323]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  7.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 3.6505603790283203
desired expected reward: 22.347564697265625



buy possibilites: [-1] 
expected returns: [[14.321638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.
 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[-5  0 10 80  0  0  0  0  0  0  0 -3  0  0 32  0] 
sum of rewards: 114 

action type: buy - action 15.0
Learning step: 5.372398376464844
desired expected reward: 18.36916732788086






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  6.] 
adversary cards in hand: [25.  0. 10.  3.  3.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.
 15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8 15] -> size -> 38 
adversary victory points: 10
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 11.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  1.  8.  8. 10. 10.  5. 10.  6.] 
adversary cards in hand: [25.  0. 10.  3.  3.] 
adversary cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.
 15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8 15] -> size -> 38 
adversary victory points: 10
player victory points: 2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 2 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 2 

Remodel: 2 
Workshop: 2 
Chapel: 1 
Witch: 2 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  0. 10.  3.  3.] 
cards in discard: [10.  3.  3.  3.  0.  6. 10.  8. 11.  0.  3.  0.  3.  0. 25.  0. 16.  0.
 15.  0.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1  3 16  3 25  3  0 25  0 10  3  6  3  3  0  0 11  3
 11  1  0 16  0 15  0 10  3  0  0 10  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 30.  8.  0.  7.  0.  0.  8.  8. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 11. 16.  6.  0.  0.  0. 11.  0.  0.  0. 11.  0. 10.
  3.  8.  8.] 
adversary owned cards: [11  3 11 11  3  0 11  0  8 11  6  0  0  6  6  3  3  8  3  0 10  6  0 10
  0 11  0  8 16  8 11  0  0  0  0  3  8  0  0  0  0  8] -> size -> 42 
adversary victory points: 2
player victory points: 10 

Reward from previous game state: 
[ -5 500  10  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 585 

action type: buy - action -1
Learning step: 28.533918380737305
desired expected reward: 42.85555648803711



